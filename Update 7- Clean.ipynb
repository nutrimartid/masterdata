{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbad2c91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data SKU\n",
      "Scrapping Tatanama\n",
      "ok\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3984\\321549261.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SKU_File\\Master tatanama.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mSKU_append\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SKU_File\\Master tatanama.xlsx'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'openpyxl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mSKU_append\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mSKU_append\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mdata_SKU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_SKU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mdata_SKU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SKU'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSKU_append\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SKU'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mdata_SKU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_SKU\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSKU_append\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mdata_SKU\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_SKU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Price List NFI'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Price List NFI'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mto_excel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_SKU\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SKU_File\\data_SKU.xlsx'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5985\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5986\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5987\u001b[0m         ):\n\u001b[0;32m   5988\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5989\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "## run-1\n",
    "## download data sku dari tatanama\n",
    "## common problems: slow server pyany & make sure path to file\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import smtplib\n",
    "\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from smtplib import SMTP\n",
    "import smtplib\n",
    "import sys\n",
    "import requests\n",
    "import os\n",
    "\n",
    "\n",
    "print('Reading Data SKU')\n",
    "data_SKU = pd.read_excel('SKU_File\\data_SKU.xlsx')\n",
    "print('Scrapping Tatanama')\n",
    "s = requests.Session()\n",
    "s.get(\"https://tatanama.pythonanywhere.com\")\n",
    "s.post(\"https://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "r = s.get(\"https://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "with open('SKU_File\\Master tatanama.xlsx', 'wb') as output:\n",
    "    output.write(r.content)\n",
    "\n",
    "print('ok')\n",
    "\n",
    "if os.path.isfile('SKU_File\\Master tatanama.xlsx') :    \n",
    "    SKU_append = pd.read_excel('SKU_File\\Master tatanama.xlsx')\n",
    "    SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "    data_SKU = data_SKU[~data_SKU['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "    data_SKU = data_SKU.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "data_SKU.loc[data_SKU['Price List NFI'].isin(['-']), 'Price List NFI'] = 0\n",
    "to_excel = data_SKU.to_excel('SKU_File\\data_SKU.xlsx', index = False)\n",
    "print('data SKU done')\n",
    "\n",
    "data_SKU['Price List NFI'] = data_SKU['Price List NFI'].astype(float).astype('int64')\n",
    "\n",
    "download = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c25dfc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314138c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec7ed68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run-2\n",
    "## belum scrap dari forstok\n",
    "download = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6e0bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2113a434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d548ed6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25dd088a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Forstok Date\n",
      "2024-01-28-2024-02-07\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'download' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m options \u001b[38;5;241m=\u001b[39m Options()\n\u001b[0;32m     29\u001b[0m options\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--disable-blink-features=AutomationControlled\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m download:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpening Chrome\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     33\u001b[0m     driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'download' is not defined"
     ]
    }
   ],
   "source": [
    "## run-3\n",
    "## scrap data forstok & blibli lmen\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from datetime import datetime, timedelta\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import requests\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "diff_date = 10\n",
    "data_now = str(datetime.today().day) + ' ' + str(datetime.today().strftime(\"%B\"))\n",
    "\n",
    "print('Input Forstok Date')\n",
    "start_date = datetime.today() - timedelta(days=diff_date)\n",
    "end_date = datetime.today()\n",
    "date = start_date.strftime('%Y-%m-%d') + '-' + end_date.strftime('%Y-%m-%d')\n",
    "print(date)\n",
    "\n",
    "options = Options()\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "\n",
    "if not download:\n",
    "    print('Opening Chrome')\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    actions = ActionChains(driver)\n",
    "    driver.get(\"https://www.forstok.com/dashboard/users/login\")\n",
    "    print('Login Forstok')\n",
    "    \n",
    "    time.sleep(10)\n",
    "    print('input email')\n",
    "    username = driver.find_element(By.NAME, \"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"timotius.giovandi@nutrifood.co.id\")\n",
    "\n",
    "    print('input password')\n",
    "    password = driver.find_element(By.NAME, \"password\")\n",
    "    password.send_keys(\"timo123\")\n",
    "    \n",
    "    print('click')\n",
    "    driver.find_element(By.XPATH, \"/html/body/div[1]/div/div/div/form/input[3]\").click()\n",
    "    \n",
    "    #time.sleep(30)\n",
    "    #driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    #print('scroll down')\n",
    "    time.sleep(10)\n",
    "    datefield = WebDriverWait(driver, 100).until(EC.element_to_be_clickable((By.XPATH,'/html/body/div[1]/section/section[2]/article/div/div/aside/div/div[1]/section[4]/div/button')))\n",
    "    time.sleep(20)\n",
    "    #datef = WebDriverWait(driver, 100).until(EC.element_to_be_clickable((By.XPATH,'///html/body/div[1]/section/section[2]/article/div/div/aside/div/div[1]/section[5]/div/section/h2')))\n",
    "    #driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datef)\n",
    "    time.sleep(20)\n",
    "    driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "    time.sleep(10)\n",
    "    driver.find_element(By.XPATH, \"/html/body/div[1]/section/section[2]/article/div/div/aside/div/div[1]/section[4]/div/button\").click()\n",
    "    time.sleep(10)\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"exportSalesOrderForm\"]/div/section/section/div[1]/section/article/article[1]/div/section/div/div[2]').click()\n",
    "    #datefield.click()\n",
    "    pilih=0\n",
    "    while pilih < 3:    \n",
    "            n_elem=0\n",
    "            for i in driver.find_elements(By.XPATH, '(//*[@class=\"DateRangePicker__MonthHeaderLabel DateRangePicker__MonthHeaderLabel--month\"])'):\n",
    "                val=(driver.find_elements(By.XPATH, '(//*[@class=\"DateRangePicker__MonthHeaderLabel DateRangePicker__MonthHeaderLabel--month\"])')[n_elem].text.split()[0])\n",
    "                if val==start_date.strftime('%B'):\n",
    "                    # print(n_elem)\n",
    "                    fin_n_elem=n_elem\n",
    "                n_elem=n_elem+1\n",
    "            if fin_n_elem==0:\n",
    "                text = '(//*[@class=\"DateRangePicker__Month\"])[1]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(start_date.day) + '\")]'\n",
    "                if len(driver.find_elements(By.XPATH, text))==2:\n",
    "                    text = '('+text+')[2]'\n",
    "            else:\n",
    "                text = '(//*[@class=\"DateRangePicker__Month\"])[2]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(start_date.day) + '\")]'\n",
    "                if len(driver.find_elements(By.XPATH, text))==2:\n",
    "                    text = '('+text+')[1]'\n",
    "            driver.find_element(By.XPATH, text).click()\n",
    "            time.sleep(10)\n",
    "    \n",
    "            n_elem=0\n",
    "            for i in driver.find_elements(By.XPATH, '(//*[@class=\"DateRangePicker__MonthHeaderLabel DateRangePicker__MonthHeaderLabel--month\"])'):\n",
    "                val=(driver.find_elements(By.XPATH, '(//*[@class=\"DateRangePicker__MonthHeaderLabel DateRangePicker__MonthHeaderLabel--month\"])')[n_elem].text.split()[0])\n",
    "                if val==end_date.strftime('%B'):\n",
    "                    fin_n_elem=n_elem\n",
    "                n_elem=n_elem+1\n",
    "            if fin_n_elem==0:\n",
    "                text = '(//*[@class=\"DateRangePicker__Month\"])[1]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(end_date.day) + '\")]'\n",
    "                if len(driver.find_elements(By.XPATH, text))==2:\n",
    "                    text = '('+text+')[2]'\n",
    "            else:\n",
    "                text = '(//*[@class=\"DateRangePicker__Month\"])[2]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(end_date.day) + '\")]'\n",
    "                if end_date.strftime('%B')==start_date.strftime('%B'):\n",
    "                    text = '('+text+')'#[2]\n",
    "                else :\n",
    "                    text = '('+text+')[1]'\n",
    "            driver.find_element(By.XPATH, text).click()\n",
    "            time.sleep(10)\n",
    "            pilih=pilih+1\n",
    "    driver.find_element(By.XPATH, '//*[@type=\"button\" and contains(text(),\"Apply\")]').click()\n",
    "    time.sleep(30)\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/section/section[2]/div/form/div/section/section/div[2]/aside[2]/button[2]').click()\n",
    "    #WebDriverWait(driver, 30).until(EC.element_to_be_clickable((By.XPATH, \"(//*[@type='button' and contains(text(),'Save')])\"))).click()\n",
    "    #driver.find_element(By.XPATH, '//span[text()=\"Sales Order v2\"]').click()\n",
    "    #driver.find_element(By.XPATH, '//span[text()=\"Sales Order v2\"]').click()\n",
    "    #WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"(//*[@type='button' and contains(text(),'Export')])[2]\"))).click()\n",
    "    time.sleep(2)\n",
    "    driver.quit()\n",
    "   \n",
    "    print('Forstok Downloaded')\n",
    "    download = True\n",
    "\n",
    "print('Download Data SKU')\n",
    "#Import library\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import smtplib \n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from smtplib import SMTP\n",
    "import smtplib\n",
    "import sys\n",
    "import requests\n",
    "import os\n",
    "\n",
    "print('Waiting to Download Forstok')\n",
    "s = requests.Session()\n",
    "r = s.get(\"https://www.forstok.com/dashboard/users/login\")\n",
    "data = {'dashboard_user_email' : 'andra.miftah@nutrifood.co.id', \"dashboard_user_password\" : 'nutrimart1234'}\n",
    "r = s.post(\"https://www.forstok.com/dashboard/users/login\", data = data)\n",
    "startdate = start_date-timedelta(days=1)\n",
    "startdate1 = startdate.strftime(\"%Y-%m-%d\")\n",
    "enddate = end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "text = 'https://forstok-staging-storage.s3.ap-southeast-1.amazonaws.com/items_import/Nutrifood-forstok-sales_orders-version_2-' + startdate1 + 'T17:00:00Z-' + enddate + 'T16:59:59Z.xlsx'\n",
    "print(text)\n",
    "while True:\n",
    "   r = s.get(text)\n",
    "   print('Waiting to Download Forstok')\n",
    "  \n",
    "   if r.status_code == requests.codes.ok:\n",
    "       print(r.status_code)\n",
    "       with open('Input Data/Forstok_new_input.xls', 'wb') as output:\n",
    "           output.write(r.content)\n",
    "       break\n",
    "   else :\n",
    "       time.sleep(60)\n",
    "          \n",
    "with open('Input Data/nutrifood--forstok-sales_orders-' + date + '.xls', 'wb') as output:\n",
    "   output.write(r.content)\n",
    "    \n",
    "# Import data\n",
    "start_time = time.time()\n",
    "print(\"Import Data ====== 1/10\")\n",
    "\n",
    "data_forstok = pd.read_excel(r'Input Data/Forstok_new_input.xls')\n",
    "\n",
    "#EMERGENCY DOWNLOAD IF MAINTAINANCE\n",
    "# data_forstok = pd.read_excel(r\"C:\\Users\\steven.nathanael\\Downloads\\Nutrifood-forstok-sales_orders-version_2-2023-06-27T17 00 00Z-2023-07-07T16 59 59Z.xlsx\")\n",
    "# data_forstok = data_forstok[['Order Date', 'Channel', 'Store', 'Sales Order ID',\n",
    "#                             'Order Reference No.', 'Payment Status', 'Fulfillment Status', 'Payment Type',\n",
    "#                             'Payment Date', 'Shipping Label Printed Date', 'Shipped Date', 'Delivered Date',\n",
    "#                             'Cancelled Date', 'Return ID', 'Shipping Courier', 'Service Type', 'AWB', 'Customer Name',\n",
    "#                             'Customer Email', 'Currency Code', 'Item Name', 'SKU Code', 'Bundle SKU Code', 'Barcode ID',\n",
    "#                             'Warehouse Name', 'Warehouse Code', 'Quantity', 'Regular Price', 'Selling Price',\n",
    "#                             'Sub Total', 'VAT', 'Shipping Fee (Non-cashless)', 'Voucher Seller', 'Platform Rebate',\n",
    "#                             'Shipping Customer Name', 'Shipping Address1', 'Shipping Address2', 'Shipping City',\n",
    "#                             'Shipping Zip', 'Shipping Province', 'Shipping Country', 'Shipping Phone', 'Order Note',\n",
    "#                             'Invoice ID']]\n",
    "data_forstok.rename(columns = {'Shipping Label Printed Date' : 'Printed Date',\n",
    "                              'Shipping Date' : 'Fulfilled Date',\n",
    "                              'SKU Code' : 'SKU',\n",
    "                              'Shipping Fee (Non-cashless)' : 'Shipping',\n",
    "                              'Voucher Seller' : 'Seller Voucher',\n",
    "                              'Platform Rebate' : 'Channel Rebate',\n",
    "                              'Order Note' : 'Note'}, inplace = True)\n",
    "\n",
    "data_forstok_pure = data_forstok.copy()\n",
    "\n",
    "data_forstok = data_forstok.dropna(how = 'all')\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "# Forstok formatting\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Formatting Data ====== 2/10\")\n",
    "\n",
    "if 'Unnamed: 35' in data_forstok:\n",
    "    data_forstok = data_forstok.drop(['Unnamed: 35'], axis = 'columns')\n",
    "if 'Unnamed: 36' in data_forstok:\n",
    "    data_forstok = data_forstok.rename(columns={'Unnamed: 36' : 'Comment'})\n",
    "if 'Unnamed: 37' in data_forstok:\n",
    "    data_forstok = data_forstok.drop(['Unnamed: 37'], axis = 'columns')\n",
    "if 'Unnamed: 38' in data_forstok:\n",
    "    data_forstok = data_forstok.drop(['Unnamed: 38'], axis = 'columns')\n",
    "if 'Unnamed: 39' in data_forstok:\n",
    "    data_forstok = data_forstok.drop(['Unnamed: 39'], axis = 'columns')\n",
    "if 'Unnamed: 40' in data_forstok:\n",
    "    data_forstok = data_forstok.drop(['Unnamed: 40'], axis = 'columns')\n",
    "if 'Unnamed: 41' in data_forstok:\n",
    "    data_forstok = data_forstok.drop(['Unnamed: 41'], axis = 'columns')\n",
    "    \n",
    "data_forstok[\"Order Date\"] = data_forstok[\"Order Date\"].str.replace('WIB', '')\n",
    "data_forstok[\"Payment Date\"] = data_forstok[\"Payment Date\"].str.replace('WIB', '')\n",
    "#data_forstok[\"Cancelled Date\"] = data_forstok[\"Cancelled Date\"].str.replace('WIB', '')\n",
    "data_forstok[\"Order Date\"] = pd.to_datetime(data_forstok[\"Order Date\"], errors = 'coerce')\n",
    "data_forstok[\"Payment Date\"] = pd.to_datetime(data_forstok[\"Payment Date\"], errors = 'coerce')\n",
    "data_forstok[\"Cancelled Date\"] = pd.to_datetime(data_forstok[\"Cancelled Date\"], errors = 'coerce')\n",
    "data_forstok['Customer Name'] = data_forstok['Customer Name'].fillna(data_forstok['Shipping Customer Name'])\n",
    "data_forstok = data_forstok.rename(columns = {'Seller Voucher' : 'Seller Discount'})\n",
    "data_forstok = data_forstok[~((data_forstok['Store']=='Shopee')&(data_forstok['Order Date']<'21-12-2021'))] ###TMO###\n",
    "print('Date formatted')\n",
    "\n",
    "# Phone formatting\n",
    "\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('=','', regex = False)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('\"','', regex = False)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('(','', regex = False)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace(')','', regex = False)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('-','', regex = False)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('+','', regex = False)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('^620','0', regex = True)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('^62','0', regex = True)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('^620','0', regex = True)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('^8','08', regex = True)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('^21','021', regex = True)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('^008','08', regex = True)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('(021)','021', regex = False)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('+62','0', regex = False)\n",
    "print('Phone Formatted')\n",
    "# Forstok SKU\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Fulfilling SKU ====== 3/10\")\n",
    "indeks = data_forstok[data_forstok['Item Name'].astype(str) == 'Buy 1 Get 1 FREE Tropicana Slim Goldenmil Vanilla Manuka Honey (6 Sch)'][data_forstok[data_forstok['Item Name'].astype(str) == 'Buy 1 Get 1 FREE Tropicana Slim Goldenmil Vanilla Manuka Honey (6 Sch)']['SKU'] == 'PE8B27'].index.to_list()\n",
    "data_forstok['SKU'][indeks] = '2101384106P2'\n",
    "data_forstok.loc[data_forstok['SKU']==\"(E)2101492P04\",'SKU']=\"(E)2101492P4\"\n",
    "data_forstok.loc[data_forstok['SKU']==\"P2101151180P2\",'SKU']=\"PT7(2)B65\"\n",
    "data_forstok.loc[data_forstok['SKU']==' PT28(2)B65','SKU']='PT28(2)B65'\n",
    "data_forstok.loc[data_forstok['SKU']==' PT6(2)B65','SKU']='PT6(2)B65'\n",
    "data_forstok.loc[data_forstok['SKU']==' PT1(2)B65','SKU']='PT1(2)B65'\n",
    "data_forstok.loc[(data_forstok['SKU']=='2101865450P3')&(data_forstok['Item Name'].astype(str)=='Tropicana Slim White Coffee 4 Sachet x 3 pcs - Kopi Susu Nikmat Tanpa Gula Pasir'),'SKU']='2104170164P3'\n",
    "data_forstok.loc[(data_forstok['SKU']=='2104170104P3')&(data_forstok['Item Name'].astype(str)=='Triple Pack: Tropicana Slim White Coffee - Kopi Bebas Gula'),'SKU']='2104170164P3'\n",
    "data_forstok.loc[(data_forstok['SKU']=='COLLETTEP24')&(data_forstok['Item Name'].astype(str)=='HiLo School Cotton Candy 200ml - Ready to Drink (24 Pcs)'),'SKU']='2HF1403250P24'\n",
    "data_forstok.loc[(data_forstok['SKU']=='COLLETTEP4')&(data_forstok['Item Name'].astype(str)=='HiLo School Cotton Candy 200ml - Ready to Drink (4 Pcs) Tinggi Kalsium'),'SKU']='2HF1403250P4'\n",
    "\n",
    "skushopee = data_forstok[data_forstok['SKU'].astype(str).str.contains('(S)',regex = False)]\n",
    "data_forstok = data_forstok[~data_forstok['SKU'].astype(str).isin(skushopee['SKU'].astype(str))]\n",
    "\n",
    "skushopee = skushopee.reset_index(drop = True)\n",
    "data_forstok = data_forstok.reset_index(drop = True)\n",
    "\n",
    "forstok_all_sku = pd.read_excel(r'SKU_File\\forstok_all_sku.xlsx')\n",
    "indeks = data_forstok[data_forstok['SKU'].isnull()].index.to_list()\n",
    "\n",
    "for i in indeks:\n",
    "    if str(data_forstok['Item Name'][i]).lower() in data_SKU['Nama Produk'].astype(str).str.lower().values:\n",
    "        data_forstok['SKU'][i] = data_SKU['SKU'].loc[str(data_forstok['Item Name'][i]).lower() == data_SKU['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "indeks = data_forstok[data_forstok['SKU'].isnull()].index.to_list()\n",
    "for i in indeks:\n",
    "    if str(data_forstok['Item Name'][i]).lower() in forstok_all_sku['Item Name'].astype(str).str.lower().values:\n",
    "        data_forstok['SKU'][i] = forstok_all_sku['SKU'].loc[str(data_forstok['Item Name'][i]).lower() == forstok_all_sku['Item Name'].astype(str).str.lower()].values[0]\n",
    "\n",
    "indeks = data_forstok[data_forstok['Item Name'].astype(str).str.contains(' - ')].index.to_list()\n",
    "\n",
    "# Formatting double name\n",
    "for i in indeks:\n",
    "    if data_forstok['Item Name'][i].count(' - ') == 1 :\n",
    "        if (data_forstok['Item Name'][i].split(' - ')[0] == data_forstok['Item Name'][i].split(' - ')[1]):\n",
    "            data_forstok['Item Name'][i] = data_forstok['Item Name'][i].split(' - ')[0]\n",
    "    elif data_forstok['Item Name'][i].count(' - ') > 1:\n",
    "        temp = math.ceil(data_forstok['Item Name'][i].count(' - ')/2)\n",
    "        itemname = ''\n",
    "        duplicate = ''\n",
    "        for j in range(temp):\n",
    "            if j == 0:\n",
    "                itemname = itemname + data_forstok['Item Name'][i].split(' - ')[j]\n",
    "                duplicate = duplicate + data_forstok['Item Name'][i].split(' - ')[temp+j]\n",
    "            else :\n",
    "                itemname = itemname + ' ' +data_forstok['Item Name'][i].split(' - ')[j]\n",
    "                duplicate = duplicate + ' ' +data_forstok['Item Name'][i].split(' - ')[temp+j]\n",
    "        if itemname == duplicate:\n",
    "            data_forstok['Item Name'][i] = itemname\n",
    "        \n",
    "data_forstok['Item Name'] = data_forstok['Item Name'].str.replace(r' - $', '')\n",
    "data_forstok[\"Item Name\"] = data_forstok[\"Item Name\"].str.replace('Special Promo by Nutrimart Serba 12 RIBU Varian:', '', regex=False)\n",
    "data_forstok[\"Item Name\"] = data_forstok[\"Item Name\"].str.replace('Khusus Jabodetabek', '- Khusus Jabodetabek', regex=False)\n",
    "data_forstok['Item Name'] = data_forstok['Item Name'].str.replace('Buy 1 Get F', 'Buy 1 Get 1 F')\n",
    "data_forstok['Item Name'] = data_forstok['Item Name'].str.replace('Buy 1 Get H', 'Buy 1 Get 1 H')\n",
    "data_forstok['Item Name'] = data_forstok['Item Name'].str.replace('Buy 12 FREE', 'Buy 12 FREE 12')\n",
    "\n",
    "# Formatting SKU based on name\n",
    "indeks = data_forstok[data_forstok['SKU'].isnull()].index.to_list()\n",
    "for i in indeks:\n",
    "    if str(data_forstok['Item Name'][i]).lower().strip() in data_SKU['Nama Produk'].astype(str).str.lower().str.strip().values:\n",
    "        data_forstok['SKU'][i] = data_SKU['SKU'].loc[str(data_forstok['Item Name'][i]).lower().strip() == data_SKU['Nama Produk'].astype(str).str.lower().str.strip()].values[0]\n",
    "\n",
    "indeks = data_forstok[data_forstok['SKU'].isnull()].index.to_list()\n",
    "for i in indeks:\n",
    "    if str(data_forstok['Item Name'][i]).lower() in forstok_all_sku['Item Name'].astype(str).str.lower().values:\n",
    "        data_forstok['SKU'][i] = forstok_all_sku['SKU'].loc[str(data_forstok['Item Name'][i]).lower() == forstok_all_sku['Item Name'].astype(str).str.lower()].values[0]\n",
    "\n",
    "indeks = data_forstok[data_forstok['SKU'].isnull()].index.tolist()\n",
    "\n",
    "data_adasku = data_forstok[['Item Name', 'SKU']]\n",
    "data_adasku = data_adasku[data_adasku['SKU'].notnull()]\n",
    "\n",
    "data_nosku = data_forstok[['Item Name', 'SKU']]\n",
    "data_nosku = data_nosku[data_nosku['SKU'].isnull()]\n",
    "\n",
    "for i in indeks:\n",
    "    if data_adasku['SKU'].loc[data_nosku['Item Name'][i] == data_adasku['Item Name']].size != 0:\n",
    "        data_forstok['SKU'][i] = data_adasku['SKU'].loc[data_nosku['Item Name'][i] == data_adasku['Item Name']].values[0]\n",
    "\n",
    "for i in indeks:\n",
    "    if data_forstok['Item Name'][i] == 'Lokalate Kopi Durian 10s':\n",
    "        data_forstok['SKU'][i] = '1101675318'\n",
    "    elif data_forstok['Item Name'][i] == 'Nutrisari Madu Kurma Isi 16 Renceng X 10 Sachet Karton' or data_forstok['Item Name'][i] =='Nutrisari Madu Kurma Isi 16 Renceng X 10 SachetKarton': \n",
    "        data_forstok['SKU'][i] = 'PN30(16)'\n",
    "    elif data_forstok['Item Name'][i] == 'L-Men Protein Bar Crunchy Chocolate Isi X12 (Exp Date:10-Apr-2019)':\n",
    "        data_forstok['SKU'][i] = '2306592173'\n",
    "    elif data_forstok['Item Name'][i] == 'FS Hilo Active Chocolate Minuman Kesehatan [750 gr]' or data_forstok['Item Name'][i] == 'FSHilo Active Chocolate Minuman Kesehatan [750 gr]':\n",
    "        data_forstok['SKU'][i] = '2101452190'\n",
    "    elif data_forstok['Item Name'][i] == 'FS L-Men Platinum Suplemen Kesehatan + Free Spider Bottle [800 g] Hitam' or data_forstok['Item Name'][i] == 'FSL-Men Platinum Suplemen Kesehatan + Free Spider Bottle [800 g] Hitam':\n",
    "        data_forstok['SKU'][i] = '2305551288P1G26'\n",
    "    elif data_forstok['Item Name'][i] == 'NutriSari Premium ala Jus Mangga':\n",
    "        data_forstok['SKU'][i] = '1100534104'\n",
    "    elif data_forstok['Item Name'][i] == 'Buy 1 Get 1 FREE Tropicana Slim Sweetener Honey (50 Sch) - FS':\n",
    "        data_forstok['SKU'][i] = '2102501125P1G53'\n",
    "\n",
    "indeks = data_forstok[~data_forstok['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "for i in indeks:\n",
    "    if str(data_forstok['Item Name'][i]).lower() in forstok_all_sku['Item Name'].astype(str).str.lower().values:\n",
    "        data_forstok['SKU'][i] = forstok_all_sku['SKU'].loc[str(data_forstok['Item Name'][i]).lower() == forstok_all_sku['Item Name'].astype(str).str.lower()].values[0]\n",
    "\n",
    "list_alias = []\n",
    "list_alias_name = []\n",
    "for colname in data_SKU.columns:\n",
    "    if 'Alias SKU' in colname:\n",
    "        list_alias.append(colname)\n",
    "    if 'Alias Nama' in colname:\n",
    "        list_alias_name.append(colname)\n",
    "\n",
    "\n",
    "for i in indeks:\n",
    "    for j in list_alias:\n",
    "        if str(data_forstok['SKU'][i]) in data_SKU[j].astype(str).values:\n",
    "            idx = data_SKU[str(data_forstok['SKU'][i]) == data_SKU[j].astype(str)].index.to_list()\n",
    "            for k in idx:\n",
    "                if str(data_forstok['Item Name'][i]) == data_SKU[j.replace('SKU', 'Nama')][k]:\n",
    "                    data_forstok['SKU'][i] = data_SKU['SKU'][k]\n",
    "                        \n",
    "indeks = data_forstok[~data_forstok['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "\n",
    "for i in indeks:\n",
    "    for j in list_alias_name:\n",
    "        if str(data_forstok['Item Name'][i]).lower() in data_SKU[j].astype(str).str.lower().values:\n",
    "            data_forstok['SKU'][i] = data_SKU['SKU'].loc[str(data_forstok['Item Name'][i]).lower() == data_SKU[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "indeks = data_forstok[~data_forstok['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "\n",
    "for i in indeks:\n",
    "    if str(data_forstok['Item Name'][i]).lower() in data_SKU['Nama Produk'].astype(str).str.lower().values:\n",
    "        data_forstok['SKU'][i] = data_SKU['SKU'].loc[str(data_forstok['Item Name'][i]).lower() == data_SKU['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "indeks = skushopee[~skushopee['SKU'].astype(str).str.replace('(S)','', regex = False).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "for i in indeks:\n",
    "    if str(skushopee['Item Name'][i]).lower() in data_SKU['Nama Produk'].astype(str).str.lower().values:\n",
    "        skushopee['SKU'][i] = data_SKU['SKU'].loc[str(skushopee['Item Name'][i]).lower() == data_SKU['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "        skushopee['SKU'][i] = '(S)' + str(skushopee['SKU'][i])\n",
    "\n",
    "indeks = skushopee[~skushopee['SKU'].astype(str).str.replace('(S)','', regex = False).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "for i in indeks:\n",
    "    for j in list_alias:\n",
    "        if str(skushopee['SKU'][i]).replace('(S)','') in data_SKU[j].astype(str).values:\n",
    "            idx = data_SKU[str(skushopee['SKU'][i]).replace('(S)','') == data_SKU[j].astype(str)].index.to_list()\n",
    "            for k in idx:\n",
    "                if str(skushopee['Item Name'][i]) == data_SKU[j.replace('SKU', 'Nama')][k]:\n",
    "                    skushopee['SKU'][i] = data_SKU['SKU'][k]\n",
    "\n",
    "indeks = data_forstok[data_forstok['SKU'].astype(str) == 'Gift Sosro'].index.to_list()\n",
    "data_forstok = data_forstok.drop(indeks, axis = 0).reset_index(drop = True)\n",
    "\n",
    "indeks = data_forstok[data_forstok['Item Name'].astype(str).str.contains('Fricella')].index.to_list()\n",
    "data_forstok = data_forstok.drop(indeks, axis = 0).reset_index(drop = True)\n",
    "\n",
    "indeks = data_forstok[data_forstok['Item Name'].astype(str).str.contains('Zaskia Mecca')].index.to_list()\n",
    "data_forstok = data_forstok.drop(indeks, axis = 0).reset_index(drop = True)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Listing SKU Missing ====== 4/10\")\n",
    "\n",
    "data_forstok = data_forstok.append(skushopee, ignore_index = True, sort = False)\n",
    "data_forstok = data_forstok.reset_index(drop = True)\n",
    "\n",
    "indeks = data_forstok[data_forstok['SKU'].astype(str) == '71210111'].index.to_list()\n",
    "data_forstok['SKU'][indeks] = 'PN28N29N34(2)N53N54N55'\n",
    "\n",
    "indeks = data_forstok[data_forstok['SKU'].astype(str) == '71210112'].index.to_list()\n",
    "data_forstok['SKU'][indeks] = 'PN19N22N30N34(2)N53N55'\n",
    "\n",
    "indeks = data_forstok[data_forstok['SKU'].astype(str) == '(B) 2101656'].index.to_list()\n",
    "data_forstok['SKU'][indeks] = '(B)2101656'\n",
    "\n",
    "indeks = data_forstok[data_forstok['Item Name'].astype(str) == 'PRE ORDER NutriSari NUTRI-C1000 40sch Suplemen Kesehatan Vit C 1000mg '].index.to_list()\n",
    "data_forstok['SKU'][indeks] = '1102110453'\n",
    "\n",
    "data_forstok.loc[data_forstok['Item Name']==\"HiLo Active Caramel Latte 500gr - Susu Tinggi Kalsium\",'SKU']=\"2101478180\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"NutriSari Es Rujak 40 Sachet - Minuman Buah Vitamin C - Expired 4 Bulan\",'SKU']=\"(E)1101984453\"\n",
    "data_forstok.loc[data_forstok['SKU']=='PH39(12)U8(12) ','SKU']='PH39(12)U8(12)'\n",
    "\n",
    "\n",
    "shopee_con = pd.read_excel(r'data_supp\\Shopee Converter.xlsx')\n",
    "indeks = data_forstok[data_forstok['SKU'].astype(str).str.replace('(S)','', regex = False).isin(shopee_con['SKU'].astype(str))][data_forstok[data_forstok['SKU'].astype(str).str.replace('(S)','', regex = False).isin(shopee_con['SKU'].astype(str))]['Item Name'].astype(str).str.lower().isin(shopee_con['Product Name'].astype(str).str.lower())].index.to_list()\n",
    "product = data_forstok[data_forstok['SKU'].astype(str).str.replace('(S)','', regex = False).isin(shopee_con['SKU'].astype(str))][data_forstok[data_forstok['SKU'].astype(str).str.replace('(S)','', regex = False).isin(shopee_con['SKU'].astype(str))]['Item Name'].astype(str).str.lower().isin(shopee_con['Product Name'].astype(str).str.lower())]['Item Name'].unique()\n",
    "\n",
    "for i in product:\n",
    "    indeks_shopee = data_forstok.iloc[indeks][data_forstok.iloc[indeks]['Item Name'].astype(str).str.lower() == str(i).lower()].index.to_list()\n",
    "    data_forstok['SKU'][indeks_shopee] = shopee_con[shopee_con['Product Name'].astype(str).str.lower() == str(i).lower()]['Real SKU'].values[0]\n",
    "\n",
    "\n",
    "to_excel = data_forstok.to_excel(r'forstok_new.xlsx', index = False)\n",
    "\n",
    "skushopee = data_forstok[data_forstok['SKU'].astype(str).str.contains('(S)',regex = False)]\n",
    "data_forstok = data_forstok[~data_forstok['SKU'].astype(str).isin(skushopee['SKU'].astype(str))]\n",
    "\n",
    "skushopee = skushopee.reset_index(drop = True)\n",
    "data_forstok = data_forstok.reset_index(drop = True)\n",
    "\n",
    "sku_exclude = ['5337754001-1623228299159-0',\"TESSS\"]\n",
    "data_forstok = data_forstok[~data_forstok['SKU'].isin(sku_exclude)]\n",
    "\n",
    "data_forstok.loc[data_forstok['Item Name']==\"HiLo Teen Strawberry Milkshake 500 gram – Susu Tinggi Kalsium - Milkshake\",'SKU']=\"2101683180\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"Paket Minyak Hemat – Tropicana Slim Canola Oil & Tropicana Slim Sunflower Oil - Package\",'SKU']=\"PT3T46\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"Buy 2 Get 1 - L-Men Protein Crunch BBQ Beef (20gr) - Triplepack\",'SKU']=\"2309005300P3\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"Paket Kecap Sehat - Topicana Slim Kecap Manis & Tropicana Slim Kecap Asin - Package\",\"SKU\"]=\"PT26T44\"\n",
    "data_forstok.loc[(data_forstok['Item Name']==\"(Free Gift) 3pcs L-Men Protein Crunch BBQ Beef 20g\")&\n",
    "                 (data_forstok['Store']==\"Lazada\"),\"SKU\"]=\"(B)2309005305P3\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"WHS - Paket NutriSari Jeruk Peras, HiLo Es Ketan Hitam, dan HiLo Klepon Latte Powder Drink Refill 500 gram\",'SKU']=\"PH81H82N60G187\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"WHS - HiLo Milky Brown Sugar Ready to Drink 200ml (24 tetrapack) - Minuman Sumber Kalsium Rendah Lemak\",'SKU']=\"2101941250P24\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"WHS - Twin Pack - Tropicana Slim Shirataki Noodle: Mie Goreng [71 g]\",'SKU']=\"2106023014\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"WHS - HiLo School Chocolate Ready to Drink 200ml (4 tetrapack) - Susu Tinggi Kalsium Rendah Lemak\",'SKU']=\"2101492P4\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"WHS - HiLo Kacang Hijau Ready to Drink 200ml (24 tetrapack) - Minuman Sumber Kalsium Rendah Lemak\",'SKU']=\"2101907250P24\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"WHS NutriSari Es Rujak Jeruk Bali 40sch Minuman Buah Vitamin C Vitamin D\",'SKU']=\"1101996453\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"DISKON BOMBASTIS - Tropicana Slim Almond Drink Chocolicious 190ml (1 pcs) - Minuman Almond Ready to Drink Rasa Cokelat \",'SKU']=\"2T01402249\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"DISKON BOMBASTIS Tropicana Slim Almond Drink Chocolicious 190ml (1 pcs) Minuman Almond Ready to Drink Rasa Cokelat \",'SKU']=\"2T01402249\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"WHS NutriSari RTD Squeezed Orange Minuman Jeruk Peras Vitamin C 200 mL \",'SKU']=\"1N01402250P4\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"WHS HiLo Active Vanilla 500g x 2 pcs Susu Tinggi Kalsium Rendah Lemak\",'SKU']=\"2101485180P2\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"WHS HiLo Teen Taro 500 gr Susu Tinggi Kalsium\",'SKU']=\"2101609180\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"Tropicana Slim Hampers Lebaran Idul Fitri Fancy Tote Bag\",'SKU']=\"PT24T51T52T61T79G292G294\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"WHS HiLo Chocolate Avocado Ready to Drink 200ml (4 Tetrapack) Susu Siap Minum Tinggi Kalsium\",'SKU']=\"(E)2HH1407250P4\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"TG HiLo School Chocolate RTD 200ml\",'SKU']=\"2101492\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"TG HiLo School Chocolate RTD 200ml \",'SKU']=\"2101492\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"TG Tropicana Slim Almond Drink Chocolicious 190ml (1 pcs) Minuman Almond Ready to Drink Rasa Cokelat \",'SKU']=\"2T01402249\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"Tropicana Slim Oat Drink Japanese Cantaloupe Melon 190 ml (1 Pcs) Minuman Oat Vegan Plant Based Bebas Gula Ready to Drink\",'SKU']=\"2T01403249\"\n",
    "data_forstok.loc[data_forstok['SKU']==\"1101588454\",'SKU']=\"1101588453\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"WHS HiLo Gold Biscuit Cereal 500g Susu Tinggi Kalsium Lebih Rendah Lemak\",'SKU']=\"(E)2101524180\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"Nutrifood BBF Mystery Box\",'SKU']=\"PH100H108(2)T71\"\n",
    "data_forstok.loc[data_forstok['SKU']==\"(E)2104406P1\",'SKU']=\"(E)2104406\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"WHS HiLo Teen Chocolate Ready to Drink (4 pcs) Susu Tinggi Kalsium Rendah Lemak\",'SKU']=\"(E)2101461P4\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"WHS Paket HiLo School HiLo School Vanilla Vegiberi 500g & Original 400g\",'SKU']=\"PH4H102\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"WHS Twin Pack HiLo Gold Biscuit Cereal 500g Susu Tinggi Kalsium Lebih Rendah Lemak\",'SKU']=\"(E)2101524180P2\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"WHS Paket School 3+ HiLo School 3+ Strawberry Pop 400g & School 3+ Soya Vanilla Malt 400g\",'SKU']=\"PE229E230\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"WHS HiLo Gold Susu Tinggi Kalsium Rendah Lemak Chocolate [500 g ]\",'SKU']=\"(E)2101551180\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"TG HiLo Protein Chocofit UHT 190 mL (1 pcs) – Susu Tinggi Protein dengan Collagen Rasa Cokelat\",'SKU']=\"2HH1409249\"\n",
    "\n",
    "idx = []\n",
    "idx = idx + data_forstok[data_forstok['SKU'].isnull()].drop_duplicates().index.to_list()\n",
    "idx = idx + data_forstok[~data_forstok['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "idx = list(dict.fromkeys(idx))\n",
    "idx_s = skushopee[~skushopee['SKU'].astype(str).str.replace('(S)','', regex = False).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "idx_s = list(dict.fromkeys(idx_s))\n",
    "\n",
    "\n",
    "for i in product:\n",
    "    indeks_shopee = data_forstok.iloc[indeks][data_forstok.iloc[indeks]['Item Name'].astype(str).str.lower() == str(i).lower()].index.to_list()\n",
    "    data_forstok['SKU'][indeks_shopee] = shopee_con[shopee_con['Product Name'].astype(str).str.lower() == str(i).lower()]['Real SKU'].values[0]\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "if len(idx) != 0 or len(idx_s) != 0:\n",
    "    alert = data_forstok.iloc[idx, ][['SKU', 'Item Name', 'Channel']].drop_duplicates()\n",
    "    alert = alert.append(skushopee.iloc[idx_s][['SKU', 'Item Name', 'Channel', 'Selling Price']].drop_duplicates(), ignore_index = True, sort = False)\n",
    "    alert['SKU'] = alert['SKU'].astype(str)\n",
    "    alert['SKU Valid'] = np.nan\n",
    "    to_excel = alert.to_excel('ALERT_FORSTOK_SKU_MISSING.xlsx')\n",
    "    print(\"Some SKU Missing Please Complete It ====== 5/10\")\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    # creates SMTP session \n",
    "    s = smtplib.SMTP('smtp.gmail.com', 587) \n",
    "\n",
    "    # start TLS for security \n",
    "    s.starttls() \n",
    "\n",
    "    # Authentication \n",
    "    s.login(\"automationnfi@gmail.com\", \"nutrifood2020\") \n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['Subject'] = \"ALERT SKU FORSTOK MISSING\"\n",
    "\n",
    "\n",
    "    html = \"\"\"\\\n",
    "    <html>\n",
    "      <head></head>\n",
    "      <body>\n",
    "        {0}\n",
    "      </body>\n",
    "    </html>\n",
    "    \"\"\".format(alert.to_html())\n",
    "\n",
    "    part1 = MIMEText(html, 'html')\n",
    "    msg.attach(part1)\n",
    "\n",
    "    # sending the mail \n",
    "    s.sendmail(\"automationnfi@gmail.com\", \"steven.nathanael@nutrifood.co.id\", msg.as_string()) \n",
    "\n",
    "    # terminating the session \n",
    "    s.quit() \n",
    "else :\n",
    "    print(\"Filling Brand ====== 5/10\")\n",
    "    data_forstok['SKU'] = data_forstok['SKU'].astype(str)\n",
    "    data_forstok['Item Name'] = data_forstok['Item Name'].astype(str)\n",
    "    data_SKU['Real SKU'] = data_SKU['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "    data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "    \n",
    "    data_forstok = data_forstok.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "    temp = data_forstok[data_forstok['Real SKU'].isnull()].copy()\n",
    "    temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "    temp = temp.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "    temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "    temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "    temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "    temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "    indeks = data_forstok[data_forstok['Real SKU'].isnull()].index.to_list()\n",
    "    data_forstok['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "    data_forstok['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "    temp = data_forstok[data_forstok['Real SKU'].isnull()].copy()\n",
    "    temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "    temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "    temp = temp.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "    temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "    temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "    temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "    temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "    indeks = data_forstok[data_forstok['Real SKU'].isnull()].index.to_list()\n",
    "    data_forstok['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "    data_forstok['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "    data_forstok['Real SKU'] = data_forstok['Real SKU'].astype(str)\n",
    "    data_forstok = data_forstok.merge(data_SKU[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "    data_forstok = data_forstok.drop(['SKU_y'], axis = 1)\n",
    "    data_forstok = data_forstok.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"Unbundling ====== 6/10\")        \n",
    "    # Forstok Unbundling    \n",
    "    list_col = ['SKU'] + data_SKU.columns[data_SKU.columns.get_loc('Produk 1'):data_SKU.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "    data_forstok = data_forstok.merge(data_SKU[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "    list_pcs = [x for x in data_forstok.columns if 'PCS' in x]\n",
    "    for i in list_pcs:\n",
    "        data_forstok[i] = data_forstok[i] * data_forstok['Quantity']\n",
    "    data_forstok = data_forstok.drop(['SKU_y'], axis = 1)\n",
    "    data_forstok = data_forstok.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "    indeks = data_forstok[data_forstok['Brand'] == 'Bundle'].index.to_list()\n",
    "    data_forstok['Bundle Flag'] = np.nan\n",
    "    data_forstok['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "    indeks = data_forstok[data_forstok['Brand'] == 'Bundle'][data_forstok[data_forstok['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "    data_forstok['SKU Produk 1'][indeks] = '(S)' + data_forstok['SKU Produk 1'][indeks].astype(str)\n",
    "    data_forstok['SKU Produk 2'][indeks] = '(S)' + data_forstok['SKU Produk 2'][indeks].astype(str)\n",
    "    data_forstok['SKU Produk 3'][indeks] = '(S)' + data_forstok['SKU Produk 3'][indeks].astype(str)\n",
    "    data_forstok['SKU Produk 4'][indeks] = '(S)' + data_forstok['SKU Produk 4'][indeks].astype(str)\n",
    "    data_forstok['SKU Produk 5'][indeks] = '(S)' + data_forstok['SKU Produk 5'][indeks].astype(str)\n",
    "    data_forstok['SKU Produk 6'][indeks] = '(S)' + data_forstok['SKU Produk 6'][indeks].astype(str)\n",
    "    data_forstok['SKU Produk 7'][indeks] = '(S)' + data_forstok['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"Filling Date ====== 7/10\")\n",
    "    data_forstok['Date'] = np.nan\n",
    "    data_forstok['Month'] = np.nan\n",
    "    data_forstok['Year'] = np.nan\n",
    "\n",
    "    for i in range(data_forstok.shape[0]):\n",
    "        if int(data_forstok['Order Date'][i].strftime('%d')) <= 12:\n",
    "            data_forstok['Date'][i] = pd.to_datetime(data_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "            data_forstok['Month'][i] = pd.to_datetime(data_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "            data_forstok['Year'][i] = pd.to_datetime(data_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "        else :\n",
    "            data_forstok['Date'][i] = pd.to_datetime(data_forstok['Order Date'][i]).day\n",
    "            data_forstok['Month'][i] = pd.to_datetime(data_forstok['Order Date'][i]).month_name()\n",
    "            data_forstok['Year'][i] = pd.to_datetime(data_forstok['Order Date'][i]).year\n",
    "\n",
    "    quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "            ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "    data_forstok = data_forstok.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "    data_forstok = data_forstok.drop(['Bulan'], axis = 1)\n",
    "    data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "            {'Bulan' : 'January' , 'Number': 1},\n",
    "            {'Bulan' : 'February' , 'Number': 2},\n",
    "            {'Bulan' : 'March' , 'Number': 3},\n",
    "            {'Bulan' : 'April' , 'Number': 4},\n",
    "            {'Bulan' : 'May' , 'Number': 5},\n",
    "            {'Bulan' : 'June', 'Number': 6},\n",
    "            {'Bulan' : 'July' , 'Number': 7},\n",
    "            {'Bulan' : 'August', 'Number' : 8},\n",
    "            {'Bulan' : 'September', 'Number' : 9},\n",
    "            {'Bulan' : 'October' , 'Number': 10},\n",
    "            {'Bulan' : 'November' , 'Number': 11}])\n",
    "    temp = data_forstok.copy()\n",
    "    temp['Day'] = temp['Date']\n",
    "    temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "    temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "    data_forstok['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).strftime(\"%U\")\n",
    "    temp['Hour'] = pd.to_datetime(data_forstok['Order Date']).dt.hour\n",
    "    temp['Minute'] = pd.to_datetime(data_forstok['Order Date']).dt.minute\n",
    "    temp['Second'] = pd.to_datetime(data_forstok['Order Date']).dt.second\n",
    "    data_forstok['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "    \n",
    "    \n",
    "    forstok_all = data_forstok\n",
    "    forstok_all['Total'] = forstok_all['Sub Total']\n",
    "    forstok_all['Price List NFI'] = np.nan\n",
    "    forstok_all['Total Net'] = np.nan\n",
    "\n",
    "    forstok_all = forstok_all.rename(columns={'Order Reference No.' : 'Order #',\n",
    "                                            'Fulfillment Status' : 'Order Status',\n",
    "                                            'Order Date' : 'Order date',\n",
    "                                            'Item Name' :'Product Name',\n",
    "                                            'Bundle Name' : 'Bundle',\n",
    "                                            'Shipping Country' : 'Country',\n",
    "                                            'Shipping Province' : 'Region',\n",
    "                                            'Shipping City' : 'City',\n",
    "                                            'Shipping Zip' : 'Zip Code',\n",
    "                                            'Shipping Address1' : 'Address',\n",
    "                                            'Shipping Phone' : 'Phone',\n",
    "                                            'Quantity' : 'Qty. Invoiced',\n",
    "                                            'Sub Total' : 'Subtotal'})\n",
    "    forstok_all['Kecamatan'] = np.nan\n",
    "    forstok_all['Kelurahan'] = np.nan\n",
    "    forstok_all['Store'] = forstok_all['Channel']\n",
    "\n",
    "    print(\"Filling Location ===== 7/10\")\n",
    "    indeks = forstok_all[forstok_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        forstok_all['Kecamatan'][indeks] = forstok_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "        forstok_all['City'][indeks] = forstok_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "    indeks = forstok_all[forstok_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        forstok_all['Kelurahan'][indeks] = forstok_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "        forstok_all['Kecamatan'][indeks] = forstok_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "    indeks = forstok_all[forstok_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        forstok_all['Kecamatan'][indeks] = forstok_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "        forstok_all['City'][indeks] = forstok_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "    indeks = forstok_all[forstok_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        forstok_all['Kelurahan'][indeks] = forstok_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "        forstok_all['Kecamatan'][indeks] = forstok_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "    forstok_all['City'] = forstok_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "    master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "    master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "    master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "    master_map['Kode Prov'][515] = 14\n",
    "    master_map['Province'][515] = 'Riau'\n",
    "    master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "    master_map['Province'] = master_map['Province'].str.title()\n",
    "    master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "    city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "    temp = forstok_all.copy()\n",
    "    temp['City'] = temp['City'].astype(str).str.lower()\n",
    "    temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "    city['All City'] = city['All City'].astype(str).str.lower()\n",
    "    temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "    indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "    forstok_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "    province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "    temp = forstok_all.copy()\n",
    "    temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "    province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "    temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "    indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "    forstok_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "    temp = forstok_all.copy()\n",
    "    temp = temp[temp['Region'].isnull()]\n",
    "    temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "    forstok_all['Region'][temp.index] = temp['Region']  \n",
    "    \n",
    "    district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "    temp = forstok_all.copy()\n",
    "    temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "    district['All District'] = district['All District'].astype(str).str.lower()\n",
    "    temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "    indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "    forstok_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "    temp = forstok_all.copy()\n",
    "    temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "    indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "    forstok_all['City'][indeks] = np.nan\n",
    "\n",
    "    data_SKU['Real SKU'] = data_SKU['SKU'].astype(str)\n",
    "    data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "\n",
    "    print(\"Unbundling ===== 9/10\")\n",
    "    data_bundle1 = forstok_all[~forstok_all['Produk 1'].isnull()]\n",
    "    data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "    data_bundle1['Bundle SKU'] = data_bundle1['SKU']\n",
    "    data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "    data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "    data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "    data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "    data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "    data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "    data_bundle2 = forstok_all[~forstok_all['Produk 2'].isnull()]\n",
    "    data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "    data_bundle2['Bundle SKU'] = data_bundle2['SKU']\n",
    "    data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "    data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "    data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "    data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "    data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "    data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "    data_bundle3 = forstok_all[~forstok_all['Produk 3'].isnull()]\n",
    "    data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "    data_bundle3['Bundle SKU'] = data_bundle3['SKU']\n",
    "    data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "    data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "    data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "    data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "    data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "    data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "    data_bundle4 = forstok_all[~forstok_all['Produk 4'].isnull()]\n",
    "    data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "    data_bundle4['Bundle SKU'] = data_bundle4['SKU']\n",
    "    data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "    data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "    data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "    data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "    data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "    data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "    data_bundle5 = forstok_all[~forstok_all['Produk 5'].isnull()]\n",
    "    data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "    data_bundle5['Bundle SKU'] = data_bundle5['SKU']\n",
    "    data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "    data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "    data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "    data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "    data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "    data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "    data_bundle6 = forstok_all[~forstok_all['Produk 6'].isnull()]\n",
    "    data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "    data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "    data_bundle6['Bundle SKU'] = data_bundle6['SKU']\n",
    "    data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "    data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "    data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "    data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "    data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "    data_bundle7 = forstok_all[~forstok_all['Produk 7'].isnull()]\n",
    "    data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "    data_bundle7['Bundle SKU'] = data_bundle7['SKU']\n",
    "    data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "    data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "    data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "    data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "    data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "    data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "    data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "    data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "    data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "    data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "    temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "    temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "    temp = temp.merge(data_SKU[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "    indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "    data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "    data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "    data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "    data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "    data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "    data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "    print(\"Pricing ===== 10/10\")\n",
    "    forstok_all = forstok_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "    \n",
    "    forstok_all = forstok_all.merge(data_SKU[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(forstok_all.index)\n",
    "    forstok_all['Price List NFI_x'] = forstok_all['Price List NFI_x'].fillna(forstok_all['Price List NFI_y'])\n",
    "    forstok_all =  forstok_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "    forstok_all = forstok_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "    forstok_all['Price List NFI'] = pd.to_numeric(forstok_all['Price List NFI']).astype(int)\n",
    "    forstok_all['Harga Cost'] = pd.to_numeric(forstok_all['Harga Cost']).astype(int)\n",
    "    forstok_all['Qty. Invoiced'] = pd.to_numeric(forstok_all['Qty. Invoiced']).astype(int)\n",
    "    \n",
    "    forstok_all['Total Net'] = forstok_all['Price List NFI'] * forstok_all['Qty. Invoiced']\n",
    "    forstok_all['Total Harga Cost'] = forstok_all['Harga Cost'] * forstok_all['Qty. Invoiced']\n",
    "    \n",
    "    forstok_all = forstok_all.reset_index(drop = True)\n",
    "    forstok_all['Order #'] = forstok_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.maximize_window()\n",
    "    driver.get(\"https://seller.blibli.com/sign-in\")\n",
    "    time.sleep(40)\n",
    "\n",
    "    username = driver.find_element(By.ID, \"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customer1@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element(By.ID, \"password\")\n",
    "    password.send_keys(\"NutrimartNutrif00d\")\n",
    "\n",
    "    driver.find_element(By.ID, \"sign-in\").click()\n",
    "    time.sleep(40)\n",
    "\n",
    "    driver.get(\"https://seller.blibli.com/MTA/order/summary\")\n",
    "    time.sleep(30)\n",
    "    WebDriverWait(driver, 40).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[7]/div/div/div/div/div[4]/button'))).click()\n",
    "    time.sleep(30)\n",
    "    WebDriverWait(driver, 40).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[3]/div[1]/div/div/div[2]/div[2]/div[3]/button'))).click()\n",
    "    time.sleep(10)\n",
    "    driver.find_element(By.ID, \"semuaFilter\").click()\n",
    "\n",
    "    driver.find_element(By.CLASS_NAME, \"order-filter-input\").click()\n",
    "    start_date = datetime.today() - timedelta(days=14)\n",
    "    end_date = datetime.today()\n",
    "    date = start_date.strftime('%Y-%m-%d') + '-' + end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    if start_date.month == end_date.month:\n",
    "        text = \"//div[@class='calendar left']//td[@class = 'available' or @class='weekend available'][text() = \" + str(start_date.day) + \"]\"\n",
    "        driver.find_element(By.XPATH, text).click()\n",
    "        text = \"//div[@class='calendar left']//td[contains(@class, 'today')][text() = \" + str(end_date.day) + \"]\"\n",
    "        driver.find_element(By.XPATH, text).click()\n",
    "    else :\n",
    "        driver.find_element(By.CSS_SELECTOR, \"th.prev.available\").click()\n",
    "        text = \"//div[@class='calendar left']//td[@class = 'available' or @class='weekend available'][text() = \" + str(start_date.day) + \"]\"\n",
    "        driver.find_element(By.XPATH, text).click()\n",
    "        text = \"//div[@class='calendar right']//td[contains(@class, 'today')][text() = \" + str(end_date.day) + \"]\"\n",
    "        driver.find_element(By.XPATH, text).click()\n",
    "    driver.find_element(By.CSS_SELECTOR, 'button.btn.col-sm-3.btn-default.order-option-buttons.dropdown-toggle').click()\n",
    "    driver.find_element(By.XPATH, \"/html/body/div[3]/div[2]/div/div/div[1]/div[3]/div[2]/ul\").click()\n",
    "    try:\n",
    "        time.sleep(10)\n",
    "        driver.find_element(By.CLASS_NAME, \"btn-primary-mta\").click()\n",
    "        time.sleep(10)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    cond = False\n",
    "    while not cond:\n",
    "        time.sleep(30)\n",
    "        driver.find_element(By.CLASS_NAME, 'fa-bell-o').click()\n",
    "        print('click 1')\n",
    "        time.sleep(20)\n",
    "        driver.find_element(By.CLASS_NAME, 'fa-bell-o').click()\n",
    "        print('click 2')\n",
    "        time.sleep(20)\n",
    "        driver.find_element(By.CLASS_NAME, 'fa-bell-o').click()\n",
    "        print('click 3')\n",
    "\n",
    "        time_now = str(datetime.now().hour) + ':' + str(datetime.now().minute)\n",
    "        time.sleep(10)\n",
    "        time_notif = driver.find_element(By.XPATH, '//*[@id=\"viewNotification\"]/div[2]/div[2]/ul/li[1]/span[2]').text\n",
    "        print(time_notif)\n",
    "        time_notif1 = driver.find_element(By.CSS_SELECTOR, 'li.ng-scope.notification-unread').text[-5:]\n",
    "        end = datetime.strptime(time_notif, '%H:%M').time()\n",
    "        print(end)\n",
    "        duration = int((datetime.today() - timedelta(hours=end.hour, minutes=end.minute)).strftime('%M'))\n",
    "        print(duration)\n",
    "        if duration < 40:\n",
    "            time.sleep(1)\n",
    "            driver.find_element(By.XPATH, '//ul[@class = \"notification-item-container\"]//li[@class = \"ng-scope notification-unread\"]').click()\n",
    "            cond = True\n",
    "        else :\n",
    "            driver.find_element(By.CLASS_NAME, 'fa-bell-o').click()\n",
    "            time.sleep(10)\n",
    "            driver.find_element(By.CLASS_NAME, 'fa-bell-o').click()\n",
    "            time.sleep(10)\n",
    "            \n",
    "    print('Blibli LMS Downloaded')     \n",
    "\n",
    "   \n",
    "    time.sleep(15)\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    else:\n",
    "        print(\"More than one file or no file downloaded\")\n",
    "    print(file_name)\n",
    "    new_name = 'Blibli ' + str(date) + '.csv'\n",
    "    if os.path.isfile('Input Data/' + str(new_name)) :\n",
    "        os.remove('Input Data/' + str(new_name))\n",
    "    os.rename('Input Data/' + str(file_name), 'Input Data/' + str(new_name))\n",
    "    driver.quit()\n",
    "    print(\"Import Data ====== 1/10\")\n",
    "    \n",
    "    lmen = pd.read_csv(r'Input Data/' + str(new_name) , dayfirst = True)\n",
    "    lmen = lmen.dropna(how = 'all')\n",
    "    lmen_pure = lmen.copy()\n",
    "\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"Formatting Data ====== 2/10\")\n",
    "    lmen['No. Order'] = lmen['No. Order'].astype(str).str.replace('^=\"','')\n",
    "    lmen['No. Order'] = lmen['No. Order'].astype(str).str.replace('\"$','')\n",
    "    lmen['No. Order Item'] = lmen['No. Order Item'].astype(str).str.replace('^=\"','')\n",
    "    lmen['No. Order Item'] = lmen['No. Order Item'].astype(str).str.replace('\"$','')\n",
    "    lmen['No. Awb'] = lmen['No. Awb'].astype(str).str.replace('^=\"','')\n",
    "    lmen['No. Awb'] = lmen['No. Awb'].astype(str).str.replace('\"$','')\n",
    "    lmen['Merchant SKU'] = lmen['Merchant SKU'].astype(str).str.replace('^=\"','')\n",
    "    lmen['Merchant SKU'] = lmen['Merchant SKU'].astype(str).str.replace('\"$','')\n",
    "    \n",
    "    #INPUT SKU BLIBLI LMS ERROR\n",
    "    lmen.loc[lmen['Nama Produk']=='Daily Protein Package - L-Men Daily Popcorn Caramel 250g & L-Men Protein Bar Crunchy Chocolate 12 Sachet','Merchant SKU']='PL19L23'\n",
    "    lmen.loc[lmen['Nama Produk']=='[Tebus Murah] L-Men Lose Weight Mango Sticky Rice 300g - Suplemen Penurun Berat Badan Tinggi Whey Protein ','Merchant SKU']='2304576112'\n",
    "    lmen.loc[lmen['Nama Produk']=='WHS - FREE PROTEIN CRUNCH - L-Men PlantProtein Ogura 216g - Suplemen Tinggi Protein Nabati Rendah Lemak Vegan Lactose Free','Merchant SKU']='PL24B102'\n",
    "    lmen.loc[lmen['Nama Produk']=='WHS - L-Men Platinum Ketan Hitam 800g (25g protein) - Suplemen Tinggi Whey Protein Rendah Lemak','Merchant SKU']='2305545288'\n",
    "    lmen.loc[lmen['Nama Produk']=='WHS- Paket High Protein Snack - L-Men Protein Bar & 2 pcs L-Men Protein Crunch','Merchant SKU']='PL18(2)L19'\n",
    "    lmen.loc[lmen['Nama Produk']=='WHS - L-Men Protein Crunch BBQ Beef (20gr)','Merchant SKU']='2309005305'\n",
    "    lmen.loc[lmen['Nama Produk'].isin(['FREE SPIDER BOTTLE ']),'Merchant SKU']='(B)71210026'\n",
    "    lmen.loc[lmen['Blibli SKU'].isin(['LMS-60022-00307-00001']),'Merchant SKU']='(G)71310033'\n",
    "    lmen.loc[lmen['Blibli SKU'].isin(['LMS-60022-00306-00001']),'Merchant SKU']='(G)71310032'\n",
    "    lmen.loc[lmen['Blibli SKU'].isin(['LMS-60022-00311-00001']),'Merchant SKU']='2307061250P4'\n",
    "    lmen.loc[lmen['Blibli SKU'].isin(['LMS-60022-00310-00001']),'Merchant SKU']='(E)2304576112P2'\n",
    "    lmen.loc[lmen['Blibli SKU'].isin(['LMS-60022-00309-00001']),'Merchant SKU']='(E)2304576112'\n",
    "    lmen.loc[lmen['Blibli SKU'].isin(['LMS-60022-00314-00001']),'Merchant SKU']='PL7(2)B102(2)'\n",
    "    lmen.loc[lmen['Blibli SKU'].isin(['LMS-60022-00313-00001']),'Merchant SKU']='2304515112P2'\n",
    "    lmen.loc[lmen['Blibli SKU'].isin(['LMS-60022-00319-00001']),'Merchant SKU']='(E)2305551288'\n",
    "    lmen.loc[lmen['Blibli SKU'].isin(['LMS-60022-00318-00001']),'Merchant SKU']='(E)2305551288P2'\n",
    "    lmen.loc[lmen['Blibli SKU'].isin(['LMS-60022-00322-00001']),'Merchant SKU']='(E)2LL1402249P24'\n",
    "    lmen.loc[lmen['Blibli SKU'].isin(['LMS-60022-00323-00001']),'Merchant SKU']='PL3G128'\n",
    "    lmen.loc[lmen['Blibli SKU'].isin(['LMS-60022-00324-00001']),'Merchant SKU']='PE66E80'\n",
    "    lmen.loc[lmen['Blibli SKU'].isin(['LMS-60022-00325-00001']),'Merchant SKU']='(E)2305559288'\n",
    "    lmen.loc[lmen['Blibli SKU'].isin(['LMS-60022-00320-00001']),'Merchant SKU']='(E)2LL1402249P4'\n",
    "    lmen.loc[lmen['Blibli SKU'].isin(['LMS-60022-00330-00001']),'Merchant SKU']='(E)2305584288'\n",
    "    lmen.loc[lmen['Blibli SKU'].isin(['LMS-60022-00332-00001']),'Merchant SKU']='(E)2305551288P3'\n",
    "    lmen.loc[lmen['Blibli SKU'].isin(['LMS-60022-00333-00001']),'Merchant SKU']='(E)2301050106'\n",
    "    lmen.loc[lmen['Blibli SKU'].isin(['LMS-60022-00335-00001']),'Merchant SKU']='(E)2304036151'\n",
    "     \n",
    "    for i in lmen[lmen['Merchant SKU']=='nan']['Blibli SKU'].unique():\n",
    "        print(i)\n",
    "        skunfi=lmen[(lmen['Blibli SKU'] == i)&(lmen['Merchant SKU']!='nan')].reset_index()['Merchant SKU'][0]\n",
    "        lmen.loc[(lmen['Blibli SKU']==i)&(lmen['Merchant SKU']=='nan'),'Merchant SKU']=skunfi\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"Listing SKU ====== 3/10\")\n",
    "    lmen_sku = pd.read_excel(r'SKU_File/Converter Paket Blibli.xlsx')\n",
    "\n",
    "    lmen['Merchant SKU'] = lmen['Merchant SKU'].astype(str).str.replace('\\.0$','', regex = True)\n",
    "\n",
    "    null_sku = lmen[lmen['Merchant SKU'] == 'nan'].copy()\n",
    "    lmen = lmen[lmen['Merchant SKU'] != 'nan']\n",
    "\n",
    "    null_sku['Nama Produk'] = null_sku['Nama Produk'].astype(str).str.strip()\n",
    "    lmen_sku['Nama Produk'] = lmen_sku['Nama Produk'].astype(str).str.strip()\n",
    "    null_sku['Merchant SKU'] = null_sku.merge(lmen_sku[['SKU Merchant', 'Nama Produk']].drop_duplicates(['Nama Produk']), how = 'left', on = 'Nama Produk').set_index(null_sku.index)['SKU Merchant']\n",
    "\n",
    "    lmen = lmen.append(null_sku, ignore_index = True, sort = False)\n",
    "\n",
    "    gaada_sku = lmen[~lmen['Merchant SKU'].astype(str).isin(data_SKU['SKU'].astype(str))].copy()\n",
    "    lmen = lmen[lmen['Merchant SKU'].astype(str).isin(data_SKU['SKU'].astype(str))]\n",
    "\n",
    "    gaada_sku['Nama Produk'] = gaada_sku['Nama Produk'].astype(str).str.strip()\n",
    "    lmen_sku['Nama Produk'] = lmen_sku['Nama Produk'].astype(str).str.strip()\n",
    "    gaada_sku['Merchant SKU'] = gaada_sku.merge(lmen_sku[['SKU Merchant', 'Nama Produk']].drop_duplicates(['Nama Produk']), how = 'left', on = 'Nama Produk').set_index(gaada_sku.index)['SKU Merchant']\n",
    "    lmen = lmen.append(gaada_sku, ignore_index = True, sort = False)\n",
    "\n",
    "    indeks = []\n",
    "    indeks = indeks + lmen[lmen['Merchant SKU'].isnull()].index.to_list()\n",
    "    indeks = indeks + lmen[~lmen['Merchant SKU'].astype(str).str.replace('\\.0$','', regex = True).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0 :\n",
    "        alert = lmen.iloc[indeks][['Blibli SKU','Merchant SKU', 'Nama Produk']].drop_duplicates()\n",
    "        alert['SKU Valid'] = np.nan\n",
    "        to_excel = alert.to_excel('ALERT_LMEN-STORE_SKU_MISSING.xlsx')\n",
    "        print(\"Some SKU Missing Please Complete It ====== 4/10\")\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    else :\n",
    "        data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "        data_SKU['Real SKU'] = data_SKU['SKU'].astype(str)\n",
    "        lmen['Merchant SKU'] = lmen['Merchant SKU'].astype(str)\n",
    "        data_SKU.loc[data_SKU['Price List NFI'].isin(['-']),'Price List NFI'] = 0\n",
    "        data_SKU['Price List NFI'] = data_SKU['Price List NFI'].astype(float).astype('int64')\n",
    "        lmen = lmen.merge(data_SKU[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU', 'Price List NFI']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'Merchant SKU', right_on = 'Real SKU')\n",
    "        lmen['Total Net'] = lmen['Price List NFI'] * lmen['Total Barang']\n",
    "\n",
    "        indeks = lmen[lmen['Brand'] == 'Bundle'].index.to_list()\n",
    "        lmen['Bundle Flag'] = np.nan\n",
    "        lmen['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        lmen['Date'] = pd.to_datetime(lmen['Tanggal Order'], format = '%d/%m/%Y %H:%M').dt.day\n",
    "        lmen['Month'] = pd.to_datetime(lmen['Tanggal Order'], format = '%d/%m/%Y %H:%M').dt.month_name()\n",
    "        lmen['Year'] = pd.to_datetime(lmen['Tanggal Order'], format = '%d/%m/%Y %H:%M').dt.year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                    ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        lmen = lmen.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        lmen = lmen.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = lmen.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        lmen['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        lmen['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day']])\n",
    "\n",
    "        lmen = lmen.rename(columns = {'No. Order' : 'Order #', 'No. Order Item' : 'No. Order Item L-Men Blibli',\n",
    "                                    'Tanggal Order' : 'Order date', 'Nama Pemesan' : 'Customer Name',\n",
    "                                    'Merchant SKU' : 'SKU', 'Nama Produk' : 'Product Name', 'Total Barang':'Qty. Invoiced',\n",
    "                                    'Servis Logistik' : 'Shipping Courier', 'Nama Store' : 'Channel',\n",
    "                                    'Toko/Gudang' : 'Warehouse Name', 'No. Awb' : 'AWB'\n",
    "                                    })\n",
    "\n",
    "        lmen['Selling Price'] = (lmen['Qty. Invoiced']-lmen['Diskon'])/lmen['Qty. Invoiced']\n",
    "        lmen['Channel'] = 'L-Men Store Blibli'\n",
    "        lmen['Store'] = 'Blibli'\n",
    "\n",
    "        data_SKU['Real SKU'] = data_SKU['SKU'].astype(str)\n",
    "        data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "\n",
    "        lmen['SKU'] = lmen['SKU'].astype(str)\n",
    "        list_col = ['SKU'] + data_SKU.columns[data_SKU.columns.get_loc('Produk 1'):data_SKU.columns.get_loc('Harga Cost 7')+1].to_list()\n",
    "        lmen = lmen.merge(data_SKU[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        lmen = lmen.drop(['SKU_y'], axis = 1)\n",
    "        lmen = lmen.rename(columns = {'SKU_x':'SKU'})\n",
    "        \n",
    "        data_bundle1 = lmen[~lmen['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Bundle SKU'] = data_bundle1['SKU']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1'] * data_bundle1['Qty. Invoiced']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1'] * data_bundle1['Qty. Invoiced']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = lmen[~lmen['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Bundle SKU'] = data_bundle2['SKU']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2'] * data_bundle2['Qty. Invoiced']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] * data_bundle2['Qty. Invoiced']\n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = lmen[~lmen['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Bundle SKU'] = data_bundle3['SKU']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']* data_bundle3['Qty. Invoiced']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] * data_bundle3['Qty. Invoiced']\n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = lmen[~lmen['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Bundle SKU'] = data_bundle4['SKU']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']* data_bundle4['Qty. Invoiced']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] * data_bundle4['Qty. Invoiced']\n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = lmen[~lmen['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Bundle SKU'] = data_bundle5['SKU']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']* data_bundle5['Qty. Invoiced']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5'] * data_bundle5['Qty. Invoiced']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = lmen[~lmen['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Bundle SKU'] = data_bundle6['SKU']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']* data_bundle6['Qty. Invoiced']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6'] * data_bundle6['Qty. Invoiced']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = lmen[~lmen['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Bundle SKU'] = data_bundle7['SKU']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']* data_bundle7['Qty. Invoiced']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7'] * data_bundle7['Qty. Invoiced']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        lmen = lmen.append(data_bundle, ignore_index = True, sort = False)\n",
    "        lmen = lmen.merge(data_SKU[['Real SKU', 'Harga Cost']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "        lmen['Total Harga Cost'] = pd.to_numeric(lmen['Harga Cost'], errors = 'coerce') * lmen['Qty. Invoiced']\n",
    "        print(lmen[lmen['Harga Cost'] == 0][['SKU','Product Name']].drop_duplicates())\n",
    "        lmen['Total'] = lmen['Selling Price'] * lmen['Qty. Invoiced']\n",
    "        lmen['Subtotal'] = lmen['Selling Price'] * lmen['Qty. Invoiced']\n",
    "        lmen = lmen.rename(columns = {'Real SKU_x' : 'Real SKU'})\n",
    "\n",
    "        forstok_all = forstok_all.append(lmen, ignore_index = True, sort = False)\n",
    "\n",
    "        list_bundle = forstok_all[forstok_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = forstok_all[forstok_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        forstok_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        forstok_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = forstok_all[forstok_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        forstok_all['Total'][temp.index] = temp['Total']\n",
    "        forstok_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        forstok_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "        \n",
    "\n",
    "        forstok_all['Order #'] = forstok_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = forstok_all[forstok_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = forstok_all[forstok_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        forstok_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = forstok_all[forstok_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        forstok_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "        temp = forstok_all[forstok_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = forstok_all.merge(temp_group, how = 'left', on = 'Order #').set_index(forstok_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        forstok_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = forstok_all[forstok_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = forstok_all[forstok_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        forstok_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = forstok_all[forstok_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        forstok_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        forstok_all['True datetime'] = pd.to_datetime(forstok_all['True datetime'])\n",
    "        forstok_all['Promo'] = np.nan\n",
    "        forstok_all['Discount MC'] = np.nan\n",
    "\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f30521c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d3098f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lmen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lmen\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lmen' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e21dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a666531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b63b533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafa0653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8daf1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63014d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79282c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c2c1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e316e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65341831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54a73b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32    LMS-60022-00330-00001\n",
       "Name: Blibli SKU, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmen[lmen['Merchant SKU']=='nan']['Blibli SKU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffcea87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d63bd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 2), dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skushopee[['Item Name', 'SKU']].drop_duplicates().values\n",
    "### ini harus null juga, jgn ada item masuk pake sku shopee (S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f444a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9742320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 3), dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### opsional , if errror\n",
    "### cek sku missing (belum ada di tatanama)\n",
    "### to do: regist single/bundle/alias \n",
    "\n",
    "data_forstok[data_forstok['SKU'].isnull()]['Item Name'] .unique()\n",
    "data_forstok[~data_forstok['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))][['Store','Item Name','SKU']].drop_duplicates().values#.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99e4d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddd38bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre Run-4\n",
    "#Belum scraping magento dan blibli\n",
    "magento_scrape = False\n",
    "magentoUser_scrape = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fa2f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2bb6ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Magento\n",
      "Opening Chrome\n",
      "Login Magento\n",
      "Go To Sales Form\n",
      "2024-01-25 16:07:08.247257\n",
      "2024-02-06 16:07:08.247257\n",
      "Input Date\n",
      "Download Magento\n",
      "bulk-order-download-template (1).csv\n",
      "bulk-order-download-template (1).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_15676\\592636022.py:131: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(SKU_append, ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Data ====== 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_15676\\592636022.py:150: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_magentoUser = data_magentoUser.append(data_magentoUser2, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_15676\\592636022.py:259: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^\\+62\", \"0\")\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_15676\\592636022.py:264: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"(021)\", \"021\")\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_15676\\592636022.py:282: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^\\+62\", \"0\")\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_15676\\592636022.py:287: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"(021)\", \"021\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3.974240303039551 seconds ---\n",
      "Formatting Data ====== 2/10\n",
      "--- 4.154117584228516 seconds ---\n",
      "Fulfilling SKU ====== 3/10\n",
      "--- 4.1766722202301025 seconds ---\n",
      "Listing SKU Missing ====== 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_15676\\592636022.py:366: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  to_excel = data_magento.to_excel(r'magento_new.xls', index = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4.537216663360596 seconds ---\n",
      "Preparing Appending Magento to Masterdata\n",
      "Filling Brand ====== 5/10\n",
      "--- 4.584114074707031 seconds ---\n",
      "Unbundling ====== 6/10\n",
      "--- 4.599701642990112 seconds ---\n",
      "Filling Date ====== 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_15676\\592636022.py:408: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_magento = data_magento.append(skushopee, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_15676\\592636022.py:495: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  data_magento['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4.922954559326172 seconds ---\n",
      "Pricing\n",
      "Filling Location\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_15676\\592636022.py:630: DtypeWarning: Columns (12,15,20,24,25,27,29,30,31,32,33,34,35,36,37,39,53,54,57,59,60,66,67,73,74,80,81,87,88,94,95,101,102,108,122,123,134,135,136,153,159,161,167,168,169,172,173,174,175,176,180,181,183,197,198,199,200,201,202,203,205,209,210) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_all = pd.read_csv(latest_file, sep = ';',converters = {'Phone' : str, 'Order #' : str, 'AWB' : str})\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_15676\\592636022.py:719: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  forstok_all = forstok_all.append(lmen_store, ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blibli Done\n",
      "Unbundling Paket J\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_15676\\592636022.py:778: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  forstok_all = forstok_all.append(tes1, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_15676\\592636022.py:785: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_all = data_all.append(forstok_all, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_15676\\592636022.py:786: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_all = data_all.append(data_magento, ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6272-072\n",
      "62-0\n",
      "6282-082\n",
      "6280-080\n",
      "6246-046\n",
      "6255-055\n",
      "6288-088\n",
      "6259-059\n",
      "6228-028\n",
      "6286-086\n",
      "6227-027\n",
      "6267-067\n",
      "6218-018\n",
      "6233-033\n",
      "6263-063\n",
      "6208-008\n",
      "6213-013\n",
      "6296-096\n",
      "6260-060\n",
      "6277-077\n",
      "6299-099\n",
      "6266-066\n",
      "6244-044\n",
      "6278-078\n",
      "6281-081\n",
      "6221-021\n",
      "6231-031\n",
      "6242-042\n",
      "6271-071\n",
      "6283-083\n",
      "6206-006\n",
      "6230-030\n",
      "6293-093\n",
      "6265-065\n",
      "6270-070\n",
      "6229-029\n",
      "6256-056\n",
      "6268-068\n",
      "6204-004\n",
      "6235-035\n",
      "6205-005\n",
      "6275-075\n",
      "6225-025\n",
      "6273-073\n",
      "6269-069\n",
      "6262-062\n",
      "6222-022\n",
      "6236-036\n",
      "6248-048\n",
      "6203-003\n",
      "6224-024\n",
      "6212-012\n",
      "6209-009\n",
      "6264-064\n",
      "6297-097\n",
      "6241-041\n",
      "6207-007\n",
      "6291-091\n",
      "6226-026\n",
      "6253-053\n",
      "6223-023\n",
      "6215-015\n",
      "6219-019\n",
      "done\n",
      "--- 586.861421585083 seconds ---\n",
      "Read Data Settlement\n",
      "Opening Chrome\n",
      "Login Forstok\n"
     ]
    }
   ],
   "source": [
    "## Run-4\n",
    "## scrap magento detail order blibli update order status\n",
    "## kadang auto logout di blibli -> solusi: run partial / add code\n",
    "\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "if not magento_scrape: \n",
    "    print(\"Starting Magento\")\n",
    "\n",
    "    # Download the file using Selenium here\n",
    "    #service = Service(executable_path=r\"C:\\Users\\steven.nathanael\\Documents\\Python\\Data\\2. Master Data Git\\chromedriver.exe\")\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(r\"C:\\Users\\steven.nathanael\\Documents\\Python\\Data\\2. Master Data Git\\Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    print('Opening Chrome')\n",
    "    driver = webdriver.Chrome(options = options)\n",
    "    driver.get(\"https://nutrimart.co.id/backoffice\")\n",
    "    print('Login Magento')\n",
    "    username = driver.find_element(By.ID, \"username\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"timotius\")\n",
    "    password = driver.find_element(By.ID, \"login\")\n",
    "    password.send_keys(\"timo123\")\n",
    "\n",
    "    print('Go To Sales Form')\n",
    "    time.sleep(5)\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "    driver.find_element(By.XPATH, \"//button[@class = 'action-login action-primary']\").click()\n",
    "    time.sleep(5)\n",
    "    WebDriverWait(driver, 300).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"menu-magento-sales-sales\"]'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"menu-magento-sales-sales\"]/div/ul/li[2]/ul/li[2]/div/ul/li[1]/a').click()\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"profile_id\"]').click()\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"profile_id\"]/optgroup[2]/option[2]').click()\n",
    "    \n",
    "\n",
    "    start_date = datetime.today() - timedelta(days=12)\n",
    "    print(start_date)\n",
    "    end_date = datetime.today()\n",
    "    print(end_date)\n",
    "    date = start_date.strftime('%d %b %Y') + '-' + end_date.strftime('%d %b %Y')\n",
    "\n",
    "    print('Input Date')\n",
    "    date_from = driver.find_element(By.NAME, 'daterange_from')\n",
    "    date_from.clear()\n",
    "    date_from.send_keys(start_date.strftime('%m/%d/%Y'))\n",
    "\n",
    "    date_to = driver.find_element(By.NAME, 'daterange_to')\n",
    "    date_to.clear()\n",
    "    date_to.send_keys(end_date.strftime('%m/%d/%Y'))\n",
    "    print('Download Magento')\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"export_button\"]').click()\n",
    "\n",
    "    time.sleep(120)\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        magento_name = change.pop()\n",
    "    else:\n",
    "        print(\"More than one file or no file downloaded\")\n",
    "    #data_magento = pd.read_csv('Input Data\\export_sales_detailed_report_320667.csv', sep = ',', index_col = False)\n",
    "    data_magento = pd.read_csv('Input Data/' + magento_name, sep = ',', index_col = False)\n",
    "    magento_scrape = True\n",
    "else :\n",
    "    #data_magento = pd.read_csv('Input Data\\export_sales_detailed_report_321223.csv', sep = ',', index_col = False)\n",
    "    data_magento = pd.read_csv('Input Data/' + magento_name, sep = ',', index_col = False)\n",
    "    \n",
    "if not magentoUser_scrape:\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"profile_id\"]').click()\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"profile_id\"]/optgroup[2]/option[1]').click()\n",
    "\n",
    "    start_date = datetime.today() - timedelta(days=14)\n",
    "    end_date = datetime.today()\n",
    "    date = start_date.strftime('%d %b %Y') + '-' + end_date.strftime('%d %b %Y')\n",
    "\n",
    "    date_from = driver.find_element(By.NAME, 'daterange_from')\n",
    "    date_from.clear()\n",
    "    date_from.send_keys(start_date.strftime('%m/%d/%Y'))\n",
    "    date_to = driver.find_element(By.NAME, 'daterange_to')\n",
    "    date_to.clear()\n",
    "    date_to.send_keys(end_date.strftime('%m/%d/%Y'))\n",
    "\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"export_button\"]').click()\n",
    "    time.sleep(60)\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        magentouser_name = change.pop()\n",
    "        print(file_name)\n",
    "    else:\n",
    "        print(\"More than one file or no file downloaded\")\n",
    "        print(change)\n",
    "    driver.quit()\n",
    "\n",
    "    print(file_name)\n",
    "    \n",
    "    #data_magentoUser2 = pd.read_csv(r\"C:\\Users\\steven.nathanael\\Documents\\Python\\Data\\2. Master Data Git\\Input Data\\export_320691.csv\", sep = ',', index_col = False)\n",
    "    data_magentoUser2 = pd.read_csv('Input Data/' + magentouser_name, sep = ',', index_col = False)\n",
    "    for i in range(data_magentoUser2.shape[1]):\n",
    "        data_magentoUser2 = data_magentoUser2.rename(columns={ data_magentoUser2.columns[i] : data_magentoUser2.columns[i].replace(\"    \",\" \")})\n",
    "    magentoUser_scrape = True\n",
    "else :\n",
    "    data_magentoUser2 = pd.read_csv('Input Data/' + magentouser_name, sep = ',', index_col = False)\n",
    "    #data_magentoUser2 = pd.read_csv(r\"C:\\Users\\steven.nathanael\\Documents\\Python\\Data\\2. Master Data Git\\Input Data\\export_321224.csv\", sep = ',', index_col = False)\n",
    "    for i in range(data_magentoUser2.shape[1]):\n",
    "        data_magentoUser2 = data_magentoUser2.rename(columns={ data_magentoUser2.columns[i] : data_magentoUser2.columns[i].replace(\"    \",\" \")})\n",
    "\n",
    "data_SKU = pd.read_excel(r\"SKU_File\\data_SKU.xlsx\")\n",
    "\n",
    "s = requests.Session()\n",
    "s.get(\"https://tatanama.pythonanywhere.com\")\n",
    "s.post(\"https://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "r = s.get(\"https://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "with open(r\"SKU_File\\Master tatanama.xlsx\", 'wb') as output:\n",
    "    output.write(r.content)\n",
    "\n",
    "if os.path.isfile(r\"SKU_File\\Master tatanama.xlsx\") :    \n",
    "    SKU_append = pd.read_excel(r\"SKU_File\\Master tatanama.xlsx\")\n",
    "    SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "    data_SKU = data_SKU[~data_SKU['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "    data_SKU = data_SKU.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "to_excel = data_SKU.to_excel(r\"SKU_File\\data_SKU.xlsx\", index = False)\n",
    "\n",
    "\n",
    "# Import library\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Import data\n",
    "start_time = time.time()\n",
    "print(\"Import Data ====== 1/10\")\n",
    "\n",
    "data_magentoUser = pd.read_excel('All Data\\data_magentoUser_2020.xlsx', index_col = False)\n",
    "data_magentoUser = data_magentoUser[~data_magentoUser['Sales Order Id'].astype(str).isin(data_magentoUser2['Sales Order Id'].astype(str))]\n",
    "data_magentoUser = data_magentoUser.append(data_magentoUser2, ignore_index = True, sort = False)\n",
    "magento_pure = data_magento.copy()\n",
    "\n",
    "list_skumiss = []\n",
    "\n",
    "# Formatting Magento\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Formatting Data ====== 2/10\")\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "if set(['Qty. Ordered\"', 'Qty. Shipped\"']).issubset(data_magento.columns):\n",
    "    data_magento = data_magento.rename(columns={'Qty. Ordered\"' : 'Qty. Ordered', \n",
    "                                            'Qty. Shipped\"' : 'Qty. Shipped'})\n",
    "if \"Manufacturer\" in data_magento.columns:\n",
    "    data_magento= data_magento.drop([\"Manufacturer\"], axis=1)\n",
    "if \"Item Cost\" in data_magento.columns:\n",
    "    data_magento= data_magento.drop([\"Item Cost\"], axis=1)\n",
    "if \"Package Name\" in data_magento.columns:\n",
    "    data_magento= data_magento.drop([\"Package Name\"], axis=1)\n",
    "if \"Tax Refunded\" in data_magento.columns:\n",
    "    data_magento= data_magento.drop([\"Tax Refunded\"], axis=1)\n",
    "if \"Catalog Name Rule\" in data_magento.columns:\n",
    "    data_magento= data_magento.drop([\"Catalog Name Rule\"], axis=1)\n",
    "if \"Order date\" in data_magento.columns:\n",
    "    data_magento[\"Order date\"] = pd.to_datetime(data_magento[\"Order date\"], errors = 'coerce')\n",
    "if \"Customer Email\" in data_magento.columns:\n",
    "    data_magento[\"Customer Email\"] = data_magento[\"Customer Email\"].replace(regex = r'\"', value=\"\")\n",
    "if \"Qty. Ordered\" in data_magento.columns:\n",
    "    data_magento['Qty. Ordered'] = data_magento['Qty. Ordered'].fillna(0)\n",
    "    if \"Qty. Invoiced\" in data_magento.columns:\n",
    "        data_magento['Qty. Invoiced'] = data_magento['Qty. Invoiced'].fillna(0)\n",
    "    if \"Qty. Shipped\" in data_magento.columns:\n",
    "        data_magento['Qty. Shipped'] = data_magento['Qty. Shipped'].fillna(0)\n",
    "    if \"Qty. Refunded\" in data_magento.columns:\n",
    "        data_magento['Qty. Refunded'] = data_magento['Qty. Refunded'].fillna(0)\n",
    "    if \"Item Price\" in data_magento.columns:\n",
    "        data_magento['Item Price'] = data_magento['Item Price'].fillna(0)\n",
    "    if \"Subtotal\" in data_magento.columns:\n",
    "        data_magento['Subtotal'] = data_magento['Subtotal'].fillna(0)\n",
    "    if \"Discounts\" in data_magento.columns:\n",
    "        data_magento['Discounts'] = data_magento['Discounts'].fillna(0)\n",
    "    if \"Invoiced\" in data_magento.columns:\n",
    "        data_magento['Invoiced'] = data_magento['Invoiced'].fillna(0)\n",
    "    if \"Tax Invoiced\" in data_magento.columns:\n",
    "        data_magento['Tax Invoiced'] = data_magento['Tax Invoiced'].fillna(0)\n",
    "    if \"Voucher Amount\" in data_magento.columns:\n",
    "        data_magento[data_magento['Voucher Amount'].astype(str).str.isdigit()]['Voucher Amount'] = data_magento[data_magento['Voucher Amount'].fillna(0).astype(str).str.isdigit()]['Voucher Amount'].astype(float).div(10000)\n",
    "    if \"Discount Poin Reward\" in data_magento.columns:\n",
    "        data_magento['Discount Poin Reward'] = data_magento['Discount Poin Reward'].fillna(0)\n",
    "    if \"Discount Product\" in data_magento.columns:\n",
    "        data_magento['Discount Product'] = data_magento['Discount Product'].fillna(0)\n",
    "if \"Tax\" in data_magento.columns:\n",
    "    data_magento['Tax'] = data_magento['Tax'].astype(np.float32)\n",
    "if \"Total\" in data_magento.columns:\n",
    "    data_magento['Total'] = data_magento['Total'].astype(np.float32)\n",
    "if \"Total incl. Tax\" in data_magento.columns:\n",
    "    data_magento['Total incl. Tax'] = pd.to_numeric(data_magento['Total incl. Tax'], errors = 'coerce').astype(np.float32)\n",
    "if \"Invoiced incl. Tax\" in data_magento.columns:\n",
    "    data_magento['Invoiced incl. Tax'] = data_magento['Invoiced incl. Tax'].astype(np.float32)\n",
    "if \"Refunded\" in data_magento.columns:\n",
    "    data_magento['Refunded'] = data_magento['Refunded'].astype(np.float32)\n",
    "if \"Refunded incl. Tax\" in data_magento.columns:\n",
    "    data_magento['Refunded incl. Tax'] = data_magento['Refunded incl. Tax'].astype(np.float32)\n",
    "if \"Ship Date\" in data_magento.columns:\n",
    "    data_magento['Ship Date'] = data_magento['Ship Date'].astype(str).str.replace('false', '')\n",
    "\n",
    "# Customer Information Filling  \n",
    "for i in range(data_magentoUser.shape[1]):\n",
    "    data_magentoUser = data_magentoUser.rename(columns={ data_magentoUser.columns[i] : data_magentoUser.columns[i].replace(\"    \",\" \")})\n",
    "\n",
    "for i in range(data_magento.shape[0]):\n",
    "    if str(data_magento[\"Customer Group\"][i]) == 'nan':\n",
    "        if data_magento[\"Order #\"][i] in data_magentoUser[\"Sales Order Id\"].values:\n",
    "            data_magento[\"Customer Name\"][i] = data_magentoUser[\"Shipping Name\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "            data_magento[\"Customer Group\"][i] = \"Not Logged In\"\n",
    "            data_magento[\"Country\"][i] = data_magentoUser[\"Shipping Country\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "            data_magento[\"Region\"][i] = data_magentoUser[\"Shipping Province\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "            data_magento[\"City\"][i] = data_magentoUser[\"Shipping City\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "            data_magento[\"Zip Code\"][i] = data_magentoUser[\"Shipping Zip\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "            data_magento[\"Address\"][i] = data_magentoUser[\"Shipping Address1\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "            data_magento[\"Phone\"][i] = data_magentoUser[\"Shipping Phone\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "\n",
    "indeks = data_magento[data_magento['Phone'].isnull()].index.to_list()\n",
    "data_magento['Phone Condition'] = np.nan\n",
    "data_magento['Phone Condition'][indeks] = 'X'\n",
    "\n",
    "data_magentoUser['Sales Order Id'] = data_magentoUser['Sales Order Id'].astype(str)\n",
    "data_magento['Order #'] = data_magento['Order #'].astype(str)\n",
    "\n",
    "temp2 = data_magento.merge(data_magentoUser[['Sales Order Id', 'AWB', 'Shipping Cost', 'Shipping Address1', 'Shipping City', 'Shipping Province', 'Shipping Phone', 'Shipping Courier']].drop_duplicates('Sales Order Id'), how = 'left', left_on = 'Order #', right_on = 'Sales Order Id').set_index(data_magento.index)\n",
    "\n",
    "data_magento['Shipping'] = np.nan\n",
    "data_magento['AWB'] = np.nan\n",
    "data_magento['Shipping Courier'] = np.nan\n",
    "\n",
    "data_magento['Shipping'][temp2.index] = temp2['Shipping Cost']\n",
    "data_magento['AWB'][temp2.index] = temp2['AWB']\n",
    "data_magento['Shipping Courier'][temp2.index] = temp2['Shipping Courier']\n",
    "\n",
    "\n",
    "# Phone formatting\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].fillna(0.0)\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\" \",\"\")\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"-\",\"\")\n",
    "temp = data_magento[\"Phone\"].astype(str).str.split(\",\", expand = True)\n",
    "data_magento[\"Phone\"] = temp[0]\n",
    "temp = data_magento[\"Phone\"].astype(str).str.split(\"/\", expand = True)\n",
    "data_magento[\"Phone\"] = temp[0]\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^\\+620\", \"0\", regex = True)\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^\\+62\", \"0\")\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^620\", \"0\", regex = True)\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^62\", \"0\", regex = True)\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^8\", \"08\", regex = True)\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^62\", \"0\", regex = True)\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"(021)\", \"021\")\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^21\", \"021\", regex = True)\n",
    "\n",
    "\n",
    "data_magento['Shipping Address1'] = np.nan\n",
    "data_magento['Shipping City'] = np.nan\n",
    "data_magento['Shipping Province'] = np.nan\n",
    "data_magento['Shipping Phone'] = np.nan\n",
    "\n",
    "\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].fillna(0.0)\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\" \",\"\")\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"-\",\"\")\n",
    "temp = data_magento[\"Shipping Phone\"].astype(str).str.split(\",\", expand = True)\n",
    "data_magento[\"Shipping Phone\"] = temp[0]\n",
    "temp = data_magento[\"Shipping Phone\"].astype(str).str.split(\"/\", expand = True)\n",
    "data_magento[\"Shipping Phone\"] = temp[0]\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^\\+620\", \"0\", regex = True)\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^\\+62\", \"0\")\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^620\", \"0\", regex = True)\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^62\", \"0\", regex = True)\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^8\", \"08\", regex = True)\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^62\", \"0\", regex = True)\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"(021)\", \"021\")\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^21\", \"021\", regex = True)\n",
    "\n",
    "# Master tatanama\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Fulfilling SKU ====== 3/10\")\n",
    "\n",
    "data_magento['SKU'] = data_magento['SKU'].astype(str).str.split('-').str[0]\n",
    "indeks = data_magento[~data_magento['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))]['SKU'].index.to_list()\n",
    "\n",
    "skuhd = data_magento[data_magento['SKU'].astype(str).str.contains('hd', case = False)]\n",
    "skushopee = data_magento[data_magento['SKU'].astype(str).str.contains('(S)',regex = False)]\n",
    "data_magento = data_magento[~data_magento['SKU'].astype(str).isin(skushopee['SKU'].astype(str))]\n",
    "data_magento = data_magento[~data_magento['SKU'].astype(str).isin(skuhd['SKU'].astype(str))]\n",
    "\n",
    "skuhd = skuhd.reset_index(drop = True)\n",
    "skushopee = skushopee.reset_index(drop = True)\n",
    "data_magento = data_magento.reset_index(drop = True)\n",
    "\n",
    "indeks = data_magento[~data_magento['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))]['SKU'].index.to_list()\n",
    "for i in indeks:\n",
    "    if data_magento['Product Name'][i].lower() in data_SKU['Nama Produk'].str.lower().values:\n",
    "        data_magento['SKU'][i] = data_SKU['SKU'].loc[data_SKU['Nama Produk'].str.lower() == str(data_magento['Product Name'][i]).lower()].values[0]\n",
    "\n",
    "list_alias = []\n",
    "list_alias_name = []\n",
    "for colname in data_SKU.columns:\n",
    "    if 'Alias SKU' in colname:\n",
    "        list_alias.append(colname)\n",
    "    if 'Alias Nama' in colname:\n",
    "        list_alias_name.append(colname)\n",
    "\n",
    "for i in indeks:\n",
    "    for j in list_alias:\n",
    "        if str(data_magento['SKU'][i]) in data_SKU[j].astype(str).values:\n",
    "            idx = data_SKU[str(data_magento['SKU'][i]) == data_SKU[j].astype(str)].index.to_list()\n",
    "            for k in idx:\n",
    "                if str(data_magento['SKU'][i]) == data_SKU[j.replace('SKU', 'Nama')][k]:\n",
    "                    data_magento['SKU'][i] = data_SKU['SKU'][k]\n",
    "\n",
    "indeks = data_magento[~data_magento['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))]['SKU'].index.to_list()\n",
    "\n",
    "for i in indeks:\n",
    "    for j in list_alias_name:\n",
    "        if str(data_magento['Product Name'][i]).lower() in data_SKU[j].astype(str).str.lower().values:\n",
    "            data_magento['SKU'][i] = data_SKU['SKU'].loc[str(data_magento['Product Name'][i]).lower() == data_SKU[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'WRP Everyday Low Fat Milk Coklat 4 Pillow Bag']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Kitchen Vietnamese Coffee Latte (12 Sch)']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Blush Yo Raspberry Pumpkin (24 pcs)']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Blush Yo Raspberry Pumpkin (1 pc)']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Kitchen Thai Tea Latte (12 Sch)']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Blush Greek Yogurt Blueberry (24 Pcs)']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Blush Greek Yogurt Blueberry']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Blush Yo Lychee Spinach (24 Pcs)']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Blush Yo Lychee Spinach (1 pc)']\n",
    "\n",
    "\n",
    "\n",
    "data_magento['SKU'] = data_magento['SKU'].astype(str).str.replace('7300281P24', '7300281')\n",
    "\n",
    "data_magento = data_magento[~data_magento['Product Name'].astype(str).str.contains('JANGAN DIORDER INI TESTING')]\n",
    "data_magento = data_magento[~data_magento['SKU'].astype(str).str.contains('7300851')]\n",
    "data_magento = data_magento[~data_magento['SKU'].astype(str).str.contains('F0301002006')]\n",
    "data_magento = data_magento[~data_magento['SKU'].astype(str).str.contains('F0302004002')]\n",
    "data_magento = data_magento[~data_magento['SKU'].astype(str).str.contains('F0301002005P24')]\n",
    "data_magento = data_magento[~data_magento['SKU'].astype(str).str.contains('F0301002005')]\n",
    "\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Listing SKU Missing ====== 4/10\")   \n",
    "idx = data_magento[['SKU']][data_magento['SKU'].isnull()].drop_duplicates().index.to_list()\n",
    "idx = idx + data_magento[['SKU', 'Product Name']][~data_magento['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "idx = list(dict.fromkeys(idx))\n",
    "idx_s = skushopee[~skushopee['SKU'].astype(str).str.replace('(S)','', regex = False).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "idx_s = list(dict.fromkeys(idx_s))\n",
    "idx_hd = skuhd[~skuhd['SKU'].astype(str).str.replace('hd','',case = False).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "idx_hd = list(dict.fromkeys(idx_hd))\n",
    "\n",
    "to_excel = data_magento.to_excel(r'magento_new.xls', index = False)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "if len(idx) != 0 or len(idx_s) != 0 or len(idx_hd) != 0:\n",
    "    print('SKU is missing')\n",
    "    alert = data_magento.iloc[idx, ][['SKU', 'Product Name']].drop_duplicates()\n",
    "    alert = alert.append(skushopee.iloc[idx_s][['SKU', 'Product Name']].drop_duplicates(), ignore_index = True, sort = False)\n",
    "    alert['SKU Valid'] = np.nan\n",
    "    to_excel = alert.to_excel('ALERT_MAGENTO_SKU_MISSING.xlsx')\n",
    "    print(\"Some SKU Missing Please Complete It ====== 5/10\")\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    s = smtplib.SMTP('smtp.gmail.com', 587) \n",
    "\n",
    "    # start TLS for security \n",
    "    s.starttls() \n",
    "\n",
    "    # Authentication \n",
    "    s.login(\"automationnfi@gmail.com\", \"nutrifood2020\") \n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['Subject'] = \"ALERT SKU MAGENTO MISSING\"\n",
    "\n",
    "\n",
    "    html = \"\"\"\\\n",
    "    <html>\n",
    "    <head></head>\n",
    "    <body>\n",
    "        {0}\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\".format(alert.to_html())\n",
    "\n",
    "    part1 = MIMEText(html, 'html')\n",
    "    msg.attach(part1)\n",
    "\n",
    "    # sending the mail \n",
    "    s.sendmail(\"automationnfi@gmail.com\", \"andra.miftah@nutrifood.co.id\", msg.as_string()) \n",
    "\n",
    "    # terminating the session \n",
    "    s.quit()\n",
    "else :\n",
    "    print(\"Preparing Appending Magento to Masterdata\")\n",
    "    print(\"Filling Brand ====== 5/10\")  \n",
    "    data_magento = data_magento.append(skushopee, ignore_index = True, sort = False)\n",
    "    data_magento = data_magento.reset_index(drop = True)\n",
    "\n",
    "    data_magento['SKU'] = data_magento['SKU'].astype(str)\n",
    "    data_magento['Product Name'] = data_magento['Product Name'].astype(str)\n",
    "    data_SKU['Real SKU'] = data_SKU['SKU'].astype(str)\n",
    "    data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "\n",
    "    data_magento = data_magento.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "    temp = data_magento[data_magento['Real SKU'].isnull()].copy()\n",
    "    temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "    temp = temp.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "    temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "    temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "    temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "    temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "    indeks = data_magento[data_magento['Real SKU'].isnull()].index.to_list()\n",
    "    data_magento['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "    data_magento['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "    temp = data_magento[data_magento['Real SKU'].isnull()].copy()\n",
    "    temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "    temp = temp.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "    temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "    temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "    temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "    temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "    indeks = data_magento[data_magento['Real SKU'].isnull()].index.to_list()\n",
    "    data_magento['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "    data_magento['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "    data_magento['Real SKU'] = data_magento['Real SKU'].astype(str)\n",
    "    data_magento = data_magento.merge(data_SKU[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "    data_magento = data_magento.drop(['SKU_y'], axis = 1)\n",
    "    data_magento = data_magento.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"Unbundling ====== 6/10\")\n",
    "    list_col = ['SKU'] + data_SKU.columns[data_SKU.columns.get_loc('Produk 1'):data_SKU.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "    data_magento = data_magento.merge(data_SKU[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "    data_magento = data_magento.drop(['SKU_y'], axis = 1)\n",
    "    data_magento = data_magento.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "    indeks = data_magento[data_magento['Brand'] == 'Bundle'].index.to_list()\n",
    "    data_magento['Bundle Flag'] = np.nan\n",
    "    data_magento['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"Filling Date ====== 7/10\")\n",
    "    data_magento['Date'] = np.nan\n",
    "    data_magento['Month'] = np.nan\n",
    "    data_magento['Year'] = np.nan\n",
    "\n",
    "    for i in range(data_magento.shape[0]):\n",
    "        if int(data_magento['Order date'][i].strftime('%d')) <= 12:\n",
    "            data_magento['Date'][i] = pd.to_datetime(data_magento['Order date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "            data_magento['Month'][i] = pd.to_datetime(data_magento['Order date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "            data_magento['Year'][i] = pd.to_datetime(data_magento['Order date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "        else :\n",
    "            data_magento['Date'][i] = pd.to_datetime(data_magento['Order date'][i]).day\n",
    "            data_magento['Month'][i] = pd.to_datetime(data_magento['Order date'][i]).month_name()\n",
    "            data_magento['Year'][i] = pd.to_datetime(data_magento['Order date'][i]).year\n",
    "\n",
    "\n",
    "    quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "            ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "    data_magento = data_magento.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "    data_magento = data_magento.drop(['Bulan'], axis = 1)\n",
    "    data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "            {'Bulan' : 'January' , 'Number': 1},\n",
    "            {'Bulan' : 'February' , 'Number': 2},\n",
    "            {'Bulan' : 'March' , 'Number': 3},\n",
    "            {'Bulan' : 'April' , 'Number': 4},\n",
    "            {'Bulan' : 'May' , 'Number': 5},\n",
    "            {'Bulan' : 'June', 'Number': 6},\n",
    "            {'Bulan' : 'July' , 'Number': 7},\n",
    "            {'Bulan' : 'August', 'Number' : 8},\n",
    "            {'Bulan' : 'September', 'Number' : 9},\n",
    "            {'Bulan' : 'October' , 'Number': 10},\n",
    "            {'Bulan' : 'November' , 'Number': 11}])\n",
    "    temp = data_magento.copy()\n",
    "    temp['Day'] = temp['Date']\n",
    "    temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "    temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "    data_magento['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "    data_magento['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day']])\n",
    "    data_magento['Channel'] = 'Nutrimart'\n",
    "    data_magento['Store'] = 'Nutrimart'\n",
    "    data_magento['Selling Price'] = data_magento['Item Price']\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"Pricing\")\n",
    "    data_magento = data_magento.merge(data_SKU[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(data_magento.index)\n",
    "    data_magento = data_magento.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "    data_magento['Price List NFI'] = pd.to_numeric(data_magento['Price List NFI']).astype(int)\n",
    "    data_magento['Harga Cost'] = pd.to_numeric(data_magento['Harga Cost'], errors = 'coerce').fillna(0).astype(int)\n",
    "    data_magento['Qty. Invoiced'] = pd.to_numeric(data_magento['Qty. Invoiced']).astype(int)\n",
    "    data_magento['Total Net'] = data_magento['Price List NFI'] * data_magento['Qty. Invoiced']\n",
    "    data_magento['Total Harga Cost'] = data_magento['Harga Cost'] * data_magento['Qty. Invoiced']\n",
    "\n",
    "    data_magento = data_magento.drop('SKU_y', axis = 1)\n",
    "    data_magento = data_magento.reset_index(drop = True)\n",
    "    data_magento['Order #'] = data_magento['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "    list_bundle = data_magento[data_magento['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "    list_nobundle = data_magento[data_magento['Bundle Name'].notnull()]\n",
    "    list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "    list_nobundle\n",
    "\n",
    "    data_magento['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "    data_magento['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "    temp = data_magento[data_magento['Bundle Name'].notnull()]\n",
    "    temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "    temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "    temp['Selling Price'] = temp['Subtotal'] / temp['Qty. Invoiced']\n",
    "\n",
    "    data_magento['Total'][temp.index] = temp['Total'].fillna(0).astype(int)\n",
    "    data_magento['Subtotal'][temp.index] = temp['Subtotal'].fillna(0).astype(int)\n",
    "    data_magento['Selling Price'][temp.index] = temp['Selling Price'].fillna(0).astype(int)\n",
    "\n",
    "    print(\"Filling Location\")\n",
    "    data_magento['Kecamatan'] = np.nan\n",
    "    data_magento['Kelurahan'] = np.nan\n",
    "\n",
    "    indeks = data_magento[data_magento['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        data_magento['Kecamatan'][indeks] = data_magento['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "        data_magento['City'][indeks] = data_magento['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "    indeks = data_magento[data_magento['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        data_magento['Kelurahan'][indeks] = data_magento['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "        data_magento['Kecamatan'][indeks] = data_magento['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "    indeks = data_magento[data_magento['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        data_magento['Kecamatan'][indeks] = data_magento['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "        data_magento['City'][indeks] = data_magento['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "    indeks = data_magento[data_magento['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        data_magento['Kelurahan'][indeks] = data_magento['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "        data_magento['Kecamatan'][indeks] = data_magento['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "    city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "    temp = data_magento.copy()\n",
    "    temp['City'] = temp['City'].astype(str).str.lower()\n",
    "    city['All City'] = city['All City'].astype(str).str.lower()\n",
    "    temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "    indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "    data_magento['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "    province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "    temp = data_magento.copy()\n",
    "    temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "    province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "    temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "    indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "    data_magento['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "    temp = data_magento.copy()\n",
    "    temp = temp[temp['Region'].isnull()]\n",
    "    temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "    data_magento['Region'][temp.index] = temp['Region']\n",
    "\n",
    "    district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "    temp = data_magento.copy()\n",
    "    temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "    district['All District'] = district['All District'].astype(str).str.lower()\n",
    "    temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "    indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "    data_magento['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "    temp = data_magento.copy()\n",
    "    temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "    indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "    data_magento['City'][indeks] = np.nan\n",
    "\n",
    "    indeks = data_magento[data_magento['Shipping City'].astype(str).str.contains('/')]['Shipping City'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        data_magento['Shipping City'][indeks] = data_magento['Shipping City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "    indeks = data_magento[data_magento['Shipping City'].astype(str).str.contains(',')]['Shipping City'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        data_magento['Shipping City'][indeks] = data_magento['Shipping City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "    city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "    temp = data_magento.copy()\n",
    "    temp['Shipping City'] = temp['Shipping City'].astype(str).str.lower()\n",
    "    city['All City'] = city['All City'].astype(str).str.lower()\n",
    "    temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'Shipping City', right_on = 'All City').set_index(temp.index)\n",
    "    indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "    data_magento['Shipping City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "    province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "    temp = data_magento.copy()\n",
    "    temp['Shipping Province'] = temp['Shipping Province'].astype(str).str.lower()\n",
    "    province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "    temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Shipping Province', right_on = 'All Province').set_index(temp.index)\n",
    "    indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "    data_magento['Shipping Province'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "    temp = data_magento.copy()\n",
    "    temp = temp[temp['Shipping Province'].isnull()]\n",
    "    temp['Shipping Province'] = temp.merge(master_map, how = 'left', left_on = 'Shipping City', right_on = 'City').set_index(temp.index)['Shipping Province']\n",
    "    data_magento['Shipping Province'][temp.index] = temp['Shipping Province']\n",
    "\n",
    "    temp = data_magento.copy()\n",
    "    temp2 = temp[['Shipping Province', 'Shipping City']].merge(master_map, how = 'left', left_on = 'Shipping City', right_on = 'City')\n",
    "    indeks = temp2[temp2['Shipping Province'] != temp2['Province']][temp2[temp2['Shipping Province'] != temp2['Province']]['Shipping City'].notnull()].index.to_list()\n",
    "    data_magento['Shipping City'][indeks] = np.nan\n",
    "    data_magento['Warehouse Name'] = 'Primary Warehouse'\n",
    "\n",
    "    import os\n",
    "    import glob\n",
    "\n",
    "    list_of_files = glob.glob('D:\\Masterdata\\Clean Data\\*.csv')\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "\n",
    "    data_all = pd.read_csv(latest_file, sep = ';',converters = {'Phone' : str, 'Order #' : str, 'AWB' : str})\n",
    "    #data_all = pd.read_csv(r\"D:\\Masterdata\\Clean Data\\data_all_3 November With Order Online.csv\", sep = ';',converters = {'Phone' : str, 'Order #' : str, 'AWB' : str})\n",
    "    \n",
    "    data_all = data_all[data_all['Store Type'] != 'Retail Online']\n",
    "\n",
    "    data_all['Phone'] = data_all['Phone'].astype(str).str.replace('=\"', '', regex = False)\n",
    "    data_all['Phone'] = data_all['Phone'].astype(str).str.replace('\"', '', regex = False)\n",
    "\n",
    "    lmen_store = forstok_all[forstok_all['Channel'] == 'L-Men Store Blibli']\n",
    "\n",
    "    lmen_store = lmen_store[~lmen_store['Order #'].astype(str).isin(data_all['Order #'].astype(str))]\n",
    "    lmen_store['Sales Order ID'] = lmen_store['Sales Order ID'].fillna(lmen_store['No. Order Item L-Men Blibli'])\n",
    "    ornum = lmen_store[['Order #', 'Sales Order ID']].drop_duplicates('Order #')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": str(os.getcwd())  + '/Input Data',\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.maximize_window()\n",
    "    driver.get(\"https://seller.blibli.com/sign-in\")\n",
    "    time.sleep(30)\n",
    "\n",
    "\n",
    "    username = driver.find_element(By.ID, \"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customer1@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element(By.ID, \"password\")\n",
    "    password.send_keys(\"NutrimartNutrif00d\")\n",
    "\n",
    "    driver.find_element(By.ID, \"sign-in\").click()\n",
    "    time.sleep(25)\n",
    "\n",
    "    driver.get(\"https://seller.blibli.com/MTA/order/summary\")\n",
    "    WebDriverWait(driver, 40).until(EC.presence_of_element_located((By.CLASS_NAME, 'btn-primary-mta'))).click()\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"semuaFilter\"]/span[1]').click()\n",
    "\n",
    "    ornum['Phone'] = np.nan\n",
    "    ornum['Email'] = np.nan\n",
    "    ornum['Address'] = np.nan\n",
    "\n",
    "    for i in ornum.index:\n",
    "        orderNo = ornum['Order #'][i]\n",
    "        orderItemNo = int(pd.to_numeric(ornum['Sales Order ID'][i]))\n",
    "        link = \"https://seller.blibli.com/MTA/neo/order/order-detail/\" + \"?orderNo=\" + str(orderNo) + \"&orderItemNo=\" + str(orderItemNo)\n",
    "        driver.get(link)\n",
    "        WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"customer-phone\"]/div/span')))\n",
    "        hp = driver.find_elements(By.XPATH, '//*[@id=\"customer-phone\"]/div/span')[0].text\n",
    "        if len(driver.find_elements(By.XPATH, '//*[@id=\"customer-email\"]/span')) != 0:\n",
    "            email = driver.find_elements(By.XPATH, '//*[@id=\"customer-email\"]/span')[0].text\n",
    "            ornum['Email'][i] = email\n",
    "        address = driver.find_elements(By.XPATH, '//*[@id=\"alamat-pengiriman\"]//div//p')[0].text\n",
    "        ornum['Phone'][i] = hp\n",
    "        ornum['Address'][i] = address\n",
    "\n",
    "    driver.quit()\n",
    "    if len(ornum) != 0:\n",
    "        tes = ornum.copy()\n",
    "        tes['Real Address'] = tes['Address'].str.split('\\n', expand = True)[1].str.strip()\n",
    "        tes['Kelurahan'] = tes['Address'].str.split('\\n', expand = True)[3].str.split('-', expand = True)[0].str.strip()\n",
    "        tes['Kecamatan'] = tes['Address'].str.split('\\n', expand = True)[3].str.split('-', expand = True)[1].str.strip()\n",
    "        tes['City'] = tes['Address'].str.split('\\n', expand = True)[4].str.split(',', expand = True)[0].str.strip()\n",
    "        tes['Region'] = tes['Address'].str.split('\\n', expand = True)[4].str.split(',', expand = True)[1].str.strip()\n",
    "        tes['Zip Code'] = tes['Address'].str.split('\\n', expand = True)[5].str.strip()\n",
    "\n",
    "        lmen_store['Order #'] = lmen_store['Order #'].astype(str)\n",
    "        tes['Order #'] = tes['Order #'].astype(str)\n",
    "        lmen_store = lmen_store.merge(tes[['Order #', 'Phone', 'Email', 'Real Address', 'Kelurahan', 'Kecamatan', 'City', 'Region', 'Zip Code']].drop_duplicates('Order #'), how = 'left', on = 'Order #')\n",
    "\n",
    "        indeks = lmen_store[lmen_store['Phone_y'].notnull()].index.to_list()\n",
    "        lmen_store['Phone_x'][indeks] = lmen_store['Phone_y'][indeks]\n",
    "        lmen_store['Customer Email'][indeks] = lmen_store['Email'][indeks]\n",
    "        lmen_store['Phone_x'][indeks] = lmen_store['Phone_y'][indeks]\n",
    "        lmen_store['Region_x'][indeks] = lmen_store['Region_y'][indeks]\n",
    "        lmen_store['City_x'][indeks] = lmen_store['City_y'][indeks]\n",
    "        lmen_store['Kecamatan_x'][indeks] = lmen_store['Kecamatan_y'][indeks]\n",
    "        lmen_store['Kelurahan_x'][indeks] = lmen_store['Kelurahan_y'][indeks]\n",
    "        lmen_store['Zip Code_x'][indeks] = lmen_store['Zip Code_y'][indeks]\n",
    "        lmen_store['Address'][indeks] = lmen_store['Real Address'][indeks]\n",
    "\n",
    "        lmen_store = lmen_store.drop(['Phone_y', 'Email', 'Region_y', 'City_y', 'Kecamatan_y', 'Kelurahan_y', 'Real Address', 'Zip Code_y'], axis = 1)\n",
    "        lmen_store = lmen_store.rename(columns = {'Phone_x' : 'Phone', 'Region_x' : 'Region', 'City_x' : 'City', 'Kecamatan_x' : 'Kecamatan', 'Kelurahan_x' : 'Kelurahan', 'Zip Code_x' : 'Zip Code'})\n",
    "\n",
    "    forstok_all = forstok_all[forstok_all['Channel'] != 'L-Men Store Blibli']\n",
    "    forstok_all = forstok_all.append(lmen_store, ignore_index = True, sort = False)\n",
    "\n",
    "    indeks = data_all[data_all['Channel'] == 'L-Men Store Blibli'].index.to_list()\n",
    "    data_all['Store'][indeks] = 'Blibli'\n",
    "\n",
    "    print('Blibli Done')\n",
    "    \n",
    "    #UNBUNDLING (J)\n",
    "    print('Unbundling Paket J')\n",
    "    \n",
    "    skuj = pd.read_excel(r\"C:\\Users\\steven.nathanael\\Documents\\Python\\Data\\2. Master Data Git\\data_supp\\Rumus Realisasi.xlsx\")\n",
    "    skuj = skuj[['SKU','Nama Paket','SKU.1','Konversi ke UOM']]\n",
    "    skuj.rename(columns = {'SKU' : 'Bundle SKU',\n",
    "                           'Nama Paket' : 'Bundle Name',\n",
    "                           'SKU.1' : 'Real SKU',\n",
    "                           'Konversi ke UOM' : 'Qty Bundle'}, inplace = True)\n",
    "    skuj['Real SKU'] = skuj['Real SKU'].astype(str)\n",
    "\n",
    "    # data_SKU['Real SKU'] = data_SKU['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "    # data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "\n",
    "    skuj2 = pd.merge(skuj,data_SKU[['Real SKU','Brand','Real Nama Produk','Price List NFI','Sub Brand', 'Parent Item', 'Parent SKU']], on = 'Real SKU', how = 'left')\n",
    "    skuj2.rename(columns = {'Real SKU' : 'Real SKU.1',\n",
    "                            'Brand' : 'Brand.1',\n",
    "                            'Real Nama Produk' : 'Real Nama Produk.1',\n",
    "                            'Price List NFI' : 'Price List NFI.1',\n",
    "                            'Sub Brand' : 'Sub Brand.1',\n",
    "                            'Parent Item' : 'Parent Item.1',\n",
    "                            'Parent SKU' : 'Parent SKU.1'}, inplace = True)\n",
    "\n",
    "    skuj1 = skuj['Bundle SKU'].unique()\n",
    "    skuj3 = skuj['Bundle Name'].unique()\n",
    "\n",
    "    tes = forstok_all[forstok_all['Real SKU'].isin(skuj1)]\n",
    "    tes['Bundle SKU'] = tes['Real SKU']\n",
    "    tes1 = pd.merge(tes, skuj2, on = 'Bundle SKU', how = 'left')\n",
    "\n",
    "    tes1['Real SKU'] = tes1['Real SKU.1'].astype(str)\n",
    "    tes1['Real Nama Produk'] = tes1['Real Nama Produk.1']\n",
    "    tes1['Qty. Invoiced.1'] = tes1['Qty. Invoiced'] * tes1['Qty Bundle']\n",
    "    tes1['Qty. Invoiced'] = pd.to_numeric(tes1['Qty. Invoiced.1'])\n",
    "    tes1['Brand'] = tes1['Brand.1']\n",
    "    tes1['Sub Brand'] = tes1['Sub Brand.1']\n",
    "    tes1['Real Nama Produk'] = tes1['Real Nama Produk.1']\n",
    "    tes1['Parent Item'] = tes1['Parent Item.1']\n",
    "    tes1['Parent SKU'] = tes1['Parent SKU.1'].astype(str)\n",
    "    tes1['Price List NFI'] = pd.to_numeric(tes1['Price List NFI.1'].astype(int))\n",
    "\n",
    "    tes1.rename(columns = {'Bundle Name_x' : 'Bundle Name'}, inplace = True)\n",
    "    tes1['Bundle Name'] = tes1['Bundle Name_y']\n",
    "    tes1.drop(columns = ['Bundle SKU','Bundle Name_y','Real SKU.1','Real Nama Produk.1','Qty. Invoiced.1','Qty Bundle','Brand.1','Sub Brand.1','Real Nama Produk.1','Parent Item.1','Parent SKU.1','Price List NFI.1'], inplace = True)\n",
    "\n",
    "    tes1['Total Net'] = tes1['Price List NFI'] * tes1['Qty. Invoiced']\n",
    "    tes1['Harga Cost'] = tes1['Price List NFI']\n",
    "    tes1['Total Harga Cost'] = tes1['Total Net']\n",
    "\n",
    "    forstok_all.loc[forstok_all['Real SKU'].str.contains('J', na = False, case = False),'Brand']= 'Bundle'\n",
    "    forstok_all.loc[forstok_all['Real SKU'].str.contains('J', na = False, case = False),'Sub Brand']= np.nan\n",
    "    forstok_all.loc[forstok_all['Real SKU'].str.contains('J', na = False, case = False),'Bundle Flag']= 'Bundle J'\n",
    "    forstok_all = forstok_all.append(tes1, ignore_index = True)\n",
    "    \n",
    "    print('Done')\n",
    "    \n",
    "    #GABUNG MASTERDATA\n",
    "    data_all = data_all[~data_all['Order #'].astype(str).isin(forstok_all['Order #'].astype(str))]\n",
    "    data_all = data_all[~data_all['Order #'].astype(str).isin(data_magento['Order #'].astype(str))]\n",
    "    data_all = data_all.append(forstok_all, ignore_index = True, sort = False)\n",
    "    data_all = data_all.append(data_magento, ignore_index = True, sort = False)\n",
    "    data_all['Brand'] = data_all['Brand'].astype(str).str.replace('Tropicana Slim', 'TS')\n",
    "\n",
    "    indeks = data_all[data_all['Qty. Invoiced'] == 0].index.to_list()\n",
    "    data_all['Qty. Invoiced'][indeks] = data_all['Qty. Shipped'][indeks]\n",
    "    data_all['Total Net'][indeks] = data_all['Price List NFI'][indeks] * data_all['Qty. Invoiced'][indeks]\n",
    "    indeks = data_all[data_all['Qty. Invoiced'] == 0].index.to_list()\n",
    "    data_all['Qty. Invoiced'][indeks] = data_all['Qty. Ordered'][indeks]\n",
    "    data_all['Total Net'][indeks] = data_all['Price List NFI'][indeks] * data_all['Qty. Invoiced'][indeks]\n",
    "\n",
    "# #   Cleaning Phone Number\n",
    "    import re \n",
    "    from re import sub            \n",
    "    data_all['Phone'] = data_all['Phone'].astype(str).str.split(';', expand = True)[0]\n",
    "    data_all['Phone'] = data_all['Phone'].astype(str).str.replace('.0','', regex = False)\n",
    "    data_all['Phone'] = data_all['Phone'].astype(str).str.replace('+','', regex = False)\n",
    "    non_phone = data_all[(data_all['Phone'].astype(str).str.startswith('62'))]['Phone'].unique()\n",
    "    non_phone1 = data_all[(data_all['Phone'].astype(str).str.startswith('62'))][['Store','Phone']].drop_duplicates()\n",
    "    for i in non_phone:\n",
    "        index = data_all[data_all['Phone'].astype(str) == str(i)].index.to_list()\n",
    "        phone = str(i).replace('62','0', 1)\n",
    "        print(i, phone, sep='-')\n",
    "        data_all['Phone'][index] = phone\n",
    "      \n",
    "    \n",
    "    print('done')\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    data_all['Phone'] = data_all['Phone'].apply('=\"{}\"'.format)\n",
    "    data_all['Shipping Phone'] = data_all['Shipping Phone'].apply('=\"{}\"'.format)\n",
    "    indeks = data_all[data_all['City'] == 'nan'].index.to_list()\n",
    "    data_all['City'][indeks] = np.nan\n",
    "\n",
    "    indeks = data_all[data_all['Region'] == 'nan'].index.to_list()\n",
    "    data_all['Region'][indeks] = np.nan\n",
    "\n",
    "    indeks = data_all[data_all['Channel'] == 'FBL'].index.to_list()\n",
    "    data_all['Warehouse Name'][indeks] = 'Lazada Warehouse'\n",
    "\n",
    "    indeks = data_all[data_all['Warehouse Name'] == 'Lazada Warehouse'].index.to_list()\n",
    "    data_all['Channel'][indeks] = 'FBL'\n",
    "\n",
    "    print(\"Read Data Settlement\")\n",
    "    \n",
    "    #EDIT KHUSUS PERIOD FORSTOK\n",
    "    from datetime import datetime, timedelta\n",
    "    start_date = datetime.today() - timedelta(days=12)\n",
    "    end_date = datetime.today()\n",
    "    \n",
    "    print('Opening Chrome')\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    actions = ActionChains(driver)\n",
    "    driver.get(\"https://www.forstok.com/dashboard/users/login\")\n",
    "    print('Login Forstok')\n",
    "    \n",
    "    time.sleep(10)\n",
    "    print('input email')\n",
    "    username = driver.find_element(By.NAME, \"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"timotius.giovandi@nutrifood.co.id\")\n",
    "\n",
    "    print('input password')\n",
    "    password = driver.find_element(By.NAME, \"password\")\n",
    "    password.send_keys(\"timo123\")\n",
    "    \n",
    "    print('click')\n",
    "    driver.find_element(By.XPATH, \"/html/body/div[1]/div/div/div/form/input[3]\").click()\n",
    "    \n",
    "    #time.sleep(30)\n",
    "    #driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    #print('scroll down')\n",
    "    time.sleep(10)\n",
    "    datefield = WebDriverWait(driver, 100).until(EC.element_to_be_clickable((By.XPATH,'html/body/div[1]/section/section[2]/article/div/div/aside/div/div[1]/section[4]/div/button')))\n",
    "    time.sleep(20)\n",
    "    #datef = WebDriverWait(driver, 100).until(EC.element_to_be_clickable((By.XPATH,'///html/body/div[1]/section/section[2]/article/div/div/aside/div/div[1]/section[5]/div/section/h2')))\n",
    "    #driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datef)\n",
    "    time.sleep(20)\n",
    "    driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "    time.sleep(10)\n",
    "    driver.find_element(By.XPATH, \"/html/body/div[1]/section/section[2]/article/div/div/aside/div/div[1]/section[4]/div/button\").click()\n",
    "    time.sleep(10)\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"exportSalesOrderForm\"]/div/section/section/div[1]/section/article/article[1]/div/section/div/div[2]').click()\n",
    "    #datefield.click()\n",
    "    pilih=0\n",
    "    while pilih < 3:    \n",
    "            n_elem=0\n",
    "            for i in driver.find_elements(By.XPATH, '(//*[@class=\"DateRangePicker__MonthHeaderLabel DateRangePicker__MonthHeaderLabel--month\"])'):\n",
    "                val=(driver.find_elements(By.XPATH, '(//*[@class=\"DateRangePicker__MonthHeaderLabel DateRangePicker__MonthHeaderLabel--month\"])')[n_elem].text.split()[0])\n",
    "                if val==start_date.strftime('%B'):\n",
    "                    # print(n_elem)\n",
    "                    fin_n_elem=n_elem\n",
    "                n_elem=n_elem+1\n",
    "            if fin_n_elem==0:\n",
    "                text = '(//*[@class=\"DateRangePicker__Month\"])[1]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(start_date.day) + '\")]'\n",
    "                if len(driver.find_elements(By.XPATH, text))==2:\n",
    "                    text = '('+text+')[2]'\n",
    "            else:\n",
    "                text = '(//*[@class=\"DateRangePicker__Month\"])[2]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(start_date.day) + '\")]'\n",
    "                if len(driver.find_elements(By.XPATH, text))==2:\n",
    "                    text = '('+text+')[1]'\n",
    "            driver.find_element(By.XPATH, text).click()\n",
    "            time.sleep(10)\n",
    "    \n",
    "            n_elem=0\n",
    "            for i in driver.find_elements(By.XPATH, '(//*[@class=\"DateRangePicker__MonthHeaderLabel DateRangePicker__MonthHeaderLabel--month\"])'):\n",
    "                val=(driver.find_elements(By.XPATH, '(//*[@class=\"DateRangePicker__MonthHeaderLabel DateRangePicker__MonthHeaderLabel--month\"])')[n_elem].text.split()[0])\n",
    "                if val==end_date.strftime('%B'):\n",
    "                    fin_n_elem=n_elem\n",
    "                n_elem=n_elem+1\n",
    "            if fin_n_elem==0:\n",
    "                text = '(//*[@class=\"DateRangePicker__Month\"])[1]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(end_date.day) + '\")]'\n",
    "                if len(driver.find_elements(By.XPATH, text))==2:\n",
    "                    text = '('+text+')[2]'\n",
    "            else:\n",
    "                text = '(//*[@class=\"DateRangePicker__Month\"])[2]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(end_date.day) + '\")]'\n",
    "                if end_date.strftime('%B')==start_date.strftime('%B'):\n",
    "                    text = '('+text+')'#[2]\n",
    "                else :\n",
    "                    text = '('+text+')[1]'\n",
    "            driver.find_element(By.XPATH, text).click()\n",
    "            time.sleep(10)\n",
    "            pilih=pilih+1\n",
    "    driver.find_element(By.XPATH, '//*[@type=\"button\" and contains(text(),\"Apply\")]').click()\n",
    "    time.sleep(30)\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/section/section[2]/div/form/div/section/section/div[2]/aside[2]/button[2]').click()\n",
    "    #WebDriverWait(driver, 30).until(EC.element_to_be_clickable((By.XPATH, \"(//*[@type='button' and contains(text(),'Save')])\"))).click()\n",
    "    #driver.find_element(By.XPATH, '//span[text()=\"Sales Order v2\"]').click()\n",
    "    #driver.find_element(By.XPATH, '//span[text()=\"Sales Order v2\"]').click()\n",
    "    #WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"(//*[@type='button' and contains(text(),'Export')])[2]\"))).click()\n",
    "    time.sleep(2)\n",
    "    driver.quit()\n",
    "    \n",
    "    print('Forstok Downloaded')\n",
    "\n",
    "    print('Download Data SKU')\n",
    "    # Import library\n",
    "\n",
    "    import time\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import math\n",
    "\n",
    "    import smtplib \n",
    "    from email.mime.text import MIMEText\n",
    "    from email.mime.application import MIMEApplication\n",
    "    from email.mime.multipart import MIMEMultipart\n",
    "    from smtplib import SMTP\n",
    "    import smtplib\n",
    "    import sys\n",
    "    import requests\n",
    "    import os\n",
    "\n",
    "    startdate = start_date-timedelta(days=1)\n",
    "    startdate1 = startdate.strftime(\"%Y-%m-%d\")\n",
    "    enddate = end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    text = 'https://forstok-staging-storage.s3.ap-southeast-1.amazonaws.com/items_import/Nutrifood-forstok-sales_orders-version_2-' + startdate1 + 'T17:00:00Z-' + enddate + 'T16:59:59Z.xlsx'\n",
    "    print(text)\n",
    "    while True:\n",
    "        r = s.get(text)\n",
    "        print('Waiting to Download Forstok 2')\n",
    "\n",
    "        if r.status_code == requests.codes.ok:\n",
    "            print(r.status_code)\n",
    "            with open('Input Data/Forstok_new_input.xls', 'wb') as output:\n",
    "                output.write(r.content)\n",
    "            print('output out')\n",
    "            break\n",
    "        else :\n",
    "            time.sleep(30)\n",
    "\n",
    "    with open('Input Data/nutrifood--forstok-sales_orders-' + str(date) + '.xls', 'wb') as output:\n",
    "        output.write(r.content)\n",
    "        \n",
    "    orstat_forstok = pd.read_excel(r'Input Data/Forstok_new_input.xls')\n",
    "    orstat_forstok['Date'] = np.nan\n",
    "    orstat_forstok['Month'] = np.nan\n",
    "    orstat_forstok['Year'] = np.nan\n",
    "\n",
    "#    orstat_forstok = pd.read_excel(r\"C:\\Users\\steven.nathanael\\Downloads\\Nutrifood-forstok-sales_orders-version_2-2023-05-14T17 00 00Z-2023-05-29T16 59 59Z.xlsx\")\n",
    "#    orstat_forstok = orstat_forstok[['Order Date', 'Channel', 'Store', 'Sales Order ID',\n",
    "#                             'Order Reference No.', 'Payment Status', 'Fulfillment Status', 'Payment Type',\n",
    "#                             'Payment Date', 'Shipping Label Printed Date', 'Shipped Date', 'Delivered Date',\n",
    "#                             'Cancelled Date', 'Return ID', 'Shipping Courier', 'Service Type', 'AWB', 'Customer Name',\n",
    "#                             'Customer Email', 'Currency Code', 'Item Name', 'SKU Code', 'Bundle SKU Code', 'Barcode ID',\n",
    "#                             'Warehouse Name', 'Warehouse Code', 'Quantity', 'Regular Price', 'Selling Price',\n",
    "#                             'Sub Total', 'VAT', 'Shipping Fee (Non-cashless)', 'Voucher Seller', 'Platform Rebate',\n",
    "#                             'Shipping Customer Name', 'Shipping Address1', 'Shipping Address2', 'Shipping City',\n",
    "#                             'Shipping Zip', 'Shipping Province', 'Shipping Country', 'Shipping Phone', 'Order Note',\n",
    "#                             'Invoice ID']]\n",
    "    orstat_forstok.rename(columns = {'Shipping Label Printed Date' : 'Printed Date',\n",
    "                              'Shipping Date' : 'Fulfilled Date',\n",
    "                              'SKU Code' : 'SKU',\n",
    "                              'Shipping Fee (Non-cashless)' : 'Shipping',\n",
    "                              'Voucher Seller' : 'Seller Voucher',\n",
    "                              'Platform Rebate' : 'Channel Rebate',\n",
    "                              'Order Note' : 'Note'}, inplace = True)\n",
    "    orstat_forstok[\"Order Date\"] = orstat_forstok[\"Order Date\"].str.replace('WIB', '')\n",
    "    orstat_forstok[\"Payment Date\"] = orstat_forstok[\"Payment Date\"].str.replace('WIB', '')\n",
    "    #orstat_forstok[\"Cancelled Date\"] = orstat_forstok[\"Cancelled Date\"].str.replace('WIB', '')\n",
    "\n",
    "    orstat_forstok['Order Date'] = pd.to_datetime(orstat_forstok['Order Date'])\n",
    "    for i in range(orstat_forstok.shape[0]):\n",
    "        if int(orstat_forstok['Order Date'][i].strftime('%d')) <= 12:\n",
    "            orstat_forstok['Date'][i] = pd.to_datetime(orstat_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "            orstat_forstok['Month'][i] = pd.to_datetime(orstat_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "            orstat_forstok['Year'][i] = pd.to_datetime(orstat_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "        else :\n",
    "            orstat_forstok['Date'][i] = pd.to_datetime(orstat_forstok['Order Date'][i]).day\n",
    "            orstat_forstok['Month'][i] = pd.to_datetime(orstat_forstok['Order Date'][i]).month_name()\n",
    "            orstat_forstok['Year'][i] = pd.to_datetime(orstat_forstok['Order Date'][i]).year\n",
    "\n",
    "    temp = orstat_forstok.copy()\n",
    "    temp['Day'] = temp['Date']\n",
    "    temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "    temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "    orstat_forstok['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "    temp['Hour'] = pd.to_datetime(orstat_forstok['Order Date']).dt.hour\n",
    "    temp['Minute'] = pd.to_datetime(orstat_forstok['Order Date']).dt.minute\n",
    "    temp['Second'] = pd.to_datetime(orstat_forstok['Order Date']).dt.second\n",
    "    orstat_forstok['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "    print(\"Update Order Status\")\n",
    "    date_min  = orstat_forstok['True datetime'].min()\n",
    "    orstat_forstok = orstat_forstok[['Sales Order ID','Fulfillment Status']].drop_duplicates('Sales Order ID')\n",
    "    shopee_bp = data_all[data_all['Customer Name'] == 'Shopee Brand Portal']\n",
    "    data_all = data_all[data_all['Customer Name'] != 'Shopee Brand Portal']\n",
    "    data_all['True datetime1'] = pd.to_datetime(data_all['True datetime'])\n",
    "    temp_all = data_all[data_all['True datetime1'] >= pd.to_datetime(date_min)][~data_all[data_all['True datetime1'] >= pd.to_datetime(date_min)]['Channel'].isin(['Nutrimart', 'L-Men Store Blibli', 'Order Online', 'Order Online Jakarta', 'Order Online Surabaya'])]\n",
    "    orstat_forstok['Sales Order ID'] = orstat_forstok['Sales Order ID'].astype(str)\n",
    "    temp_all['Sales Order ID'] = temp_all['Sales Order ID'].astype(str)\n",
    "    temp_all = temp_all.merge(orstat_forstok, how = 'left', on = 'Sales Order ID')\n",
    "    temp_all['Fulfillment Status'] = temp_all['Fulfillment Status'].fillna('Canceled')\n",
    "    temp_all['Order Status'] = temp_all['Fulfillment Status']\n",
    "    temp_all = temp_all.drop('Fulfillment Status', axis = 1)\n",
    "    data_all['Order #'] = data_all['Order #'].astype(str)\n",
    "    temp_all['Order #'] = temp_all['Order #'].astype(str)\n",
    "    data_all = data_all[~data_all['Order #'].isin(temp_all['Order #'])]\n",
    "    data_all = data_all.append(temp_all, ignore_index = True, sort = False)\n",
    "    data_all = data_all.append(shopee_bp, ignore_index = True, sort = False)\n",
    "    print(\"Export Master Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513743bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642191c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac51de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee84240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2108ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0c6a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555a1ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2608fe27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               SKU                                 Product Name\n",
      "543  2101150180P12  Tropicana Slim Milk Skim Coffee 500gr (12D)\n",
      "['Tropicana Slim Milk Skim Coffee 500gr (12D)']\n"
     ]
    }
   ],
   "source": [
    "### if sku missing di magento\n",
    "### to do : listing di tatanama rerun kode atas Run -4 \n",
    "print(data_magento[~data_magento['SKU'].isin(data_SKU['SKU'])][['SKU','Product Name']].drop_duplicates())\n",
    "print(data_magento[~data_magento['SKU'].isin(data_SKU['SKU'])]['Product Name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f21c991f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Blibli', 'L-Men Store Blibli'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a17d3bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245a396a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6146dfcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78fd26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORAMI - Seminggu Sekali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2a97853e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbundling\n",
      "Empty DataFrame\n",
      "Columns: [SKU, Product Name]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_16836\\1850596331.py:167: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_16836\\1850596331.py:172: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  orami = orami.append(data_bundle, ignore_index = True, sort = False)\n"
     ]
    }
   ],
   "source": [
    "#ORAMI RUN 1 - Seminggu Sekali, Export 3 Minggu Sebelumnya\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from smtplib import SMTP\n",
    "import smtplib\n",
    "import sys\n",
    "import requests\n",
    "import os\n",
    "\n",
    "orami = pd.read_csv(r\"C:\\Users\\steven.nathanael\\Downloads\\OramiSeller_01092023-30092023.csv\", sep = \",\",converters = {'Phone' : str, 'AWB' : str})\n",
    "orami.drop(columns = 'Total', inplace = True)\n",
    "orami.rename(columns = {'Tanggal pesanan' : 'Order Date',\n",
    "                        'Nomor pesanan' : 'Order #',\n",
    "                        'Provinsi' : 'City',\n",
    "                        'Nama produk' : 'Product Name',\n",
    "                        'No. Resi' : 'AWB',\n",
    "                        'Nama customer' : 'Customer Name',\n",
    "                        'Alamat customer' : 'Address',\n",
    "                        'Kodepos' : 'Zip Code',\n",
    "                        'Metode pengiriman' : 'Shipping Courier',\n",
    "                        'Kuantitas' : 'Qty. Invoiced',\n",
    "                        'Voucher' : 'Coupon Code',\n",
    "                        'Total harga produk' : 'Total',\n",
    "                        'Status pesanan' : 'Order Status'}, inplace = True)\n",
    "orami['Qty. Invoiced'] = orami['Qty. Invoiced'].astype(int)\n",
    "orami['Total'].fillna(0, inplace = True)\n",
    "orami['Total'] = orami['Total'].astype(int)\n",
    "orami['Day'] = orami['Order Date'].str.slice(0, 3).astype(int)\n",
    "orami['Month'] = orami['Order Date'].str.slice(3, 6)\n",
    "orami['Month'] = orami['Month'].apply(lambda x : 'September' if x == 'Sep' else\n",
    "                                                 ('October' if x == 'Okt' else\n",
    "                                                 ('November' if x == 'Nov' else \n",
    "                                                 ('December' if x == 'Des' else\n",
    "                                                 ('January' if x == 'Jan' else\n",
    "                                                 ('February' if x == 'Feb' else\n",
    "                                                 ('March' if x == 'Mar' else\n",
    "                                                 ('April' if x == 'Apr' else\n",
    "                                                 ('May' if x == 'Mei' else\n",
    "                                                 ('June' if x == 'Jun' else\n",
    "                                                 ('July' if x == 'Jul' else 'August')))))))))))\n",
    "orami['Year'] = orami['Order Date'].str.slice(6, 11).astype(int)\n",
    "orami['month'] = orami['Month'].apply(lambda x : 9 if x == 'September' else\n",
    "                                                 (10 if x == 'October' else\n",
    "                                                 (11 if x == 'Novemer' else \n",
    "                                                 (12 if x == 'December' else\n",
    "                                                 (1 if x == 'January' else\n",
    "                                                 (2 if x == 'February' else\n",
    "                                                 (3 if x == 'March' else\n",
    "                                                 (4 if x == 'April' else\n",
    "                                                 (5 if x == 'May' else\n",
    "                                                 (6 if x == 'June' else\n",
    "                                                 (7 if x == 'July' else 8)))))))))))\n",
    "orami['Hour'] = orami['Order Date'].str.slice(12, 15).astype(int)\n",
    "orami['Minute'] = orami['Order Date'].str.slice(16, 19).astype(int)\n",
    "orami['True datetime'] = pd.to_datetime(orami[['Year','month','Day','Hour','Minute']])\n",
    "orami.rename(columns = {'Day' : 'Date'}, inplace = True)\n",
    "orami['Real SKU'] = orami['Product Name'].str.split('|').str[1].str.strip().astype(str)\n",
    "orami['SKU'] = orami['Real SKU']\n",
    "orami['Selling Price'] = orami['Total'] / orami['Qty. Invoiced']\n",
    "orami[['Store','Channel']] = 'Orami Shopping'\n",
    "\n",
    "orami.loc[orami['Product Name'].isin(['Free Spider Bottle - L-Men PlantProtein Ogura 2pcs']), 'Real SKU'] = 'PL24(2)G26'\n",
    "orami.loc[orami['Product Name'].isin(['Parsel Wonderful Sweetness']), 'Real SKU'] = '(J)71110127'\n",
    "orami.loc[orami['Product Name'].isin(['BUY 1 GET 1 - Tropicana Slim Mint Cocoa']), 'Real SKU'] = '2104148164P2'\n",
    "orami.loc[orami['Product Name'].isin(['Free Tupperware - HiLo Platinum Swiss Chocolate 420g']), 'Real SKU'] = 'PH22G184'\n",
    "orami.loc[orami['Product Name'].isin(['Buy 1 Get 1 Free - HiLo School Bubble Gum 500g']), 'Real SKU'] = '2101459180P2'\n",
    "orami.loc[orami['Product Name'].isin(['Free HiLo School RTD - HiLo Teen Strawberry Milkshake 500g']), 'Real SKU'] = 'PH78B104'\n",
    "orami.loc[orami['Product Name'].isin(['Free L-Men 2 GO - L-Men Lose Weight Chocolate Cereal 300g']), 'Real SKU'] = 'PL7B103'\n",
    "orami.loc[orami['Product Name'].isin(['HiLo Active Es Teler 175gr']), 'Real SKU'] = '2101413144'\n",
    "orami.loc[orami['Product Name'].isin(['Hampers Idul Fitri Lebaran NutriSari 25 Rasa (75s)']), 'Real SKU'] = '(J)71110126'\n",
    "orami.loc[orami['Product Name'].isin(['BUY 1 GET 1 - HiLo Multigrain Original 500 gram']), 'Real SKU'] = '2101469180P2'\n",
    "orami.loc[orami['Product Name'].isin(['Free Spider Bottle - L-Men Platinum Vanilla Caramel 800g']), 'Real SKU'] = 'PL30G26'\n",
    "\n",
    "orami.loc[orami['Real SKU'].isin(['1101672318']), 'Real SKU'] = '1101665318'\n",
    "\n",
    "data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "data_SKU['Real SKU'] = data_SKU['SKU'].astype(str)\n",
    "orami['Real SKU'] = orami['Real SKU'].astype(str)\n",
    "orami = orami.merge(data_SKU[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU', 'Price List NFI']].drop_duplicates(['Real SKU']), how = 'left', on = 'Real SKU')\n",
    "orami['Total Net'] = orami['Price List NFI'].astype(int) * orami['Qty. Invoiced'].astype(int)\n",
    "\n",
    "orami.loc[orami['Brand'].isin([\"W'dank\"]), 'Brand'] = 'WDANK'\n",
    "\n",
    "indeks = orami[orami['Brand'] == 'Bundle'].index.to_list()\n",
    "orami['Bundle Flag'] = np.nan\n",
    "orami['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "orami['SKU'] = orami['SKU'].astype(str)\n",
    "list_col = ['SKU'] + data_SKU.columns[data_SKU.columns.get_loc('Produk 1'):data_SKU.columns.get_loc('Harga Cost 7')+1].to_list()\n",
    "orami = orami.merge(data_SKU[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "orami = orami.drop(['SKU_y'], axis = 1)\n",
    "orami  = orami.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "data_orami = orami.copy()\n",
    "\n",
    "print(\"Unbundling\")\n",
    "data_bundle1 = data_orami[~data_orami['Produk 1'].isnull()]\n",
    "data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']*data_bundle1['Qty. Invoiced']\n",
    "data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle2 = data_orami[~data_orami['Produk 2'].isnull()]\n",
    "data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']*data_bundle2['Qty. Invoiced']\n",
    "data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "data_bundle2['Total Net'] = data_bundle2['Price List NFI 2']\n",
    "data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle3 = data_orami[~data_orami['Produk 3'].isnull()]\n",
    "data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']*data_bundle3['Qty. Invoiced']\n",
    "data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "data_bundle3['Total Net'] = data_bundle3['Price List NFI 3']\n",
    "data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle4 = data_orami[~data_orami['Produk 4'].isnull()]\n",
    "data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']*data_bundle4['Qty. Invoiced']\n",
    "data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "data_bundle4['Total Net'] = data_bundle4['Price List NFI 4']\n",
    "data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle5 = data_orami[~data_orami['Produk 5'].isnull()]\n",
    "data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']*data_bundle5['Qty. Invoiced']\n",
    "data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle6 = data_orami[~data_orami['Produk 6'].isnull()]\n",
    "data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']*data_bundle6['Qty. Invoiced']\n",
    "data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle7 = data_orami[~data_orami['Produk 7'].isnull()]\n",
    "data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']*data_bundle7['Qty. Invoiced']\n",
    "data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "orami = orami.append(data_bundle, ignore_index = True, sort = False)\n",
    "orami = orami.merge(data_SKU[['Real SKU', 'Harga Cost']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "orami['Total Harga Cost'] = pd.to_numeric(orami['Harga Cost'], errors = 'coerce') * orami['Qty. Invoiced']\n",
    "print(orami[orami['Harga Cost'] == 0][['SKU','Product Name']].drop_duplicates())\n",
    "orami['Total'] = orami['Selling Price'] * orami['Qty. Invoiced']\n",
    "orami['Subtotal'] = orami['Selling Price'] * orami['Qty. Invoiced']\n",
    "orami = orami.rename(columns = {'Real SKU_x' : 'Real SKU'})\n",
    "\n",
    "columns_da = data_all.columns\n",
    "columns_o = orami.columns\n",
    "orami = orami[[x for x in columns_o if x in columns_da]]\n",
    "orami['Sales Order ID'] = orami['Order #']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11bfd049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_16836\\820702064.py:24: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_all = data_all.append(append, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "#EROR\n",
    "#ORAMI RUN 2 - Cek Order ID yang ada di data_all\n",
    "\n",
    "oldoi = data_all[data_all['Store'].isin(['Orami Shopping'])]['Order #'].unique()\n",
    "\n",
    "#Sukses\n",
    "temp = orami[orami['Order Status'].isin(['Selesai'])]['Order #'].unique()\n",
    "orderid1 = [x for x in temp if x in oldoi]\n",
    "data_all.loc[data_all['Order #'].isin(orderid1),['Order Status']] = 'Selesai'\n",
    "\n",
    "#Dibatalkan\n",
    "temp = orami[orami['Order Status'].isin(['Dibatalkan'])]['Order #'].unique()\n",
    "orderid2 = [x for x in temp if x in oldoi]\n",
    "data_all.loc[data_all['Order #'].isin(orderid2),['Order Status']] = 'Dibatalkan'\n",
    "\n",
    "#Pesanan Tiba\n",
    "temp = orami[orami['Order Status'].isin(['Pesanan Tiba'])]['Order #'].unique()\n",
    "orderid3 = [x for x in temp if x in oldoi]\n",
    "data_all.loc[data_all['Order #'].isin(orderid3),['Order Status']] = 'Pesanan Tiba'\n",
    "\n",
    "#New Order\n",
    "temp = orami['Order #'].unique()\n",
    "orderid4 = (set(temp) - set(oldoi))\n",
    "append = orami[orami['Order #'].isin(orderid4)]\n",
    "data_all = data_all.append(append, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "91a47150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Net</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>July</th>\n",
       "      <td>78864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>June</th>\n",
       "      <td>162060.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Total Net\n",
       "Month           \n",
       "July     78864.0\n",
       "June    162060.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orami[orami['Brand'].isin(['TS','NS','WDANK','L-Men','HiLo']) & orami['Order Status'].isin(['Selesai','Pesanan Tiba'])].groupby(['Month']).agg({'Total Net' : 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8532fe5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_16836\\3400291211.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  orami = orami.append(orami1, ignore_index = True)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_16836\\3400291211.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_all = data_all.append(orami, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "orami = orami.append(orami1, ignore_index = True)\n",
    "#data_all = data_all[~data_all['Store'].isin(['Orami Shopping'])]\n",
    "data_all = data_all.append(orami, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "61ef36a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Net</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>July</th>\n",
       "      <td>157728.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>June</th>\n",
       "      <td>324120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>September</th>\n",
       "      <td>148740.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Total Net\n",
       "Month               \n",
       "July        157728.0\n",
       "June        324120.0\n",
       "September   148740.0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all[data_all['Store'].isin(['Orami Shopping']) & data_all['Brand'].isin(['TS','NS','WDANK','L-Men','HiLo']) & data_all['Order Status'].isin(['Selesai','Pesanan Tiba'])].groupby(['Month']).agg({'Total Net' : 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a327bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542f9d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3429f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8f5e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a7f043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee24331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17430c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6945a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb82c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run-5\n",
    "indeks = data_all[data_all['Qty. Invoiced'].isnull()].index.to_list()\n",
    "data_all['Qty. Invoiced'][indeks] = 0\n",
    "data_all['Total Net'][indeks] = data_all['Price List NFI'][indeks] * data_all['Qty. Invoiced'][indeks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73050790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed37837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c25268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8711fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##run-6\n",
    "order_online_cond = False\n",
    "shopee_scrap = False\n",
    "shopee_done = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceb243a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c822ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75c9338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##run-7\n",
    "order_online_jatim = False\n",
    "order_online_jkt = False\n",
    "order_online_jateng = False\n",
    "order_online_bali = False\n",
    "order_online_makasar = False\n",
    "order_online_samarinda = False\n",
    "order_online_medan = False\n",
    "order_online_lampung = False\n",
    "order_online_pekanbaru = False\n",
    "order_online_banjarmasin = False\n",
    "order_online_jabar = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c24aa69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fcda45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac52fb70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c79c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9562ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6ca66f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_online_pekanbaru\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7266: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7269: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7274: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7276: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7278: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7280: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7281: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7282: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7283: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7284: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7286: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7287: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7288: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7289: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7290: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7292: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7293: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7294: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7295: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7297: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7298: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7299: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7300: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7301: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7302: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7303: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7304: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7305: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7306: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7307: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7308: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7309: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7310: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7311: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7312: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7313: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7314: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7316: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - HiLo School Cotton Candy 500g', 38850, 38850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7317: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Active Chocolate 1000 gr', 61500, 61500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7319: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Sweetener Jahe 50 sch', 44600, 22300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7320: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Buy 12 Get 12 - HiLo Chocolate Avocado Ready to Drink 200ml - Minuman Siap Minum Tinggi Kalsium', 152400, 84000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7322: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) L-Men Lose Weight Avocado Coffee 300g', 138500, 69250]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7323: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Teen Strawberry Milkshake 500g', 86600, 43300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7325: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Klepon Latte Refill 500g', 51900, 25950]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7326: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Premium Jus Mangga 10 Sachet', 25000, 17760]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7328: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Milk Skim Chocolate 500gr', 117700, 58850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7329: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo School Vanilla Vegiberi 750gr', 117700, 58850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7330: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Avocado Coffee 4 sch', 16200, 8100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7331: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Stevia (50 sch)', 57700, 28850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7332: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Korean Garlic Butter Cookies 5 sch - Khusus Homdel', 23100, 11500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7333: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) NutriSari Es Rujak 40's\", 45000, 22500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7334: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Bumbu Saus Telur Asin 3 Sachet - Lebih Rendah Lemak dan Garam', 32100, 32100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7335: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) - Tropicana Slim Sweetener Rose Vanilla 50 sch\", 45000, 22500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7336: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - Tropicana Slim Santan 5 sachet', 16700, 8350]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7337: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) Tropicana Slim Klepon Cookies (5 sch)\", 23100, 11550]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7338: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Milk Skim Coffee 500gr', 117000, 58850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7340: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Wdank Madu Temulawak 10 Sachet', 17300, 9700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7341: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) - NutriSari Jeruk Nipis Jahe 40 Sachet\", 45000, 22500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7342: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['NutriSari RTD Squeezed Orange 200 ml x 24 pcs - Minuman Jeruk Peras Vitamin C', 144100, 80700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7343: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['4 pack - NutriSari RTD Squeezed Orange 200 ml - Minuman Jeruk Peras Vitamin C', 24000, 13400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7345: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Lokalate Kopi Andaliman 10 Sachet', 15000, 7500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7346: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) L-Men Whey Advanced Choco Vanilla 500gr', 173200, 86600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7347: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['L-Men Platinum Choco 800 gr - Near ED', 357900, 178950]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7348: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Milky Vanilla Cookies 200ml x 4 pcs', 30900, 30900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7350: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) W'dank Bajigur 10 sch\", 18000, 9000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7351: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Korean Goguma Cookies (5 sch)', 24200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7352: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Platinum Swiss Chocolate 420gr', 94700, 47350]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7353: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Chocolate Avocado 200ml (4pcs)', 25400, 25400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7355: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Madu 350ml', 69300, 34650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7356: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Kecap Manis 200ml', 28900, 14450]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7357: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Hampers Lebaran Fancy Tote Bag Tropicana Slim', 186500, 130000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7358: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Hampers Lebaran Fancy Tote Bag Tropicana Slim 2', 186500, 130000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7359: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) L-Men Platinum Bubble Gum 800 gram', 375200, 187600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7360: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo Active Vanilla 500gr', 79700, 39850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7361: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Salted Caramel Cocoa 4 Sachet', 33300, 16650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7362: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Hampers Lebaran Fancy Tote Bag Tropicana Slim 8', 186500, 130000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7363: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Lemon-C (25 sch)', 26600, 13300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7364: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)L-Men Gain Mass Chocolate 500gr', 152400, 76200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7365: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim French Butter Souffle Coffee 4 Sachet', 16200, 16200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7366: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) L-Men Lose Weight Mango Sticky Rice 300gr', 152400, 76200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7367: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['HiLo School Cotton Candy 200ml - Ready to Drink (4 Pcs) Tinggi Kalsium', 28600, 28600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7368: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Less Sugar Belimbing 40 sachet', 62000, 45510]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7369: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Active Vanilla 1000g', 146600, 73300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7370: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['HiLo Chocolate Taro RTD 200ml - Near ED', 6300, 4410]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7371: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo RTD Chocolate Avocado 200ml', 6300, 4410]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7372: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Lychee Tea Refill 500 gram', 36400, 18200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7373: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo RTD Milky Vanilla Cookies 200ml', 7700, 3850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7374: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim High Fiber High Calcium Milk Chocolate 500gr', 117700, 82390]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7375: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Es Ketan Hitam Refill 500g', 46200, 23100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7376: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Mint Cocoa 4 Sachet', 17300, 12110]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7377: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - Tropicana Slim White Coffee', 20200, 10100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7378: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Goldenmil Vanilla (6 sch) - Near ED', 33500, 23450]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7379: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo School RTD Cotton Candy 200ml', 7000, 3500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7380: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Thai Tea 200ml - Near ED', 6300, 3150]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7381: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - NutriSari Gula Asem 40 Sachet', 47300, 23650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7382: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Cocopandan 40sch', 23650, 23650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7383: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Peanut Almond Butter 300 gram', 66600, 33300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7384: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - Tropicana Slim Kecap Asin 200 ml', 26600, 18620]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7385: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo Taro Latte Refill 500g', 46620, 23300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7386: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Bumbu Kaldu Ayam Jamur 100 gram', 24500, 12250]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7387: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Diabetamil Milk Vanilla 150 gram', 33500, 10050]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7388: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Teen Biscuit Caramel 500gr', 87700, 26310]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7389: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['L-Men Platinum Refill Choco Latte 800g', 321900, 257500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7390: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - L-MEN Gain Mass Taro 225 gr', 78500, 23550]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7391: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['2102500320 (CI160)', 88800, 88800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7392: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['HiLo Klepon Latte Refill 500g - Powder Drink Tinggi Kalsium', 51900, 25950]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7393: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED -Tropicana Slim Sweet Orange Sugar Free 10 sch', 21900, 6570]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7394: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)Tropicana Slim Extra Virgin Olive Oil 500 ml', 92400, 27720]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7395: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo School Vanilla Vegiberi 500gr', 84300, 25290]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7396: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Milk Skim Original 1kg', 207800, 62340]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7397: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 24200, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7398: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - NutriSari Lychee Tea 40sch', 47300, 33110]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7399: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Sirup Orange 750ml', 33500, 16750]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7400: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) W'dank Bandrek 10 sachet Renceng - Khusus Homdel\", 18000, 5400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7401: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 pcs) - 12gr Protein / Serving', 304800, 304800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7402: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack HiLo Chocolate Mint 10 Sachet Minuman dengan Cokelat Tinggi Kalsium Praktis dalam Sachet\", 25530, 12765]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7403: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['BUY 12 GET 12 - Tropicana Slim Oat Drink Japanese Cantaloupe Melon', 240000, 199800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7404: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Classic Refill 500gr', 109700, 32910]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7405: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) HiLo School Susu Coklat (10 sch) Gusset - Khusus Homdel\", 45800, 22900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7406: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['HiLo School Susu Vanilla 10 sch - Near ED', 22900, 22900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7407: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Diabtx 100s\", 83100, 83100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7408: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo School Chocolate 500gr', 77000, 38500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7409: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo School Strawberry Cheesecake 500 gram', 80100, 40050]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7410: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Chocolate Taro RTD 200ml (4pcs)\", 25200, 25200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7411: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['HiLo School Vanilla Vegiberi Ready To Drink Susu [200ml/4 pcs]', 28800, 28800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7412: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['HiLo Teen Coffee Tiramisu Ready To Drink Susu UHT [4 pcs]', 28800, 28800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7413: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['HiLo Teen Chocolate Ready To Drink Susu [4 pcs]', 28800, 28800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7414: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['HiLo Thai Tea Ready to Drink 200ml x 4pcs', 25200, 25200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7415: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)L-Men Protein Bar Chocolate 12 sch', 99500, 49750]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7416: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Milk Low Fat Vanilla 500gr', 74400, 37200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7417: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim RTD Almond Drink Chocolicious 190 ml', 8700, 8700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7419: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Near ED - Tropicana Slim Low Fat Milk Korean Strawberry 500g\", 87700, 43850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7420: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Sweetener Gula Aren 50 sachet', 45000, 22500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7421: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) Tropicana Slim Cafe Latte (10 sch)\", 30600, 10300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7422: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo Teen Vanilla Caramel 500gr', 87700, 43850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7423: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Gold Chocolate 1000g', 147800, 73900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7424: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED)HiLo Teen Chocolate 500gr\", 87700, 43850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7425: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Soy Latte - Kopi Susu Kacang Bebas Gula', 28800, 28800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7426: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Es Kuwud Nipis', 47300, 33110]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7427: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Susu Low Fat Macchiato Coffee 500 gram', 85400, 42700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7428: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['BUY 1 GET 1 - HiLo Platinum Original 360 gram', 255000, 111000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7429: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) HiLo Teen RTD Coklat 200ml - Khusus Homdel\", 4800, 4800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7430: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Hokkaido Cheese Cookies', 16300, 16300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7431: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Teen RTD Coffee Tiramisu 200ml - Khusus Homdel', 4800, 4800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7432: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari American Sweet Orange (40sch)', 47300, 22800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7433: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Sunflower Oil 946 ml', 80800, 59100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7434: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo Es Pisang Ijo 10 sch', 11300, 11300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7435: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Lokalate Kopi Alpukat Refill 500 gram', 48500, 24250]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7436: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) L-Men Gain Mass Banana 225gr', 78500, 39250]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7437: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Minyak Jagung 946ml - Khusus Homdel', 68400, 68400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7438: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari RTD Jeruk Madu 200 ml', 4000, 4000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7439: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) L-Men Hi Protein 2 Go Chocolate - Khusus Homdel', 8500, 3663]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7440: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo School 3+ Strawberry Pop 400g', 56700, 24309]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7441: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Lemon Tea 500 gram', 36400, 10490]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7442: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Jeruk Manis 500gr - Near ED', 25600, 10989]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7443: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo Gold Chocolate 500gr', 74400, 24309]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 175.8560426235199 seconds ---\n",
      "Unbundling ====== 6/10\n",
      "--- 175.87167048454285 seconds ---\n",
      "Filling Date ====== 7/10\n",
      "Filling Location\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7607: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7664: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbundling\n",
      "Pricing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7784: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7802: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:7814: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8026: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_online_banjarmasin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8125: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8128: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8133: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8135: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8137: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8139: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8140: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8141: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8142: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8145: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8146: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8147: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8148: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8149: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8151: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8152: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8153: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8154: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8156: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8157: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8159: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8160: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8161: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8162: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8164: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8165: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8166: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8167: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8168: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8169: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8170: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8171: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8172: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8173: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8175: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Sweetener Jahe 50 sch - Khusus Homdel', 44600, 22300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8176: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Buy 12 Get 12 - HiLo Chocolate Avocado Ready to Drink 200ml - Minuman Siap Minum Tinggi Kalsium', 152400, 84000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8178: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['HiLo Multigrain Original 500g', 92400, 92400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8179: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['HiLo Almond Milk Coconut 200gr', 51900, 51900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8180: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['NutriSari RTD Squeezed Orange 200 ml x 24 pcs - Minuman Jeruk Peras Vitamin C', 144100, 80700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8181: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['4 pack - NutriSari RTD Squeezed Orange 200 ml - Minuman Jeruk Peras Vitamin C', 24000, 13400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8182: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['L-Men Platinum Choco 800 gr - Near ED', 326000, 163000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8184: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['L-Men Gain Mass Klepon Latte 500g', 152400, 152400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8185: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Bumbu Kaldu Ayam Jamur 100 gram', 25400, 25400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8186: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - Tropicana Slim Sweetener Rose Vanilla 50 sch', 22500, 22500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8187: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Gula Aren 50 sachet', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8188: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Lokalate Kopi Alpukat Refill 500 gram', 48500, 33950]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8189: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Bumbu Saus Telur Asin 3 Sachet - Lebih Rendah Lemak dan Garam', 25400, 25400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8190: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim French Butter Souffle Coffee 4 Sachet', 16200, 16200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8191: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Hampers Lebaran Fancy Tote Bag Tropicana Slim', 186500, 130000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8192: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Hampers Lebaran Fancy Tote Bag Tropicana Slim 6', 186500, 130000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8193: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Multigrain Original 500g', 99300, 69510]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8194: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Chocolate Avocado 200ml (4pcs)', 25400, 25400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8195: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Chocolate Avocado 200ml (24pcs)', 152400, 152400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8196: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['HiLo School Cotton Candy 200ml - Ready to Drink (24 Pcs)', 171800, 171800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8197: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Premium Jus Mangga 10 Sachet', 25000, 17760]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8198: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim RTD Almond Drink Chocolicious 190 ml', 8325, 4200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8199: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo Platinum Original 360g (12 Sachet)', 111000, 77700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8200: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - NutriSari Gula Asem 40 Sachet', 45510, 13700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8201: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Sweetener Gula Aren 50 sachet', 43290, 13000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8202: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Gold Biscuit Cereal 500g', 81030, 24300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8203: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo School Vanilla 1000g', 149850, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8204: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Active Chocolate 1000 gr', 129870, 39000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8205: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Near ED - L-MEN Gain Mass Taro 225 gr', 75480, 22600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 459.54339122772217 seconds ---\n",
      "Unbundling ====== 6/10\n",
      "--- 459.55901622772217 seconds ---\n",
      "Filling Date ====== 7/10\n",
      "Filling Location\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8386: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8443: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbundling\n",
      "Pricing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8563: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8581: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8593: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9660\\3724863462.py:8805: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_online_jabar\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 8889\u001b[0m\n\u001b[0;32m   8885\u001b[0m data_order[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data_order[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTwin Pack: Tropicana Slim Saus Tiram 200ml (x2) \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTwin Pack: Tropicana Slim Saus Tiram 200ml \u001b[39m\u001b[38;5;124m'\u001b[39m, regex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   8887\u001b[0m product \u001b[38;5;241m=\u001b[39m data_order[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m(x\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m1\u001b[39m, expand \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 8889\u001b[0m product\u001b[38;5;241m.\u001b[39mloc[\u001b[43mproduct\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHiLo Teen Taro 500gr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   8890\u001b[0m data_order[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuantity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m product[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m   8891\u001b[0m data_order[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m product[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m6 SCH\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m6sch\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDank\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdank\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL-men\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL-Men\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHilo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHiLo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDIABTX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiabtx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpon-empon\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpon-Empon\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNutrisari\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNutriSari\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhilo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHiLo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBbq\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBBQ\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mschool\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSchool\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRtd\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRTD\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHoney 50 sachet\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHoney (50sch)\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeen Coklat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeen Chocolate\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m40 sch\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m40sch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3506\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3506\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3508\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "## run 8\n",
    "## until all region true\n",
    "## error : add missing prod to code line jatim jkt jateng, other to \"D:\\Masterdata\\Order Online\\SKU buat andra updated maret 2021.xlsx\"\n",
    "\n",
    "start_time = time.time()\n",
    "if not order_online_jatim:\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "    \n",
    "    print('order_online_jatim')\n",
    "    ##komen sementara\n",
    "\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "    \n",
    "    time.sleep(30)\n",
    "\n",
    "    username = driver.find_element(By.NAME, \"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customer@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element(By.NAME, \"password\")\n",
    "    password.send_keys(\"jatimhomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element(By.CLASS_NAME, \"btn-submit\").click()\n",
    "    \n",
    "    time.sleep(20)\n",
    "    #Click Order\n",
    "    WebDriverWait(driver, 60).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a/span/span'))).click()\n",
    "    time.sleep(20)\n",
    "    #Click Order List\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div/nav/div/div/ul/li[3]/div/a[1]/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Calendar\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Last 7 Days\n",
    "    WebDriverWait(driver, 50).until(EC.visibility_of_element_located((By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    #Click Apply\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    time.sleep(20)\n",
    "    #Clicl Export\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[3]/div[1]/button/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Export to CSV\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[3]/div[1]/div/button[1]').click()\n",
    "\n",
    "    time.sleep(50)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    \n",
    "    #komen sementara\n",
    "    # data_order=pd.read_csv(r\"D:\\Masterdata\\Input Data\\orderonline_orders_all_products_08-07-2022_MOoUrPq6Pzq0pu2y.csv\")\n",
    "    driver.close()\n",
    "    product_order = pd.read_csv(r'data_supp/orderonline_products_Surabaya.csv')\n",
    "    \n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    \n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('L-Men Hi Protein 2 Go Chocolate (24 pcs) - 12gr Protein / Serving', 'L-Men Hi Protein 2 Go Chocolate (24 pcs)', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch (x2) ', 'Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch ', regex = False)\n",
    "\n",
    "    \n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch')\n",
    "                        \n",
    "    product_order['title'] = product_order['title'].str.strip().str.replace('  ', ' ')\n",
    "    product_order['title'] = product_order['title'].str.strip().str.replace('L-Men Gain Mass Chocolate 500 gr', 'L Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Mango Smoothie 200ml (6pcs)', 36300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (6pcs)', 48000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate (12sch)', 5500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey (50sch)', 39500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Orange 750ml', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 225gr', 57500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gainmass Taro 225gr', 69600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 139200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Mangga Gandaria (40 sch)', 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 750gr + Free Kertas Gambar', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Jeruk Peras (40sch x 2) + Nutrisari Mangga Gandaria (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Blewah (40sch x 2) + Nutrisari Jeruk Maroko (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Nutrisari American Sweet Orange (40sch x 2) + Nutrisari Milky Orange (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 500gr + Free Kertas Gambar', 117600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 750gr', 127100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 Sch)', 15000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Es Cincau 40 sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sunflower Oil 946 ml', 52800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Lose Weight Chocolate Cereal 300gr\", 118800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Platinum Choco Latte Dus 6 sch\", 80000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 pcs)\", 264000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 10500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Gain Mass Banana 225gr\", 61000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate 12 sch\", 105600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Hilo Chocolate Taro (10 sch)\", 14700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 1 GET 1 - W'Dank Empon Empon 10 Sachet Renceng\", 15000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 15000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(FREE) W'Dank Empon-Empon 10 sch\", 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Teen Chocolate 1000 gr\", 136400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-MEN Gain Mass Taro 225 gr\", 52800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Whey Daily Dark Chocolate 250gr\", 49500]], columns = ['title', 'price']), ignore_index = True, sort = False)                                        \n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 13200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Hilo Es Ketan Hitam 10 sch\", 13200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo School Honey 500gr\", 71500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Teen Vanilla 750gr\", 102300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 26400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 26400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    product_order = product_order.append(pd.DataFrame([['Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)', 52000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim Sweetener Jahe 50 sch\", 38500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim Korean Garlic Butter Cookies 5 Sch\", 17500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sambal Terasi 200 gr', 29700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2', 107800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)', 67500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Protein Bar Chocolate 12 sch', 105600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Protein Crunch BBQ Beef (20gr)', 9900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Avocado Coffee 4 Sch x 2', 24200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Avocado Coffee 4 Sch', 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Taro 500gr', 71500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 28900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 20700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Cocopandan 40 sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Shirataki Noodles 71gr', 28100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Saus Tiram 200ml', 39600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Shirataki Noodles 71gr', 14200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Saus Tiram 200ml', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim White Coffee (4sch)', 17600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hampers Idul Fitri Tropicana Slim', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Takjil HiLo Dessert', 67500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Ramadhan NutriSari 2021', 60000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Kehangatan WDank - Ramadhan Edition', 60000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Platinum Kacang Hijau 800g', 275000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Topping Kental Manis 150ml - SUGAR FREE', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Whey Advanced Cappuccino 250gr', 79200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Minyak Kanola 946ml - 100% Pure Canola Oil - Free Korean Garlic Butter Cookies 1 sch', 59400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Minyak Kanola 946ml', 59400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(EACH)Tropicana Slim Korean Garlic Butter Cookies - Sampling', 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Platinum Ketan Hitam 800g (25g protein / serving) - Suplemen Tinggi Whey Protein Rendah Lemak', 302500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Whey Advanced Choco Vanilla 500gr', 148500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['FREE Cookies - Tropicana Slim Susu Skim Chocolate 500gr - Bantu Turunkan Kolesterol', 106700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['FREE Cookies - Tropicana Slim Cafe Latte 10 Sachet 14gr - Kopi Susu Nikmat Tanpa Gula Pasir', 27500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Platinum Choco Latte 800gr (25gr protein)', 302500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['FREE Cookies - Tropicana Slim Susu Skim Plain 1000gr - Bantu Turunkan Kolesterol', 180400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['FREE Cookies - Tropicana Slim Susu Skim Coffee 500gr - Bantu Turunkan Kolesterol', 106700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack - HiLo Active Es Teler 175gr', 38000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Es Teler 175gr', 19000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Apel Jeruk 40 Sachet', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo Teen Popcorn Caramel 500 gram x 2', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Avocado Coffee 4 Sch', 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch', 57800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Rose Vanilla 50 sch', 28900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Milk Skim Chocolate 500gr', 106700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Milk Skim Coffee 500gr', 106700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Extra Virgin Olive Oil 500 ml - [Free] Tropicana Slim Shirataki Noodles 71gr', 83500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Chocolate 750g Susu Tinggi Kalsium Lebih Rendah Lemak - [FREE] HiLo Active Ketan Hitam 175g', 111000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim DIABTX (100 sch) - [FREE] Tropicana Slim Avocado Coffee 4 Sch', 76000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Milk Skim Original 1kg', 187700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Oat Drink 190 ml (RTD) x 4 pcs', 22600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Es Rujak Jeruk Bali 40 Sachet', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Oat Drink 190 ml (RTD)', 5650]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Mayonnaise 200 g x 2', 34800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Mayonnaise 200 g - Bantu Dukung Hidup Sehat', 17400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Chocolate 1000 gr', 115500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: L-Men Daily Popcorn Caramel 250gr x 2', 78200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Extra Virgin Olive Oil 500 ml', 83500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Daily Popcorn Caramel 250gr', 39100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 - HiLo Gold Sweet Potato 500 gram', 73200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NuTrilogi Seri Jeje Si Jeli', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Asin 200 ml', 24600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Sweet Potato 500 gram', 73200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(FREE) HiLo Gold Sweet Potato 500 gram', 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 FREE HiLo Joint Plus 140gr', 38300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Joint Plus Orange 140 gram', 38300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(FREE) HiLo Joint Plus Orange 140 gram', 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Korean Goguma Cookies (5 Sch) x 2', 32200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Goguma Cookies (5 Sch)', 16100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NuTrilogi Seri Mba Nana Si Penuh Pesona', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Popcorn Caramel 500gr', 68600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Chocolate 1000 gr', 141900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Lokalate Kopi Andaliman 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Lokalate Kopi Tape Ketan 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Special Bundle - Tropicana Slim Sweetener Rose Vanilla & Tropicana Slim Korean Goguma Cookies', 55000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Andaliman 10 Sachet', 6850]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Tape Ketan 10 Sachet', 6850]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Rose Vanilla 50 sch', 40000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(FREE) Lokalate Kopi Andaliman 10 Sachet', 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(FREE) Lokalate Kopi Tape Ketan 10 Sachet', 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Goguma Cookies (5 Sch)', 16100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Plain 1000 gr', 128200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NuTrilogi Seri Mas Kaka yang Banyak Akal', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo School Strawberry Cheesecake 500 gram x 2', 110600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Strawberry Cheesecake 500 gram', 55300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo Joint Plus Orange 140 gram x 2', 55300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Vanilla Vegiberi 750gr', 76600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Madu Kurma Pack (4R)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Jeruk Jeju [40 Sachet]', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Es Rujak (4R)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Jeruk Nipis (40 sch)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Madu Lemon (40 Sch)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Thai Tea (10 sch)', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Chocolate Taro RTD 200ml (4pcs)', 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Swiss Chocolate (10 sch) Renceng', 17200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo Teen Coffee Tiramisu Ready To Drink Susu UHT [4 pcs]', 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo Teen Chocolate Ready To Drink Susu [4 pcs]', 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Vanilla Vegiberi Ready To Drink Susu [200ml/4 pcs]', 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Lychee Tea 40 sch', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Yuzu Orange 40 sch', 46200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Jeruk Manis 500gr', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo Gold Sweet Potato 500 gram x 2', 105600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin pack - Lokalate Kopi Andaliman 10 Sachet', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Sweet Potato 500 gram', 52800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Andaliman 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin pack - Lokalate Kopi Tape Ketan 10 Sachet', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Tape Ketan 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim DIABTX (100 sch)', 76100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Nutty Chocolate Cookies 200gr', 40000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Markisa (40 Sch)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Madu Jeruk (40sch)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari NUTRI C1000 Jeruk 40 Sachet', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Chocolate 500gr', 61800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"W'Dank Bajigur (10 sch)\", 17200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener I Sweet', 21700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Kacang Hijau 200gr', 40000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack - Lokalate Kopi Tape Ketan 10 Sachet', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Tape Ketan 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Classic Refill 500gr', 98400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Milk Skim Fiber Pro Plain 500gr', 111000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Vanilla Caramel 500gr', 76600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim High Fiber High Calcium Milk Chocolate 500gr', 112100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack - Lokalate Kopi Andaliman 10 Sachet', 35000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Andaliman 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo Almond Milk Coconut 200gr x 2', 70000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Almond Milk Coconut 200gr', 35000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Yoghurt Smoothie Bowl Strawberry (8 sch)', 62900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"W'Dank Bandrek 10 sachet Renceng\", 17200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo School Chocolate Candy (10 sch)\", 18300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"2102500320 (CI160)\", 72160]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"2102500336 (CS)\", 45100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Jeruk Maroko (40 Sch) FREE Lokalate Andaliman (10 Sch)\", 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Jeruk Peras Refill 500 gr\", 34300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Nutrisari Jeruk Maroko (40 sch)\", 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(FREE) Lokalate Kopi Andaliman 10 Sachet\", 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twin Pack:HiLo Teen Strawberry Milkshake 500g x 2\", 100000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Teen Strawberry Milkshake 500g\", 50000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo School Chocolate Ready To Drink (4 tetrapack)\", 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo School RTD Coklat 200ml\", 6525]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim Sirup Leci 750ml\", 30900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Mango Smoothie 200ml (4 Pcs)\", 27500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari RTD Jeruk Madu 200 ml (4 tetrapack)\", 22900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari RTD Mango Smoothie 200 ml\", 6900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari RTD Jeruk Madu 200 ml\", 5750]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Active Chocolate 750gr\", 89200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate x 4 pcs\", 38400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate\", 9600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey 50 sachet', 40000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Triple Pack - Tropicana Slim Klepon Cookies (5 Sch) - Snack Bebas Gula, 100 Kalori', 50000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Klepon Cookies (5 Sch)', 16700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Platinum Swiss Chocolate 420gr', 91500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Chocolate 250g (Health & Green Science Competition)', 38300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Shirataki Rice 72 g', 50000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Shirataki Rice 72 g', 25000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Jeruk Nipis Jahe 40 Sachet', 35000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Vanilla 500gr', 65200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Yoghurt Banana 250gr', 38400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['TS SHIRATAKI RICE RASA NASI UDUK 24PX72G', 29700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Cotton Candy 500g', 62500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Es Kuwud Nipis', 37500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Lychee Tea Refill 500 gram', 34300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Thai Tea Ready to Drink 200ml x 4pcs', 23600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo RTD Thai Tea 200ml', 5900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 Free - HiLo School Bubble Gum 500g', 92400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED) HiLo School RTD Coklat 200ML', 6270]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Brownies Instant Powder Cake Mix 230 g - Bantu Dukung Hidup Sehat', 59400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Klepon Latte Refill 500g - Powder Drink Tinggi Kalsium', 49500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim BROWNIES  Instant Powder Cake Mix 230 g', 29700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Caramel Latte 500g', 50500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Avocado Chocolate (10 Sch)', 127160]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Bundle - HiLo Teen Taro 500gr & HiLo Teen Strawberry Milkshake 500g', 11400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Taro 500gr', 63600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Strawberry Milkshake 500g', 63600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED)Bundle L-Men Platinum Ketan Hitam 800g & L-Men Platinum Kacang Hijau 800g', 314600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED)L-Men Platinum Ketan Hitam 800g ', 157300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED)L-Men Platinum Kacang Hijau 800g', 157300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED)Twinpack: L-Men Platinum Kacang Hijau 800g', 314600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED)L-Men Platinum Kacang Hijau 800g', 157300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Es Ketan Hitam 500g - Powder Drink Tinggi Kalsium', 44000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Biscuit Caramel 500gr', 65000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Plain (Original) 500gr', 77800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Lemon Tea 500 gram', 34300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Lokalate Kopi Pisang Bakar 10 sch', 17500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Pisang Bakar Epe 10 sch', 8750]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Bubble Gum 500g', 80100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack/B1G1 HiLo Multigrain Original 500g', 176000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Multigrain Original 500g', 88000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Lemon-C (25 sch)', 25200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Belgian Chocolate (10 sch)', 49200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Chocolate Polos 10's\", 12000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo White Chocolate (10 Sch)', 12000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Cookies Paket Hampers Idul Fitri Parcel Lebaran', 131600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Chocolate Banana 10 sch', 12000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese Cookies', 22300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Nutty Chocolate Cookies 200gr', 40000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Garlic Butter Cookies 5 Sch', 22300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Goguma Cookies (5 Sch)', 22300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Klepon Cookies (5 Sch)', 21500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Gift - Paper Bag Ramadhan Tropicana Slim', 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Es Pisang Ijo 10 Sch x 2 pcs', 17500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Mangga 500gr', 132700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 - Tropicana Slim Mint Cocoa - Minuman Cokelat Mint Nikmat Tanpa Gula Pasir', 20000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 FREE L-Men Lose Weight Mango Sticky Rice 300gr', 145200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 FREE Tropicana Slim Susu Low Fat Macchiato Coffee 500gr', 143000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Diabetamil Milk Vanilla 150 gram', 29700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Susu Low Fat Macchiato Coffee 500 gram', 71500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Brownies Instant Powder Cake Mix 230 g - Bantu Dukung Hidup Sehat', 30900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-MEN PLANTPROTEIN OGURA 6Dx216G', 103900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr - Near ED', 16150]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Choco Series Paket Hampers Idul Fitri Parcel Lebaran', 139600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 1000g - Susu Tinggi Kalsium Lebih Rendah Lemak', 104800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Vanilla 1000g - Susu Tinggi Kalsium Lebih Rendah Lemak', 115500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Vanilla 1000g - Susu Tinggi Kalsium Lebih Rendah Lemak', 86650]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Es Pisang Ijo 10 Sch', 14300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Soy Latte - Kopi Plant Based Rendah Gula', 36900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Mint Cocoa 4 Sachet', 20000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Taro 500g x 2 pcs', 133900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 Free - HiLo Gold Biscuit Cereal 500g', 80800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Alpukat 500 gram - Tinggi Vitamin A Lebih Rendah Gula', 44400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Thai Tea Refill 500g', 48000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Soy Latte - Kopi Susu Kacang Bebas Gula', 36900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Berondong 500 gram - Tinggi Vitamin A Lebih Rendah Gula', 44400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['2102900319 (D)', 90400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Biscuit Cereal 500g', 80800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Anggur Hijau 40 Sachet', 43300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Gula Asem 40 Sachet', 43300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack - Tropicana Slim Low Fat Milk Korean Strawberry 500g', 159900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Low Fat Milk Korean Strawberry 500g', 79900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese Cookies 100gr', 22500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Wdank Madu Temulawak 10 Sachet', 16600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Es Ketan Hitam Refill 500g - Powder Drink Tinggi Kalsium', 59400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) Lokalate Kopi Tape Ketan 10's\", 7500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED) HiLo Joint Plus Orange 140 gram', 19150]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED) BUY 1 GET 1 L-Men Gain Mass Mangga 500gr', 132700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED) HiLo Teen Taro 500gr', 43300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Bundle - Lokalate Kopi Alpukat Refill 500 gram & Kopi Berondong Refill 500 gram', 92400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Thai Tea RTD 200ml x 4pcs', 24000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 1 GET 1 - W'Dank Temulawak Madu\", 33300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['TRIPLE HEMAT - HiLo Thai Tea Refill 500g', 100900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['TRIPLE HEMAT - NutriSari Lemon Tea 500 gram', 72700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"W'dank Sarabba Extra 10 Sachet\", 18870]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"W'dank Madu Temulawak 10 Sachet\", 16650]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Blewah 40 sch', 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Mangga Gandaria 40 sch', 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Nutrisari Jeruk Nipis 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Nutrisari American Sweet Orange 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Jeruk Peras 40 sch', 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Milky Orange 40 sch', 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Chocolate Polos 10 sch\", 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Madu Lemon 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"Nutrisari Florida Orange 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Anggur Hijau 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari NUTRI C1000 Jeruk 40 sch', 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Markisa 40 sch', 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Es Kuwud Nipis 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"TRIPLE HEMAT - NutriSari Lychee Tea Refill 500 gram\", 72700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"Nutrisari Jeruk Maroko 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Apel Jeruk 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo Chocolate Taro 10 sch', 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Avocado Chocolate 10 sch', 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 1 GET 1 - HiLo Platinum Original 360 gram\", 111000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"TRIPLE DEALS - NutriSari Lychee Tea & Lemon Tea 500 gram Refill\", 72700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Gula Asem 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Nutrisari Madu Jeruk 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Lemon Tea Refill 500 gram\", 34600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"TRIPLE HEMAT - HiLo Klepon Latte Refill 500g\", 109100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twinpack Tropicana Slim Bumbu Saus Telur Asin 3 Sachet - Lebih Rendah Lemak dan Garam\", 29000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Madu Kurma Pack 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo White Chocolate 10 sch\", 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Taro Latte Refill 500g\", 32700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Es Rujak 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Es Rujak Jeruk Bali 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"TRIPLE DEALS - HiLo Thai Tea , Klepon Latte , Taro Latte Refill 500g\", 103900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"Buy 3 Get 3 - HiLo Milky Vanilla Cookies Ready to Drink 200ml\", 60000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twinpack Lokalate Kopi Alpukat Refill 500 gram\", 92400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twinpack Lokalate Kopi Berondong Refill 500 gram\", 92400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Nutrisari Jeruk Jeju 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Jeruk Nipis Jahe 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"2102500320 (CI160) TS SWT 160S IND\", 76590]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Platinum Original 360g (12 Sachet)\", 127500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 2 GET 2 - NutriSari RTD Squeezed Orange 200 ml - Minuman Jeruk Peras Vitamin C\", 40000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) HiLo Klepon Latte Refill 500g\", 25950]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Near ED - Lokalate Kopi Andaliman 10 Sachet\", 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) HiLo Active Caramel Latte 500g\", 32600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"Buy 1 Get 1 Free - HiLo School 3+ Strawberry Pop 400g\", 199800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"TRIPLE HEMAT - HiLo Taro Latte Refill 500g\", 145454]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim Bumbu Saus Telur Asin 3 Sachet - Lebih Rendah Lemak dan Garam\", 29000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo School 3+ Strawberry Pop 400g\", 99900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"Near ED - HiLo Almond Milk Coconut 200gr\", 51500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim Orange Cocoa 4 Sachet - Minuman Cokelat Jeruk Nikmat Tanpa Gula Pasir\", 16650]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Buy 1 Get 1 Free - HiLo School Original 400g - Susu Tinggi Kalsium Lebih Rendah Lemak\", 191400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Buy 1 Get 1 Free - HiLo Teen Original 400g - Susu Tinggi Kalsium Lebih Rendah Lemak\", 191400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twin Pack: HiLo Platinum Swiss Chocolate (12 Sch)\", 189300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Choco Hazelnut (10 Sch)\", 12210]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo School Strawberry 10 Sachet - Susu Tinggi Kalsium Lebih Rendah Lemak & Gula\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"4 pack - NutriSari RTD Squeezed Orange 200 ml - Minuman Jeruk Peras Vitamin C\", 24000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twinpack HiLo Platinum Original 360gram\", 230900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim Sweet Orange Sugar Free 10sachet\", 20200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Lose Weight Mango Sticky Rice 300gr\", 127000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari RTD Squeezed Orange 200 ml x 24 pcs - Minuman Jeruk Peras Vitamin C\", 144100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 1 GET 1 - Tropicana Slim Orange Cocoa 4 Sachet - Minuman Cokelat Jeruk Nikmat Tanpa Gula Pasir\", 33300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 2 GET 2 - Tropicana Slim RTD Almond Drink Chocolicious 190 ml\", 33400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Buy 1 Get 1 - Tropicana Slim Bumbu Kaldu Ayam dan Jamur 100 gram\", 48500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Hampers Lebaran Fancy Tote Bag Tropicana Slim\", 186500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 12 GET 12 - Tropicana Slim RTD Almond Drink Chocolicious 190 ml\", 199800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Buy 1 Get 1 - L-Men Gain Mass Klepon Latte\", 277100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 1 GET 1 - Tropicana Slim Salted Caramel Cocoa 4 Sachet\", 33300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim French Butter Souffle Coffee 4 Sachet\", 16200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Teh Tarik (10 Sachet) - Teh Tarik Tinggi Kalsium Bervitamin\", 16050]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Premium Jus Mangga 420g - Minuman Juice Kental Rasa Mangga Asli Vitamin C\", 46600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim Salted Caramel Cocoa 4 Sachet\", 26000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY1GET 1 - Tropicana Slim French Butter Souffle Coffee 4 Sachet\", 32400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Lemon Tea 40 sch\", 47300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 1 GET 1 - Tropicana Slim Peanut Almond Butter Spread Jam 300 gram\", 184800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim Bumbu Kaldu Ayam Jamur 100 gram\", 24200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY1 GET1 - Tropicana Slim Sweetener Luo Han Guo 50 sachet - Pemanis Alami Natural untuk Batasi Gula\", 115400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim RTD Almond Drink Chocolicious 190 ml\", 8700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) L-Men Gain Mass Taro 500g (Ags 23)\", 66950]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Buy 12 Get 12 Free - L-Men UHT PlantProtein 2GO Ogura / Kacang Merah 190ml\", 319680]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) HiLo Multigrain Original 500g (Ags 23)\", 49650]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Less Sugar Belimbing 40 sachet\", 62000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Platinum Bubble Gum 800 gram\", 375200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) HiLo RTD Milky Vanilla Cookies 200ml (Ags 23)\", 3850]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Near ED - L-MEN Gain Mass Taro 225 gr\", 39250]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Buy 2 Get 2 Free - L-Men UHT PlantProtein 2GO Ogura / Kacang Merah 190ml\", 61600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) HiLo School Cotton Candy 200ml - Ready to Drink (24 Pcs) / ED Sept 2023\", 171800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) Tropicana Slim Susu Low Fat Macchiato Coffee 500 gram / ED Nov 23\", 85400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Near ED - HiLo Teen Chocolate 1000 gr\", 161600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) HiLo Gold Chocolate 1000g / ED Okt 23\", 147800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) NutriSari Gula Asem 40 Sachet / ED Nov 23\", 47300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Near ED - HiLo Teen Chocolate 1000 gr / ED Okt 23\", 161600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) NutriSari Gula Asem 40 Sachet\", 47300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "   \n",
    "    product_order = product_order.append(pd.DataFrame([[\"2102900319 (D) TS SWT DIABETICS INDUSTRIAL 150S\", 82500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) Lokalate Kopi Berondong 500 gram - Tinggi Vitamin A Lebih Rendah Gula / ED Sept 23\", 48500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) HiLo Es Ketan Hitam Refill 500g\", 46200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) Lokalate Kopi Berondong 500 gram - Tinggi Vitamin A Lebih Rendah Gula\", 48500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) HiLo Teen Biscuit Caramel 500gr / ED Nov 23\", 87700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Premium Jus Mangga 10 Sachet\", 25000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Buy 1 Get 1 - Tropicana Slim Sweetener Gula Aren 50 sachet - Pemanis untuk Bantu Batasi Gula\", 90000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) Lokalate Kopi Berondong 500 gram\", 48500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) L-Men Lose Weight Mango Sticky Rice 300gr / ED Nov 23\", 152400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Buy 2 Get 2 Free - L-Men UHT PlantProtein 2GO Ogura / Kacang Merah 190ml (4pcs) with 12g Protein & 1,6g BCAA / Serving - Suplemen Tinggi Protein Nabati Siap Minum\", 61600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Isotonik 40 Sachet – Minuman Isotonik Buah Jeruk Segar\", 62000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Bundle Special Pack Isi 6 pcs - NutriSari RTD Squeezed Orange 200 ml\", 35700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Isopower Stargizing 30 Sachet with Creatine & Vitamin B\", 111000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Isotonik 40 Sachet – Minuman Isotonik Buah Jeruk Segar\", 62000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 12 GET 12 - Tropicana Slim Oat Drink Japanese Cantaloupe Melon 190 ml (RTD)\", 240000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 2 GET 2 - Tropicana Slim Oat Drink Japanese Cantaloupe Melon 190 ml (RTD)\", 40000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Buy 1 Get 1 Free - HiLo Chocolate Mint 10 Sachet\", 25530]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) Tropicana Slim Lemon-C (25 sch) / ED Okt 23\", 26600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 1 GET 1 - Tropicana Slim Gula Buah 50 Sch - Alami untuk Batasi Gula\", 138000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "   \n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 1 GET 1 - Tropicana Slim 7 Fruits Fiber Daily 12 Sachet\", 217560]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) NutriSari Madu Lemon (40 Sch)\", 45510]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) Nutrisari Jeruk Madu Jeruk 40'sachet (4 Renceng)\", 45510]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) - NutriSari Lychee Tea 40 sch\", 45510]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Near ED - Nutrisari Florida Orange (40 Sch)\", 45510]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) NutriSari Madu Kurma 40 sch\", 45510]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) HiLo School Vanilla 1000g\", 149850]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Near ED - NutriSari RTD Squeezed Orange 200 ml\", 5772]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Near ED - Tropicana Slim Bumbu Kaldu Ayam Jamur 100 gram\", 24420]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Near ED - HiLo Teen Vanilla Caramel 500gr\", 84360]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) HiLo Gold Biscuit Cereal 500g\", 81030]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim Peanut Almond Butter Spread Jam 300 gram\", 92400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) HiLo Active Chocolate 1000 gr\", 129870]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Near ED - Wdank Madu Temulawak 10 Sachet\", 17316]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Near ED - Tropicana Slim Sweetener Gula Aren 50 sachet\", 43290]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Near ED - Tropicana Slim Soy Latte - Kopi Susu Kacang Bebas Gula\", 37740]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) Tropicana Slim BROWNIES Instant Powder Cake Mix 230 g\", 33300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) W'Dank Bandrek 10 sachet Renceng - Khusus Homdel\", 17316]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) Tropicana Slim Susu Low Fat Macchiato Coffee 500 gram\", 82140]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Near ED - Tropicana Slim Low Fat Milk Korean Strawberry 500g\", 84360]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo School 3+ Soya Multigrain Vanilla Malt 400g\", 99900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) HiLo Gold Chocolate 1000g\", 142080]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) L-Men Lose Weight Mango Sticky Rice 300gr\", 146520]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "   \n",
    "\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) HiLo Teen Biscuit Caramel 500gr\", 87700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Chocolate Mint 10 Sachet\", 18300]], columns = ['title', 'price']), ignore_index = True, sort = False) \n",
    "    \n",
    "    price = product_order[product_order['title'] == 'Tropicana Slim Goldenmil Vanilla (6sch)']['price'].values[0]\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    price = product_order[product_order['title'] == 'Lokalate Kopi Kawista (10sch)']['price'].values[0]\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Lokalate Kopi Kawista (10sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    price = product_order[product_order['title'] == 'Tropicana Slim Kecap Manis 200ml']['price'].values[0]\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200m', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    \n",
    "    #Komen Testing\n",
    "    data_SKU = pd.read_excel(r\"T:\\08. Learning Project\\Project eCom\\Proposal Andra\\Order Online\\Input Data\\SKU buat andra.xlsx\")\n",
    "    #data_SKU = pd.read_excel(r'Order Online\\SKU buat andra.xlsx')\n",
    "    data_SKU = data_SKU.rename(columns = {'Unnamed: 0' : 'SKU', 'ref.1' : 'product', 'Pricelist Nutrimart' : 'Price List NFI', 'Harga jua Homdel' : 'Harga Display'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip()\n",
    "\n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "    product_order['title'] = product_order['title'].astype(str)\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    s = requests.Session()\n",
    "    s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    with open(r'SKU_File\\Master tatanama.xlsx', 'wb') as output:\n",
    "        output.write(r.content)\n",
    "\n",
    "    if os.path.isfile(r'SKU_File\\Master tatanama.xlsx') :    \n",
    "        SKU_append = pd.read_excel(r'SKU_File\\Master tatanama.xlsx')\n",
    "        SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "        data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "        data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    to_excel = data_SKU2.to_excel(r'SKU_File\\data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    \n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Surabaya'\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "        indeks = data_order[data_order['Item Name'].astype(str).str.contains('pcs')].index.to_list()\n",
    "        temp = data_order.iloc[indeks].copy()\n",
    "        product = temp['Item Name'].str.split(\"\\(\",1, expand = True)\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        index = order_all[order_all['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        order_all['SKU'][index] = '2306592173'\n",
    "        order_all['Real SKU'][index] = '2306592173'\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Price' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "        \n",
    "        \n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Bundle SKU'] = data_bundle1['SKU']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['Bundle SKU'] = data_bundle2['SKU']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Bundle SKU'] = data_bundle3['SKU']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Bundle SKU'] = data_bundle4['SKU']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Bundle SKU'] = data_bundle5['SKU']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Bundle SKU'] = data_bundle6['SKU']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Bundle SKU'] = data_bundle7['SKU']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        \n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "        \n",
    "        order_all['Selling Price'] = order_all['Regular Price'].astype(int)\n",
    "        \n",
    "        data_SKU3 = pd.read_excel(r\"T:\\08. Learning Project\\Project eCom\\Proposal Andra\\Order Online\\Input Data\\SKU buat andra.xlsx\")\n",
    "        data_SKU3 = data_SKU3.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "        data_SKU3['SKU'] = data_SKU3['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "        data_SKU3 = data_SKU3[data_SKU3['SKU'] != 'nan'][data_SKU3[data_SKU3['SKU'] != 'nan']['SKU'] != '0'][data_SKU3[data_SKU3['SKU'] != 'nan'][data_SKU3[data_SKU3['SKU'] != 'nan']['SKU'] != '0']['Harga Coret'].notnull()]\n",
    "        data_SKU3['product'] = data_SKU3['product'].str.strip()\n",
    "        data_SKU3 = data_SKU3.reset_index(drop = True)\n",
    "        \n",
    "        for i in range(data_SKU3.shape[0]):\n",
    "            if data_SKU3['SKU'][i] in order_all['SKU'].values:\n",
    "                indeks = order_all[order_all['SKU'].astype(str) == i].index.to_list()\n",
    "                order_all['Regular Price'][indeks] = data_SKU3['Harga Display'][i]\n",
    "                order_all['Selling Price'][indeks] = data_SKU3['Harga Coret'][i]\n",
    "        \n",
    "        \n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Order Online Surabaya Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "         'Product Name',\n",
    "         'Customer Name',\n",
    "         'Phone',\n",
    "         'Address',\n",
    "         'Region',\n",
    "         'City',\n",
    "         'Zip Code',\n",
    "         'payment_status',\n",
    "         'Regular Price',\n",
    "         'Shipping Courier',\n",
    "         'Shipping Cost',\n",
    "         'Subtotal',\n",
    "         'Qty. Invoiced',\n",
    "         'SKU',\n",
    "         'Order #',\n",
    "         'Invoice Number',\n",
    "         'Shipping Name',\n",
    "         'Shipping Address2',\n",
    "         'Country',\n",
    "         'AWB',\n",
    "         'Channel',\n",
    "         'Order date',\n",
    "         'Real SKU',\n",
    "         'Real Nama Produk',\n",
    "         'Brand',\n",
    "         'Sub Brand',\n",
    "         'Parent Item',\n",
    "         'Parent SKU',\n",
    "         'Produk 1',\n",
    "         'SKU Produk 1',\n",
    "         'PCS Produk 1',\n",
    "         'Price List NFI 1',\n",
    "         'Subtotal Produk 1',\n",
    "         'Harga Display 1',\n",
    "         'Harga Cost 1',\n",
    "         'Harga Organik 1',\n",
    "         'Produk 2',\n",
    "         'SKU Produk 2',\n",
    "         'PCS Produk 2',\n",
    "         'Price List NFI 2',\n",
    "         'Subtotal Produk 2',\n",
    "         'Harga Display 2',\n",
    "         'Harga Cost 2',\n",
    "         'Harga Organik 2',\n",
    "         'Produk 3',\n",
    "         'SKU Produk 3',\n",
    "         'PCS Produk 3',\n",
    "         'Price List NFI 3',\n",
    "         'Subtotal Produk 3',\n",
    "         'Harga Display 3',\n",
    "         'Harga Cost 3',\n",
    "         'Harga Organik 3',\n",
    "         'Produk 4',\n",
    "         'SKU Produk 4',\n",
    "         'PCS Produk 4',\n",
    "         'Price List NFI 4',\n",
    "         'Subtotal Produk 4',\n",
    "         'Harga Display 4',\n",
    "         'Harga Cost 4',\n",
    "         'Harga Organik 4',\n",
    "         'Produk 5',\n",
    "         'SKU Produk 5',\n",
    "         'PCS Produk 5',\n",
    "         'Price List NFI 5',\n",
    "         'Subtotal Produk 5',\n",
    "         'Harga Display 5',\n",
    "         'Harga Cost 5',\n",
    "         'Harga Organik 5',\n",
    "         'Produk 6',\n",
    "         'SKU Produk 6',\n",
    "         'PCS Produk 6',\n",
    "         'Price List NFI 6',\n",
    "         'Subtotal Produk 6',\n",
    "         'Harga Display 6',\n",
    "         'Harga Cost 6',\n",
    "         'Harga Organik 6',\n",
    "         'Produk 7',\n",
    "         'SKU Produk 7',\n",
    "         'PCS Produk 7',\n",
    "         'Price List NFI 7',\n",
    "         'Subtotal Produk 7',\n",
    "         'Harga Display 7',\n",
    "         'Harga Cost 7',\n",
    "         'Harga Organik 7',\n",
    "         'Bundle Flag',\n",
    "         'Date',\n",
    "         'Month',\n",
    "         'Year',\n",
    "         'Quarter',\n",
    "         'Week',\n",
    "         'True datetime',\n",
    "         'Total',\n",
    "         'Price List NFI',\n",
    "         'Total Net',\n",
    "         'Selling Price',\n",
    "         'Kecamatan',\n",
    "         'Kelurahan',\n",
    "         'Bundle SKU',                             \n",
    "         'Bundle Name',\n",
    "         'Harga Cost',\n",
    "         'Total Harga Cost',\n",
    "         'Seller Discount',\n",
    "         'Shipping',\n",
    "         'Promo',\n",
    "         'Discount MC',\n",
    "         'Warehouse Name',\n",
    "         'Customer Email',\n",
    "         'Order Status',\n",
    "         'Payment Channel',\n",
    "         'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "\n",
    "        order_online_jatim = True\n",
    "        del file_name\n",
    "\n",
    "if not order_online_jkt:\n",
    "    import pandas as pd \n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "    \n",
    "    print('order_online_jkt')\n",
    "    #komen sementara\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    time.sleep(8)\n",
    "    username = driver.find_element(By.NAME, \"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"nutrimart.nfi@gmail.com\")\n",
    "\n",
    "    password = driver.find_element(By.NAME, \"password\")\n",
    "    password.send_keys(\"sumselhomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element(By.CLASS_NAME, \"btn-submit\").click()\n",
    "    time.sleep(20)\n",
    "    #Click Order\n",
    "    WebDriverWait(driver, 60).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a/span/span'))).click()\n",
    "    time.sleep(20)\n",
    "    #Click Order List\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div/nav/div/div/ul/li[3]/div/a[1]/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Calendar\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Last 7 Days\n",
    "    WebDriverWait(driver, 50).until(EC.visibility_of_element_located((By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    #Click Apply\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    time.sleep(20)\n",
    "    #Clicl Export\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[3]/div[1]/button/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Export to CSV\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[3]/div[1]/div/button[1]').click()\n",
    "\n",
    "\n",
    "    time.sleep(50)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "\n",
    "    product_order = pd.read_csv(r'data_supp/orderonline_products_Jakarta.csv')\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "\n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch')\n",
    "\n",
    "    data_SKU = pd.read_excel(r\"T:\\08. Learning Project\\Project eCom\\Proposal Andra\\Order Online\\Input Data\\SKU buat andra.xlsx\")\n",
    "    data_SKU = data_SKU.rename(columns = {'Unnamed: 0' : 'SKU', 'ref.1' : 'product', 'Pricelist Nutrimart' : 'Price List NFI', 'Harga jua Homdel' : 'Harga Display'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip()\n",
    "    product_order['title'] = product_order['title'].str.strip().str.replace('  ', ' ')\n",
    "    product_order['title'] = product_order['title'].str.strip().str.replace('L-Men Gain Mass Chocolate 500 gr', 'L Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Mango Smoothie 200ml (6pcs)', 36300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (6pcs)', 48000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)', 264000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate (12sch)', 5500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey (50sch)', 39500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Orange 750ml', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 225gr', 57500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gainmass Taro 225gr', 69600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo Milk Brown Sugar RTD 200ml (6pcs)', 33000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Lose Weight Chocolate Cereal (12sch)', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 139200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Strawberry Jam 375gr', 72600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Mangga Gandaria (40 sch)', 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Cegah Diabetes (+Kaos)', 116100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 250gr + Free Kertas Gambar', 40500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 750gr + Free Kertas Gambar', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Jeruk Peras (40sch x 2) + Nutrisari Mangga Gandaria (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Blewah (40sch x 2) + Nutrisari Jeruk Maroko (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Nutrisari American Sweet Orange (40sch x 2) + Nutrisari Milky Orange (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 500gr + Free Kertas Gambar', 117600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Ngopi Lokalate', 136000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 750gr', 127100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Florida Orange (40sch x 2) + Nutrisari Markisa (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Extra Virgin Olive Oil 500 ml', 82000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)', 94000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 Sch)', 15000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Platinum Choco Latte Dus 6 sch\", 80000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 104000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 75000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 42500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Es Cincau 40 sch\", 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 180400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 13200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 26400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 26400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Hilo Es Ketan Hitam 10 sch\", 13200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Jeruk Nipis (40 sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Madu Lemon (40 Sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Sweet Mango (40 sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Protein Bar Chocolate 12 sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Protein Crunch BBQ Beef (20gr)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo Chocolate Taro (10 sch)', 11000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Markisa (40 Sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)', 67500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Avocado Coffee 4 Sch x 2', 18200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Avocado Coffee 4 Sch', 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Cocopandan 40 sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sambal Terasi 200 gr', 22300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Lemon Tea 40 sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    product_order = product_order.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 13200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Vanilla 750gr', 102300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo RTD Kacang Hijau 200ml (6pcs)', 29700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Chocolate 250gr', 29150]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Milky Orange (40sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 28900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)', 52000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Vanilla 500gr', 66000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Jahe 50 sch', 38500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 13200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Gold Plain (Original) 750gr\", 92400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Vanilla Vegiberi 500gr', 71500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Lose Weight Chocolate Cereal 300gr', 104500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Honey 500gr', 71500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Garlic Butter Cookies 5 Sch', 20400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Taro 500gr', 71500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 pcs) - 12gr Protein / Serving', 211200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-MEN Gain Mass Taro 225 gr', 52800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School RTD Chocolate 200ml (6pcs)', 36300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sunflower Oil 946 ml', 57200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Whey Daily Dark Chocolate 250gr\", 49500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Vanilla 200gr', 59400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Chocolate 1000 gr', 136400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 1 GET 1 - W'Dank Empon Empon 10 Sachet Renceng\", 26400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Banana 225gr', 60500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Mangga Gandaria', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo RTD Kacang Hijau 200 ml', 4950]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate', 8800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(FREE) W'Dank Empon-Empon 10 sch\", 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Khusus Homdel - HiLo Chocolate Banana 10 sch', 11000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Lychee Tea 40 sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Strawberry 40 Sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School RTD Vanila Vegiberi 200ml (6pcs)', 36300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Saus Tiram 200ml', 39600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Shirataki Noodles 71gr', 28100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School RTD Vanila Vegiberi 200ml', 6100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Saus Tiram 200ml', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Shirataki Noodles 71gr', 14100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari American Sweet Orange (40 Sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Madu Kurma Pack (4R)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Milky Orange (40 sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo Chocolate (10 sch)', 11000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Swiss Chocolate (10 sch) Renceng', 16500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Leci 40 sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Sweet Guava (40 sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Hilo - Lebaran Edition', 56100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Ramadhan NutriSari 7 Rasa (7 x 10 sch)', 294000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Jeruk Peras (40 Sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Lebaran Tropicana Slim', 96300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Lokalate untuk Sobatku - Idul Fitri Edition', 54120]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Topping Kental Manis 150ml - SUGAR FREE', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Florida Orange (40 Sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo RTD Milky Brown Sugar 200 ml', 4950]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Belgian Chocolate (10 sch)', 41800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Mangga Gandaria (40 sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Asin 200 ml', 23650]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Apel Jeruk 40 Sachet', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Minyak Jagung 1lt', 69300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Coffee Tiramisu 200ml (6pcs) - Ready to Drink', 36300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Nutrisari Jeruk Madu Jeruk 40'sachet (4 Renceng)\", 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen RTD Coffee Tiramisu 200ml', 6050]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Milk Skim Chocolate 500gr', 111000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Mayonnaise 200 g x 2', 34800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Oat Drink 190 ml (RTD) x 4 pcs', 22600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Mayonnaise 200 g - Bantu Dukung Hidup Sehat', 17400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Oat Drink 190 ml (RTD)', 5650]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Baru! NutriSari NUTRI C1000 Jeruk 40 Sachet', 35000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: L-Men Daily Popcorn Caramel 250gr x 2', 78300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Daily Popcorn Caramel 250gr', 39150]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 FREE HiLo Joint Plus 140gr', 38300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Es Rujak Jeruk Bali 40 Sachet', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Lokalate Kopi Tape Ketan 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Tape Ketan 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False) \n",
    "    product_order = product_order.append(pd.DataFrame([['(FREE) Lokalate Kopi Tape Ketan 10 Sachet', 0]], columns = ['title', 'price']), ignore_index = True, sort = False) \n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Korean Goguma Cookies (5 Sch) x 2', 32200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Goguma Cookies (5 Sch)', 16100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Lokalate Kopi Andaliman 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Andaliman 10 Sachet', 6850]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(FREE) Lokalate Kopi Andaliman 10 Sachet', 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Goguma Cookies (5 Sch)', 16100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Plain 1000 gr', 128200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NuTrilogi Seri Mas Kaka yang Banyak Akal', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Vanilla Vegiberi 500gr', 76600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Vanilla Caramel 500gr', 76600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari NUTRI C1000 Jeruk 40 Sachet', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo Joint Plus Orange 140 gram x 2', 55300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Tape Ketan 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Popcorn Caramel 500 gram - Susu Tinggi Kalsium Lebih Rendah Lemak', 68600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo School Strawberry Cheesecake 500 gram x 2', 110600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Yuzu Orange 40 sch', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Jeruk Jeju [40 Sachet]', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Strawberry Cheesecake 500 gram', 55300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin pack - Lokalate Kopi Andaliman 10 Sachet', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Masak Sehat', 125000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Extra Virgin Olive Oil 500 ml', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200ml', 27500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Santan 5 sachet', 15400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin pack - Lokalate Kopi Tape Ketan 10 Sachet', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Tape Ketan 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Chocolate Taro RTD 200ml (4pcs)', 22900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Chocolate Taro RTD 200ml', 5750]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Ngemil Sehat', 125000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Goguma Cookies (5 Sch)', 21200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Oat Drink 190 ml (RTD)', 7500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Topping Kental Manis 150ml - SUGAR FREE', 29700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese Cookies', 21200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Avocado Coffee 4 Sch', 12600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['2102900319 (D)', 82500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['2102500336 (classic stick)', 46900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Jeruk Maroko (40 Sch) FREE Lokalate Andaliman (10 Sch)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Nutty Chocolate Cookies 200gr', 40000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Es Rujak (4R)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Jeruk Maroko (40 sch)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(FREE) Lokalate Kopi Andaliman 10 Sachet', 13600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Chocolate 750gr', 111000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Yoghurt Smoothie Bowl Strawberry (8 sch)', 62900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Chocolate Ready To Drink (4 tetrapack)', 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo Teen Chocolate Ready To Drink Susu [4 pcs]', 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School RTD Coklat 200ml', 6525]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen RTD Coklat 200ml', 6525]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo Almond Milk Coconut 200gr x 2', 70000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate x 4 pcs', 38400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Almond Milk Coconut 200gr', 35000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate', 9600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Thai Tea Ready to Drink 200ml x 4pcs', 22900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo RTD Thai Tea 200ml', 5750]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"W'Dank Bajigur (10 sch)\", 17200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"W'Dank Bandrek 10 sachet Renceng\", 17200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo Milky Brown Sugar Ready To Drink 200ml (4 Tetrapack)', 22900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Vanilla Vegiberi Ready To Drink Susu [200ml/4 pcs]', 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Hilo RTD Milky Brown Sugar 200 ml\", 5725]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo School RTD Vanila Vegiberi 200ml\", 6525]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo School Chocolate Candy (10 sch)\", 18300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"2102500320 (CI160)\", 72160]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Chocolate 1000 gr', 141900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Triple Pack: Tropicana Slim Klepon Cookies (5 Sch)', 50000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Klepon Cookies (5 Sch)', 16700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Jeruk Nipis Jahe 40 Sachet', 35000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Shirataki Rice 72 g', 50000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Shirataki Rice 72 g', 25000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Leci 750ml', 30900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Mango Smoothie 200ml (4 Pcs)', 27500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari RTD Mango Smoothie 200 ml', 6900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Es Teler 175gr', 26300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Platinum Swiss Chocolate 420gr', 91500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Es Kuwud Nipis', 37500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Classic Refill 500gr', 104100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Brownies Instant Powder Cake Mix 230 g - Bantu Dukung Hidup Sehat', 59400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Bundle - HiLo Teen Taro 500gr & HiLo Teen Strawberry Milkshake 500g', 127200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 Free - HiLo School Bubble Gum 500g', 92400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HILO ALMOND MILK COCONUT 12DX200G', 51500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Taro 500gr', 80100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED) HiLo School RTD Coklat 200ML', 6900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Strawberry Milkshake 500g', 75500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener I Sweet', 25200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Lokalate Kopi Pisang Bakar 10 sch', 17500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Pisang Bakar Epe 10 sch', 8750]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Vanilla Vegiberi 750gr', 116700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Coffee Milk Pillow Bag (2 sch)', 10300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Lychee Tea Refill 500 gram', 34300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Cookies Paket Hampers Idul Fitri Parcel Lebaran', 131600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Lemon-C (25 sch)', 25200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim High Fiber High Calcium Milk Chocolate 500gr', 116700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Lemon Tea 500 gram', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Jeruk Peras Refill 500 gr', 37800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['LOKALATE KOPI PISANG BAKAR EPE', 15000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 - Tropicana Slim Mint Cocoa - Minuman Cokelat Mint Nikmat Tanpa Gula Pasir', 20000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Es Pisang Ijo 10 Sch x 2 pcs', 17500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ '(Near ED)L-Men Platinum Kacang Hijau 800g', 158750]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'L-Men Platinum Choco Latte 800 gr - Near ED', 164500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'NutriSari RTD Jeruk Madu 200 ml', 6000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'NutriSari Jeruk Manis 500gr', 38100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'L-Men Gain Mass Mangga 500gr', 133900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Avocado Chocolate (10 Sch)', 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo White Chocolate (10 Sch)', 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'Diabetamil Milk Vanilla 150 gram', 35000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'Buy 1 Get 1 FREE Tropicana Slim Susu Low Fat Macchiato Coffee 500gr', 143000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Active Chocolate 1000 gr', 121200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Joint Plus Orange 140 gram', 38700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'Tropicana Slim Susu Low Fat Macchiato Coffee 500 gram', 71500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Teen Biscuit Caramel 500gr', 65000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Active Caramel Latte 500g', 65800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'Buy 1 Get 1 Free - HiLo Gold Biscuit Cereal 500g', 80800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HILO TEEN STRAWBERRY MILKSHAKE\\xa0 12DX500G', 76200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo School Bubble Gum 500g', 80800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ '2102500336 (CS)', 49200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Thai Tea Refill 500g', 48000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'Hilo Teen Coffee Tiramisu Ready To Drink Susu UHT [4 pcs]', 27600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ '(Near ED)L-Men Platinum Ketan Hitam 800g', 157300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Klepon Latte Refill 500g - Powder Drink Tinggi Kalsium', 46800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'NutriSari Gula Asem 40 Sachet', 43300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'NutriSari Anggur Hijau 40 Sachet', 43300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Es Pisang Ijo 10 Sch', 14300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'Buy 1 Get 1 FREE L-Men Lose Weight Mango Sticky Rice 300gr', 145200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[ 'TRIPLE DEALS - NutriSari Lychee Tea & Lemon Tea 500 gram Refill', 72700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'TRIPLE HEMAT - NutriSari Lemon Tea 500 gram', 72700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'TRIPLE HEMAT - HiLo Thai Tea Refill 500g', 72700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'TRIPLE HEMAT - HiLo Klepon Latte Refill 500g', 109100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'Bundle - Lokalate Kopi Alpukat Refill 500 gram & Kopi Berondong Refill 500 gram', 46200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'TRIPLE HEMAT - NutriSari Lychee Tea Refill 500 gram', 72700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ '(Near ED)L-Men Gain Mass Mangga 500gr', 66350]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'Lokalate Kopi Berondong 500 gram - Tinggi Vitamin A Lebih Rendah Gula', 44400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'Lokalate Kopi Alpukat 500 gram - Tinggi Vitamin A Lebih Rendah Gula', 44400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"Buy 1 Get 1 - Tropicana Slim Bumbu Kaldu Ayam dan Jamur 100 gram\", 48500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 1 GET 1 - HiLo Platinum Original 360 gram\", 255000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) HiLo School Chocolate 1000 gr\", 148700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Near ED - HiLo Teen Chocolate 1000 gr\", 148700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) HiLo Joint Plus Orange 140 gram\", 19150]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "   \n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twinpack Lokalate Kopi Berondong Refill 500 gram\", 92400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 1 GET 1 - Tropicana Slim Soy Latte - Kopi Plant Based Rendah Gula\", 40900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twinpack Tropicana Slim Bumbu Saus Telur Asin 3 Sachet - Lebih Rendah Lemak dan Garam\", 29000]], columns = ['title', 'price']), ignore_index = True, sort = False)       \n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) HiLo Active Caramel Latte 500g\", 65200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) HiLo Active Chocolate 1000 gr\", 120100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 12 GET 12 - NutriSari RTD Squeezed Orange 200 ml - Minuman Jeruk Peras Vitamin C\", 240000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) Lokalate Kopi Pisang Bakar Epe 10 sch\", 15000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 3 Get 3 - HiLo Milky Vanilla Cookies Ready to Drink 200ml', 60000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED) - Tropicana Slim Sweetener Classic Stick Industrial (100 Sch)', 26640]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Vanilla 1000g - Susu Tinggi Kalsium Lebih Rendah Lemak', 115000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 Free - HiLo Teen Original 400g - Susu Tinggi Kalsium Lebih Rendah Lemak', 191400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Near ED - HiLo Gold Plain 1000 gr', 144300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 Free - HiLo School Original 400g - Susu Tinggi Kalsium Lebih Rendah Lemak', 191400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Peanut Almond Butter Spread Jam 300 gram', 184800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Orange Cocoa 4 Sachet - Minuman Cokelat Jeruk Nikmat Tanpa Gula Pasir', 16650]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari RTD Squeezed Orange 200 ml x 24 pcs - Minuman Jeruk Peras Vitamin C', 144100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twinpack HiLo Platinum Original 360gram', 230900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Es Ketan Hitam 500g - Powder Drink Tinggi Kalsium', 46200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['4 pack - NutriSari RTD Squeezed Orange 200 ml - Minuman Jeruk Peras Vitamin C', 24000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 1000g - Susu Tinggi Kalsium Lebih Rendah Lemak', 147800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Orange Cocoa 4 Sachet - Minuman Cokelat Jeruk Nikmat Tanpa Gula Pasir', 40000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 2 GET 2 - NutriSari RTD Squeezed Orange 200 ml - Minuman Jeruk Peras Vitamin C', 40000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Taro 500g x 2 pcs', 267800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Taro Latte Refill 500g', 48500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo Platinum Swiss Chocolate (12 Sch)', 189300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Hampers Lebaran Fancy Tote Bag Tropicana Slim\", 186500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 2 GET 2 - Tropicana Slim RTD Almond Drink Chocolicious 190 ml\", 33400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo RTD Milky Vanilla Cookies 200ml\", 7700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 12 GET 12 - Tropicana Slim RTD Almond Drink Chocolicious 190 ml\", 199800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Platinum Bubble Gum 800 gram\", 375200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Less Sugar Belimbing 40 sachet\", 62000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Wdank Madu Temulawak 10 Sachet\", 18000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Buy 2 Get 2 Free - L-Men UHT PlantProtein 2GO Ogura with 12g Protein & 1,6g BCAA\", 61600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim RTD Almond Drink Chocolicious 190 ml\", 8700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) L-Men Platinum Bubble Gum 800 gram\", 375200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Buy 1 Get 1 Free - HiLo Teh Tarik (10 Sachet) - Teh Tarik Tinggi Kalsium Bervitamin\", 32190]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Isotonik 40 Sachet – Minuman Isotonik Buah Jeruk Segar\", 62000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Teh Tarik (10 Sachet) - Teh Tarik Tinggi Kalsium Bervitamin\", 16095]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 12 GET 12 - Tropicana Slim Oat Drink Japanese Cantaloupe Melon\", 240000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Near ED - Wdank Madu Temulawak 10 Sachet\", 17316]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Near ED - Wdank Sarabba Extra 10 Sachet\", 18870]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) Tropicana Slim Susu Low Fat Macchiato Coffee 500 gram\", 82140]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Near ED - L-Men Gain Mass Klepon Latte 500g\", 146520]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    \n",
    "    price = product_order[product_order['title'] == 'Tropicana Slim Goldenmil Vanilla (6sch)']['price'].values[0]\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    price = product_order[product_order['title'] == 'Lokalate Kopi Kawista (10sch)']['price'].values[0]\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Lokalate Kopi Kawista (10sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Kawista', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    price = product_order[product_order['title'] == 'Tropicana Slim Kecap Manis 200ml']['price'].values[0]\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200m', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    price = product_order[product_order['title'] == 'Tropicana Slim Diabtx 50 sch']['price'].values[0]\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Diabtx (50 sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "    product_order['title'] = product_order['title'].astype(str)\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    s = requests.Session()\n",
    "    s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    with open(r'SKU_File\\Master tatanama.xlsx', 'wb') as output:\n",
    "        output.write(r.content)\n",
    "\n",
    "    if os.path.isfile(r'SKU_File\\Master tatanama.xlsx') :    \n",
    "        SKU_append = pd.read_excel(r'SKU_File\\Master tatanama.xlsx')\n",
    "        SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "        data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "        data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    to_excel = data_SKU2.to_excel(r'SKU_File\\data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    indeks\n",
    "    \n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Jakarta'\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "        indeks = data_order[data_order['Item Name'].astype(str).str.contains('pcs')].index.to_list()\n",
    "        temp = data_order.iloc[indeks].copy()\n",
    "        product = temp['Item Name'].str.split(\"\\(\",1, expand = True)\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        index = order_all[order_all['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        order_all['SKU'][index] = '2306592173'\n",
    "        order_all['Real SKU'][index] = '2306592173'\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Price' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Bundle SKU'] = data_bundle1['SKU']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['Bundle SKU'] = data_bundle2['SKU']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Bundle SKU'] = data_bundle3['SKU']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Bundle SKU'] = data_bundle4['SKU']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Bundle SKU'] = data_bundle5['SKU']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Bundle SKU'] = data_bundle6['SKU']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Bundle SKU'] = data_bundle7['SKU']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "        \n",
    "        order_all = order_all.reset_index()\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost'], errors = 'coerce').fillna(0).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        \n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        order_all['Selling Price'] = order_all['Regular Price'].astype(int)\n",
    "\n",
    "        data_SKU3 = pd.read_excel(r\"T:\\08. Learning Project\\Project eCom\\Proposal Andra\\Order Online\\Input Data\\SKU buat andra.xlsx\")\n",
    "        data_SKU3 = data_SKU3.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "        data_SKU3['SKU'] = data_SKU3['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "        data_SKU3 = data_SKU3[data_SKU3['SKU'] != 'nan'][data_SKU3[data_SKU3['SKU'] != 'nan']['SKU'] != '0'][data_SKU3[data_SKU3['SKU'] != 'nan'][data_SKU3[data_SKU3['SKU'] != 'nan']['SKU'] != '0']['Harga Coret'].notnull()]\n",
    "        data_SKU3['product'] = data_SKU3['product'].str.strip()\n",
    "        data_SKU3 = data_SKU3.reset_index(drop = True)\n",
    "\n",
    "        for i in range(data_SKU3.shape[0]):\n",
    "            if data_SKU3['SKU'][i] in order_all['SKU'].values:\n",
    "                indeks = order_all[order_all['SKU'].astype(str) == i].index.to_list()\n",
    "                order_all['Regular Price'][indeks] = data_SKU3['Harga Display'][i]\n",
    "                order_all['Selling Price'][indeks] = data_SKU3['Harga Coret'][i]\n",
    "\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle SKU', \n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "        \n",
    "        order_all_append['True datetime'] = pd.to_datetime(order_all_append['True datetime'])\n",
    "\n",
    "        indeks = order_all_append[\n",
    "            (order_all_append['True datetime'] > pd.to_datetime('2021-02-28')) &\n",
    "            (order_all_append['Channel'] == 'Order Online Jakarta')\n",
    "        ].index.to_list()\n",
    "\n",
    "        order_all_append['Channel'][indeks] = 'Order Online Sumsel'\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "\n",
    "        order_online_jkt = True\n",
    "        del file_name\n",
    "\n",
    "if not order_online_jateng:\n",
    "            \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "    \n",
    "    print('order_online_jateng')\n",
    "\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element(By.NAME, \"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customer1@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element(By.NAME, \"password\")\n",
    "    password.send_keys(\"jatenghomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element(By.CLASS_NAME, \"btn-submit\").click()\n",
    "    time.sleep(20)\n",
    "    #Click Order\n",
    "    WebDriverWait(driver, 60).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a/span/span'))).click()\n",
    "    time.sleep(20)\n",
    "    #Click Order List\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div/nav/div/div/ul/li[3]/div/a[1]/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Calendar\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Last 7 Days\n",
    "    WebDriverWait(driver, 50).until(EC.visibility_of_element_located((By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    #Click Apply\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    time.sleep(20)\n",
    "    #Clicl Export\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[3]/div[1]/button/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Export to CSV\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[3]/div[1]/div/button[1]').click()\n",
    "\n",
    "\n",
    "    time.sleep(30)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name), error_bad_lines=False, engine=\"python\")\n",
    "    \n",
    "    driver.close()\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch (x2) ', 'Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Tropicana Slim Oat Drink 190 ml \\(RTD\\) x 4 pcs$', 'Tropicana Slim Oat Drink 190 ml (RTD) x 4 pcs (x1)')\n",
    "    data_order=data_order[data_order['product']!=\"2102500336 (CS)\"]\n",
    "    data_order=data_order.reset_index(drop=True)\n",
    "    \n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    product = product[product[0] != 'nan']\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"Rtd\", \"RTD\").str.replace('Turmeric 180gr', 'Turmeric (6 sch)').str.replace('L-Men Gainmass Taro 225gr', 'L-Men Gain Mass Taro 225 gr').str.replace('L-Men Lose Weight Chocolate Cereal (12sch)', 'L-Men Lose Weight Chocolate Cereal 300gr').str.replace(' (+kaos)', ' (+Kaos)', regex = False).str.replace('40 sch', '40sch', regex = False).str.replace('Coklat', 'Chocolate', regex = False)\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "\n",
    "    data_SKU = pd.read_excel(r\"T:\\08. Learning Project\\Project eCom\\Proposal Andra\\Order Online\\Input Data\\SKU buat andra.xlsx\")\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"Rtd\", \"RTD\").str.replace('Turmeric 180gr', 'Turmeric (6 sch)').str.replace('L-Men Gainmass Taro 225gr', 'L-Men Gain Mass Taro 225 gr').str.replace('L-Men Lose Weight Chocolate Cereal (12sch)', 'L-Men Lose Weight Chocolate Cereal 300gr').str.replace(' (+kaos)', ' (+Kaos)', regex = False).str.replace('40 sch', '40sch', regex = False).str.replace('Coklat', 'Chocolate', regex = False)\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Platinum Swiss Chocolate 420gr', 91500, 91500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim White Coffee (4 sch)', 21200, 18400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-MEN Gain Mass Taro 225 gr', 58300, 58300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Extra Virgin Olive Oil 500ml', 85800, 85800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Jeruk Peras Refill 500gr', 34300, 34300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500gr', 125800, 125800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Jeruk Manis Refill 500gr', 37800, 37800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Roasted Sesame Mayonnaise 200g - Bantu Dukung Hidup Sehat', 22900, 22900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Shirataki Rice 72 g', 50000, 50000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Jeruk Nipis Jahe 40 Sachet', 62500, 35000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo school Chocolate 250g (Health & green Science Competition)', 38300, 38300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Kacang Hijau Ready to Drink 200ml (4 tetrapack)', 22900, 22900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Shirataki Noodles 71gr', 9700, 9700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo RTD Kacang Hijau 200 ml', 2850, 2850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo RTD Milky Brown Sugar 200 ml', 2550, 2550]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HILO TEEN STRAWBERRY MILKSHAKEÂ\\xa0 12Dx500G', 66800, 66800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Cocopandan 40sch', 21300, 21300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Lemon Tea (40sch)', 42600, 42600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Mayonnaise 200 g', 11450, 11450]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Caramel Latte 500g', 95000, 50500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo school Cotton Candy 500g', 88400, 62500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Oat Drink 190ml (RTD)', 9999, 7500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 Free - HiLo school Bubble Gum 500g', 154000, 92400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Brownies Instant Powder Cake Mix 230 g - Bantu Dukung Hidup Sehat', 59400, 59400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 pcs) - 12gr Protein / Serving', 237600, 199000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Klepon Latte Refill 500g - Powder Drink Tinggi Kalsium', 59400, 49500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Brownies Instant Powder Cake Mix 230g - Bantu Dukung Hidup Sehat', 59400, 59400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HILO ALMOND MILK COCONUT 12Dx200G', 51500, 51500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo school Bubble Gum 500g', 80100, 80100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Lemon Tea 500 gram', 42000, 34300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Teen Biscuit Caramel 500gr', 92400, 65000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE L-Men Lose Weight Mango Sticky Rice 300gr', 290400, 145200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 - Tropicana Slim Mint Cocoa - Minuman Cokelat Mint Nikmat Tanpa Gula Pasir', 40000, 20000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Es Pisang Ijo 10 sch x 2 pcs', 35000, 17500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NuTrilogi Seri Mas Kaka yang Banyak Akal', 70000, 42600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE Tropicana Slim Susu Low Fat Macchiato Coffee 500gr', 257400, 143000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Lokalate Kopi Pisang Bakar 10 sch', 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Choco Series Paket Hampers Idul Fitri Parcel Lebaran', 185300, 139600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Brownies Instant Powder Cake Mix 230g - Bantu Dukung Hidup Sehat', 31200, 31200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Soy Latte - Kopi Plant Based Rendah Gula', 81800, 36900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Susu Low Fat Macchiato Coffee 500 gram', 75000, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Teen Taro 500gr - Khusus Homdel', 80800, 40400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari RTD Jeruk Madu 200 ml (4 tetrapack)', 24000, 24000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) W'dank Bandrek 10 sachet Renceng - Khusus Homdel\", 17300, 8650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) W'dank Empon-Empon 10 sch - Khusus Homdel\", 15000, 7500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 1 Get 1 Free - HiLo Gold Biscuit Cereal 500g\", 161600, 80800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 500 gram - Tinggi Vitamin A Lebih Rendah Gula\", 59400, 44400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) HiLo Joint Plus Orange 140 gram\", 38300, 19150]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) HiLo Active Es Teler 175gr\", 29700, 14850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) Lokalate Kopi Tape Ketan 10's\", 14900, 7450]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sweetener Jahe (50 sch)\", 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Anggur Hijau 40 Sachet\", 62000, 43290]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Gula Asem 40 Sachet\", 62000, 43290]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack - Tropicana Slim Low Fat Milk Korean Strawberry 500g\", 257400, 159900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Temulawak Madu\", 42000, 33300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack - Tropicana Slim Low Fat Milk Korean Strawberry 500g\", 257400, 159900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Temulawak Madu\", 42000, 33300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"TRIPLE HEMAT - HiLo Taro Latte Refill 500g\", 145500, 101800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"TRIPLE HEMAT - HiLo Thai Tea Refill 500g\", 144000, 100900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"TRIPLE DEALS - NutriSari Lychee Tea & Lemon Tea 500 gram Refill\", 103900, 72700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twinpack Tropicana Slim Bumbu Saus Telur Asin 3 Sachet - Lebih Rendah Lemak dan Garam\", 58000, 29000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Near ED - Lokalate Kopi Andaliman 10 Sachet\", 15000, 7500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo RTD Chocolate Avocado 200ml (4pcs)\", 25400, 25400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 1 Get 1 - L-Men Gain Mass Klepon Latte\", 277100, 138500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HILO TEEN STRAWBERRY MILKSHAKE\\xa0 12Dx500G\", 86600, 86600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Bumbu Kaldu Ayam Jamur 100 gram\", 24200, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo school Cotton Candy 200ml - Ready to Drink (4 Pcs) Tinggi Kalsium\", 28600, 28600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Bumbu Saus Telur Asin 3 Sachet - Lebih Rendah Lemak dan Garam\", 23100, 23100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Wdank Madu Temulawak 10 Sachet\", 17300, 17300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Lokalate Kopi Pisang Bakar Epe 10 sch', 15000, 7500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"4 pack - NutriSari RTD Squeezed Orange 200 ml - Minuman Jeruk Peras Vitamin C\", 24000, 17500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Active Caramel Latte 500g', 71600, 35800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    " \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Twinpack HiLo Platinum Original 360gram', 230900, 129200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Teen Strawberry Milkshake 500g', 87700, 43850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Klepon Latte Refill 500g', 51900, 15570]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hampers Lebaran Fancy Tote Bag Tropicana Slim', 186500, 130000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Premium Jus Mangga 10 Sachet', 25000, 17760]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - NutriSari Jeruk Nipis Jahe 40 Sachet', 47300, 14190]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - Tropicana Slim Sweetener Rose Vanilla 50 sch', 45000, 13500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Multigrain Original 500g', 99300, 49650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Gula Aren 50 sachet', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari RTD Squeezed Orange 200 ml x 24 pcs - Minuman Jeruk Peras Vitamin C', 144100, 144100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Es Ketan Hitam Refill 500g', 46200, 23100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Less Sugar Belimbing 40 sachet', 62000, 45510]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim French Butter Souffle Coffee 4 Sachet', 16200, 16200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim RTD Almond Drink Chocolicious 190 ml', 8700, 8700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - L-MEN Gain Mass Taro 225 gr', 78500, 39250]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Lokalate Kopi Berondong Refill 500 gram', 48500, 14550]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Lokalate Kopi Alpukat Refill 500 gram', 48500, 14550]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Active Vanilla 1000g', 146600, 43980]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Goldenmil Vanilla (6 sch)', 33500, 16750]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Salted Caramel Cocoa 4 Sachet', 26000, 16650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Susu Low Fat Macchiato Coffee 500 gram', 85400, 42700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Active Chocolate 1000 gr', 135100, 40530]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo Es Pisang Ijo 10 sch', 16700, 8350]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['2102500320 (CI160)', 88800, 88800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Korean Garlic Butter Cookies (5 sch)', 24200, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese Cookies (5 sch)', 24200, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo Gold Plain (Original) 500gr', 78600, 23500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Jeruk Peras Refill 500 gr', 36300, 18150]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Soy Latte - Kopi Susu Kacang Bebas Gula', 37300, 18650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Bumbu Kaldu Ayam Jamur 100 gram', 24500, 7700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - NutriSari Gula Asem 40 Sachet', 47200, 14200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Apel Jeruk 40 Sachet', 47300, 23650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False) \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Santan Less Fat (5 sch)', 18500, 18500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False) \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Choco Hazelnut (10 sch)', 13300, 13300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False) \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Teen Biscuit Caramel 500gr', 87700, 26310]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False) \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Teen Coffee Tiramisu Ready To Drink Susu UHT [4 pcs]', 28800, 28800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False) \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate x 4 pcs', 50800, 50800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False) \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'dank Bajigur (10 sch)\", 18000, 18000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False) \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo Taro Latte Refill 500g', 46620, 14000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False) \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Cocopandan (40sch)', 47300, 47300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False) \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Gold Biscuit Cereal 500g', 81030, 24400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False) \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) W'dank Bandrek 10 sachet Renceng\", 17316, 8700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False) \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Low Fat Milk Korean Strawberry 500g', 84360, 59100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False) \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Wdank Madu Temulawak 10 Sachet', 17316, 8700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False) \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Es Kuwud Nipis', 45520, 31900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False) \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo school Chocolate Ready To Drink (4 tetrapack)', 28800, 28800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False) \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo school Vanilla Vegiberi Ready To Drink Susu [200ml/4 pcs]', 28800, 28800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False) \n",
    "\n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    s = requests.Session()\n",
    "    s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    with open(r'SKU_File\\Master tatanama.xlsx', 'wb') as output:\n",
    "        output.write(r.content)\n",
    "\n",
    "    if os.path.isfile(r'SKU_File\\Master tatanama.xlsx') :    \n",
    "        SKU_append = pd.read_excel(r'SKU_File\\Master tatanama.xlsx')\n",
    "        SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "        data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "        data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    to_excel = data_SKU2.to_excel(r'SKU_File\\data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Jateng'\n",
    "\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "\n",
    "        \n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Bundle SKU'] = data_bundle1['SKU']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['Bundle SKU'] = data_bundle2['SKU']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Bundle SKU'] = data_bundle3['SKU']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Bundle SKU'] = data_bundle4['SKU']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Bundle SKU'] = data_bundle5['SKU']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Bundle SKU'] = data_bundle6['SKU']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Bundle SKU'] = data_bundle7['SKU']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "        \n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "        \n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost'], errors = 'coerce').fillna(0).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "        \n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "        \n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle SKU',                           \n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "\n",
    "        order_online_jateng = True\n",
    "        del file_name\n",
    "\n",
    "if not order_online_bali:\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "    \n",
    "    print('order_online_bali')\n",
    "\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element(By.NAME, \"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customerbali@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element(By.NAME, \"password\")\n",
    "    password.send_keys(\"balihomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element(By.CLASS_NAME, \"btn-submit\").click()\n",
    "    time.sleep(20)\n",
    "    #Click Order\n",
    "    WebDriverWait(driver, 60).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a/span/span'))).click()\n",
    "    time.sleep(20)\n",
    "    #Click Order List\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div/nav/div/div/ul/li[3]/div/a[1]/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Calendar\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Last 7 Days\n",
    "    WebDriverWait(driver, 50).until(EC.visibility_of_element_located((By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    #Click Apply\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    time.sleep(20)\n",
    "    #Clicl Export\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[3]/div[1]/button/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Export to CSV\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[3]/div[1]/div/button[1]').click()\n",
    "\n",
    "\n",
    "    time.sleep(30)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "#         data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Jakarta.csv')\n",
    "#             product_order = pd.read_csv(r'Input Data/orderonline_products_Jakarta.csv')\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch (x2) ', 'Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch ', regex = False)\n",
    "\n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\")\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "\n",
    "    data_SKU = pd.read_excel(r\"T:\\08. Learning Project\\Project eCom\\Proposal Andra\\Order Online\\Input Data\\SKU buat andra.xlsx\")\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\")\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "  \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "  \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo School Chocolate 500gr', 38300, 38300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)Tropicana Slim Extra Virgin Olive Oil 500 ml', 42900, 42900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo Active Vanilla 500gr', 32600, 32600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo Gold Plain (Original) 500gr', 36600, 36600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo Teen Chocolate 750gr', 55500, 55500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo School Chocolate 750gr', 55500, 55500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)L-Men Gain Mass Chocolate 500gr', 62900, 62900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Platinum Choco 800 gr - Near ED', 157300, 157300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo Teen Chocolate 500gr', 38300, 38300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo RTD Milky Brown Sugar 200 ml', 2574, 2574]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Thai Tea 200ml - Near ED', 2860, 2860]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 - L-Men Gain Mass Klepon Latte', 277100, 138500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 12 Get 12 - HiLo Chocolate Avocado Ready to Drink 200ml - Minuman Siap Minum Tinggi Kalsium', 152400, 84000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Korean Garlic Butter Cookies 5 sch - Khusus Homdel', 11150, 11150]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Active Chocolate 1000 gr', 60050, 60050]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) L-Men PlantProtein Ogura 216g', 57700, 57700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Active Caramel Latte 500g', 32600, 32600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari RTD Squeezed Orange 200 ml x 24 pcs - Minuman Jeruk Peras Vitamin C', 144100, 99000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Premium Jus Mangga 10 Sachet', 25000, 17760]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['4 pack - NutriSari RTD Squeezed Orange 200 ml - Minuman Jeruk Peras Vitamin C', 24000, 13400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Twinpack HiLo Platinum Original 360gram', 230800, 129200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hampers Lebaran Fancy Tote Bag Tropicana Slim 6', 186500, 130000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - L-MEN Gain Mass Taro 225 gr', 78500, 39250]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Platinum Swiss Chocolate 420gr', 94700, 47350]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Blewah (40 sch)', 47300, 23635]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Oat Drink 190 ml (RTD)', 8100, 4050]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Milk Skim Chocolate 500gr', 117700, 58850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - NutriSari Jeruk Peras (40 sch)', 47300, 23650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Avocado Chocolate (10 sch)', 13650, 6650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari American Sweet Orange (40 sch)', 47300, 23650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - NutriSari Florida Orange (40 sch)', 47300, 23650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Klepon Latte Refill 500g', 51900, 25950]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Teen Biscuit Caramel 500gr', 87700, 43850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Susu Low Fat Macchiato Coffee 500 gram', 85400, 42700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Goldenmil Vanilla (6 sch) - Near ED', 33500, 16750]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim RTD Almond Drink Chocolicious 190 ml', 8700, 8700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Less Sugar Belimbing 40 sachet', 62000, 45510]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['2102500320 (CI160)', 88800, 88800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo RTD Chocolate Avocado 200ml', 6300, 3150]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Jeruk Peras Refill 500 gr', 190500, 19050]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari RTD Jeruk Madu 200 ml', 6000, 3000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 24200, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Es Ketan Hitam 500g - Powder Drink Tinggi Kalsium', 46200, 46200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Leci 40 sch', 42600, 42600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Chocolate Taro RTD 200ml (4pcs)', 25200, 25200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)Tropicana Slim Strawberry Jam 375gr', 77300, 38650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Avocado Coffee 4 sch', 15540, 7800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) L-Men Proteinmix Coffee 6 sachet x 33gr', 61050, 18300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - L-Men Gain Mass Klepon Latte 500g', 146520, 102564]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Low Fat Milk Korean Strawberry 500g', 84360, 42180]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Minyak Kanola 946ml', 77700, 54400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Teen RTD Coklat 200ml - Khusus Homdel', 6882, 3400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)L-Men Protein Bar Chocolate 12 sch', 102564, 71800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - HiLo Swiss Chocolate (10 sch) Renceng', 19425, 9700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo School RTD Coklat 200ML', 6882, 3400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Teen RTD Coffee Tiramisu 200ml - Khusus Homdel', 6882, 3400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Bumbu Kaldu Ayam Jamur 100 gram', 24420, 7300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Sunflower Oil 946 ml', 84360, 25408]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Gold Vanilla 500gr - Khusus Homdel', 81030, 40500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Lemon Tea 500 gram', 34965, 17483]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Lokalate Kopi Berondong Refill 500 gram', 46620, 14000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari NUTRI C1000 Jeruk 40 Sachet', 45510, 22800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo School Vanilla 1000g', 149850, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo School Susu Coklat (10 sch) Gusset - Khusus Homdel', 46620, 23300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Madu Lemon (40 sch)', 45510, 22800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) NutriSari Es Rujak 40's\", 45510, 13650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Markisa (40 sch)', 45510, 22800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Lemon-C (25 sch)', 25530, 7700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Es Kuwud Nipis', 45510, 13650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Sweetener Gula Aren 50 sachet', 43290, 13000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo Es Pisang Ijo 10 sch', 16095, 4829]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) Tropicana Slim Madu 350ml\", 66600, 46600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Thai Tea (10sch) - Near ED', 16095, 11300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Salted Caramel Cocoa 4 Sachet', 26000, 16650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Chocolate Taro RTD 200ml - Near ED', 6105, 1832]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Choco Hazelnut (10 sch)', 13300, 13300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Anggur (40 sch)', 42600, 42600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Sweet Mango (40 sch)\", 42600, 42600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Diabtx (25 sch)', 22900, 22900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Strawberry 40 sch', 42600, 42600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Teen Chocolate 250gr', 39500, 39500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Jeruk Nipis (40 sch)', 47300, 47300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'dank Bajigur (10 sch)\", 18000, 18000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo Teen Vanilla 750 gr', 122100, 85500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo Es Ketan Hitam 10 sch', 16095, 11300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Es Rujak Jeruk Bali 40 Sachet', 22300, 22300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Sarabba Ekstra\", 46000, 37740]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Jeruk Extra Manis (40 sch)\", 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Gold Plain 750gr', 117600, 82400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo Gold Plain 1000 gr', 142080, 82400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Sirsak (40 sch)', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Near ED - NutriSari Apel Jeruk 40 Sachet\", 45510, 13650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) W'dank Bandrek 10 sachet Renceng - Khusus Homdel\", 17316, 8700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Soy Latte - Kopi Susu Kacang Bebas Gula', 37740, 18000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo School Chocolate 1000 gr', 149850, 74900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo Platinum Original 360g (12 Sachet)', 111000, 77700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Near ED - NutriSari Anggur Hijau 40 Sachet\", 45510, 31900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) NutriSari Milky Orange (40 sch)\", 45510, 31900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - Tropicana Slim Kecap Asin 200 ml', 25530, 17900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Wdank Madu Temulawak 10 Sachet', 17316, 8700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Madu Kurma 40 sch', 45510, 13650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Orange Cocoa 4 sachet', 16650, 11700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - NutriSari Lemon Tea 40 sch', 45510, 22800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Classic Industrial (125 Sachet)', 74370, 37200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "   \n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Bali'\n",
    "\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "\n",
    "\n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Bundle SKU'] = data_bundle1['SKU']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['Bundle SKU'] = data_bundle2['SKU']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Bundle SKU'] = data_bundle3['SKU']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Bundle SKU'] = data_bundle4['SKU']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Bundle SKU'] = data_bundle5['SKU']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Bundle SKU'] = data_bundle6['SKU']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Bundle SKU'] = data_bundle7['SKU']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle SKU', \n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "\n",
    "        order_online_bali = True\n",
    "        del file_name\n",
    "\n",
    "if not order_online_makasar :\n",
    "                    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "\n",
    "    print('order_online_makasar')\n",
    "    \n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element(By.NAME, \"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customermakassar@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element(By.NAME, \"password\")\n",
    "    password.send_keys(\"makassarhomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element(By.CLASS_NAME, \"btn-submit\").click()\n",
    "    time.sleep(20)\n",
    "    #Click Order\n",
    "    WebDriverWait(driver, 60).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a/span/span'))).click()\n",
    "    time.sleep(20)\n",
    "    #Click Order List\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div/nav/div/div/ul/li[3]/div/a[1]/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Calendar\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Last 7 Days\n",
    "    WebDriverWait(driver, 50).until(EC.visibility_of_element_located((By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    #Click Apply\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    time.sleep(20)\n",
    "    #Clicl Export\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[3]/div[1]/button/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Export to CSV\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[3]/div[1]/div/button[1]').click()\n",
    "\n",
    "\n",
    "    time.sleep(30)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "#         data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Jakarta.csv')\n",
    "#             product_order = pd.read_csv(r'Input Data/orderonline_products_Jakarta.csv')\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch (x2) ', 'Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch ', regex = False)\n",
    "\n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace(\"tetra\", \"Tetra\").str.replace(\"[6pcs]\", \"(6pcs)\", regex = False)\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "    data_order['product'] = data_order['product'].str.replace(\"Tropicana Slim Goldenmil Vanilla Turmeric 180gr\", 'Tropicana Slim Goldenmil Vanilla Turmeric (6 sch)')\n",
    "    data_order['product'] = data_order['product'].str.replace(\"NutriSari Mango Smoothie Ready to Drink Jus 200ml (6pcs)\", 'NutriSari Mango Smoothie 200ml (6pcs)', regex = False)\n",
    "    \n",
    "    data_SKU = pd.read_excel(r\"T:\\08. Learning Project\\Project eCom\\Proposal Andra\\Order Online\\Input Data\\SKU buat andra.xlsx\")\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace(\"tetra\", \"Tetra\").str.replace(\"[6pcs]\", \"(6pcs)\", regex = False)\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    " \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    " \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 12 Get 12 - HiLo Chocolate Avocado Ready to Drink 200ml - Minuman Siap Minum Tinggi Kalsium', 152400, 84000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari RTD Squeezed Orange 200 ml', 6000, 6000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Chocolate Avocado 200ml (24pcs)', 152400, 152400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Wdank Sarabba Extra 10 Sachet', 19600, 19600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Wdank Madu Temulawak 10 Sachet', 17300, 9700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari RTD Squeezed Orange 200 ml x 24 pcs - Minuman Jeruk Peras Vitamin C', 144100, 80700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Milky Vanilla Cookies 200ml', 7700, 7700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Chocolate Avocado 200ml (4pcs)', 25400, 25400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Twinpack HiLo Platinum Original 360gram', 230900, 129200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Bumbu Kaldu Ayam Jamur 100 gram', 25400, 25400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hampers Lebaran Fancy Tote Bag Tropicana Slim 3', 186500, 130000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hampers Lebaran Fancy Tote Bag Tropicana Slim 4', 186500, 130000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Premium Jus Mangga 10 Sachet', 17760, 17760]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Less Sugar Belimbing 40 sachet', 62000, 45510]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Thai Tea 200ml - Near ED', 6300, 3150]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo RTD Milky Vanilla Cookies 200ml', 7700, 3850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Chocolate Taro RTD 200ml - Near ED', 6300, 3150]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo School RTD Cotton Candy 200ml', 7200, 3600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo RTD Chocolate Avocado 200ml', 6300, 3150]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Teen RTD Coffee Tiramisu 200ml - Khusus Homdel', 7200, 3600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo School RTD Vanilla Vegiberi 200ml', 7200, 3600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo RTD Milky Brown Sugar 200 ml', 6300, 3150]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo School RTD Coklat 200ML', 7200, 3600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Lemon Tea 40 sch', 47300, 47300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Teen RTD Coklat 200ml - Khusus Homdel', 7200, 3600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) L-Men Hi Protein 2 Go Chocolate - Khusus Homdel', 12700, 3810]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari RTD Jeruk Madu 200 ml', 6000, 1800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 24200, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['2102500320 (CI160)', 88800, 88800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Es Ketan Hitam Refill 500g', 46200, 13860]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) L-MEN PROTEIN CRUNCH BBQ BEEF 20Bx20G', 12700, 3810]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Bundle Special Pack Isi 6 pcs - NutriSari RTD Squeezed Orange 200 ml', 35700, 35700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo School Chocolate Ready To Drink (4 Tetrapack)', 28800, 28800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Milky Orange (40sch)', 47300, 47300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Lokalate Kopi Alpukat Refill 500 gram', 48500, 14550]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim RTD Almond Drink Chocolicious 190 ml', 8700, 8700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Susu Low Fat Macchiato Coffee 500 gram', 24600, 24600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Korean Goguma Cookies (5 sch)', 7000, 7000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) L-Men Lose Weight Mango Sticky Rice 300gr', 44000, 44000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Thai Tea Refill 500g', 46620, 23310]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Chocolate Spread 300g - Near ED', 42735, 42735]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Sweetener Honey 50 sachet', 43290, 21645]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)Tropicana Slim Strawberry Jam 375gr', 74370, 37185]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari NUTRI C1000 Jeruk 40 Sachet', 45510, 22755]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - Tropicana Slim White Coffee', 9713, 9713]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Jeruk Peras Refill 500 gr', 17200, 17203]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Minyak Kanola 946ml', 54400, 54400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Belgian Chocolate (10 sch) - Near ED', 51060, 25530]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo School Susu Vanilla 10 sch - Near ED', 46620, 23310]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)L-Men Protein Bar Chocolate 12 sch', 71800, 51282]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    \n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    \n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Makassar'\n",
    "\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "\n",
    "        \n",
    "\n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Bundle SKU'] = data_bundle1['SKU']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['Bundle SKU'] = data_bundle2['SKU']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Bundle SKU'] = data_bundle3['SKU']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Bundle SKU'] = data_bundle4['SKU']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Bundle SKU'] = data_bundle5['SKU']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Bundle SKU'] = data_bundle6['SKU']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Bundle SKU'] = data_bundle7['SKU']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost'], errors = 'coerce').fillna(0).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle SKU', \n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "\n",
    "        order_online_makasar = True\n",
    "        del file_name\n",
    "\n",
    "if not order_online_medan:\n",
    "                        \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "    \n",
    "    print('order_online_medan')\n",
    "\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element(By.NAME, \"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customermedan@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element(By.NAME, \"password\")\n",
    "    password.send_keys(\"medanhomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element(By.CLASS_NAME, \"btn-submit\").click()\n",
    "    time.sleep(20)\n",
    "    #Click Order\n",
    "    WebDriverWait(driver, 60).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a/span/span'))).click()\n",
    "    time.sleep(20)\n",
    "    #Click Order List\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div/nav/div/div/ul/li[3]/div/a[1]/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Calendar\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Last 7 Days\n",
    "    WebDriverWait(driver, 50).until(EC.visibility_of_element_located((By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    #Click Apply\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    time.sleep(20)\n",
    "    #Clicl Export\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[3]/div[1]/button/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Export to CSV\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[3]/div[1]/div/button[1]').click()\n",
    "\n",
    "\n",
    "    time.sleep(30)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "#         data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Jakarta.csv')\n",
    "#             product_order = pd.read_csv(r'Input Data/orderonline_products_Jakarta.csv')\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch (x2) ', 'Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Tropicana Slim Oat Drink 190 ml \\(RTD\\) x 4 pcs$', 'Tropicana Slim Oat Drink 190 ml (RTD) x 4 pcs (x1)')\n",
    "    \n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men', case = False).str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace(\"tetra\", \"Tetra\").str.replace(\"[6pcs]\", \"(6pcs)\", regex = False)\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "    data_order['product'] = data_order['product'].str.replace(\"NutriSari Jeruk Nipis 40'sachet (4 Renceng)\", 'NutriSari Jeruk Nipis (40 sch)', regex = False)\n",
    "    data_order['product'] = data_order['product'].str.replace(\"Tropicana Slim Sweetener Honey 50 sachet\", 'Tropicana Slim Sweetener Honey (50sch)', regex = False)\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Teen Coklat 250gr\", 'HiLo Teen Chocolate 250gr', regex = False)\n",
    "    data_order.loc[data_order['product']=='HILO TEEN STRAWBERRY MILKSHAKE\\xa0 12Dx500G','product']=\"HiLo Teen Strawberry Milkshake 500gr\"\n",
    "    \n",
    "\n",
    "\n",
    "    data_SKU = pd.read_excel(r\"T:\\08. Learning Project\\Project eCom\\Proposal Andra\\Order Online\\Input Data\\SKU buat andra.xlsx\")\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men', case = False).str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace(\"tetra\", \"Tetra\").str.replace(\"[6pcs]\", \"(6pcs)\", regex = False)\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    " \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    " \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Korean Garlic Butter Cookies 5 sch - Khusus Homdel', 11500, 11500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo Active Vanilla 500gr', 35450, 35450]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Minyak Jagung 946ml - Khusus Homdel', 50800, 50800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari RTD Jeruk Madu 200 ml', 5900, 2950]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo Teen Vanilla Caramel 500gr', 43300, 43300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - NutriSari Jeruk Nipis Jahe 40 Sachet', 44600, 22300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Lokalate Kopi Andaliman 10 Sachet', 7450, 7450]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo School Cotton Candy 200ml - Ready to Drink (24 Pcs)', 171800, 171800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Chocolate Avocado 200ml (4pcs)', 25400, 25400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - HiLo School Cotton Candy 500g', 80100, 40050]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['4 pack - NutriSari RTD Squeezed Orange 200 ml - Minuman Jeruk Peras Vitamin C', 16650, 14153]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Active Chocolate 750gr', 97200, 48600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Active Caramel Latte 500g', 65200, 35600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Twinpack HiLo Platinum Original 360gram', 230800, 129200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Teen Strawberry Milkshake 500g', 86600, 43300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - Tropicana Slim Santan 5 sachet', 16600, 8300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - Tropicana Slim Sweetener Rose Vanilla 50 sch', 44600, 22300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) L-Men Lose Weight Avocado Coffee 300g', 138200, 69250]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo School Cotton Candy 200ml - Ready to Drink (4 Pcs) Tinggi Kalsium', 28600, 28600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Premium Jus Mangga 10 Sachet', 17760, 17760]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari RTD Squeezed Orange 200 ml x 24 pcs - Minuman Jeruk Peras Vitamin C', 144100, 99000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hampers Lebaran Fancy Tote Bag Tropicana Slim', 186500, 130000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hampers Lebaran Fancy Tote Bag Tropicana Slim 4', 186500, 130000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hampers Lebaran Fancy Tote Bag Tropicana Slim 3', 186500, 130000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Bumbu Kaldu Ayam Jamur 100 gram', 25400, 25400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Gula Aren 50 sachet', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Less Sugar Belimbing 40 sachet', 62000, 45510]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo School RTD Coklat 200ML', 7200, 7200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Chocolate Avocado 200ml (24pcs)', 152400, 152400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED BUY 1 GET 1 Tropicana Slim Extra Virgin Olive Oil 500 ml', 184800, 92400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)L-Men Gain Mass Chocolate 500gr', 152400, 76200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - Tropicana Slim Kecap Asin 200 ml', 26600, 13300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo RTD Milky Vanilla Cookies 200ml', 7700, 3850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Classic Refill 500gr', 109700, 54850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Platinum Swiss Chocolate 420gr', 94700, 47350]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['BUY 1 GET 1 - Near ED - L-Men Gain Mass Taro 225 gr', 157000, 78500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Shirataki Noodles 71gr', 21400, 10700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Madu 350ml', 69300, 34650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Milk Skim Coffee 500gr', 117700, 58850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Susu Low Fat Macchiato Coffee 500 gram', 85400, 42700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Stevia (50 sch)', 61200, 30600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Es Kuwud Nipis', 47300, 23650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Multigrain Original 500g', 99300, 49650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['BUY 1 GET 1 - (Near ED) Tropicana Slim Shirataki Noodles 71gr', 42800, 21400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari NUTRI C1000 Jeruk 40 Sachet', 47300, 23650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim High Fiber High Calcium Milk Chocolate 500gr', 117700, 58850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo Teen Chocolate 500gr', 87700, 43850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Teen Biscuit Caramel 500gr', 84600, 42300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo School Bubble Gum 500g', 109700, 54850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Sweetener Gula Aren 50 sachet', 45000, 22500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Gold Vanilla 500gr - Khusus Homdel', 84300, 42150]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Active Vanilla 1000g', 146600, 73300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Es Ketan Hitam Refill 500g', 46200, 23100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Platinum Choco 800 gr - Near ED', 375200, 187600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim BROWNIES Instant Powder Cake Mix 230 g', 34360, 17300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Kecap Manis 200ml', 28900, 14450]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo Es Pisang Ijo 10 sch', 16700, 8350]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo School Cokelat 30gr (10sch)', 33300, 33300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Gold Biscuit Cereal 500g', 84300, 42150]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Topping Kental Manis 150ml - Near ED', 30900, 15450]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Kecap Manis 200ml', 28900, 14450]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['2102500320 (CI160)', 88800, 88800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Lemon Tea 40 sch', 47300, 47300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo School Chocolate Ready To Drink (4 Tetrapack)', 28800, 28800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Choco Hazelnut (10 sch)', 13300, 13300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Milky Orange (40sch)', 47300, 47300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Jeruk Nipis (40 sch)', 47300, 47300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Klepon Latte Refill 500g - Powder Drink Tinggi Kalsium', 51900, 36330]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 24200, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['2102500320 (CI160)', 88800, 88800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo School RTD Vanila Vegiberi 200ml (6pcs)', 43200, 43200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim RTD Almond Drink Chocolicious 190 ml', 8700, 8700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)Tropicana Slim Strawberry Jam 375gr', 77300, 38650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 pcs) - 12gr Protein / Serving', 304800, 304800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Bumbu Kaldu Ayam Jamur 100 gram', 25400, 12700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Diabetamil Milk Vanilla 150 gram', 33500, 16750]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Minyak Kanola 946ml', 80800, 40400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo School Chocolate 500gr', 77000, 38500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Oat Drink 190 ml (RTD) x 4 pcs', 32400, 32400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Kelapa Muda (40 sch)', 62000, 42600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Twin Pack: Tropicana Slim Saus Tiram 200ml', 64600, 32300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Avocado Coffee (4 sch)', 16300, 11340]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 152400, 152400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Kecap Asin 200ml', 26600, 26600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Kacang Hijau 200 ml - Near ED', 6300, 3150]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Es Rujak Jeruk Bali 40 Sachet', 47300, 23650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo Gold Sweet Potato 500 gram', 42150, 42150]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)L-Men Protein Crunch BBQ Beef (20gr)', 12700, 6350]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo Teen Chocolate 750gr', 127000, 63500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Gold Plain 750gr', 122400, 61200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Yoghurt Smootie Bowl Strawberry 8s x 30g', 68100, 34050]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo School Chocolate Candy (10 sch) - Near ED', 23100, 11550]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Milk Skim Original 1kg', 207800, 103900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo Gold Sweet Potato 500 gram', 42150, 42150]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['4 pack HiLo RTD Thai Tea 200ml - Near ED', 25200, 12600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Chocolate Spread 300g - Near ED', 76600, 38300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Thai Tea 200ml (6pcs) - Ready to Drink', 35400, 35400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Chocolate 250gr', 40000, 20000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Teen Chocolate Ready To Drink Susu [4 pcs]', 28800, 28800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Hokkaido Cheese Cookies', 24200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Minyak Jagung 946ml - Khusus Homdel', 101600, 50800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Es Ketan Hitam 500g - Powder Drink Tinggi Kalsium', 46200, 32340]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo School 3+ Soya Vanilla Malt 400g', 83250, 58300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'dank Sarabba Ekstra\", 18870, 13290]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Sarabba Ekstra\", 18870, 13290]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Milk Low Fat Vanilla 500gr', 82140, 41070]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Wdank Madu Temulawak 10 Sachet', 17316, 8658]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 43290, 21645]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Saus Tiram 200ml', 31080, 15540]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Sunflower Oil 946 ml', 84360, 59100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "  \n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Medan'\n",
    "\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "\n",
    "        \n",
    "        \n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Bundle SKU'] = data_bundle1['SKU']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['Bundle SKU'] = data_bundle2['SKU']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Bundle SKU'] = data_bundle3['SKU']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Bundle SKU'] = data_bundle4['SKU']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Bundle SKU'] = data_bundle5['SKU']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Bundle SKU'] = data_bundle6['SKU']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Bundle SKU'] = data_bundle7['SKU']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        #order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost'], errors = 'coerce').fillna(0).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle SKU', \n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "\n",
    "        order_online_medan = True\n",
    "        del file_name\n",
    "\n",
    "if not order_online_samarinda:\n",
    "                            \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "\n",
    "    print('order_online_samarinda')\n",
    "    \n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element(By.NAME, \"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customersamarinda@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element(By.NAME, \"password\")\n",
    "    password.send_keys(\"samarindahomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element(By.CLASS_NAME, \"btn-submit\").click()\n",
    "    time.sleep(10)\n",
    "\n",
    "    time.sleep(20)\n",
    "    #Click Order\n",
    "    WebDriverWait(driver, 60).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a/span/span'))).click()\n",
    "    time.sleep(20)\n",
    "    #Click Order List\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div/nav/div/div/ul/li[3]/div/a[1]/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Calendar\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Last 7 Days\n",
    "    WebDriverWait(driver, 50).until(EC.visibility_of_element_located((By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    #Click Apply\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    time.sleep(20)\n",
    "    #Clicl Export\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[3]/div[1]/button/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Export to CSV\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[3]/div[1]/div/button[1]').click()\n",
    "\n",
    "\n",
    "    time.sleep(30)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "\n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate')\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "\n",
    "    data_SKU = pd.read_excel(r\"T:\\08. Learning Project\\Project eCom\\Proposal Andra\\Order Online\\Input Data\\SKU buat andra.xlsx\")\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate')\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    " \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) L-Men Lose Weight Avocado Coffee 300g', 69250, 69250]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 12 Get 12 - HiLo Chocolate Avocado Ready to Drink 200ml - Minuman Siap Minum Tinggi Kalsium', 152400, 84000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari American Sweet Orange (40 sch)', 45000, 43000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Twinpack HiLo Platinum Original 360gram', 230800, 129200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['4 pack - NutriSari RTD Squeezed Orange 200 ml - Minuman Jeruk Peras Vitamin C', 24000, 13400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari RTD Squeezed Orange 200 ml x 24 pcs - Minuman Jeruk Peras Vitamin C', 144100, 80700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Chocolate Avocado 200ml (4pcs)', 25400, 25400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Gula Aren 50 sachet', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hampers Lebaran Fancy Tote Bag Tropicana Slim', 186500, 130000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Premium Jus Mangga 10 Sachet', 25000, 17760]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Gula Aren 50 sachet', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim RTD Almond Drink Chocolicious 190 ml', 8700, 8700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo School Cotton Candy 200ml - Ready to Drink (4 Pcs) Tinggi Kalsium', 28600, 28600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Salted Caramel Cocoa 4 Sachet', 26000, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Gold Chocolate 1000g', 147800, 73900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - L-MEN Gain Mass Taro 225 gr', 78500, 23550]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim French Butter Souffle Coffee 4 Sachet', 16200, 16200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Multigrain Original 500g', 99300, 49650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Multigrain Original 500g', 99300, 99300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 24200, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Jeruk Nipis (40 sch)', 47300, 47300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'dank Empon-Empon 10 sch\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 152400, 152400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Oat Drink 190 ml (RTD) x 4 pcs', 29700, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Near ED - Tropicana Slim Low Fat Milk Korean Strawberry 500g\", 84360, 42200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Gold Biscuit Cereal 500g', 81030, 24300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo Platinum Original 360g (12 Sachet)', 111000, 55500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Lokalate Kopi Alpukat Refill 500 gram', 46620, 14000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo School Vanilla 1000g', 149850, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Susu Low Fat Macchiato Coffee 500 gram', 82140, 24600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "   \n",
    "       \n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Samarinda'\n",
    "\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "\n",
    "\n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Bundle SKU'] = data_bundle1['SKU']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['Bundle SKU'] = data_bundle2['SKU']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Bundle SKU'] = data_bundle3['SKU']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Bundle SKU'] = data_bundle4['SKU']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Bundle SKU'] = data_bundle5['SKU']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Bundle SKU'] = data_bundle6['SKU']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Bundle SKU'] = data_bundle7['SKU']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle SKU', \n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "        data_all_aft_order = data_all.copy()\n",
    "        del file_name\n",
    "        order_online_samarinda = True\n",
    "        \n",
    "if not order_online_lampung:\n",
    "                            \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "\n",
    "    print('order_online_lampung')\n",
    "    \n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element(By.NAME, \"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customerlampung@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element(By.NAME, \"password\")\n",
    "    password.send_keys(\"lampunghomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element(By.CLASS_NAME, \"btn-submit\").click()\n",
    "    time.sleep(20)\n",
    "    #Click Order\n",
    "    WebDriverWait(driver, 60).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a/span/span'))).click()\n",
    "    time.sleep(20)\n",
    "    #Click Order List\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div/nav/div/div/ul/li[3]/div/a[1]/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Calendar\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Last 7 Days\n",
    "    WebDriverWait(driver, 50).until(EC.visibility_of_element_located((By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    #Click Apply\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    time.sleep(20)\n",
    "    #Clicl Export\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[3]/div[1]/button/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Export to CSV\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[3]/div[1]/div/button[1]').click()\n",
    "\n",
    "\n",
    "    time.sleep(30)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "\n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate').str.replace('40 sch', '40sch').str.replace('6 tetrapack', '6 Tetrapack').str.replace(\"Diabetx 100s\", \"Diabtx (100 sch)\").str.replace(\"Alpukat 10's\", \"Alpukat (10sch)\").str.replace(\"Kawista 10 sch\", \"Kawista (10sch)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "\n",
    "    data_SKU = pd.read_excel(r\"T:\\08. Learning Project\\Project eCom\\Proposal Andra\\Order Online\\Input Data\\SKU buat andra.xlsx\")\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate').str.replace('40 sch', '40sch').str.replace('6 tetrapack', '6 Tetrapack').str.replace(\"Diabetx 100s\", \"Diabtx (100 sch)\").str.replace(\"Alpukat 10's\", \"Alpukat (10sch)\").str.replace(\"Kawista 10 sch\", \"Kawista (10sch)\")\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    " \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "  \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo School Susu Coklat (10 sch) Gusset - Khusus Homdel', 45800, 22900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo School Chocolate 500gr', 40050, 40050]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo School Susu Coklat (10 sch) Gusset - Khusus Homdel', 45800, 22900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo School Chocolate 500gr', 40050, 40050]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo School Susu Coklat (10 sch) Gusset - Khusus Homdel', 45800, 22900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo School Chocolate 500gr', 40050, 40050]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - NutriSari Lychee Tea 40 sch', 40050, 40050]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Orange Cocoa 4 Sachet - Minuman Cokelat Jeruk Nikmat Tanpa Gula Pasir', 40000, 33300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Bumbu Saus Telur Asin 3 Sachet - Lebih Rendah Lemak dan Garam\", 290000, 22200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) NutriSari RTD Jeruk Madu 200 ml\", 5900, 2950]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - Tropicana Slim Kecap Asin 200 ml', 13150, 13150]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo Teen Chocolate 500gr', 86600, 43300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Active Caramel Latte 500g', 65200, 32600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Active Chocolate 1000 gr', 120100, 60050]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Premium Jus Mangga 10 Sachet', 25000, 17760]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo Teen Vanilla Caramel 500gr', 86600, 43300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Lokalate Kopi Pisang Bakar Epe 10 sch', 15000, 7500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Goldenmil Vanilla (6 sch) - Near ED', 57700, 28850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Stevia (50 sch)', 33500, 16750]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari RTD Squeezed Orange 200 ml x 24 pcs - Minuman Jeruk Peras Vitamin C', 144100, 80700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) Lokalate Kopi Berondong 10's\", 14900, 7450]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['4 pack - NutriSari RTD Squeezed Orange 200 ml - Minuman Jeruk Peras Vitamin C', 24000, 13400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - HiLo School Cotton Candy 500g', 80800, 40400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo School Cotton Candy 200ml - Ready to Drink (4 Pcs) Tinggi Kalsium', 28600, 28600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari NUTRI C1000 Jeruk 40 Sachet', 45000, 22500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Soy Latte - Kopi Susu Kacang Bebas Gula', 36900, 18450]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Korean Garlic Butter Cookies 5 sch - Khusus Homdel', 24200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Thai Tea 200ml - Near ED', 6300, 3150]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hampers Lebaran Fancy Tote Bag Tropicana Slim', 186500, 130000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - Tropicana Slim Santan 5 sachet', 18500, 9250]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Twin Pack: HiLo Platinum Swiss Chocolate (12 sch)', 189300, 169300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Choco Hazelnut (10 sch)', 12210, 6105]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Active Chocolate 750gr', 109700, 54850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) L-Men Whey Advanced Choco Vanilla 500gr', 184700, 92350]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Teen Strawberry Milkshake 500g', 86600, 43300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Bumbu Kaldu Ayam Jamur 100 gram', 25400, 25400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) L-Men Platinum Bubble Gum 800 gram', 375200, 187600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo School Cotton Candy 200ml - Ready to Drink (4 Pcs) Tinggi Kalsium', 28600, 28600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo RTD Milky Vanilla Cookies 200ml', 7700, 3850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Lychee Tea Refill 500 gram', 36400, 18200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Active Vanilla 1000g', 146600, 73300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Avocado Coffee 4 sch', 16200, 8100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - Tropicana Slim White Coffee', 20200, 10100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Korean Goguma Cookies (5 sch)', 24200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Bundle Special Pack Isi 6 pcs - NutriSari RTD Squeezed Orange 200 ml', 35700, 35700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Klepon Cookies (5 sch)', 24200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Less Sugar Belimbing 40 sachet', 62000, 45510]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo Active Vanilla 500gr', 79700, 39850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim RTD Almond Drink Chocolicious 190 ml', 8700, 8700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Platinum Swiss Chocolate 420gr', 94700, 47350]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo School Chocolate 250g', 38300, 19150]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) L-Men Lose Weight Mango Sticky Rice 300gr', 152400, 76200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim French Butter Souffle Coffee 4 Sachet', 16200, 16200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - L-MEN Gain Mass Taro 225 gr', 62900, 31450]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - NutriSari Jeruk Nipis Jahe 40 Sachet', 47300, 47300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo School RTD Cotton Candy 200ml',7200, 7200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Oat Drink 190 ml (RTD)',8100, 8100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Klepon Latte Refill 500g',51900, 25950]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Wdank Madu Temulawak 10 Sachet',18000, 18000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Minyak Kanola 946ml',80800, 40400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Milk Skim Chocolate 500gr',117700, 58850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Es Ketan Hitam Refill 500g',46200, 46200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Gold Chocolate 1000g',147800, 73900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Sirup Leci 750ml',33500, 33500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Saus Tiram 200ml',32300, 16150]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)Tropicana Slim Extra Virgin Olive Oil 500 ml',92400, 92400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Sirup Cocopandan 750ml',33500, 33500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Sirup Orange 750ml',33500, 33500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Sirup Orange 750ml',33500, 33500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['2102500320 (CI160)',88800, 88800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Mint Cocoa 4 Sachet', 17300, 8650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Lokalate Kopi Alpukat Refill 500 gram', 48500, 24250]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Lokalate Kopi Alpukat (10sch) - Near ED', 14900, 7450]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Chocolate Spread 300g - Near ED', 80100, 40050]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Topping Kental Manis 150ml - Near ED',34600, 17300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) L-Men Hi Protein 2 Go Chocolate - Khusus Homdel',11500, 6350]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - NutriSari Lychee Tea 40sch', 23650, 23650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED -Tropicana Slim Sweet Orange Sugar Free 10 sch',21900, 10950]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Nutty Chocolate Cookies 200gr',48500, 48500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)Tropicana Slim Strawberry Jam 375gr',77300, 77300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo School RTD Coklat 200ML',3600, 3600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Teen RTD Coffee Tiramisu 200ml - Khusus Homdel',7200, 7200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Jeruk Peras Refill 500 gr',38100, 19050]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)L-Men Platinum Kacang Hijau 800g',314600, 94400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Sunflower Oil 946 ml', 87700, 87700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - NutriSari Nanas 40sch', 47300, 47300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Teen RTD Coklat 200ml - Khusus Homdel',7200, 7200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Hokkaido Cheese Cookies', 24200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Minyak Jagung 946ml - Khusus Homdel', 101600, 50800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - NutriSari Apel Jeruk 40 Sachet',45510, 31900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) NutriSari Jeruk Nipis 40'sachet (4 Renceng)\", 45510, 31900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - NutriSari Jeruk Peras (40sch)', 45510, 31900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo School Vanilla 1000g', 149850, 104900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo Chocolate Banana 10 sch',45510, 31900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) HiLo Gold Vanilla 500gr - Khusus Homdel\", 84300, 42150]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Avocado Chocolate (10 sch)', 12765, 8900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Teen Biscuit Caramel 500gr', 84360, 25300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo School RTD Vanilla Vegiberi 200ml', 6882, 2100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    \n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "   \n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    s = requests.Session()\n",
    "    s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    with open(r'SKU_File\\Master tatanama.xlsx', 'wb') as output:\n",
    "        output.write(r.content)\n",
    "\n",
    "    if os.path.isfile(r'SKU_File\\Master tatanama.xlsx') :    \n",
    "        SKU_append = pd.read_excel(r'SKU_File\\Master tatanama.xlsx')\n",
    "        SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "        data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "        data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    to_excel = data_SKU2.to_excel(r'SKU_File\\data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Lampung'\n",
    "\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "\n",
    "\n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Bundle SKU'] = data_bundle1['SKU']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['Bundle SKU'] = data_bundle2['SKU']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Bundle SKU'] = data_bundle3['SKU']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Bundle SKU'] = data_bundle4['SKU']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Bundle SKU'] = data_bundle5['SKU']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Bundle SKU'] = data_bundle6['SKU']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Bundle SKU'] = data_bundle7['SKU']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "\n",
    "        order_all.loc[data_SKU['SKU'].isin(['(E)2HH1407250']),'Price List NFI'] = '6105'\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle SKU', \n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "#         data_all_aft_order = data_all.copy()\n",
    "        del file_name\n",
    "        order_online_lampung = True\n",
    "        \n",
    "\n",
    "        \n",
    "if not order_online_pekanbaru:\n",
    "                            \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "\n",
    "    print('order_online_pekanbaru')\n",
    "    \n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element(By.NAME, \"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customerpekanbaru@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element(By.NAME, \"password\")\n",
    "    password.send_keys(\"pekanbaruhomdel1\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element(By.CLASS_NAME, \"btn-submit\").click()\n",
    "    time.sleep(20)\n",
    "    #Click Order\n",
    "    WebDriverWait(driver, 60).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a/span/span'))).click()\n",
    "    time.sleep(20)\n",
    "    #Click Order List\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div/nav/div/div/ul/li[3]/div/a[1]/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Calendar\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Last 7 Days\n",
    "    WebDriverWait(driver, 50).until(EC.visibility_of_element_located((By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    #Click Apply\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    time.sleep(20)\n",
    "    #Clicl Export\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[3]/div[1]/button/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Export to CSV\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[3]/div[1]/div/button[1]').click()\n",
    "\n",
    "\n",
    "    time.sleep(35)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "    data_order.loc[data_order['product']=='HILO TEEN STRAWBERRY MILKSHAKE\\xa0 12Dx500G','product']=\"HiLo Teen Strawberry Milkshake 500gr\"\n",
    "    \n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "\n",
    "    product.loc[product[0]==\"HiLo Teen Taro 500gr\",1]=\"1)\"\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate').str.replace('40 sch', '40sch')\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "\n",
    "    data_SKU = pd.read_excel(r\"T:\\08. Learning Project\\Project eCom\\Proposal Andra\\Order Online\\Input Data\\SKU buat andra.xlsx\")\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate').str.replace('40 sch', '40sch')\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "  \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "  \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - HiLo School Cotton Candy 500g', 38850, 38850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Active Chocolate 1000 gr', 61500, 61500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Sweetener Jahe 50 sch', 44600, 22300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 12 Get 12 - HiLo Chocolate Avocado Ready to Drink 200ml - Minuman Siap Minum Tinggi Kalsium', 152400, 84000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) L-Men Lose Weight Avocado Coffee 300g', 138500, 69250]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Teen Strawberry Milkshake 500g', 86600, 43300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Klepon Latte Refill 500g', 51900, 25950]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Premium Jus Mangga 10 Sachet', 25000, 17760]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Milk Skim Chocolate 500gr', 117700, 58850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo School Vanilla Vegiberi 750gr', 117700, 58850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Avocado Coffee 4 sch', 16200, 8100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Stevia (50 sch)', 57700, 28850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Korean Garlic Butter Cookies 5 sch - Khusus Homdel', 23100, 11500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) NutriSari Es Rujak 40's\", 45000, 22500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Bumbu Saus Telur Asin 3 Sachet - Lebih Rendah Lemak dan Garam', 32100, 32100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) - Tropicana Slim Sweetener Rose Vanilla 50 sch\", 45000, 22500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - Tropicana Slim Santan 5 sachet', 16700, 8350]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) Tropicana Slim Klepon Cookies (5 sch)\", 23100, 11550]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Milk Skim Coffee 500gr', 117000, 58850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Wdank Madu Temulawak 10 Sachet', 17300, 9700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) - NutriSari Jeruk Nipis Jahe 40 Sachet\", 45000, 22500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari RTD Squeezed Orange 200 ml x 24 pcs - Minuman Jeruk Peras Vitamin C', 144100, 80700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['4 pack - NutriSari RTD Squeezed Orange 200 ml - Minuman Jeruk Peras Vitamin C', 24000, 13400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Lokalate Kopi Andaliman 10 Sachet', 15000, 7500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) L-Men Whey Advanced Choco Vanilla 500gr', 173200, 86600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Platinum Choco 800 gr - Near ED', 357900, 178950]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Milky Vanilla Cookies 200ml x 4 pcs', 30900, 30900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) W'dank Bajigur 10 sch\", 18000, 9000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Korean Goguma Cookies (5 sch)', 24200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Platinum Swiss Chocolate 420gr', 94700, 47350]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Chocolate Avocado 200ml (4pcs)', 25400, 25400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Madu 350ml', 69300, 34650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Kecap Manis 200ml', 28900, 14450]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hampers Lebaran Fancy Tote Bag Tropicana Slim', 186500, 130000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hampers Lebaran Fancy Tote Bag Tropicana Slim 2', 186500, 130000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) L-Men Platinum Bubble Gum 800 gram', 375200, 187600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo Active Vanilla 500gr', 79700, 39850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Salted Caramel Cocoa 4 Sachet', 33300, 16650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hampers Lebaran Fancy Tote Bag Tropicana Slim 8', 186500, 130000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Lemon-C (25 sch)', 26600, 13300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)L-Men Gain Mass Chocolate 500gr', 152400, 76200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim French Butter Souffle Coffee 4 Sachet', 16200, 16200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) L-Men Lose Weight Mango Sticky Rice 300gr', 152400, 76200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo School Cotton Candy 200ml - Ready to Drink (4 Pcs) Tinggi Kalsium', 28600, 28600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Less Sugar Belimbing 40 sachet', 62000, 45510]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Active Vanilla 1000g', 146600, 73300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Chocolate Taro RTD 200ml - Near ED', 6300, 4410]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo RTD Chocolate Avocado 200ml', 6300, 4410]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Lychee Tea Refill 500 gram', 36400, 18200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo RTD Milky Vanilla Cookies 200ml', 7700, 3850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim High Fiber High Calcium Milk Chocolate 500gr', 117700, 82390]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Es Ketan Hitam Refill 500g', 46200, 23100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Mint Cocoa 4 Sachet', 17300, 12110]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - Tropicana Slim White Coffee', 20200, 10100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Goldenmil Vanilla (6 sch) - Near ED', 33500, 23450]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo School RTD Cotton Candy 200ml', 7000, 3500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Thai Tea 200ml - Near ED', 6300, 3150]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - NutriSari Gula Asem 40 Sachet', 47300, 23650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Cocopandan 40sch', 23650, 23650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Peanut Almond Butter 300 gram', 66600, 33300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - Tropicana Slim Kecap Asin 200 ml', 26600, 18620]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo Taro Latte Refill 500g', 46620, 23300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Bumbu Kaldu Ayam Jamur 100 gram', 24500, 12250]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Diabetamil Milk Vanilla 150 gram', 33500, 10050]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Teen Biscuit Caramel 500gr', 87700, 26310]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Platinum Refill Choco Latte 800g', 321900, 257500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - L-MEN Gain Mass Taro 225 gr', 78500, 23550]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['2102500320 (CI160)', 88800, 88800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Klepon Latte Refill 500g - Powder Drink Tinggi Kalsium', 51900, 25950]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED -Tropicana Slim Sweet Orange Sugar Free 10 sch', 21900, 6570]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)Tropicana Slim Extra Virgin Olive Oil 500 ml', 92400, 27720]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo School Vanilla Vegiberi 500gr', 84300, 25290]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Milk Skim Original 1kg', 207800, 62340]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 24200, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - NutriSari Lychee Tea 40sch', 47300, 33110]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Sirup Orange 750ml', 33500, 16750]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) W'dank Bandrek 10 sachet Renceng - Khusus Homdel\", 18000, 5400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 pcs) - 12gr Protein / Serving', 304800, 304800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack HiLo Chocolate Mint 10 Sachet Minuman dengan Cokelat Tinggi Kalsium Praktis dalam Sachet\", 25530, 12765]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['BUY 12 GET 12 - Tropicana Slim Oat Drink Japanese Cantaloupe Melon', 240000, 199800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Classic Refill 500gr', 109700, 32910]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) HiLo School Susu Coklat (10 sch) Gusset - Khusus Homdel\", 45800, 22900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo School Susu Vanilla 10 sch - Near ED', 22900, 22900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Diabtx 100s\", 83100, 83100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo School Chocolate 500gr', 77000, 38500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo School Strawberry Cheesecake 500 gram', 80100, 40050]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Chocolate Taro RTD 200ml (4pcs)\", 25200, 25200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo School Vanilla Vegiberi Ready To Drink Susu [200ml/4 pcs]', 28800, 28800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Teen Coffee Tiramisu Ready To Drink Susu UHT [4 pcs]', 28800, 28800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Teen Chocolate Ready To Drink Susu [4 pcs]', 28800, 28800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Thai Tea Ready to Drink 200ml x 4pcs', 25200, 25200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)L-Men Protein Bar Chocolate 12 sch', 99500, 49750]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Milk Low Fat Vanilla 500gr', 74400, 37200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim RTD Almond Drink Chocolicious 190 ml', 8700, 8700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Near ED - Tropicana Slim Low Fat Milk Korean Strawberry 500g\", 87700, 43850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Sweetener Gula Aren 50 sachet', 45000, 22500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) Tropicana Slim Cafe Latte (10 sch)\", 30600, 10300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo Teen Vanilla Caramel 500gr', 87700, 43850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Gold Chocolate 1000g', 147800, 73900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED)HiLo Teen Chocolate 500gr\", 87700, 43850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Soy Latte - Kopi Susu Kacang Bebas Gula', 28800, 28800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Es Kuwud Nipis', 47300, 33110]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Susu Low Fat Macchiato Coffee 500 gram', 85400, 42700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['BUY 1 GET 1 - HiLo Platinum Original 360 gram', 255000, 111000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) HiLo Teen RTD Coklat 200ml - Khusus Homdel\", 4800, 4800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Hokkaido Cheese Cookies', 16300, 16300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Teen RTD Coffee Tiramisu 200ml - Khusus Homdel', 4800, 4800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari American Sweet Orange (40sch)', 47300, 22800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Sunflower Oil 946 ml', 80800, 59100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo Es Pisang Ijo 10 sch', 11300, 11300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Lokalate Kopi Alpukat Refill 500 gram', 48500, 24250]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) L-Men Gain Mass Banana 225gr', 78500, 39250]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Minyak Jagung 946ml - Khusus Homdel', 68400, 68400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari RTD Jeruk Madu 200 ml', 4000, 4000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) L-Men Hi Protein 2 Go Chocolate - Khusus Homdel', 8500, 3663]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo School 3+ Strawberry Pop 400g', 56700, 24309]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Lemon Tea 500 gram', 36400, 10490]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Jeruk Manis 500gr - Near ED', 25600, 10989]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo Gold Chocolate 500gr', 74400, 24309]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "\n",
    "    \n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "    data_order.loc[data_order['product']=='HILO TEEN STRAWBERRY MILKSHAKE\\xa0 12Dx500G','product']=\"HiLo Teen Strawberry Milkshake 500gr\"\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Pekanbaru'\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "        \n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "\n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Bundle SKU'] = data_bundle1['SKU']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['Bundle SKU'] = data_bundle2['SKU']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Bundle SKU'] = data_bundle3['SKU']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Bundle SKU'] = data_bundle4['SKU']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Bundle SKU'] = data_bundle5['SKU']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Bundle SKU'] = data_bundle6['SKU']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Bundle SKU'] = data_bundle7['SKU']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle SKU', \n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "\n",
    "        del file_name\n",
    "        order_online_pekanbaru = True\n",
    "\n",
    "if not order_online_banjarmasin:\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "\n",
    "    print('order_online_banjarmasin')\n",
    "\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element(By.NAME, \"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"banjarmasinpromosi.nhd2022@gmail.com\")\n",
    "\n",
    "    password = driver.find_element(By.NAME, \"password\")\n",
    "    password.send_keys(\"nhdcuan\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element(By.CLASS_NAME, \"btn-submit\").click()\n",
    "    time.sleep(20)\n",
    "    #Click Order\n",
    "    WebDriverWait(driver, 60).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a/span/span'))).click()\n",
    "    time.sleep(20)\n",
    "    #Click Order List\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div/nav/div/div/ul/li[3]/div/a[1]/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Calendar\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Last 7 Days\n",
    "    WebDriverWait(driver, 50).until(EC.visibility_of_element_located((By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    #Click Apply\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    time.sleep(20)\n",
    "    #Clicl Export\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[3]/div[1]/button/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Export to CSV\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[3]/div[1]/div/button[1]').click()\n",
    "\n",
    "\n",
    "    time.sleep(35)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "\n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "\n",
    "    product.loc[product[0]==\"HiLo Teen Taro 500gr\",1]=\"1)\"\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate').str.replace('40 sch', '40sch')\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "\n",
    "    data_SKU = pd.read_excel(r\"T:\\08. Learning Project\\Project eCom\\Proposal Andra\\Order Online\\Input Data\\SKU buat andra.xlsx\")\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate').str.replace('40 sch', '40sch')\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Sweetener Jahe 50 sch - Khusus Homdel', 44600, 22300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 12 Get 12 - HiLo Chocolate Avocado Ready to Drink 200ml - Minuman Siap Minum Tinggi Kalsium', 152400, 84000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Multigrain Original 500g', 92400, 92400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Almond Milk Coconut 200gr', 51900, 51900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari RTD Squeezed Orange 200 ml x 24 pcs - Minuman Jeruk Peras Vitamin C', 144100, 80700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['4 pack - NutriSari RTD Squeezed Orange 200 ml - Minuman Jeruk Peras Vitamin C', 24000, 13400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Platinum Choco 800 gr - Near ED', 326000, 163000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Gain Mass Klepon Latte 500g', 152400, 152400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Bumbu Kaldu Ayam Jamur 100 gram', 25400, 25400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - Tropicana Slim Sweetener Rose Vanilla 50 sch', 22500, 22500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Gula Aren 50 sachet', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Lokalate Kopi Alpukat Refill 500 gram', 48500, 33950]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Bumbu Saus Telur Asin 3 Sachet - Lebih Rendah Lemak dan Garam', 25400, 25400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim French Butter Souffle Coffee 4 Sachet', 16200, 16200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hampers Lebaran Fancy Tote Bag Tropicana Slim', 186500, 130000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hampers Lebaran Fancy Tote Bag Tropicana Slim 6', 186500, 130000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Multigrain Original 500g', 99300, 69510]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Chocolate Avocado 200ml (4pcs)', 25400, 25400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Chocolate Avocado 200ml (24pcs)', 152400, 152400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo School Cotton Candy 200ml - Ready to Drink (24 Pcs)', 171800, 171800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Premium Jus Mangga 10 Sachet', 25000, 17760]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim RTD Almond Drink Chocolicious 190 ml', 8325, 4200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - HiLo Platinum Original 360g (12 Sachet)', 111000, 77700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - NutriSari Gula Asem 40 Sachet', 45510, 13700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - Tropicana Slim Sweetener Gula Aren 50 sachet', 43290, 13000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Gold Biscuit Cereal 500g', 81030, 24300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo School Vanilla 1000g', 149850, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Active Chocolate 1000 gr', 129870, 39000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Near ED - L-MEN Gain Mass Taro 225 gr', 75480, 22600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)   \n",
    "    \n",
    "    \n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    #             data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "    # data_order = data_order[data_order['SKU'].notnull()]\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    #         s = requests.Session()\n",
    "    #         s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    #         s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    #         r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    #         with open(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx', 'wb') as output:\n",
    "    #             output.write(r.content)\n",
    "\n",
    "    #         if os.path.isfile(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx') :    \n",
    "    #             SKU_append = pd.read_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx')\n",
    "    #             SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "    #             data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "    #             data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    # to_excel = data_SKU.to_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Banjarmasin'\n",
    "\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "\n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Bundle SKU'] = data_bundle1['SKU']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['Bundle SKU'] = data_bundle2['SKU']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Bundle SKU'] = data_bundle3['SKU']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Bundle SKU'] = data_bundle4['SKU']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Bundle SKU'] = data_bundle5['SKU']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Bundle SKU'] = data_bundle6['SKU']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Bundle SKU'] = data_bundle7['SKU']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle SKU', \n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "\n",
    "        del file_name\n",
    "        order_online_banjarmasin = True\n",
    "\n",
    "if not order_online_jabar:\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "\n",
    "    print('order_online_jabar')\n",
    "\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(r\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element(By.NAME, \"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"nutrimartbandung1@gmail.com\")\n",
    "\n",
    "    password = driver.find_element(By.NAME, \"password\")\n",
    "    password.send_keys(\"nhdcuancuan\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element(By.CLASS_NAME, \"btn-submit\").click()\n",
    "    time.sleep(20)\n",
    "    #Click Order\n",
    "    WebDriverWait(driver, 60).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a/span/span'))).click()\n",
    "    time.sleep(20)\n",
    "    #Click Order List\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div/nav/div/div/ul/li[3]/div/a[1]/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Calendar\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Last 7 Days\n",
    "    WebDriverWait(driver, 50).until(EC.visibility_of_element_located((By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    #Click Apply\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    time.sleep(20)\n",
    "    #Clicl Export\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[3]/div[1]/button/span').click()\n",
    "    time.sleep(20)\n",
    "    #Click Export to CSV\n",
    "    driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div/div[1]/div[3]/div[1]/div/button[1]').click()\n",
    "\n",
    "\n",
    "    time.sleep(30)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "\n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "\n",
    "    product.loc[product[0]==\"HiLo Teen Taro 500gr\",1]=\"1)\"\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate').str.replace('40 sch', '40sch')\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "\n",
    "    data_SKU = pd.read_excel(r\"T:\\08. Learning Project\\Project eCom\\Proposal Andra\\Order Online\\Input Data\\SKU buat andra.xlsx\")\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate').str.replace('40 sch', '40sch')\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Chocolate Avocado 200ml (24pcs)', 152400, 152400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Chocolate Avocado 200ml (4pcs)', 25400, 25400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Chocolate Taro RTD 200ml - Near ED', 6300, 3800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Thai Tea 200ml - Near ED', 6300, 3800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['4 pack - NutriSari RTD Squeezed Orange 200 ml - Minuman Jeruk Peras Vitamin C', 24000, 13400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hampers Lebaran Fancy Tote Bag Tropicana Slim', 186500, 130000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Bumbu Saus Telur Asin 3 Sachet - Lebih Rendah Lemak dan Garam', 25400, 25400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Sweetener Jahe 50 sch - Khusus Homdel', 45000, 22500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) - Tropicana Slim Sweetener Rose Vanilla 50 sch', 45000, 22500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim French Butter Souffle Coffee 4 Sachet', 16200, 16200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Salted Caramel Cocoa 4 Sachet', 26000, 16650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 12 Get 12 - HiLo Chocolate Avocado Ready to Drink 200ml - Minuman Siap Minum Tinggi Kalsium', 152400, 84000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo School Cotton Candy 200ml - Ready to Drink (4 Pcs) Tinggi Kalsium', 28600, 28600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Less Sugar Belimbing 40 sachet', 62000, 45510]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Active Caramel Latte 500g', 65200, 32600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Premium Jus Mangga 10 Sachet', 25000, 17760]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['2102500320 (CI160)', 88800, 88800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Klepon Latte Refill 500g - Powder Drink Tinggi Kalsium', 51900, 36330]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'dank Empon-Empon 10 sch\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim RTD Almond Drink Chocolicious 190 ml\", 8700, 8700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Jabar'\n",
    "\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "\n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Bundle SKU'] = data_bundle1['SKU']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['Bundle SKU'] = data_bundle2['SKU']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Bundle SKU'] = data_bundle3['SKU']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Bundle SKU'] = data_bundle4['SKU']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Bundle SKU'] = data_bundle5['SKU']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Bundle SKU'] = data_bundle6['SKU']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Bundle SKU'] = data_bundle7['SKU']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle SKU', \n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "        \n",
    "        \n",
    "        del file_name\n",
    "        order_online_jabar = True\n",
    "        order_online_cond = True\n",
    "        \n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e167895e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a25dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda3d187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b6ded07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c97c595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 1), dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### optional cek item yang error\n",
    "### to do: add to code jatim jkt jateng\n",
    "### add to sheet sisanya\n",
    "order_all[order_all['Regular Price'].isnull()][['Product Name']].drop_duplicates().values#.to_excel('nhd ed.xlsx',index=False)#.values\n",
    "#order_all[order_all['Price List NFI'].isnull()][['SKU','Product Name']].drop_duplicates().values#.to_excel('nhd ed.xlsx',index=False)#.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "823b84ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_online_jabar = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c24d25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "### optional cman utk cek ada kota homdel yang belum ke run atau tidak\n",
    "for n in [order_online_jatim,order_online_jkt,\n",
    "          order_online_jateng,order_online_bali,\n",
    "          order_online_makasar, order_online_medan,\n",
    "          order_online_samarinda,order_online_lampung,\n",
    "          order_online_pekanbaru,order_online_banjarmasin,order_online_jabar]:\n",
    "    print (n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7a531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25f1fc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order #\n",
      "No. Order Item L-Men Blibli\n",
      "AWB\n",
      "Order date\n",
      "Customer Name\n",
      "Kode SKU\n",
      "Blibli SKU\n",
      "SKU\n",
      "Product Name\n",
      "Qty. Invoiced\n",
      "Selling Price\n",
      "Shipping Courier\n",
      "Kode Merchant\n",
      "Channel\n",
      "Order Status\n",
      "Warehouse Name\n",
      "Real SKU\n",
      "Real Nama Produk\n",
      "Brand\n",
      "Sub Brand\n",
      "Parent Item\n",
      "Parent SKU\n",
      "Price List NFI\n",
      "Total Net\n",
      "Bundle Flag\n",
      "Date\n",
      "Month\n",
      "Year\n",
      "Quarter\n",
      "Week\n",
      "True datetime\n",
      "Store\n",
      "Produk 1\n",
      "SKU Produk 1\n",
      "PCS Produk 1\n",
      "Price List NFI 1\n",
      "Subtotal Produk 1\n",
      "Harga Display 1\n",
      "Harga Cost 1\n",
      "Harga Organik 1\n",
      "Produk 2\n",
      "SKU Produk 2\n",
      "PCS Produk 2\n",
      "Price List NFI 2\n",
      "Subtotal Produk 2\n",
      "Harga Display 2\n",
      "Harga Cost 2\n",
      "Harga Organik 2\n",
      "Produk 3\n",
      "SKU Produk 3\n",
      "PCS Produk 3\n",
      "Price List NFI 3\n",
      "Subtotal Produk 3\n",
      "Harga Display 3\n",
      "Harga Cost 3\n",
      "Harga Organik 3\n",
      "Produk 4\n",
      "SKU Produk 4\n",
      "PCS Produk 4\n",
      "Price List NFI 4\n",
      "Subtotal Produk 4\n",
      "Harga Display 4\n",
      "Harga Cost 4\n",
      "Harga Organik 4\n",
      "Produk 5\n",
      "SKU Produk 5\n",
      "PCS Produk 5\n",
      "Price List NFI 5\n",
      "Subtotal Produk 5\n",
      "Harga Display 5\n",
      "Harga Cost 5\n",
      "Harga Organik 5\n",
      "Produk 6\n",
      "SKU Produk 6\n",
      "PCS Produk 6\n",
      "Price List NFI 6\n",
      "Subtotal Produk 6\n",
      "Harga Display 6\n",
      "Harga Cost 6\n",
      "Harga Organik 6\n",
      "Produk 7\n",
      "SKU Produk 7\n",
      "PCS Produk 7\n",
      "Price List NFI 7\n",
      "Subtotal Produk 7\n",
      "Harga Display 7\n",
      "Harga Cost 7\n",
      "Bundle Name\n",
      "Bundle SKU\n"
     ]
    }
   ],
   "source": [
    "for i in data_bundle1.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7819fa45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4442986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e000a7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd26dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa6e85c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer SO Parent Desc</th>\n",
       "      <th>Customer SO Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>ECOM RETAIL - EMOS</td>\n",
       "      <td>ENSEVAL PUTERA MEGATRADING - JAKARTA, PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34473</th>\n",
       "      <td>ECOM MP - LAZADA</td>\n",
       "      <td>ECOM NFI - MP LAZADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42767</th>\n",
       "      <td>ECOM RETAIL - SAYUR BOX</td>\n",
       "      <td>CIBINONG CENTER INDUSTRIAL ESTATE , PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43417</th>\n",
       "      <td>ECOM MP - TIK TOK SHOP</td>\n",
       "      <td>ECOM TIK TOK SHOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43418</th>\n",
       "      <td>ECOM MP - TOKOPEDIA</td>\n",
       "      <td>ECOM NFI - MP TOKOPEDIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43675</th>\n",
       "      <td>ECOM RETAIL - SAYUR BOX</td>\n",
       "      <td>KREASI NOSTRA MANDIRI - BOGOR, PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44688</th>\n",
       "      <td>ECOM NFI - NHD</td>\n",
       "      <td>ECOM - ORDER ONLINE KALIMANTAN SELATAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44789</th>\n",
       "      <td>ECOM MP - ORAMI</td>\n",
       "      <td>ECOM - ORAMI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45043</th>\n",
       "      <td>ECOM MP - JD ID</td>\n",
       "      <td>ECOM NFI - MP JD ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46276</th>\n",
       "      <td>ECOM MP - SHOPEE</td>\n",
       "      <td>ECOM NFI - MP SHOPEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47225</th>\n",
       "      <td>ECOM RETAIL - TOKO NOW</td>\n",
       "      <td>SWIFT LOGISTICS SOLUTIONS - JKT UTARA,PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47318</th>\n",
       "      <td>ECOM MP - BUKALAPAK</td>\n",
       "      <td>ECOM NFI - MP BUKALAPAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48556</th>\n",
       "      <td>GENERAL</td>\n",
       "      <td>SAYUR UNTUK SEMUA - SERPONG, PT (SEGARI)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48635</th>\n",
       "      <td>ECOM RETAIL - ASTRO</td>\n",
       "      <td>ASTRO TECHNOLOGIES - TANGERANG, PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50050</th>\n",
       "      <td>GENERAL</td>\n",
       "      <td>GOTO SOLUSI NIAGA - CILINCING, PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51024</th>\n",
       "      <td>ECOM NFI - NHD</td>\n",
       "      <td>ECOM- ORDER ONLINE BALI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51233</th>\n",
       "      <td>ECOM NFI - NHD</td>\n",
       "      <td>ECOM- ORDER ONLINE KALIMANTAN TIMUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51245</th>\n",
       "      <td>ECOM NFI - NHD</td>\n",
       "      <td>ECOM- ORDER ONLINE SULAWESI SELATAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51246</th>\n",
       "      <td>ECOM NFI - NHD</td>\n",
       "      <td>ECOM- ORDER ONLINE PEKANBARU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51270</th>\n",
       "      <td>ECOM NFI - NHD</td>\n",
       "      <td>ECOM- ORDER ONLINE SUMATERA UTARA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51511</th>\n",
       "      <td>ECOM NFI - NHD</td>\n",
       "      <td>ECOM- ORDER ONLINE SUMATERA SELATAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74385</th>\n",
       "      <td>GENERAL</td>\n",
       "      <td>ECOM TIK TOK SHOP - NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74386</th>\n",
       "      <td>GENERAL</td>\n",
       "      <td>ECOM NFI - MP SHOPEE - NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74387</th>\n",
       "      <td>GENERAL</td>\n",
       "      <td>ECOM NFI - MP TOKOPEDIA - NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74413</th>\n",
       "      <td>ECOM MP - ALADINMALL</td>\n",
       "      <td>ECOM - ALADINMALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77435</th>\n",
       "      <td>ECOM NFI - CHATBOT</td>\n",
       "      <td>ECOM NFI- YELLOW MESSENGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77734</th>\n",
       "      <td>ECOM MP - BLIBLI</td>\n",
       "      <td>ECOM NFI - MP BLIBLI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77900</th>\n",
       "      <td>ECOM NFI - NUTRIMART</td>\n",
       "      <td>ECOM NFI - NUTRIMART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79810</th>\n",
       "      <td>ECOM RETAIL - EMOS</td>\n",
       "      <td>ENSEVAL PUTERA MEGATRADING-CIKARANG, PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79854</th>\n",
       "      <td>ECOM RETAIL - EMOS</td>\n",
       "      <td>ENSEVAL PUTERA MEGATRADING - SIDOARJO,PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84362</th>\n",
       "      <td>ECOM NFI - NHD</td>\n",
       "      <td>ECOM - ORDER ONLINE JAWA BARAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84385</th>\n",
       "      <td>ECOM NFI - NHD</td>\n",
       "      <td>ECOM- ORDER ONLINE JAWA TENGAH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84425</th>\n",
       "      <td>ECOM NFI - NHD</td>\n",
       "      <td>ECOM- ORDER ONLINE JAWA TIMUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84446</th>\n",
       "      <td>ECOM NFI - NHD</td>\n",
       "      <td>ECOM- ORDER ONLINE LAMPUNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89871</th>\n",
       "      <td>ECOM MP - GRABMART</td>\n",
       "      <td>ECOM NFI-GRABMART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92629</th>\n",
       "      <td>GENERAL</td>\n",
       "      <td>ECOM NFI - MP LAZADA - NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94035</th>\n",
       "      <td>GENERAL</td>\n",
       "      <td>COSMART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114833</th>\n",
       "      <td>ECOM NFI - NUTRIMART</td>\n",
       "      <td>ECOM NFI - NUTRIMART - NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114834</th>\n",
       "      <td>GENERAL</td>\n",
       "      <td>ECOM NFI - MP BLIBLI - NP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Customer SO Parent Desc                          Customer SO Desc\n",
       "406          ECOM RETAIL - EMOS  ENSEVAL PUTERA MEGATRADING - JAKARTA, PT\n",
       "34473          ECOM MP - LAZADA                      ECOM NFI - MP LAZADA\n",
       "42767   ECOM RETAIL - SAYUR BOX    CIBINONG CENTER INDUSTRIAL ESTATE , PT\n",
       "43417    ECOM MP - TIK TOK SHOP                         ECOM TIK TOK SHOP\n",
       "43418       ECOM MP - TOKOPEDIA                   ECOM NFI - MP TOKOPEDIA\n",
       "43675   ECOM RETAIL - SAYUR BOX         KREASI NOSTRA MANDIRI - BOGOR, PT\n",
       "44688            ECOM NFI - NHD    ECOM - ORDER ONLINE KALIMANTAN SELATAN\n",
       "44789           ECOM MP - ORAMI                              ECOM - ORAMI\n",
       "45043           ECOM MP - JD ID                       ECOM NFI - MP JD ID\n",
       "46276          ECOM MP - SHOPEE                      ECOM NFI - MP SHOPEE\n",
       "47225    ECOM RETAIL - TOKO NOW  SWIFT LOGISTICS SOLUTIONS - JKT UTARA,PT\n",
       "47318       ECOM MP - BUKALAPAK                   ECOM NFI - MP BUKALAPAK\n",
       "48556                   GENERAL  SAYUR UNTUK SEMUA - SERPONG, PT (SEGARI)\n",
       "48635       ECOM RETAIL - ASTRO        ASTRO TECHNOLOGIES - TANGERANG, PT\n",
       "50050                   GENERAL         GOTO SOLUSI NIAGA - CILINCING, PT\n",
       "51024            ECOM NFI - NHD                   ECOM- ORDER ONLINE BALI\n",
       "51233            ECOM NFI - NHD       ECOM- ORDER ONLINE KALIMANTAN TIMUR\n",
       "51245            ECOM NFI - NHD       ECOM- ORDER ONLINE SULAWESI SELATAN\n",
       "51246            ECOM NFI - NHD              ECOM- ORDER ONLINE PEKANBARU\n",
       "51270            ECOM NFI - NHD         ECOM- ORDER ONLINE SUMATERA UTARA\n",
       "51511            ECOM NFI - NHD       ECOM- ORDER ONLINE SUMATERA SELATAN\n",
       "74385                   GENERAL                    ECOM TIK TOK SHOP - NP\n",
       "74386                   GENERAL                 ECOM NFI - MP SHOPEE - NP\n",
       "74387                   GENERAL              ECOM NFI - MP TOKOPEDIA - NP\n",
       "74413      ECOM MP - ALADINMALL                         ECOM - ALADINMALL\n",
       "77435        ECOM NFI - CHATBOT                ECOM NFI- YELLOW MESSENGER\n",
       "77734          ECOM MP - BLIBLI                      ECOM NFI - MP BLIBLI\n",
       "77900      ECOM NFI - NUTRIMART                      ECOM NFI - NUTRIMART\n",
       "79810        ECOM RETAIL - EMOS   ENSEVAL PUTERA MEGATRADING-CIKARANG, PT\n",
       "79854        ECOM RETAIL - EMOS  ENSEVAL PUTERA MEGATRADING - SIDOARJO,PT\n",
       "84362            ECOM NFI - NHD            ECOM - ORDER ONLINE JAWA BARAT\n",
       "84385            ECOM NFI - NHD            ECOM- ORDER ONLINE JAWA TENGAH\n",
       "84425            ECOM NFI - NHD             ECOM- ORDER ONLINE JAWA TIMUR\n",
       "84446            ECOM NFI - NHD                ECOM- ORDER ONLINE LAMPUNG\n",
       "89871        ECOM MP - GRABMART                         ECOM NFI-GRABMART\n",
       "92629                   GENERAL                 ECOM NFI - MP LAZADA - NP\n",
       "94035                   GENERAL                                   COSMART\n",
       "114833     ECOM NFI - NUTRIMART                 ECOM NFI - NUTRIMART - NP\n",
       "114834                  GENERAL                 ECOM NFI - MP BLIBLI - NP"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TES NEW PKP\n",
    "tes = pd.read_csv(r\"C:\\Users\\steven.nathanael\\Downloads\\Main Sheet (timo) (2)_Full Data_data (20).csv\")\n",
    "tes[(tes['Year of Invoice Date SO'].isin([2023, 2024]))&(tes['Month of Invoice Date SO'].isin(['December','January']))][['Customer SO Parent Desc','Customer SO Desc']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81237db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a37aed55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Date ====== 7/10\n",
      "Filling Brand ====== 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_13268\\1512677607.py:59: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  data_nubi['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales Order ID</th>\n",
       "      <th>Order #</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Order date</th>\n",
       "      <th>Paid Date</th>\n",
       "      <th>Order Status</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Store</th>\n",
       "      <th>Currency Code</th>\n",
       "      <th>Warehouse Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Category</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Real SKU</th>\n",
       "      <th>Real Nama Produk</th>\n",
       "      <th>Sub Brand</th>\n",
       "      <th>Parent Item</th>\n",
       "      <th>Parent SKU</th>\n",
       "      <th>Price List NFI</th>\n",
       "      <th>Total</th>\n",
       "      <th>Total Net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Sales Order ID, Order #, Customer Name, Order date, Paid Date, Order Status, Channel, Store, Currency Code, Warehouse Name, Regular Price, Selling Price, Subtotal, Gross Sales, SKU, Product Name, Qty. Invoiced, Date, Month, Year, True datetime, Week, Brand, Category, Quarter, Real SKU, Real Nama Produk, Sub Brand, Parent Item, Parent SKU, Price List NFI, Total, Total Net]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_13268\\1512677607.py:145: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_nubi=data_nubi[data_nubi['Price List NFI'].notnull()].append(temp)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_13268\\1512677607.py:174: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_nubi = data_nubi.append(temp, ignore_index = True, sort = False)\n"
     ]
    }
   ],
   "source": [
    "# Run - 9\n",
    "### download file tabi di Main_Sheet_(timo)_(2)\n",
    "### replace file di var data_nubi\n",
    "### idea: use sql\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "data_all = data_all[(data_all['Store Type'] != 'Retail Online') & (data_all['Year'].isin([2023, 2024]))]\n",
    "data_nubi = pd.read_csv(r\"C:\\Users\\steven.nathanael\\Downloads\\Main Sheet (timo) (2)_Full Data_data (5).csv\")\n",
    "\n",
    "data_nubi.loc[data_nubi['Customer SO Desc']=='INDOPASIFIK FARMA MEDIKA INDONESIA, PT',['Customer SO Group Area','Customer SO Parent Desc']]='ECOM RETAIL - INDOPASIFIK FARMA MEDIKA INDONESIA'\n",
    "data_nubi.loc[data_nubi['Customer SO Desc'].isin(['SUKACITA TEKNOLOGI INDONESIA, PT','COSMART']),['Customer SO Group Area','Customer SO Parent Desc']]='ECOM RETAIL - JOYBOX(COSMART)'\n",
    "data_nubi.loc[data_nubi['Customer SO Desc'].isin(['FRESHBOX DEPO JKT']),['Customer SO Group Area','Customer SO Parent Desc']]='ECOM RETAIL - FRESHBOX'\n",
    "data_nubi.loc[data_nubi['Customer SO Desc'].isin(['GUDANG HAKUNA MATATA PELAUT']),['Customer SO Group Area','Customer SO Parent Desc']]='ECOM RETAIL - HAKUNA MATATA PELAUT'\n",
    "data_nubi.loc[data_nubi['Customer SO Desc'].isin(['GOTO SOLUSI NIAGA - CILINCING, PT']),['Customer SO Group Area','Customer SO Parent Desc']]='ECOM RETAIL - TOKO NOW'\n",
    "data_nubi.loc[data_nubi['Customer SO Desc'].isin(['SAYUR UNTUK SEMUA - SERPONG, PT (SEGARI)']),['Customer SO Group Area','Customer SO Parent Desc']]='ECOM RETAIL - SEGARI'\n",
    "data_nubi.loc[data_nubi['Customer SO Desc'].isin(['KOPI UTAMA INDONESIA, PT']),['Customer SO Group Area','Customer SO Parent Desc']]='ECOM RETAIL - COMMON GROUND'\n",
    "data_nubi.loc[data_nubi['Customer SO Desc'].isin(['PERUT AMAN SEJAHTERA, PT']),['Customer SO Group Area','Customer SO Parent Desc']]='ECOM RETAIL - TRUFFLE BELLY'\n",
    "data_nubi.loc[data_nubi['Customer SO Desc'].isin(['ADK BERKAH JAYA, CV']),['Customer SO Group Area','Customer SO Parent Desc']]='ECOM RETAIL - DINKES SURABAYA'\n",
    "\n",
    "\n",
    "data_nubi = data_nubi[data_nubi['Customer SO Group Area'].astype(str).str.contains('ECOM RETAIL')]\n",
    "\n",
    "data_SKU = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "\n",
    "data_nubi['Sales Order ID'] = 'Nubi -' + data_nubi['Customer SO Parent Desc'].astype(str)\n",
    "data_nubi['Channel Order ID'] = 'Nubi -' + data_nubi['Customer SO Parent Desc'].astype(str)\n",
    "data_nubi['Customer Name'] = 'Nubi Retail Online'\n",
    "\n",
    "print(\"Filling Date ====== 7/10\")\n",
    "\n",
    "data_nubi['Date'] = data_nubi['Day of Invoice Date SO']\n",
    "data_nubi['Month'] = data_nubi['Month of Invoice Date SO']\n",
    "data_nubi['Year'] = data_nubi['Year of Invoice Date SO']\n",
    "\n",
    "quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "        ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "data_nubi = data_nubi.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "data_nubi = data_nubi.drop(['Bulan'], axis = 1)\n",
    "data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "        {'Bulan' : 'January' , 'Number': 1},\n",
    "        {'Bulan' : 'February' , 'Number': 2},\n",
    "        {'Bulan' : 'March' , 'Number': 3},\n",
    "        {'Bulan' : 'April' , 'Number': 4},\n",
    "        {'Bulan' : 'May' , 'Number': 5},\n",
    "        {'Bulan' : 'June', 'Number': 6},\n",
    "        {'Bulan' : 'July' , 'Number': 7},\n",
    "        {'Bulan' : 'August', 'Number' : 8},\n",
    "        {'Bulan' : 'September', 'Number' : 9},\n",
    "        {'Bulan' : 'October' , 'Number': 10},\n",
    "        {'Bulan' : 'November' , 'Number': 11}])\n",
    "temp = data_nubi.copy()\n",
    "temp['Day'] = temp['Date']\n",
    "temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "data_nubi['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "data_nubi['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day']])\n",
    "\n",
    "data_nubi['Order Date'] = data_nubi['Day of Invoice Date SO']\n",
    "data_nubi['Paid Date'] = data_nubi['Day of Invoice Date SO']\n",
    "data_nubi['Status'] = 'Delivered'\n",
    "data_nubi['Channel'] = data_nubi['Customer SO Parent Desc']\n",
    "data_nubi['Store'] = data_nubi['Customer SO Group Area']\n",
    "data_nubi['Currency Code'] = \"IDR\"\n",
    "data_nubi['Warehouse Name'] = data_nubi['Customer SO Desc']\n",
    "data_nubi['Regular Price'] = data_nubi['Sales Value Netto SO'] / data_nubi['Sales Qty SO']\n",
    "data_nubi['Store Type'] = 'Retail Online'\n",
    "\n",
    "indeks = data_nubi[data_nubi['Regular Price'].isnull()].index.to_list()\n",
    "data_nubi['Regular Price'][indeks] = 0\n",
    "\n",
    "data_nubi['Selling Price'] = data_nubi['Sales Value Netto SO'] / data_nubi['Sales Qty SO']\n",
    "indeks = data_nubi[data_nubi['Selling Price'].isnull()].index.to_list()\n",
    "data_nubi['Selling Price'][indeks] = 0\n",
    "\n",
    "indeks = data_nubi[data_nubi['Sales Qty SO'] == 0].index.to_list()\n",
    "data_nubi['Selling Price'][indeks] = 0\n",
    "data_nubi['Regular Price'][indeks] = 0\n",
    "\n",
    "indeks = data_nubi[data_nubi['Sales Value Netto SO'] == 0].index.to_list()\n",
    "data_nubi['Selling Price'][indeks] = 0\n",
    "data_nubi['Regular Price'][indeks] = 0\n",
    "\n",
    "data_nubi['Sub Total'] = data_nubi['Sales Value Netto SO']\n",
    "data_nubi['Gross Sales'] = data_nubi['Sales Value Netto SO']\n",
    "\n",
    "data_nubi = data_nubi.rename(columns = {'Item Group Code' : 'SKU', 'Item Group' : 'Item Name', 'Sales Qty SO' : 'Quantity'})\n",
    "\n",
    "data_nubi = data_nubi[['Sales Order ID', 'Channel Order ID', 'Customer Name', 'Order Date', 'Paid Date','Status','Channel', 'Store', 'Currency Code', 'Warehouse Name', 'Regular Price', 'Selling Price',\n",
    "              'Sub Total', 'Gross Sales', 'SKU', 'Item Name', 'Quantity', 'Date', 'Month', 'Year', 'True datetime', \"Week\", 'Brand', 'Category']]\n",
    "\n",
    "data_nubi['Order Date'] = data_nubi['True datetime']\n",
    "data_nubi['Quarter'] = pd.to_datetime(data_nubi['True datetime']).dt.quarter\n",
    "\n",
    "print(\"Filling Brand ====== 5/10\")\n",
    "data_nubi['SKU'] = data_nubi['SKU'].astype(str)\n",
    "data_nubi['Item Name'] = data_nubi['Item Name'].astype(str)\n",
    "data_SKU['Real SKU'] = data_SKU['SKU']\n",
    "data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "\n",
    "\n",
    "data_nubi = data_nubi.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "data_nubi['Real SKU'] = data_nubi['Real SKU'].astype(str)\n",
    "data_nubi = data_nubi.merge(data_SKU[['SKU', 'Sub Brand', 'Parent Item', 'Parent SKU','Price List NFI']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "data_nubi['Parent Item'] = data_nubi['Parent Item'].fillna(data_nubi['Item Name'])\n",
    "data_nubi = data_nubi.drop(['SKU_y'], axis = 1)\n",
    "data_nubi = data_nubi.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "indeks = data_nubi[data_nubi['Real SKU'].astype(str) == 'nan'].index.to_list()\n",
    "data_nubi['Real SKU'][indeks] = data_nubi['SKU'][indeks]\n",
    "\n",
    "indeks = data_nubi[data_nubi['Real Nama Produk'].astype(str) == 'nan'].index.to_list()\n",
    "data_nubi['Real Nama Produk'][indeks] = data_nubi['Item Name'][indeks]\n",
    "\n",
    "data_nubi['Sub Brand'] = data_nubi['Category']\n",
    "\n",
    "data_nubi['Total'] = data_nubi['Sub Total']\n",
    "data_nubi['Total Net'] = np.nan\n",
    "\n",
    "data_nubi = data_nubi.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                        'Status' : 'Order Status',\n",
    "                                        'Order Date' : 'Order date',\n",
    "                                        'Item Name' :'Product Name',\n",
    "                                        'Bundle Name' : 'Bundle',\n",
    "                                        'Shipping Country' : 'Country',\n",
    "                                        'Shipping Province' : 'Region',\n",
    "                                        'Shipping City' : 'City',\n",
    "                                        'Shipping Zip' : 'Zip Code',\n",
    "                                        'Shipping Address1' : 'Address',\n",
    "                                        'Shipping Phone' : 'Phone',\n",
    "                                        'Quantity' : 'Qty. Invoiced',\n",
    "                                        'Item Price' : 'Regular Price',\n",
    "                                        'Sub Total' : 'Subtotal'})\n",
    "\n",
    "\n",
    "temp = data_nubi[data_nubi['Price List NFI'].isnull()]\n",
    "skuoff=pd.read_excel('data_supp\\item gk tau harga.xlsx')\n",
    "skuoff=skuoff[['Real SKU','Price List NFI']]\n",
    "skuoff['Real SKU']=skuoff['Real SKU'].astype(str)#.info()\n",
    "display(temp[~temp['Real SKU'].isin(skuoff['Real SKU'].unique())])\n",
    "temp=temp.merge(skuoff,how='left',on='Real SKU').rename(columns=({'Price List NFI_y':'Price List NFI'}))\n",
    "data_nubi=data_nubi[data_nubi['Price List NFI'].notnull()].append(temp)\n",
    "\n",
    "\n",
    "data_nubi['Price List NFI'] = pd.to_numeric(data_nubi['Price List NFI']).astype(int)\n",
    "data_nubi['Qty. Invoiced'] = pd.to_numeric(data_nubi['Qty. Invoiced']).fillna(0).astype(int)\n",
    "\n",
    "data_nubi['Total Net'] = data_nubi['Price List NFI'] * data_nubi['Qty. Invoiced']\n",
    "\n",
    "data_nubi = data_nubi.reset_index(drop = True)\n",
    "\n",
    "data_nubi['True datetime'] = pd.to_datetime(data_nubi['True datetime'])\n",
    "data_nubi['Promo'] = np.nan\n",
    "data_nubi['Discount MC'] = np.nan\n",
    "data_nubi['Store Type'] = 'Retail Online'\n",
    "\n",
    "for i in data_nubi['Brand'].unique():\n",
    "    indeks = data_nubi[data_nubi['Brand'] == i].index.to_list()\n",
    "    if i == 'NUTRISARI':\n",
    "        data_nubi['Brand'][indeks] = 'NS'\n",
    "    elif i == 'HI LO':\n",
    "        data_nubi['Brand'][indeks] = 'HiLo'\n",
    "        \n",
    "temp = data_nubi[data_nubi['Store'] == 'WARUNG PINTAR DISTRIBUSI - BOGOR, PT'].copy()\n",
    "data_nubi = data_nubi[data_nubi['Store'] != 'WARUNG PINTAR DISTRIBUSI - BOGOR, PT']\n",
    "\n",
    "temp['Store'] = 'WARUNG PINTAR'\n",
    "temp['Channel'] = 'WARUNG PINTAR DISTRIBUSI, PT'\n",
    "temp['Warehouse Name'] = 'WARUNG PINTAR DISTRIBUSI - BOGOR, PT'\n",
    "\n",
    "data_nubi = data_nubi.append(temp, ignore_index = True, sort = False)\n",
    "\n",
    "indeks = data_nubi[data_nubi['Store'] == 'SHOPEE'].index.to_list()\n",
    "data_nubi['Store'][indeks] = 'Shopee Sell-In'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a37e07d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Real SKU</th>\n",
       "      <th>Real Nama Produk</th>\n",
       "      <th>Qty. Invoiced</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Store, Real SKU, Real Nama Produk, Qty. Invoiced, Total]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CEK SKU KOSONG\n",
    "data_nubi[data_nubi['Price List NFI'].isnull()][['Store','Real SKU','Real Nama Produk','Qty. Invoiced','Total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedbb487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f78035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ec7138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b30958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "701e6870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_nubi\\data_nubi_2024-02-02.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_13268\\1317888647.py:24: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_nubi=data_nubi.append(data_nubinew)\n"
     ]
    }
   ],
   "source": [
    "### ini run\n",
    "from datetime import date\n",
    "from datetime import datetime, timedelta\n",
    "import glob\n",
    "import os\n",
    "#CUTOFF 1 BULAN\n",
    "cutoff=str((date.today().replace(day=1)-timedelta(1)).replace(day=1))\n",
    "\n",
    "#CUTOFF 2 BULAN\n",
    "#cutoff=str((((date.today().replace(day=1)-timedelta(1)).replace(day=1))-timedelta(1)).replace(day=1))\n",
    "\n",
    "data_nubinew=data_nubi[data_nubi['True datetime']>=cutoff]\n",
    "\n",
    "data_nubi\n",
    "\n",
    "list_of_files = glob.glob('data_nubi\\*.xlsx') # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "print(latest_file)\n",
    "\n",
    "data_nubi=pd.read_excel(latest_file)\n",
    "# data_nubi['Total Net Before ]\n",
    "data_nubi=data_nubi[data_nubi['True datetime']<cutoff]\n",
    "          \n",
    "data_nubi=data_nubi.append(data_nubinew)\n",
    "\n",
    "data_nubi.to_excel(f\"data_nubi\\data_nubi_{date.today()}.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619cf5db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec11365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5419099c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c17cf62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a42baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run satuin nama retail\n",
    "data_nubi.loc[data_nubi['Store']=='ASTRO TECHNOLOGIES - TANGERANG, PT',['Store']]='ECOM RETAIL - ASTRO'\n",
    "data_nubi.loc[data_nubi['Store']=='RITEL BERSAMA NASIONAL; PT',['Store']]='ECOM RETAIL - JD ID'\n",
    "data_nubi.loc[data_nubi['Store']=='EMOS',['Store']]='ECOM RETAIL - EMOS'\n",
    "data_nubi.loc[data_nubi['Store']=='KREASI NOSTRA MANDIRI - BOGOR, PT',['Store']]='ECOM RETAIL - SAYUR BOX JAKARTA'\n",
    "data_nubi.loc[data_nubi['Store']=='KREAS I NOSTRA MANDIRI - SURABAYA, PT',['Store']]='ECOM RETAIL - SAYUR BOX SURABAYA'\n",
    "data_nubi.loc[data_nubi['Store']=='CIBINONG CENTER INDUSTRIAL ESTATE , PT',['Store']]='ECOM RETAIL - SAYUR BOX JAKARTA'\n",
    "data_nubi.loc[data_nubi['Store']=='KREASI TANI LAKSMI - SURABAYA, PT',['Store']]='ECOM RETAIL - SAYUR BOX SURABAYA'\n",
    "data_nubi.loc[data_nubi['Store']=='ECOM RETAIL - SWIFT BEKASI',['Store']]='ECOM RETAIL - TOKO NOW'\n",
    "data_nubi.loc[data_nubi['Store']=='ECOM RETAIL - SWIFT JKT UTARA',['Store']]='ECOM RETAIL - TOKO NOW'\n",
    "data_nubi.loc[data_nubi['Store']=='INOVASI DIGITAL NIAGA - KALIDERES, PT',['Store']]='ECOM RETAIL - BAYI NINJA JAKARTA'\n",
    "data_nubi.loc[data_nubi['Store']=='INOVASI DIGITAL NIAGA - SURABAYA, PT',['Store']]='ECOM RETAIL - BAYI NINJA JAKARTA'\n",
    "data_nubi.loc[data_nubi['Store']=='INDOPASIFIK TEKNOLOGI MED INDONESIA, PT',['Store']]='ECOM RETAIL - INDOPASIFIK FARMA MEDIKA INDONESIA'\n",
    "data_nubi.loc[data_nubi['Store']=='ECOM RETAIL - LIFEPACK',['Store']]='ECOM RETAIL - INDOPASIFIK FARMA MEDIKA INDONESIA'\n",
    "data_nubi.loc[data_nubi['Store']=='SAYUR BOX',['Store']]='ECOM RETAIL - SAYUR BOX JAKARTA'\n",
    "data_nubi.loc[data_nubi['Store']=='TANIHUB',['Store']]='ECOM RETAIL - TANIHUB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5879295d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "feaec944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MITRA TOKOPEDIA', 'Shopee Sell-In', 'ECOM RETAIL - TANIHUB',\n",
       "       'ECOM RETAIL - JD ID', 'WARUNG PINTAR', 'ECOM RETAIL - EMOS',\n",
       "       'ECOM RETAIL - SAYUR BOX JAKARTA', 'CHILIBELI', 'ALGOLAB SOLUTION',\n",
       "       'CARI SAYUR', 'ECOM RETAIL - BAYI NINJA JAKARTA',\n",
       "       'ECOM RETAIL - INDOPASIFIK FARMA MEDIKA INDONESIA',\n",
       "       'ECOM RETAIL - SAYUR BOX SURABAYA', 'ECOM RETAIL - ASTRO',\n",
       "       'KREASI NOSTRA MANDIRI - SURABAYA, PT', 'ECOM RETAIL - TOKO NOW',\n",
       "       'ECOM RETAIL - JOYBOX(COSMART)', 'ECOM RETAIL - FRESHBOX',\n",
       "       'ECOM RETAIL - HAKUNA MATATA PELAUT', 'ECOM RETAIL - SEGARI',\n",
       "       'ECOM RETAIL - COMMON GROUND', 'ECOM RETAIL - DINKES SURABAYA',\n",
       "       'ECOM RETAIL - TRUFFLE BELLY'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nubi['Store'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e848b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858b902b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289ec5d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "99486796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2983c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d98531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fadbb60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7cfadc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b48f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdf52d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_13268\\67016908.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_all = data_all.append(data_nubi, ignore_index = True, sort = False)\n"
     ]
    }
   ],
   "source": [
    "## ini run\n",
    "data_all['Store'] = data_all['Store'].astype(str).str.replace('JD Indonesia - Nutrimart', 'JD Indonesia', regex = False)\n",
    "\n",
    "data_all = data_all[data_all['Store'].isin(['JD Indonesia', 'Lazada', 'Bukalapak', 'Blibli', 'Tokopedia',\n",
    "       'Shopee', 'Elevenia', 'Nutrimart', 'Order Online','Aladin Mall','TikTok','Orami Shopping'])]\n",
    "data_all = data_all.append(data_nubi, ignore_index = True, sort = False)\n",
    "\n",
    "indeks = data_all[data_all['Store'].isin(['JD Indonesia', 'Lazada', 'Bukalapak', 'Blibli', 'Tokopedia',\n",
    "       'Shopee', 'Elevenia','Aladin Mall','TikTok','Orami Shopping'])].index.to_list()\n",
    "data_all['Store Type'][indeks] = 'Marketplace'\n",
    "\n",
    "indeks = data_all[data_all['Store'].isin(['Nutrimart', 'Order Online'])].index.to_list()\n",
    "data_all['Store Type'][indeks] = 'Organic'\n",
    "\n",
    "indeks = data_all[data_all['Order #'].astype(str).str.contains('Nubi')].index.to_list()\n",
    "data_all['Store Type'][indeks] = 'Retail Online'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc59244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32aede7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f0ea88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a78cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0c4cb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ini run juga\n",
    "indeks = data_all[data_all['Product Name'] == 'L-Men Bar Crunchy Chocolate (12sch)'].index.to_list()\n",
    "data_all['Real Nama Produk'][indeks] = 'L-Men Bar Crunchy Chocolate 12sch'\n",
    "data_all['Parent Item'][indeks] = 'L-Men Bar Crunchy Chocolate (12 Sch)'\n",
    "data_all['Brand'][indeks] = 'L-Men'\n",
    "data_all['Sub Brand'][indeks] = 'L-MEN POWDER'\n",
    "data_all['Real SKU'][indeks] = '2306592173'\n",
    "data_all['Parent SKU'][indeks] = '2306592173'\n",
    "\n",
    "indeks = data_all[data_all['Product Name'] == 'Heavenly Blush Yogurt Drink To Go Peach (1 pc)'].index.to_list()\n",
    "data_all['Brand'][indeks] = 'Heavenly Blush'\n",
    "\n",
    "indeks = data_all[data_all['Brand'] == 'HB'].index.to_list()\n",
    "data_all['Brand'][indeks] = 'Heavenly Blush'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed24b887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ede988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef74778b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d84421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4549b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8424f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a11368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "845e62d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ini run juga\n",
    "data_all['Region Group'] = np.nan\n",
    "\n",
    "index = data_all[data_all['Region'].isin(['Dki Jakarta', 'Banten'])].index.to_list()\n",
    "data_all['Region Group'][index] = 'Jabodetabek'\n",
    "\n",
    "list_city = ['Kota Bekasi', 'Kabupaten Bekasi', 'Kab. Bekasi', 'Kota Bogor', 'Kabupaten Bogor', 'Kab. Bogor', 'Kota Depok', 'Kota Tangerang',\n",
    "             'Kota Tangerang Selatan','Kabupaten Tangerang', 'Kab. Tangerang']\n",
    "\n",
    "index = data_all[data_all['City'].isin(list_city)].index.to_list()\n",
    "data_all['Region Group'][index] = 'Jabodetabek'\n",
    "\n",
    "data_all['Region Group'] = data_all['Region Group'].fillna(data_all['Region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5ff862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec01c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ffe7ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Settlement Finish\n",
      "Listing missing invoice\n",
      "Repairing Table\n",
      "Finish Appending TokPed\n"
     ]
    }
   ],
   "source": [
    "#APPEND TOKOPEDIA SETTLEMENT (ATAS PERINTAH KO TIMO) - SETIAP BULAN 1X\n",
    "#First Step : Extract data settlement\n",
    "s_tok = pd.read_excel(r\"C:\\Users\\steven.nathanael\\Downloads\\Runningan Tokopedia Nov 22.xlsx\",sheet_name = 'Sheet1',converters = {'Phone' : str, 'Order #' : str})\n",
    "s_tok['Customer Phone']=s_tok['Customer Phone'].str.extract('(\\d+)')\n",
    "s_tok['Real SKU'] = s_tok['Real SKU'].astype(str)\n",
    "s_tok['Order #'] = s_tok['Invoice']\n",
    "print('Data Settlement Finish')\n",
    "\n",
    "all_df = pd.merge(s_tok[['Order #','Month','Order Status']], data_all['Order #'], on=['Order #'], how='left', indicator='exists')\n",
    "all_df[all_df['exists'] == 'left_only'].sort_values('Month')\n",
    "mis_inv = all_df[all_df['exists'] == 'left_only']['Order #'].unique()\n",
    "mis_inv\n",
    "print('Listing missing invoice')\n",
    "\n",
    "mis_tok = s_tok[s_tok['Order #'].isin(mis_inv)]\n",
    "mis_tok = mis_tok[mis_tok['Order Status'].str.contains('Dikirim|Selesai|Tiba', case = False, na = False)]\n",
    "mis_tok['day'] = mis_tok['Date'].astype(int)\n",
    "mis_tok['month'] = mis_tok['Month'].apply(lambda x : 9 if x == 'September' else\n",
    "                                                 (10 if x == 'October' else\n",
    "                                                 (11 if x == 'Novemer' else \n",
    "                                                 (12 if x == 'December' else\n",
    "                                                 (1 if x == 'January' else\n",
    "                                                 (2 if x == 'February' else\n",
    "                                                 (3 if x == 'March' else\n",
    "                                                 (4 if x == 'April' else\n",
    "                                                 (5 if x == 'May' else\n",
    "                                                 (6 if x == 'June' else\n",
    "                                                 (7 if x == 'July' else 8)))))))))))\n",
    "mis_tok['True datetime'] = pd.to_datetime(mis_tok[['Year','month','day']])\n",
    "mis_tok['Phone'] = mis_tok['Customer Phone'].astype(str)\n",
    "mis_tok['Store Type'] = 'Marketplace'\n",
    "mis_tok['Store'] = 'Tokopedia'\n",
    "print('Repairing Table')\n",
    "\n",
    "kolom = data_all.columns\n",
    "\n",
    "data_all1 = data_all.append(mis_tok, ignore_index = False)\n",
    "data_all = data_all1[kolom]\n",
    "del data_all1\n",
    "print('Finish Appending TokPed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "14515e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all1 = data_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ac710772",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = data_all1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75742a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ac7fb3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_36404\\137081300.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_all = data_all.append(tes1, ignore_index = True)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac22bed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4a78e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c9ac869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LET'S TRY FOR EMAIL\n"
     ]
    }
   ],
   "source": [
    "print(\"LET'S TRY FOR EMAIL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d732101a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export Master Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Real SKU'][index] = '1101909331'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Real SKU'][index] = '1101909331'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Real SKU'][index] = '1101569326'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Real SKU'][index] = '1101569326'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Real SKU'][index] = '1101907331'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Real SKU'][index] = '1101907331'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Real SKU'][index] = '(B)2101656'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Real SKU'][index] = '(B)2101656'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Brand'][index] = 'Bonus Produk'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Brand'][index] = 'Bonus Produk'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  no_pair['SKU Clean'] = no_pair['SKU'].astype(str).str.replace('(S)', '', regex = False).str.replace('(R)', '', regex = False).str.replace('(B)', '', regex = False).str.replace('(50%)', '', regex = False).str.replace('(E)', '', regex = False).str.replace('E', '', regex = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  no_pair['SKU Clean'][index] = '1101984453'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  no_pair['SKU Clean'][index] = '2104392210'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS MODERN'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"NS JERUK PERAS REF 12DX500G\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS MODERN'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"NS JERUK PERAS REF 12DX500G\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"W'DANK LKLT KOPI KAWISTA PLS 12RX10SX15G\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS MERAH'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS EXTRA VIRGIN OLIVE OIL 12BTLX500ML'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM CHOCO LATTE 6DX6SX33.5G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM CHOCO LATTE 6DX6SX33.5G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM CHOCO LATTE 6DX6SX33.5G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN PROTEIN BAR STRONGBERY 6SBX12SX20G'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:106: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:107: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN GM MANGGA 6DX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS MARKISA PLS 4PX40SX11G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:114: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:115: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS NANAS PLS 4PX40SX11G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:119: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS MADU KURMA PLS 4PX40SX11G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS MILKY ORANGE PLS 4PX40SX11G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS MILKY ORANGE FC 72PX10SX11G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:131: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS LYCHEE TEA PLS 4PX40SX11G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:134: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:135: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS LESS SUGAR BELIMBING PLS 4PX40SX6G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:139: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS MANGGA GANDARIA PLS 4PX40SX11G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO ACTIVE CHOCOLATE 6DX1000G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:146: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:147: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO GOLD PLAIN 6DX1000G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:150: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:151: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO GOLD BISCUIT CEREAL 12DX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:154: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:155: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO GOLD BISCUIT CEREAL 12DX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL CHOCOLATE 6DX1000G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO TEEN CHOCOLATE 6DX1000G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS SWT JAHE 24Dx50SX2.5G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:171: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS SWT JAHE 24Dx50SX2.5G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:175: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS SWT JAHE 24Dx50SX2.5G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN GM MANGGA 6DX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:182: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:183: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS ES CINCAU PLS 4PX40SX13G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:186: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:187: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS SEMANGKA PLS 4PX40SX13G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS SEMANGKA PLS 4PX40SX11G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:195: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS NANAS PLS 4PX40SX13G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS ANGGUR HIJAU PLS 4PX40SX11G '\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:202: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:203: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS WHITE COFFEE 12DX4SX15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:206: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:207: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI BERONDONG PLS 12RX10SX15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:210: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:211: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS COCOPANDAN PLS 4PX40SX14G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:214: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:215: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'PAKET NUTRISARI 25 RASA'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:219: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'PAKET NUTRISARI 25 RASA FRESHSTART'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:222: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:223: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS MIX PAKET BALI 12Dx10S'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:226: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:227: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'PAKET KEHANGATAN WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:230: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:231: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS WHITE COFFEE 12DX4SX20G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:235: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN PROTEIN CRUNCH BBQ BEEF 20BX20G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:238: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:239: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS W’DANK EMPON-EMPON PLS 12Rx10Sx12G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:242: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:243: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN BAR CRUNCHY CHOCOLATE 6SBX12SX22G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:246: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:247: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN BAR CRUNCHY CHOCOLATE 6SBX12SX22G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:250: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:251: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO ES TELER PLS 8RX10SX15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:254: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:255: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HI LO DRINK TEH TARIK PLS 8RX10SX15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:258: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:259: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HI LO DRINK CHOCO MALT 8RX10SX14G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:262: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:263: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO ES TELER PLS 8RX10SX15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:267: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO ES TELER FC 36PX10SX15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:270: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:271: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HI LO DRINK CHOCO MINT PLS 15RX10SX14G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:274: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:275: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO ES PISANG IJO PLS 8RX10SX15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:278: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:279: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO ES KETAN HITAM REF 12BAGX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:282: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:283: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO ES KETAN HITAM PLS 8RX10SX14G'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:286: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO ES KETAN HITAM PLS 8RX10SX14G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:290: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:291: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'PAKET LOKALATE UNTUK SOBATKU'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:294: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:295: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN GAINMASS TARO 6DX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:298: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:299: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM CHOCO LATTE 6DX6SX38.5G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:302: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM KACANG HIJAU 6KLRX800G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:306: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:307: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'PAKET HAMPERS IMLEK NUTRISARI'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:310: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS KOREAN GARLIC BUTTER COOKIES 12DX5SX20G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:314: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:315: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS MINT COCOA 12DX4SX15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:318: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:319: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS MINT COCOA 12DX10SX15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:322: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:323: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS ORANGE COCOA 12DX4SX15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:326: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS SALTED CARAMEL COCOA 12DX4SX15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:330: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS MERAH'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:331: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS SAMBAL TERASI 24BTLX200G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:334: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS MERAH'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:335: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS SAMBAL TERASI 24BTLX200G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:338: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:339: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS AVOCADO COFFEE 12DX4SX20G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:342: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:343: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO TEEN TARO 12DX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:346: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:347: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO ACTIVE KETAN HITAM 12DX175G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:350: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:351: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO ACTIVE VANILLA 6DX1000G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:354: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:355: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS SWT LEMONGRASS PANDAN 24DX50SX2G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:358: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS MERAH'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:359: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS SAUS TIRAM 24BTLX200ML'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:363: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM KETAN HITAM 6KLRX800G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:366: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS MERAH'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:367: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS SHIRATAKI NOODLES 40PX71G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:370: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS MERAH'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:371: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS BUMBU KALDU AYAM JAMUR 24PX100G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:374: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS MERAH'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:375: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS BUMBU SAUS TELUR ASIN 24Dx3Sx22G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:378: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET HILO'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:379: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'PAKET TAKJIL HILO DESSERT'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:382: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET TS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:383: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HAMPER IDUL FITRI TS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:386: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET TS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:387: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'PAKET TS BEAT HYPERTENSION 2022'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:390: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:391: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'PAKET RAMADHAN NUTRISARI 2021'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:394: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:395: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO ACTIVE ES TELER 12DX175G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:398: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:399: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO ACTIVE ES TELER 12DX175G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:402: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:403: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'PAKET KEHANGATAN WDANK - RAMADHAN EDITION'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:406: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET TS'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:407: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'GETPLUS HAMPERS IDUL FITRI TS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:410: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:411: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS SWT ROSE VANILLA 24DX50SX2G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:414: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:415: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO TEEN POPCORN CARAMEL 12DX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:418: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:419: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO TEEN POPCORN CARAMEL 12DX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:422: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:423: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS MADU LEMON PLS 4PX40SX11G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:426: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:427: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS LEMON TEA PLS 4PX40SX11G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:430: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:431: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS APEL JERUK PLS 4PX40SX14G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO RTD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO RTD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:435: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO TEEN RTD COFFEE TIRAMISU 24PX200ML'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:435: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO TEEN RTD COFFEE TIRAMISU 24PX200ML'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:438: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO RTD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:439: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HI LO DRINK RTD CHOCOFIT 24TPKX190ML'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:442: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO RTD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:443: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL RTD VEGIBERI 24PX200ML'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:446: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO RTD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:447: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO RTD VANILA COOKIES 24PX200ML'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:450: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO RTD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:451: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO RTD VANILA COOKIES 24PX200ML'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:454: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS BIRU'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:455: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS GOLDENMIL VANILLA 12DX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:458: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS BIRU'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:459: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS RTD OAT DRINK VANILLICIOUS 24PX190ML'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:462: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS BIRU'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:463: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS RTD ALMOND DRINK CHOCOLICIOUS 24TPKX190ML '\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:466: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS BIRU'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:467: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS RTD OAT DRINK MELON 24TPKX190ML'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:470: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS BIRU'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:471: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS LOW FAT MILK KOREAN STRAWBERRY 12DX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:474: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS MERAH'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:475: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS MAYONNAISE ROASTED SESAME 24BTLX200G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:478: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS MERAH'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:479: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS MAYONNAISE ROASTED SESAME 24BTLX200G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:482: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:483: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS ES RUJAK JERUK BALI PLS 4PX40SX14G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:486: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:487: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS MADU JERUK PLS 4PX40SX11G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:490: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:491: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS ISOTONIK REFRESHING CITRUS PLS 4PX40SX11G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:495: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN DAILY POPCORN CARAMEL 12DX250G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:498: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:499: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN ISOPOWER STARGIZING 6DX30SX7.8G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:502: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:503: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS NUTRI C1000 JERUK PLS 4PX40SX6G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:506: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:507: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NUTRILOGI SERI MBA NANA SI PENUH PESONA'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:510: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:511: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NUTRILOGI SERI MAS KAKA YANG BANYAK AKAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:514: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:515: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NUTRILOGI SERI JEJE SI JELI'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:518: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:519: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NUTRISARI 4 RASA SUMMER PACKAGE 40 SACHET'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:522: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:523: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NUTRISARI 4 RASA LOCAL PACKAGE 40 SACHET'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:526: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:527: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS KOREAN GOGUMA COOKIES 12DX5SX20G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:530: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:531: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO TEEN CHOCOLATE 12DX250G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:534: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:535: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'PAKET ORANGE ADVENTURE'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:538: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:539: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO GOLD SWEET POTATO 12DX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:542: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO GOLD CHOCOLATE 6DX1000G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:546: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:547: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO PLATINUM ORIGINAL 12DX12SX30G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:550: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:551: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HI LO PLATINUM ORIGINAL 12DX5SX30G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:554: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:555: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HI LO PLATINUM +HMB Vanilla 12DX8SX42G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:558: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:559: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO JOINT PLUS 12DX10SX14G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:562: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:563: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO JOINT PLUS 12DX10SX14G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:566: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:567: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI TAPE KETAN PLS 12RX10SX15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:570: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:571: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI TAPE KETAN PLS 12RX10SX15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:574: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:575: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI ANDALIMAN PLS 12RX10SX15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:578: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:579: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"NS W'DANK SARABBA EXTRA PLS 12RX10SX15G\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:582: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'WDANK'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:583: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"NS W'DANK MADU TEMULAWAK PLS 12RX10SX11G\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:586: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:587: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'PAKET LOKALATE #RASALOKAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:590: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:591: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL STRAW CHEESECAKE 12DX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:594: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:595: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL VANILLA 6DX1000G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:598: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:599: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO ALMOND MILK COCONUT 12DX200G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:602: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:603: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO MULTIGRAIN ORIGINAL 12DX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:606: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO TEEN STRAWBERRY MILKSHAKE 12DX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:610: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:611: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN PLANTPROTEIN OGURA 6Dx216G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:614: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:615: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN PLANTPROTEIN OGURA 12DX216G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:618: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS MERAH'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:619: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS SHIRATAKI RICE RASA NASI UDUK 24PX72G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:622: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS MERAH'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:623: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS BERAS MERAH ORGANIK 12PCHX1000G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:626: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS MODERN'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:627: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"NS TEA LYCHEE TEA REF 12BAGX500G\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:630: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS MODERN'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:631: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"NS JERUK MANIS PITCHER 12BTLX300G\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:634: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS MODERN'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:635: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"NS PREMIUM JUS MANGGA REF 12BAGX420G\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:638: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:639: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"NS JERUK NIPIS JAHE PLS 4PX40SX11G\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:642: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:643: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"NS MIX PAKET BALI 12Dx10S\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:646: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:647: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"NS JERUK NIPIS JAHE PLS 4PX40SX11G\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:650: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS RTD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:651: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"NS RTD SQUEEZED ORANGE 24TPKX200ML\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:654: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:655: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"NS ES KUWUD NIPIS PLS 4PX40SX11G\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:658: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:659: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"NS GULA ASEM PLS 4PX40SX11G\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:662: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:663: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"TS COOKIES KLEPON 12DX5SX20G\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:666: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"L-MEN LOSE WEIGHT AVOCADO COFFEE 6DX12SX25G\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"L-MEN GAINMASS KLEPON LATTE 6DX500G\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:674: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:675: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"L-MEN ADVANCE GOLD VANILLA 6DX500G\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:679: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"HILO SCHOOL CHOCOLATE 12DX250G\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:682: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:683: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"HILO SCHOOL BUBBLE GUM 12DX500G\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:686: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:687: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"HILO ACTIVE CARAMEL LATTE 12DX500G\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:690: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:691: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"HILO ACTIVE CARAMEL LATTE 12DX500G\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:694: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET TS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:695: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'PARSEL NATAL TAHUN BARU'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:698: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:699: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL COTTON CANDY 12DX500G'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:702: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO RTD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:703: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL RTD COTTON CANDY 24TPKX200ML'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:706: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:707: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI PISANG BAKAR EPE PLS 12RX10SX15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:710: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:711: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI BERONDONG 12BAGX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:714: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:715: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI ALPUKAT 12BAGX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:718: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:719: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS LOKALATE RTD KOPI BRNDONG 24TPKX185ML'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:722: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:723: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"W'DANK LKLT KOPI KAWISTA PLS 12RX10SX15G\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:726: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:727: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO KLEPON LATTE REF 12BAGX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:730: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:731: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO THAI TEA REF 12BAGX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:734: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:735: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO TARO LATTE REF 12BAGX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:739: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL CHOCOLATE CANDY 12SBX20SX8G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:742: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS MERAH'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS INSTANT CAKE MIX BROWNIES 12Dx230G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:746: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:747: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM BUBBLE GUM 6KLRX800G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:750: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:751: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM VANILLA CARAMEL 6KLRX800G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:754: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:755: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM CHOCO LATTE REF 6DX800G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:758: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:759: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN LW MANGO STICKY RICE 6DX12SX25G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:762: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS BIRU'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS LOW FAT MILK MACCHIATO COFFEE 12DX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:766: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:767: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO TEEN BISCUIT CARAMEL 12DX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:770: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'DIABETAMIL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:771: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'DIABETAMIL MILK VANILLA 12Dx150G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:774: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:775: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS SOY LATTE 12Dx10Sx15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:778: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:779: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS PEANUT ALMOND BUTTER 12BTLX300G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:782: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:783: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS 7 FRUITS FIBER DAILY 12DX12SX15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:786: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:787: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS SWT GULA AREN 24DX50SX2G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:790: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:791: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS SWT GULA BUAH 24DX50SX2.5G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:794: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS MODERN'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:795: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = \"NS TEA LEMON TEA REF 12BAGX500G\"\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:798: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO RTD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:799: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO DRINK RTD CHOC AVOCADO 24TPKX200ML'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:802: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'WDANK'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:803: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI ANDALIMAN PLS 12RX10SX15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:806: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:807: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO KLEPON LATTE REF 12BAGX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:810: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:811: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS SWT LEMONGRASS PANDAN 24DX50SX2G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:814: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:815: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS SWT ROSE VANILLA 24DX50SX2G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:818: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS JERUK MAROKO PLS 4PX40SX11G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:822: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:823: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS APEL JERUK PLS 4PX40SX14G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:826: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS MODERN'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:827: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS LEMON TEA REF 12BAGX400G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:830: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS MODERN'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:831: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS LEMON TEA REF 12BAGX400G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:834: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:835: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS FLORIDA ORANGE PLS 18PX40SX11G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:838: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:838: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:839: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS FLORIDA ORANGE FC 72OX10SX11G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:839: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS FLORIDA ORANGE FC 72OX10SX11G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:842: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:843: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS COCOPANDAN PLS 4PX40SX11G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:846: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS MODERN'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:847: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS LYCHEE TEA REF 12BAGX400G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:850: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:851: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'NS ES CINCAU PLS 4PX40SX11G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:854: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:855: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO GOLD PLAIN 6DX1000G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:858: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:859: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL STRAW CHEESECAKE 12DX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:862: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS MERAH'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:863: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS SAUS TIRAM 24BTLX200ML'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:866: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:867: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO TEEN CHOCOLATE 6DX1000G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:870: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:871: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI ANDALIMAN 12DX8SX15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:874: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:875: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HI LO SCHOOL STRAWBERRY PLS 12RX10SX27G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:878: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:879: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI KAWISTA PLS 12RX10SX15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:882: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:883: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL CHOCOLATE 6DX1000G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:886: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:887: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HI LO SCHOOL 3+ SOYA VANILLA MALT 12DX400G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:890: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:891: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN DAILY POPCORN CARAMEL 12DX250G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:894: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:895: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO GOLD SWEET POTATO 12DX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:898: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:899: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS KOREAN GARLIC BUTTER COOKIES 12DX5SX20G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:902: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:903: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI BERONDONG 12Dx8Sx15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:907: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS AVOCADO COFFEE 12DX10SX14G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:910: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:911: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS FRENCH BUTTER SOUFFLE COFFEE 12DX4SX15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:914: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:915: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS FRENCH BUTTER SOUF COFFEE 12DX10SX15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:918: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:919: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL COTTON CANDY 12DX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:922: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:923: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HI LO SCHOOL 3+ STRAWBERRY POP 12DX400G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:926: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:927: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HI LO SCHOOL ORIGINAL 12DX400G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:930: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS MERAH'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:931: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS SALTY SOY SAUCE 24BTLX200ML'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:934: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:935: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO ACTIVE CHOCOLATE 6DX1000G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:938: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:939: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN LOSE WEIGHT AVOCADO COFFEE 6DX12SX25G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:942: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:943: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM STRAWBERRRY 6KLRX800G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:946: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET TS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:947: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'PAKET TROPICANA SLIM CHILL OUT KIT 2022'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:950: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:950: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:951: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS SWT CLASSIC 12DX250G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:951: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS SWT CLASSIC 12DX250G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:954: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:955: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS SWT LUO HAN GUO 24DX50SX2G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:958: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:959: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HILO TEEN STRAWBERRY MILKSHAKE 12DX500G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:962: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HI LO TEEN HiProtein Melon 12DX400G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:967: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HI LO TEEN ORIGINAL 12DX400G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:970: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TEEN'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:971: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HI LO TEEN Berries Club 12DX400G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:974: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:975: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'HI LO TEEN VANILLA CARAMEL 6DX1000G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:978: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:979: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'PAKET NUTRISARI 35 RASA'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:982: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:983: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'PAKET NUTRISARI VALENTINE 2023'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:986: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:987: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI PISANG BAKAR EPE PLS 12RX10SX15G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'L-MEN RTD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:991: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'L-MEN PROTEIN 2GO RTD OGURA 24TPKX190ML'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:994: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET L-MEN'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:995: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'GREEN PACKAGING L-MEN 2GO CHOCOLATE'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:998: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET TS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:999: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'GREEN PACKAGING OAT DRINK RTD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1002: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET TS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1003: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'GREEN PACKAGING MINYAK KANOLA'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1006: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET HILO'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1007: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'GREEN PACKAGING HILO SCHOOL CHOCOLATE RTD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1010: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET HILO'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1011: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'GREEN PACKAGING HILO TEEN CHOCOLATE RTD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1014: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1015: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'GREEN PACKAGING NS SQUEEZED ORANGE RTD'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1018: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET LOKALATE'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1019: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'PAKET SOBAT MELEK SEGITIGA LOKALATE 2023'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1022: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET TS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1023: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'VB SSI - TS ALMOND DRINK CHOCOLICIOUS 4 PCS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1026: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET TS'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1027: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'VB SSI - TS OAT DRINK VANILICIOUS 4 PCS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1030: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1031: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'PAKET NUTRISARI 45 RASA 2023'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1034: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Category Baru'][index] = 'TS BIRU'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1035: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SKU_final['Unnamed: 3'][index] = 'TS COLLAGEN DRINK STRAWBERRY 12KLRX200G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1041: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Brand'][index] = 'Bundle'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1043: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Brand'][index] = 'Bundle'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1043: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Brand'][index] = 'Bundle'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1045: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Brand'][index] = 'L-Men'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1045: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Brand'][index] = 'L-Men'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1047: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Real SKU'][indeks] = data_all['SKU'][indeks]\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1047: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Real SKU'][indeks] = data_all['SKU'][indeks]\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1048: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Parent Item'][indeks] = 'Tropicana Slim Milk Low Fat Vanilla 500gr'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1048: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Parent Item'][indeks] = 'Tropicana Slim Milk Low Fat Vanilla 500gr'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1051: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Brand'][index] = 'WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1054: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Brand'][index] = 'WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1054: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Brand'][index] = 'WDANK'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1061: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Category Baru'][no_name.index] = no_name['Category Baru_y']\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1062: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Exported Parent Item'][no_name.index] = no_name['Exported Parent Item_y']\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1071: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1072: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Exported Parent Item'][index] = 'TS SWT CLASSIC 12DX250G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1075: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1078: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Category Baru'][index] = 'L-MEN POWDER'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1079: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Sub Brand'][index] = 'L-MEN POWDER'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1082: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Category Baru'][index] = 'HILO TEEN'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1083: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Exported Parent Item'][index] = 'HILO TEEN CHOCOLATE 12DX250G'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1088: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Sub Brand'][no_name.index] = no_name.merge(data_SKU[['SKU', 'Sub Brand']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(no_name.index)['Sub Brand_y']\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1091: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Sub Brand'][index] = 'NS TRADITIONAL'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1094: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Sub Brand'][index] = 'WDANK'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter Status\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1098: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Order Status'][index] = 'Delivered'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1098: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['Order Status'][index] = 'Delivered'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_single['Brand'][index] = 'NS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1147: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_single['Exported Parent Item'][indeks] = all_single['Product Name'][indeks]\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1147: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_single['Exported Parent Item'][indeks] = all_single['Product Name'][indeks]\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1152: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_single['Sub Brand'][indeks] = all_single['Category'][indeks]\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1152: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_single['Sub Brand'][indeks] = all_single['Category'][indeks]\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1154: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_single['Total Net'] = all_single['Total Net'].astype(float).astype('int64')\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_single['Brand'][indeks] = 'NS'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_single['Sub Brand'][indeks] = 'PAKET NUTRISARI'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1161: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_single['Exported Parent Item'][indeks] = 'PAKET ORANGE ADVENTURE'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare E-mailing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1198: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  yesterday_sales = all_single[all_single['Store']=='Order Online'][all_single['True datetime'] >= yesterday][all_single[all_single['True datetime'] >= yesterday]['True datetime']<today]\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1211: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mtd_sales = all_single[all_single['Store']=='Order Online'][all_single['True datetime'] >= mtd_date][all_single[all_single['True datetime'] >= mtd_date]['True datetime']<today]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Date 2023-11-01 00:00:00\n",
      "Last Date 2023-12-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1240: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  temp_sales = all_single[all_single['Store']=='Order Online'][all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Date 2023-12-01 00:00:00\n",
      "Last Date 2024-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1240: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  temp_sales = all_single[all_single['Store']=='Order Online'][all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Date 2024-01-01 00:00:00\n",
      "Last Date 2024-02-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1240: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  temp_sales = all_single[all_single['Store']=='Order Online'][all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1273: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table_ecom['Sub Brand'][table_ecom.index.max()] = '<b>Total E-Commerce (NHD) Sales<b>'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1291: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  yesterday_sales = all_single[all_single['Store']!='Order Online'][all_single['True datetime'] >= yesterday][all_single[all_single['True datetime'] >= yesterday]['True datetime']<today]\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1304: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mtd_sales = all_single[all_single['Store']!='Order Online'][all_single['True datetime'] >= mtd_date][all_single[all_single['True datetime'] >= mtd_date]['True datetime']<today]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Date 2023-11-01 00:00:00\n",
      "Last Date 2023-12-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1333: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  temp_sales = all_single[all_single['Store']!='Order Online'][all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Date 2023-12-01 00:00:00\n",
      "Last Date 2024-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1333: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  temp_sales = all_single[all_single['Store']!='Order Online'][all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Date 2024-01-01 00:00:00\n",
      "Last Date 2024-02-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1333: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  temp_sales = all_single[all_single['Store']!='Order Online'][all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1366: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table_ecom['Sub Brand'][table_ecom.index.max()] = '<b>Total E-Commerce (Non NHD) Sales</b>'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1380: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table_ecom[i][table_ecom.index.max()] = \"<b> {} </b>\".format(table_ecom[i][table_ecom.index.max()])\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1426: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tblall[i][tblall.index.max()] = \"<b> {} </b>\".format(tblall[i][tblall.index.max()])\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1497: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tblreg[i][tblreg.index.max()] = \"<b> {} </b>\".format(tblreg[i][tblreg.index.max()])\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1501: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tblreg[i][tblreg.index.max()] = \"<b> {} </b>\".format(tblreg[i][tblreg.index.max()])\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1506: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tblreg[i][tblreg.index.max()] = \"<b> {} </b>\".format(tblreg[i][tblreg.index.max()])\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1523: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table_brand_hilo['Sub Brand'][table_brand_hilo.index.max()] = '<b>TOTAL<b>'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1524: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table_brand_hilo['Brand'][table_brand_hilo.index.max()] = ''\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1529: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table_brand_ns['Sub Brand'][table_brand_ns.index.max()] = '<b>TOTAL<b>'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1530: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table_brand_ns['Brand'][table_brand_ns.index.max()] = ''\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1535: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table_brand_lmen['Sub Brand'][table_brand_lmen.index.max()] = '<b>TOTAL<b>'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1536: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table_brand_lmen['Brand'][table_brand_lmen.index.max()] = ''\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1541: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table_brand_ts['Sub Brand'][table_brand_ts.index.max()] = '<b>TOTAL<b>'\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1542: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table_brand_ts['Brand'][table_brand_ts.index.max()] = ''\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1547: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table_brand_hilo[i][table_brand_hilo.index.max()] = \"<b> {} </b>\".format(table_brand_hilo[i][table_brand_hilo.index.max()])\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1551: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table_brand_lmen[i][table_brand_lmen.index.max()] = \"<b> {} </b>\".format(table_brand_lmen[i][table_brand_lmen.index.max()])\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1555: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table_brand_ns[i][table_brand_ns.index.max()] = \"<b> {} </b>\".format(table_brand_ns[i][table_brand_ns.index.max()])\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\3388873355.py:1559: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table_brand_ts[i][table_brand_ts.index.max()] = \"<b> {} </b>\".format(table_brand_ts[i][table_brand_ts.index.max()])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Data Finish\n",
      "Clean Data Non Nubi Finish\n",
      "Export Data 2020 Finish\n",
      "Prepare Emailing\n",
      "Email Sent\n"
     ]
    }
   ],
   "source": [
    "print(\"Export Master Data\")\n",
    "\n",
    "#TEMPORARY ORAMI\n",
    "#data_all = data_all[~(data_all['Store'].isin(['Orami Shopping']))]\n",
    "\n",
    "data_all['True datetime'] = pd.to_datetime(data_all['True datetime'])\n",
    "data_all['Price List NFI'] = pd.to_numeric(data_all['Price List NFI'])\n",
    "data_all['PL Before PPN'] = data_all['Price List NFI']/1.1\n",
    "data_all.loc[data_all['True datetime']>='2022-04-01','PL Before PPN']= data_all['Price List NFI']/1.11\n",
    "data_all['Total Net Before PPN'] = data_all['PL Before PPN'] * data_all['Qty. Invoiced']\n",
    "\n",
    "index = data_all[\n",
    "    (pd.to_datetime(data_all['True datetime']) > '2020-09-11') &\n",
    "    (data_all['Real SKU'].astype(str) == '1101909453') \n",
    "].index.to_list()\n",
    "\n",
    "data_all['Real SKU'][index] = '1101909331'\n",
    "\n",
    "index = data_all[\n",
    "    (pd.to_datetime(data_all['True datetime']) > '2020-09-11') &\n",
    "    (data_all['Real SKU'].astype(str) == '1101569453') \n",
    "].index.to_list()\n",
    "\n",
    "data_all['Real SKU'][index] = '1101569326'\n",
    "\n",
    "index = data_all[\n",
    "    (pd.to_datetime(data_all['True datetime']) > '2020-09-11') &\n",
    "    (data_all['Real SKU'].astype(str) == '1101907453') \n",
    "].index.to_list()\n",
    "\n",
    "data_all['Real SKU'][index] = '1101907331'\n",
    "\n",
    "index = data_all[data_all['Real SKU'] == '(B) 2101656'].index.to_list()\n",
    "data_all['Real SKU'][index] = '(B)2101656'\n",
    "\n",
    "index = data_all[data_all['Real SKU'] == '(B)1101989453'].index.to_list()\n",
    "data_all['Brand'][index] = 'Bonus Produk'\n",
    "\n",
    "data_all.loc[data_all['SKU'].isin(['(U)2104115163', '(U)2101809250', '(U)2309005305',\n",
    "                                   '(U)2101845443',\"(U)2101947250\", '(B)71210295',\n",
    "                                   '(B)2106323165']),'Brand']='Bonus Produk'\n",
    "\n",
    "\n",
    "if 'Order Online' not in data_now:\n",
    "    data_now = data_now + ' With Order Online'\n",
    "SKU = pd.read_excel(r'SKU_File/data_SKU.xlsx')\n",
    "SKU_baru = pd.read_excel(r\"SKU_File/Subbrand Baru.xlsx\")\n",
    "\n",
    "SKU_final = SKU.copy()\n",
    "SKU_baru['Item Group Code'] = SKU_baru['Item Group Code'].astype(str).str.replace('.0','', regex = False)\n",
    "SKU_final['SKU Clean'] = SKU_final['SKU'].astype(str).str.replace('(S)', '', regex = False).str.replace('(R)', '', regex = False).str.replace('(B)', '', regex = False).str.replace('(50%)', '', regex = False).str.replace('(E)', '', regex = False)\n",
    "SKU_final = SKU_final.merge(SKU_baru.drop_duplicates('Item Group Code'), how = 'left', left_on = 'SKU Clean', right_on = 'Item Group Code')\n",
    "\n",
    "no_pair = SKU[SKU['SKU'].astype(str).isin(SKU_final[SKU_final['Category Baru'].isnull()]['SKU'].astype(str))]\n",
    "SKU_final = SKU_final[~SKU_final['SKU'].astype(str).isin(no_pair['SKU'].astype(str))]\n",
    "\n",
    "no_pair['SKU Clean'] = no_pair['SKU'].astype(str).str.replace('(S)', '', regex = False).str.replace('(R)', '', regex = False).str.replace('(B)', '', regex = False).str.replace('(50%)', '', regex = False).str.replace('(E)', '', regex = False).str.replace('E', '', regex = False)\n",
    "SKU_baru['Item Group Code'] = SKU_baru['Product Code'].astype(str).str.replace('.0','', regex = False)\n",
    "\n",
    "index = no_pair[no_pair['SKU'].astype(str) == '1101984451'].index[0]\n",
    "no_pair['SKU Clean'][index] = '1101984453'\n",
    "\n",
    "index = no_pair[no_pair['SKU'].astype(str) == '2104393210'].index[0]\n",
    "no_pair['SKU Clean'][index] = '2104392210'\n",
    "\n",
    "no_pair = no_pair.merge(SKU_baru.drop_duplicates('Product Code'), how = 'left', left_on = 'SKU Clean', right_on = 'Product Code')\n",
    "\n",
    "SKU_final = SKU_final.append(no_pair, ignore_index = True, sort = False)\n",
    "\n",
    "#ERROR EXPORTED PARENT ITEM - INPUT HERE\n",
    "data_all.loc[data_all['Exported Parent Item'].str.contains('Straw Milkshake', na = False, case = False),'Exported Parent Item']='HILO TEEN STRAWBERRY MILKSHAKE 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101569360'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'NS MODERN'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS JERUK PERAS REF 12DX500G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)1101569360'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'NS MODERN'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS JERUK PERAS REF 12DX500G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101686036','(E)1101686036'])].index[0]\n",
    "SKU_final['Category Baru'][index] = 'WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = \"W'DANK LKLT KOPI KAWISTA PLS 12RX10SX15G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin([\"(E)2104407\",'2104407'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS EXTRA VIRGIN OLIVE OIL 12BTLX500ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2305551106'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM CHOCO LATTE 6DX6SX33.5G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2305551106'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM CHOCO LATTE 6DX6SX33.5G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2305551106'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM CHOCO LATTE 6DX6SX33.5G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2LH1204172','(B)(R)2LH1204172'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PROTEIN BAR STRONGBERY 6SBX12SX20G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2304034180'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN GM MANGGA 6DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101976454'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS MARKISA PLS 4PX40SX11G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101927454'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS NANAS PLS 4PX40SX11G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101979454'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS MADU KURMA PLS 4PX40SX11G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(R)1101588453', '1101588453', '(B)(R)1101588453','(E)1101588453'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS MILKY ORANGE PLS 4PX40SX11G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101588016'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS MILKY ORANGE FC 72PX10SX11G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1102070454'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS LYCHEE TEA PLS 4PX40SX11G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1N03301456'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS LESS SUGAR BELIMBING PLS 4PX40SX6G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101987454'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS MANGGA GANDARIA PLS 4PX40SX11G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101452195'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ACTIVE CHOCOLATE 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101500195'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO GOLD PLAIN 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['2101524180','(E)2101524180'])].index[0]\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO GOLD BISCUIT CEREAL 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101524180'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO GOLD BISCUIT CEREAL 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101453195'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL CHOCOLATE 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101651195'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN CHOCOLATE 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2102546125'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SWT JAHE 24Dx50SX2.5G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(B)2102546125'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SWT JAHE 24Dx50SX2.5G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2102546125'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SWT JAHE 24Dx50SX2.5G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2304034180'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN GM MANGGA 6DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(R)1101989453', '1101989453', '(B)(R)1101989453'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS ES CINCAU PLS 4PX40SX13G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(R)1101954453', '1101954453', '(B)(R)1101954453'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS SEMANGKA PLS 4PX40SX13G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101954454'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS SEMANGKA PLS 4PX40SX11G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(R)1101927453', '1101927453', '(B)(R)1101927453','(E)1101927453'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS NANAS PLS 4PX40SX13G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101538453'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS ANGGUR HIJAU PLS 4PX40SX11G '\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104170104'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS WHITE COFFEE 12DX4SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101656318', '(B)1101656318', '(B)(R)1101656318','(E)1101656318'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI BERONDONG PLS 12RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(R)1101930453', '(B)(R)1101930453', '1101930453',\"(E)1101930453\"])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS COCOPANDAN PLS 4PX40SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['71210158', '(J)71110121'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET NUTRISARI 25 RASA'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(J)71110126'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET NUTRISARI 25 RASA FRESHSTART'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1102574110'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS MIX PAKET BALI 12Dx10S'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['71210165'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET KEHANGATAN WDANK'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['(E)2104170164','2104170164'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS WHITE COFFEE 12DX4SX20G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2309005300', '2309005305','(E)2309005300', '(E)2309005305'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PROTEIN CRUNCH BBQ BEEF 20BX20G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(E)1101688317','1101688317'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS W’DANK EMPON-EMPON PLS 12Rx10Sx12G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2306551173'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN BAR CRUNCHY CHOCOLATE 6SBX12SX22G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2306551173'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN BAR CRUNCHY CHOCOLATE 6SBX12SX22G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101813443'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ES TELER PLS 8RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2HH0813443'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HI LO DRINK TEH TARIK PLS 8RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2HH0817441'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HI LO DRINK CHOCO MALT 8RX10SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101813443'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ES TELER PLS 8RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101813036'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ES TELER FC 36PX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['2HH0816450'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HI LO DRINK CHOCO MINT PLS 15RX10SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['(E)2101864443','2101864443'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ES PISANG IJO PLS 8RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['(E)2101845360','2101845360'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ES KETAN HITAM REF 12BAGX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101845443'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ES KETAN HITAM PLS 8RX10SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101845443'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ES KETAN HITAM PLS 8RX10SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '71210166'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET LOKALATE UNTUK SOBATKU'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2304008180','(E)2304008180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN GAINMASS TARO 6DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2305551161'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM CHOCO LATTE 6DX6SX38.5G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2305507288',\"(E)2305507288\"])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM KACANG HIJAU 6KLRX800G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '71210163'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET HAMPERS IMLEK NUTRISARI'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104508105'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS KOREAN GARLIC BUTTER COOKIES 12DX5SX20G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['(E)2104148164','2104148164'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS MINT COCOA 12DX4SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104148024'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS MINT COCOA 12DX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2T00803164'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS ORANGE COCOA 12DX4SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2T00804164'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SALTED CARAMEL COCOA 12DX4SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104214210'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SAMBAL TERASI 24BTLX200G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2104214210'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SAMBAL TERASI 24BTLX200G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(E)2104115163','2104115163'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS AVOCADO COFFEE 12DX4SX20G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101609180','(E)2101609180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN TARO 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101445144','(E)2101445144'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ACTIVE KETAN HITAM 12DX175G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(E)2101485195','2101485195'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ACTIVE VANILLA 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2102526125'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SWT LEMONGRASS PANDAN 24DX50SX2G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104394210'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SAUS TIRAM 24BTLX200ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2305545288',\"(E)2305545288\"])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM KETAN HITAM 6KLRX800G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2106023014', '(B)2106023014',\"(E)2106023014\"])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SHIRATAKI NOODLES 40PX71G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2T03201001','(E)2T03201001'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS BUMBU KALDU AYAM JAMUR 24PX100G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2106323165','(E)2106323165'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS BUMBU SAUS TELUR ASIN 24Dx3Sx22G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110113'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET HILO'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET TAKJIL HILO DESSERT'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110110'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET TS'\n",
    "SKU_final['Unnamed: 3'][index] = 'HAMPER IDUL FITRI TS'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110129'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET TS'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET TS BEAT HYPERTENSION 2022'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110114'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET RAMADHAN NUTRISARI 2021'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101413144'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ACTIVE ES TELER 12DX175G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101413144'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ACTIVE ES TELER 12DX175G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110111'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET KEHANGATAN WDANK - RAMADHAN EDITION'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110115'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET TS'\n",
    "SKU_final['Unnamed: 3'][index] = 'GETPLUS HAMPERS IDUL FITRI TS'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2102584125'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SWT ROSE VANILLA 24DX50SX2G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101642180'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN POPCORN CARAMEL 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101642180'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN POPCORN CARAMEL 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101978454'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS MADU LEMON PLS 4PX40SX11G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1102611454'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS LEMON TEA PLS 4PX40SX11G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101543453'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS APEL JERUK PLS 4PX40SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(B) 2101656'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO RTD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN RTD COFFEE TIRAMISU 24PX200ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['2HH1409249','(B)2HH1409249'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO RTD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HI LO DRINK RTD CHOCOFIT 24TPKX190ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2HF1401250'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO RTD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL RTD VEGIBERI 24PX200ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101816250'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO RTD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO RTD VANILA COOKIES 24PX200ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101816250'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO RTD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO RTD VANILA COOKIES 24PX200ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2TA0102180'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS BIRU'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS GOLDENMIL VANILLA 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['2106386249','(E)2106386249'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS BIRU'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS RTD OAT DRINK VANILLICIOUS 24PX190ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['(E)2T01402249','2T01402249'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS BIRU'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS RTD ALMOND DRINK CHOCOLICIOUS 24TPKX190ML '\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2T01403249'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS BIRU'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS RTD OAT DRINK MELON 24TPKX190ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['(E)2105028180', '2105028180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS BIRU'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS LOW FAT MILK KOREAN STRAWBERRY 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104241210'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS MAYONNAISE ROASTED SESAME 24BTLX200G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2104241210'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS MAYONNAISE ROASTED SESAME 24BTLX200G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101996453',\"(E)1101996453\"])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS ES RUJAK JERUK BALI PLS 4PX40SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101982454'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS MADU JERUK PLS 4PX40SX11G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1N00838454'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS ISOTONIK REFRESHING CITRUS PLS 4PX40SX11G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2300542155'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN DAILY POPCORN CARAMEL 12DX250G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2LM0801029'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN ISOPOWER STARGIZING 6DX30SX7.8G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1102110453','(E)1102110453'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS NUTRI C1000 JERUK PLS 4PX40SX6G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110117'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'NUTRILOGI SERI MBA NANA SI PENUH PESONA'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110116'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'NUTRILOGI SERI MAS KAKA YANG BANYAK AKAL'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110119'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'NUTRILOGI SERI JEJE SI JELI'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1102560453'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'NUTRISARI 4 RASA SUMMER PACKAGE 40 SACHET'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1102561453'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'NUTRISARI 4 RASA LOCAL PACKAGE 40 SACHET'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2104543105','(E)2104543105'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS KOREAN GOGUMA COOKIES 12DX5SX20G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101651155'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN CHOCOLATE 12DX250G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110118'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET ORANGE ADVENTURE'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101578180'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO GOLD SWEET POTATO 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['(E)2101551195','2101551195'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO GOLD CHOCOLATE 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['(E)2101700166','2101700166'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO PLATINUM ORIGINAL 12DX12SX30G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101700037'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HI LO PLATINUM ORIGINAL 12DX5SX30G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2HG0103050'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HI LO PLATINUM +HMB Vanilla 12DX8SX42G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101710110'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO JOINT PLUS 12DX10SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101710110'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO JOINT PLUS 12DX10SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101693318'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI TAPE KETAN PLS 12RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)1101693318'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI TAPE KETAN PLS 12RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101694318'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI ANDALIMAN PLS 12RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101653318','(E)1101653318'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS W'DANK SARABBA EXTRA PLS 12RX10SX15G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101618318','(E)1101618318'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS W'DANK MADU TEMULAWAK PLS 12RX10SX11G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110120'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET LOKALATE #RASALOKAL'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101444180'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL STRAW CHEESECAKE 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101486195','(E)2101486195'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL VANILLA 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101487148', '(B)2101487148','(E)2101487148'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ALMOND MILK COCONUT 12DX200G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(E)2101469180','2101469180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO MULTIGRAIN ORIGINAL 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101683180', '(B)2101683180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN STRAWBERRY MILKSHAKE 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2304097159','2304097051'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLANTPROTEIN OGURA 6Dx216G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(E)2304097159'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLANTPROTEIN OGURA 12DX216G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2106395308','(E)2106395308'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SHIRATAKI RICE RASA NASI UDUK 24PX72G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2T02603203'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS BERAS MERAH ORGANIK 12PCHX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1102070350','(E)1102070350'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS MODERN'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS TEA LYCHEE TEA REF 12BAGX500G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1N00804229'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS MODERN'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS JERUK MANIS PITCHER 12BTLX300G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1100534034'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS MODERN'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS PREMIUM JUS MANGGA REF 12BAGX420G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101505453'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS JERUK NIPIS JAHE PLS 4PX40SX11G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(E)1102574110'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS MIX PAKET BALI 12Dx10S\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(E)1101505453'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS JERUK NIPIS JAHE PLS 4PX40SX11G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1N01402250','(E)1N01402250'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS RTD'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS RTD SQUEEZED ORANGE 24TPKX200ML\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101595453','(E)1101595453'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS ES KUWUD NIPIS PLS 4PX40SX11G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(E)1101591453','1101591453'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS GULA ASEM PLS 4PX40SX11G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2104589105','(B)2104589105', '(E)2104589105'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = \"TS COOKIES KLEPON 12DX5SX20G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2304515112'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = \"L-MEN LOSE WEIGHT AVOCADO COFFEE 6DX12SX25G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2LD0905181','(E)2LD0905181'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = \"L-MEN GAINMASS KLEPON LATTE 6DX500G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2LC0903181'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = \"L-MEN ADVANCE GOLD VANILLA 6DX500G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101453607','(E)2101453607'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = \"HILO SCHOOL CHOCOLATE 12DX250G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101459180','(E)2101459180','(B)2101459180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = \"HILO SCHOOL BUBBLE GUM 12DX500G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101478180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = \"HILO ACTIVE CARAMEL LATTE 12DX500G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(E)2101478180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = \"HILO ACTIVE CARAMEL LATTE 12DX500G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110124'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET TS'\n",
    "SKU_final['Unnamed: 3'][index] = 'PARSEL NATAL TAHUN BARU'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101479180'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL COTTON CANDY 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['(E)2HF1403250','2HF1403250'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO RTD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL RTD COTTON CANDY 24TPKX200ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101692318'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI PISANG BAKAR EPE PLS 12RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['(E)1101656360','1101656360'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI BERONDONG 12BAGX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['(E)1101685360','1101685360'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI ALPUKAT 12BAGX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['1NC1402055'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS LOKALATE RTD KOPI BRNDONG 24TPKX185ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)1101686036'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = \"W'DANK LKLT KOPI KAWISTA PLS 12RX10SX15G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101888360'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO KLEPON LATTE REF 12BAGX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['(E)2101847360','2101847360']) ].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO THAI TEA REF 12BAGX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['(E)2101819360', '2101819360'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TARO LATTE REF 12BAGX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101481118'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL CHOCOLATE CANDY 12SBX20SX8G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2106317152','(E)2106317152'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS INSTANT CAKE MIX BROWNIES 12Dx230G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(E)2305559288','2305559288'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM BUBBLE GUM 6KLRX800G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(E)2305584288','2305584288'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM VANILLA CARAMEL 6KLRX800G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2305551028'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM CHOCO LATTE REF 6DX800G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2304576112','(E)2304576112'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN LW MANGO STICKY RICE 6DX12SX25G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(E)2105055180','2105055180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS BIRU'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS LOW FAT MILK MACCHIATO COFFEE 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(E)2101618180','2101618180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN BISCUIT CARAMEL 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2154084141','(E)2154084141'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'DIABETAMIL'\n",
    "SKU_final['Unnamed: 3'][index] = 'DIABETAMIL MILK VANILLA 12Dx150G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2104119110','(E)2104119110'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SOY LATTE 12Dx10Sx15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(E)2T02703229','2T02703229'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS PEANUT ALMOND BUTTER 12BTLX300G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2T00806053','(B)2T00806053','(B)(R)2T00806053'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS 7 FRUITS FIBER DAILY 12DX12SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['(E)2T01812126','2T01812126'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SWT GULA AREN 24DX50SX2G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['2T01814125'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SWT GULA BUAH 24DX50SX2.5G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1102611360','(E)1102611360'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS MODERN'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS TEA LEMON TEA REF 12BAGX500G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2HH1407250','(E)2HH1407250'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO RTD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO DRINK RTD CHOC AVOCADO 24TPKX200ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)1101694318'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI ANDALIMAN PLS 12RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101888360'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO KLEPON LATTE REF 12BAGX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2102526125'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SWT LEMONGRASS PANDAN 24DX50SX2G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2102584125'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SWT ROSE VANILLA 24DX50SX2G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101983454'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS JERUK MAROKO PLS 4PX40SX11G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)1101543453'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS APEL JERUK PLS 4PX40SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1102611337'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS MODERN'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS LEMON TEA REF 12BAGX400G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1102611337'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS MODERN'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS LEMON TEA REF 12BAGX400G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101907335'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS FLORIDA ORANGE PLS 18PX40SX11G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101907017'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS FLORIDA ORANGE FC 72OX10SX11G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101930454'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS COCOPANDAN PLS 4PX40SX11G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1102070337'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS MODERN'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS LYCHEE TEA REF 12BAGX400G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101989454'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS ES CINCAU PLS 4PX40SX11G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101500195'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO GOLD PLAIN 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101444180'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL STRAW CHEESECAKE 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2104394210'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SAUS TIRAM 24BTLX200ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101651195'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN CHOCOLATE 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)1101694108'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI ANDALIMAN 12DX8SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2HF0111003'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HI LO SCHOOL STRAWBERRY PLS 12RX10SX27G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101686318','(E)1101686318'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI KAWISTA PLS 12RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101453195'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL CHOCOLATE 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['2HF0112021','(E)2HF0112021'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HI LO SCHOOL 3+ SOYA VANILLA MALT 12DX400G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2300542155'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN DAILY POPCORN CARAMEL 12DX250G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101578180'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO GOLD SWEET POTATO 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2104508105'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS KOREAN GARLIC BUTTER COOKIES 12DX5SX20G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)1101656108'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI BERONDONG 12Dx8Sx15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['(E)2104115110','2104115110'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS AVOCADO COFFEE 12DX10SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2T01705164'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS FRENCH BUTTER SOUFFLE COFFEE 12DX4SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2T01705024'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS FRENCH BUTTER SOUF COFFEE 12DX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['(E)2101479180','(B)2101479180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL COTTON CANDY 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['(E)2HF0113021','2HF0113021'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HI LO SCHOOL 3+ STRAWBERRY POP 12DX400G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2HF0114021'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HI LO SCHOOL ORIGINAL 12DX400G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2104393210'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SALTY SOY SAUCE 24BTLX200ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101452195'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ACTIVE CHOCOLATE 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2304515112'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN LOSE WEIGHT AVOCADO COFFEE 6DX12SX25G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2LG0906288'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM STRAWBERRRY 6KLRX800G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110130'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET TS'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET TROPICANA SLIM CHILL OUT KIT 2022'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2102000155'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SWT CLASSIC 12DX250G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2T01813126'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SWT LUO HAN GUO 24DX50SX2G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101683180'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN STRAWBERRY MILKSHAKE 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2HC0113021'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HI LO TEEN HiProtein Melon 12DX400G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2HC0109021'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HI LO TEEN ORIGINAL 12DX400G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['2HC0112021','2HC0110021'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HI LO TEEN Berries Club 12DX400G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['2101684195'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HI LO TEEN VANILLA CARAMEL 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110131'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET NUTRISARI 35 RASA'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110133'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET NUTRISARI VALENTINE 2023'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)1101692318'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI PISANG BAKAR EPE PLS 12RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['2LL1402249','(E)2LL1402249'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN RTD'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PROTEIN 2GO RTD OGURA 24TPKX190ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110143'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET L-MEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'GREEN PACKAGING L-MEN 2GO CHOCOLATE'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110141'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET TS'\n",
    "SKU_final['Unnamed: 3'][index] = 'GREEN PACKAGING OAT DRINK RTD'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110139'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET TS'\n",
    "SKU_final['Unnamed: 3'][index] = 'GREEN PACKAGING MINYAK KANOLA'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110144'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET HILO'\n",
    "SKU_final['Unnamed: 3'][index] = 'GREEN PACKAGING HILO SCHOOL CHOCOLATE RTD'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110145'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET HILO'\n",
    "SKU_final['Unnamed: 3'][index] = 'GREEN PACKAGING HILO TEEN CHOCOLATE RTD'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110142'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'GREEN PACKAGING NS SQUEEZED ORANGE RTD'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110134'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET LOKALATE'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET SOBAT MELEK SEGITIGA LOKALATE 2023'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110155'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET TS'\n",
    "SKU_final['Unnamed: 3'][index] = 'VB SSI - TS ALMOND DRINK CHOCOLICIOUS 4 PCS'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110154'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET TS'\n",
    "SKU_final['Unnamed: 3'][index] = 'VB SSI - TS OAT DRINK VANILICIOUS 4 PCS'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].isin(['(J)71110153','LN00000002'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET NUTRISARI 45 RASA 2023'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2T00805043'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS BIRU'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS COLLAGEN DRINK STRAWBERRY 12KLRX200G'\n",
    "\n",
    "SKU = SKU.merge(SKU_final[['SKU', 'Category Baru', 'Unnamed: 3']].drop_duplicates('SKU'), how = 'left', on = 'SKU')\n",
    "SKU = SKU.rename(columns = {'Unnamed: 3' : 'Exported Parent Item'})\n",
    "\n",
    "index = data_all[data_all['Real SKU'] == '2101492P24'].index.to_list()\n",
    "data_all['Brand'][index] = 'Bundle'\n",
    "index = data_all[data_all['SKU'].isin(['71210111', '71210112'])].index.to_list()\n",
    "data_all['Brand'][index] = 'Bundle'\n",
    "index = data_all[data_all['Real SKU'] == '2306592173'].index.to_list()\n",
    "data_all['Brand'][index] = 'L-Men'\n",
    "indeks = data_all[data_all['Brand'] == 'TS'][data_all[data_all['Brand'] == 'TS']['Real SKU'].astype(str) == '2101453180'].index.to_list()\n",
    "data_all['Real SKU'][indeks] = data_all['SKU'][indeks]\n",
    "data_all['Parent Item'][indeks] = 'Tropicana Slim Milk Low Fat Vanilla 500gr'\n",
    "\n",
    "index = data_all[data_all['Brand'].isin(['NS']) & data_all['Sub Brand'].str.contains('WDANK', case = False, na = False)].index.to_list()\n",
    "data_all['Brand'][index] = 'WDANK'\n",
    "\n",
    "index = data_all[data_all['Brand'] == \"W'dank\"].index.to_list()\n",
    "data_all['Brand'][index] = 'WDANK'\n",
    "\n",
    "data_all['Real SKU'] = data_all['Real SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "no_name = data_all[data_all['Exported Parent Item'].isnull()]\n",
    "no_name = no_name.merge(SKU[['SKU', 'Category Baru', 'Exported Parent Item']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(no_name.index)\n",
    "\n",
    "data_all['Category Baru'][no_name.index] = no_name['Category Baru_y']\n",
    "data_all['Exported Parent Item'][no_name.index] = no_name['Exported Parent Item_y']\n",
    "\n",
    "data_SKU = SKU.copy()\n",
    "data_SKU['Category Baru'] = data_SKU['Category Baru'].fillna(data_SKU['Sub Brand'])\n",
    "data_SKU['Category Baru'] = data_SKU['Category Baru'].fillna(data_SKU['Brand'])\n",
    "data_SKU['Sub Brand'] = data_SKU['Category Baru']\n",
    "data_all['Sub Brand'] = data_all['Category Baru']\n",
    "\n",
    "index = data_all[data_all['Real SKU'].astype(str) == '2102000155'].index.to_list()\n",
    "data_all['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "data_all['Exported Parent Item'][index] = 'TS SWT CLASSIC 12DX250G'\n",
    "\n",
    "index = data_all[data_all['Real SKU'].astype(str) == '2153000314'].index.to_list()\n",
    "data_all['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "\n",
    "index = data_all[data_all['Real SKU'].astype(str) == '2304097159'].index.to_list()\n",
    "data_all['Category Baru'][index] = 'L-MEN POWDER'\n",
    "data_all['Sub Brand'][index] = 'L-MEN POWDER'\n",
    "\n",
    "index = data_all[data_all['Real SKU'].astype(str) == '2101651155'].index.to_list()\n",
    "data_all['Category Baru'][index] = 'HILO TEEN'\n",
    "data_all['Exported Parent Item'][index] = 'HILO TEEN CHOCOLATE 12DX250G'\n",
    "\n",
    "temp = data_all.copy()\n",
    "no_name['Real SKU'] = no_name['Real SKU'].astype(str).str.replace('(S)','',regex = False).str.replace('.0','',regex = False)\n",
    "data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('(S)','',regex = False).str.replace('.0','',regex = False)\n",
    "data_all['Sub Brand'][no_name.index] = no_name.merge(data_SKU[['SKU', 'Sub Brand']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(no_name.index)['Sub Brand_y']\n",
    "\n",
    "index = data_all[data_all['Real Nama Produk'].isin(['NS FLORIDA ORANGE FC 72OX10SX11G'])].index.to_list()\n",
    "data_all['Sub Brand'][index] = 'NS TRADITIONAL'\n",
    "\n",
    "index = data_all[data_all['Brand'] == \"WDANK\"].index.to_list()\n",
    "data_all['Sub Brand'][index] = 'WDANK'\n",
    "\n",
    "print('Filter Status')\n",
    "index = data_all[data_all['Customer Name'] == 'Shopee Brand Portal'].index.to_list()\n",
    "data_all['Order Status'][index] = 'Delivered'\n",
    "osf=pd.read_excel(r\"data_supp\\order filter.xlsx\")\n",
    "data_success =data_all[data_all['Order Status'].isin(osf['order filter'].unique()) & (~data_all['Store'].isin(['Orami Shopping']))]\n",
    "\n",
    "# data_success =data_all[data_all['Order Status'].isin([\n",
    "#         '\"Delivered\"', '\"Ready to Ship\"', '\"Open\"', '\"Printed\"',\n",
    "#        '\"Shipped\"', '\"Delivered, Shipped\"', '\"Shipped, Ready to Ship\"',\n",
    "#        '\"Shipped, Delivered\"', '\"Ready to Ship, Delivered\"',\n",
    "#        '\"Ready to Ship, Shipped\"', '\"Delivered, Ready to Ship\"',\n",
    "#        '\"Delivered, Open\"', '\"Open, Delivered\"', 'Delivered',\n",
    "#        '\"Ready to Ship, Open\"', '\"Shipped, Open\"','complete', 'payment_confirmed',\n",
    "#        'completed_to_wms', 'processing', \n",
    "#        'ready_to_ship', \n",
    "#        '\"Open, Ready to Ship\"', '\"Open, Shipped, Ready to Ship\"',\n",
    "#        'Sudah Settlement', '\"Delivered, Shipped, Ready to Ship\"',\n",
    "#        '\"Ready to Ship, Shipped, Delivered\"',\n",
    "#        '\"Ready to Ship, Delivered, Shipped\"', '\"Open, Shipped\"',\n",
    "#        '\"Printed, Open\"', '\"Shipped, Printed\"', '\"Delivered, Printed\"',\n",
    "#        '\"Open, Printed\"', '\"Printed, Shipped\"', '\"Printed, Delivered\"',\n",
    "#        '\"Open, Delivered, Printed\"', '\"Open, Shipped, Printed\"',\n",
    "#        '\"Shipped, Open, Printed\"', '\"Ready to Ship, Printed\"',\n",
    "#        '\"Printed, Delivered, Open\"', '\"Delivered, Printed, Shipped\"',\n",
    "#        '\"Printed, Shipped, Open\"', '\"Delivered, Shipped, Open\"',\n",
    "#        '\"Shipped, Open, Ready to Ship\"',\n",
    "#        '\"Delivered, Open, Ready to Ship\"', \n",
    "#        '\"Ready to Ship, Open, Shipped\"', \n",
    "#        'Sudah Isi Pickup Time', '\"Shipped, Ready to Ship, Open\"',\n",
    "#        '\"Payout\"',  '\"Printed, Ready to Ship\"',\n",
    "#        'Ready to Ship', 'Open',\n",
    "#        'Shipped', 'Delivered, Shipped', \n",
    "#        'Delivered, Open', 'Printed', 'cod_sent',\n",
    "#        'entri_verified', 'incoming', 'completed', 'Open, Ready to Ship',\n",
    "#        'Open, Shipped', 'Ready to Ship, Shipped', 'completed_with_awb','Packed','Shipped','Delivered','Ready to Ship','Completed',\n",
    "#        '\"Return Waiting for Approval\"', '\"Return\"', 'bt_payment_review',\n",
    "#        'closed', 'Order Baru', 'ready_to_cod', 'Pesanan Dikirim',\n",
    "#        'Pesanan Dikomplain', 'Pesanan Selesai', 'Pesanan Tiba',\n",
    "#        'Resi Diubah', 'Pesanan Baru', 'Selesai'\n",
    "#     ])]\n",
    "\n",
    "\n",
    "all_single = data_success[data_success['Brand'].isin(['NS', 'TS', 'L-Men', 'HiLo','WDANK'])]\n",
    "all_single = all_single[all_single['Exported Parent Item'] != \"W'DANK LKLT KOPI DURIAN PLS 12RX10SX15G\"]\n",
    "\n",
    "index = all_single[all_single['Brand'] == \"WDANK\"].index.to_list()\n",
    "all_single['Brand'][index] = 'NS'\n",
    "\n",
    "all_single = all_single[~all_single['Store'].isin(['ECOM RETAIL - JD ID','MITRA TOKOPEDIA','ECOM RETAIL - SHOPEE'])]\n",
    "indeks = all_single[all_single['Store'].isin(['CARI SAYUR',  'EMOS', 'INOVASI DIGITAL NIAGA - KALIDERES, PT',\n",
    "                                              'RITEL BERSAMA NASIONAL; PT', 'SAYUR BOX', 'TANIHUB'])].index.to_list()\n",
    "all_single['Exported Parent Item'][indeks] = all_single['Product Name'][indeks]\n",
    "\n",
    "indeks = all_single[(all_single['Store'].isin(['CARI SAYUR',  'EMOS', 'INOVASI DIGITAL NIAGA - KALIDERES, PT',\n",
    "       'RITEL BERSAMA NASIONAL; PT', 'SAYUR BOX', 'TANIHUB']))&\n",
    "                   (all_single['Sub Brand'].isnull())].index.to_list()\n",
    "all_single['Sub Brand'][indeks] = all_single['Category'][indeks]\n",
    "\n",
    "all_single['Total Net'] = all_single['Total Net'].astype(float).astype('int64')\n",
    "\n",
    "bundle_name = data_all[data_all['Real SKU'] == 'PN50N86N87N89G162']['Product Name'].unique()\n",
    "bundle_name = list(bundle_name) + ['NutriSari Orange Adventure (5 x 10 Sch)','NutriSari Bundle - Orange Adventure']\n",
    "indeks = all_single[all_single['Bundle Name'].astype(str).isin(bundle_name)].index.to_list()\n",
    "all_single['Brand'][indeks] = 'NS'\n",
    "all_single['Sub Brand'][indeks] = 'PAKET NUTRISARI'\n",
    "all_single['Exported Parent Item'][indeks] = 'PAKET ORANGE ADVENTURE'\n",
    "\n",
    "all_single['Exported Parent Item'] = all_single['Exported Parent Item'].astype(str).str.replace('TS SHIRATAKI NOODLES 40Px71G', 'TS SHIRATAKI NOODLES 40PX71G')\n",
    "all_single['Exported Parent Item'] = all_single['Exported Parent Item'].astype(str).str.replace('TS KOREAN GARLIC BUTTERCOOKIES12DX5SX20G', 'TS KOREAN GARLIC BUTTER COOKIES 12DX5SX20G')\n",
    "all_single['Exported Parent Item'] = all_single['Exported Parent Item'].astype(str).str.replace('TS WHITE COFFEE 12DX4SX20G', 'TS WHITE COFFEE 12DX4SX15G')\n",
    "all_single['Exported Parent Item'] = all_single['Exported Parent Item'].astype(str).str.replace('TS AVOCADO COFFEE 12DX4SX20G', 'TS AVOCADO COFFEE 12DX4SX14G')\n",
    "\n",
    "all_single.loc[all_single['Real SKU'] == '2152051','Exported Parent Item']='TS DM COOKIES CHOCO 12DX10SX20G'#[['Year','Month','Brand','Store','Sub Brand','Real SKU','Real Nama Produk','Bundle Name']]#.drop_duplicates()\n",
    "all_single.loc[all_single['Real SKU'] == '1101907017','Exported Parent Item']='NS FLORIDA ORANGE FC 72OX10SX11G'#[['Year','Month','Brand','Store','Sub Brand','Real SKU','Real Nama Produk','Bundle Name']]#.drop_duplicates()\n",
    "\n",
    "all_single.loc[all_single['Real SKU'] == '2152051','Sub Brand']='TS KUNING OTHERS'\n",
    "all_single=all_single[all_single['Real SKU']!=\"(U)1102101155\"]\n",
    "all_single=all_single[all_single['Real SKU']!=\"(U)2307061250\"]\n",
    "all_single=all_single[all_single['Real SKU']!=\"(B)2T01705164\"]\n",
    "all_single.loc[all_single['Order #']=='1000103864','Region Group']='Kab. Bogor'\n",
    "\n",
    "zipnotmapped=all_single[(all_single['Region Group'].isnull())&(all_single['Store Type']=='Marketplace')&(all_single['Year']==2022)&(all_single['Zip Code'].notnull())]['Zip Code'].unique()#.to_excel('Gk ke mapping.xlsx',index=False)\n",
    "for i in zipnotmapped:\n",
    "    regionvalue=all_single[(all_single['Zip Code']==i)&(all_single['Region Group'].notnull())]['Region Group'].unique()[0]\n",
    "    all_single.loc[(all_single['Region Group'].isnull())&(all_single['Region Group'].isnull())&(all_single['Store Type']=='Marketplace')&(all_single['Year']==2022),'Region Group']=regionvalue\n",
    "\n",
    "\n",
    "indeks = all_single[all_single['Exported Parent Item'].isnull()].index.to_list()\n",
    "indeks = indeks + all_single[all_single['Exported Parent Item'] == 'nan'].index.to_list()\n",
    "\n",
    "if len(indeks) == 0:\n",
    "    print(\"Prepare E-mailing\")\n",
    "    \n",
    "    ########################################################\n",
    "    \n",
    "    table_brand = all_single[all_single['Store']=='Order Online'][['Brand','Sub Brand']].drop_duplicates().reset_index(drop = True)\n",
    "    all_single['True datetime'] = pd.to_datetime(all_single['True datetime'])\n",
    "    from datetime import datetime, timedelta\n",
    "    today = datetime.today()\n",
    "    yesterday = datetime.today() - timedelta(days=1)\n",
    "    today = pd.to_datetime(today.strftime('%Y-%m-%d'))\n",
    "    yesterday = pd.to_datetime(yesterday.strftime('%Y-%m-%d'))\n",
    "    yesterday_sales = all_single[all_single['Store']=='Order Online'][all_single['True datetime'] >= yesterday][all_single[all_single['True datetime'] >= yesterday]['True datetime']<today]\n",
    "    yesterday_sales = yesterday_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "    yesterday_sales['Total Net'] = yesterday_sales['Total Net']/1.1\n",
    "    yesterday_sales = yesterday_sales.rename(columns = {'Total Net' : 'Yesterday Sales'})\n",
    "    table_brand = table_brand.merge(yesterday_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "    if int(today.strftime('%d')) > 1 :\n",
    "        mtd_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)\n",
    "        mtd_date = pd.to_datetime(mtd_date.strftime('%Y-%m-%d'))\n",
    "    else :\n",
    "        mtd_date = datetime.today()-timedelta(days=int(yesterday.strftime('%d')))\n",
    "        mtd_date = pd.to_datetime(mtd_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "    mtd_sales = all_single[all_single['Store']=='Order Online'][all_single['True datetime'] >= mtd_date][all_single[all_single['True datetime'] >= mtd_date]['True datetime']<today]\n",
    "    mtd_sales = mtd_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "    mtd_sales['Total Net'] = mtd_sales['Total Net']/1.1\n",
    "    mtd_sales = mtd_sales.rename(columns = {'Total Net' : 'Local Sales'})\n",
    "    table_brand = table_brand.merge(mtd_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "    from calendar import monthrange\n",
    "\n",
    "\n",
    "    if int(today.strftime('%d')) > 1 :\n",
    "        table_brand['Average This Month'] = table_brand['Local Sales']/(int(today.strftime('%d'))-1)\n",
    "        number_of_days = monthrange(today.year, today.month)[1]\n",
    "    else :\n",
    "        table_brand['Average This Month'] = table_brand['Local Sales']/(int(yesterday.strftime('%d')))\n",
    "        number_of_days = monthrange(yesterday.year, yesterday.month)[1]\n",
    "\n",
    "    table_brand['Projected'] = table_brand['Average This Month'] * number_of_days\n",
    "\n",
    "    from dateutil import rrule\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "\n",
    "    start_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)-relativedelta(months=3)\n",
    "    start_date = pd.to_datetime(start_date.strftime('%Y-%m-%d'))\n",
    "    end_date = datetime.today()-timedelta(days=int(today.strftime('%d')))\n",
    "    for dt in rrule.rrule(rrule.MONTHLY, dtstart=start_date, until=end_date):\n",
    "        first_date = pd.to_datetime(dt)\n",
    "        print(\"First Date \" + str(first_date))\n",
    "        last_date = first_date + relativedelta(months=1)\n",
    "        print(\"Last Date \" + str(last_date))\n",
    "        temp_sales = all_single[all_single['Store']=='Order Online'][all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n",
    "        temp_sales = temp_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "        temp_sales['Total Net'] = temp_sales['Total Net']/1.1\n",
    "        colname = str(first_date.month_name()) + ' ' + str(first_date.year)\n",
    "        temp_sales = temp_sales.rename(columns = {'Total Net' : colname})\n",
    "        table_brand = table_brand.merge(temp_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "    cols = list(table_brand)\n",
    "    cols[len(cols)-1], cols[len(cols)-3] = cols[len(cols)-3], cols[len(cols)-1]\n",
    "    table_brand = table_brand.loc[:,cols]\n",
    "    table_brand = table_brand.reset_index(drop = True)\n",
    "    table_brand = table_brand.drop('Average This Month', axis = 1)\n",
    "\n",
    "    def highlight_max(x):\n",
    "        return ['font-weight: bold' if v == x.loc[x.index.max()] else ''\n",
    "                    for v in x]\n",
    "\n",
    "    #     table_brand = table_brand[table_brand['Local Sales'].notnull()]\n",
    "    table_brand['Yesterday Sales'] = table_brand['Yesterday Sales'].fillna(0).astype('int64')\n",
    "    table_brand['Local Sales'] = table_brand['Local Sales'].fillna(0).astype('int64')\n",
    "    table_brand = table_brand.sort_values(['Brand','Local Sales'], ascending = [True, False])\n",
    "\n",
    "    table_ecom = table_brand.copy()\n",
    "\n",
    "    for i in table_ecom.columns[2:]:\n",
    "        table_ecom[i] = table_ecom[i].fillna(0).astype('int64')\n",
    "\n",
    "    table_ecom = table_ecom.append(table_ecom.sum(numeric_only=True), ignore_index=True)\n",
    "    # for i in table_ecom.columns[2:]:\n",
    "    #     table_ecom[i] = table_ecom[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "    #     table_ecom[i][table_ecom.index.max()] = \"<b> {} </b>\".format(table_ecom[i][table_ecom.index.max()])\n",
    "\n",
    "    table_ecom = table_ecom.drop('Brand', axis = 1)\n",
    "    table_ecom['Sub Brand'][table_ecom.index.max()] = '<b>Total E-Commerce (NHD) Sales<b>'\n",
    "    table_ecom = table_ecom.rename(columns = {'Sub Brand' : ''})\n",
    "\n",
    "    table_ecom2 = table_ecom.iloc[[-1]].reset_index(drop = True)\n",
    "\n",
    "    ###############################################################\n",
    "\n",
    "    table_brand = all_single[all_single['Store']!='Order Online'][['Brand','Sub Brand']].drop_duplicates().reset_index(drop = True)\n",
    "    all_single['True datetime'] = pd.to_datetime(all_single['True datetime'])\n",
    "\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    today = datetime.today()\n",
    "    yesterday = datetime.today() - timedelta(days=1)\n",
    "\n",
    "    today = pd.to_datetime(today.strftime('%Y-%m-%d'))\n",
    "    yesterday = pd.to_datetime(yesterday.strftime('%Y-%m-%d'))\n",
    "\n",
    "    yesterday_sales = all_single[all_single['Store']!='Order Online'][all_single['True datetime'] >= yesterday][all_single[all_single['True datetime'] >= yesterday]['True datetime']<today]\n",
    "    yesterday_sales = yesterday_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "    yesterday_sales['Total Net'] = yesterday_sales['Total Net']/1.1\n",
    "    yesterday_sales = yesterday_sales.rename(columns = {'Total Net' : 'Yesterday Sales'})\n",
    "    table_brand = table_brand.merge(yesterday_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "    if int(today.strftime('%d')) > 1 :\n",
    "        mtd_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)\n",
    "        mtd_date = pd.to_datetime(mtd_date.strftime('%Y-%m-%d'))\n",
    "    else :\n",
    "        mtd_date = datetime.today()-timedelta(days=int(yesterday.strftime('%d')))\n",
    "        mtd_date = pd.to_datetime(mtd_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "    mtd_sales = all_single[all_single['Store']!='Order Online'][all_single['True datetime'] >= mtd_date][all_single[all_single['True datetime'] >= mtd_date]['True datetime']<today]\n",
    "    mtd_sales = mtd_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "    mtd_sales['Total Net'] = mtd_sales['Total Net']/1.1\n",
    "    mtd_sales = mtd_sales.rename(columns = {'Total Net' : 'Local Sales'})\n",
    "    table_brand = table_brand.merge(mtd_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "    from calendar import monthrange\n",
    "\n",
    "\n",
    "    if int(today.strftime('%d')) > 1 :\n",
    "        table_brand['Average This Month'] = table_brand['Local Sales']/(int(today.strftime('%d'))-1)\n",
    "        number_of_days = monthrange(today.year, today.month)[1]\n",
    "    else :\n",
    "        table_brand['Average This Month'] = table_brand['Local Sales']/(int(yesterday.strftime('%d')))\n",
    "        number_of_days = monthrange(yesterday.year, yesterday.month)[1]\n",
    "\n",
    "    table_brand['Projected'] = table_brand['Average This Month'] * number_of_days\n",
    "\n",
    "    from dateutil import rrule\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "\n",
    "    start_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)-relativedelta(months=3)\n",
    "    start_date = pd.to_datetime(start_date.strftime('%Y-%m-%d'))\n",
    "    end_date = datetime.today()-timedelta(days=int(today.strftime('%d')))\n",
    "    for dt in rrule.rrule(rrule.MONTHLY, dtstart=start_date, until=end_date):\n",
    "        first_date = pd.to_datetime(dt)\n",
    "        print(\"First Date \" + str(first_date))\n",
    "        last_date = first_date + relativedelta(months=1)\n",
    "        print(\"Last Date \" + str(last_date))\n",
    "        temp_sales = all_single[all_single['Store']!='Order Online'][all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n",
    "        temp_sales = temp_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "        temp_sales['Total Net'] = temp_sales['Total Net']/1.1\n",
    "        colname = str(first_date.month_name()) + ' ' + str(first_date.year)\n",
    "        temp_sales = temp_sales.rename(columns = {'Total Net' : colname})\n",
    "        table_brand = table_brand.merge(temp_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "    cols = list(table_brand)\n",
    "    cols[len(cols)-1], cols[len(cols)-3] = cols[len(cols)-3], cols[len(cols)-1]\n",
    "    table_brand = table_brand.loc[:,cols]\n",
    "    table_brand = table_brand.reset_index(drop = True)\n",
    "    table_brand = table_brand.drop('Average This Month', axis = 1)\n",
    "\n",
    "    def highlight_max(x):\n",
    "        return ['font-weight: bold' if v == x.loc[x.index.max()] else ''\n",
    "                    for v in x]\n",
    "\n",
    "    #     table_brand = table_brand[table_brand['Local Sales'].notnull()]\n",
    "    table_brand['Yesterday Sales'] = table_brand['Yesterday Sales'].fillna(0).astype('int64')\n",
    "    table_brand['Local Sales'] = table_brand['Local Sales'].fillna(0).astype('int64')\n",
    "    table_brand = table_brand.sort_values(['Brand','Local Sales'], ascending = [True, False])\n",
    "\n",
    "    table_ecom = table_brand.copy()\n",
    "\n",
    "    for i in table_ecom.columns[2:]:\n",
    "        table_ecom[i] = table_ecom[i].fillna(0).astype('int64')\n",
    "\n",
    "    table_ecom = table_ecom.append(table_ecom.sum(numeric_only=True), ignore_index=True)\n",
    "    # for i in table_ecom.columns[2:]:\n",
    "    #     table_ecom[i] = table_ecom[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "    #     table_ecom[i][table_ecom.index.max()] = \"<b> {} </b>\".format(table_ecom[i][table_ecom.index.max()])\n",
    "\n",
    "    table_ecom = table_ecom.drop('Brand', axis = 1)\n",
    "    table_ecom['Sub Brand'][table_ecom.index.max()] = '<b>Total E-Commerce (Non NHD) Sales</b>'\n",
    "    table_ecom = table_ecom.rename(columns = {'Sub Brand' : ''})\n",
    "\n",
    "    table_ecom1 = table_ecom.iloc[[-1]].reset_index(drop = True)\n",
    "    # table_ecom=table_ecom1.append(table_ecom2,ignore_index=True,sort=False)\n",
    "    # table_ecom=table_ecom.append(table_ecom.sum(numeric_only=True), ignore_index=True,sort=False)\n",
    "\n",
    "    table_ecom=table_ecom1.append(table_ecom2,ignore_index=True,sort=False)\n",
    "    table_ecom=table_ecom.append(table_ecom.sum(numeric_only=True), ignore_index=True)\n",
    "    table_ecom.loc[(table_ecom[\"\"].isnull()),\"\"]='<b>Total E-Commerce Sales</b>'\n",
    "    table_ecom\n",
    "\n",
    "    for i in table_ecom.columns[1:]:\n",
    "        table_ecom[i] = table_ecom[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        table_ecom[i][table_ecom.index.max()] = \"<b> {} </b>\".format(table_ecom[i][table_ecom.index.max()])\n",
    "\n",
    "    ###############################################################\n",
    "    from datetime import date\n",
    "    sales_total=all_single.groupby(['Year','Month','True datetime','Store'],dropna=False)[['Total Net']].sum().reset_index()\n",
    "    sales_total.loc[sales_total['Store']=='Order Online','Store Group']='<b>Total Ecommerce (NHD) Sales</b>'\n",
    "    sales_total.loc[sales_total['Store']!='Order Online','Store Group']='<b>Total Ecommerce (non NHD) Sales</b>'\n",
    "\n",
    "    sales_total['Total Net Before PPN']=sales_total['Total Net']/1.1\n",
    "    sales_total.loc[sales_total['True datetime']>='2022-04-01','Total Net Before PPN']=sales_total['Total Net']/1.11\n",
    "\n",
    "    sales_total['Date']=pd.to_datetime(sales_total['True datetime']).dt.date\n",
    "\n",
    "    col1=sales_total[(sales_total['Date']>=(date.today()-timedelta(1)))&\n",
    "                        (sales_total['Date']<(date.today()))].groupby(['Store Group'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':'Yesterday Sales'}))\n",
    "\n",
    "    if '<b>Total Ecommerce (NHD) Sales</b>' not in col1['Store Group'].unique():\n",
    "        col1=col1.append(pd.DataFrame({'Store Group': [\"<b>Total Ecommerce (NHD) Sales</b>\"], 'Yesterday Sales': [0]}))\n",
    "\n",
    "    col2=sales_total[(sales_total['Year']==(datetime.now()-timedelta(1)).year)&\n",
    "                         (sales_total['Month']==(datetime.now()-timedelta(1)).strftime(\"%B\"))&\n",
    "                         (sales_total['Date']<(date.today()))].groupby(['Store Group'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':'Local Sales'}))\n",
    "    lastmonth1=(date.today().replace(day=1)-timedelta(1))#.strftime(\"%B\")\n",
    "    lastmonth2=(lastmonth1.replace(day=1)-timedelta(1))#.strftime(\"%B\")\n",
    "    lastmonth3=(lastmonth2.replace(day=1)-timedelta(1))\n",
    "    col3=col2.copy()\n",
    "    maxday=monthrange((datetime.now()-timedelta(1)).year, (datetime.now()-timedelta(1)).month)[1]\n",
    "    col3['Projected']=col3['Local Sales']*maxday/((datetime.now()-timedelta(1)).day)\n",
    "\n",
    "    col4=sales_total[(sales_total['Year']==lastmonth1.year)&\n",
    "                 (sales_total['Month']==lastmonth1.strftime(\"%B\"))].groupby(['Store Group'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':f'{lastmonth1.strftime(\"%B\")} {lastmonth1.year}'}))\n",
    "    col5=sales_total[(sales_total['Year']==lastmonth2.year)&\n",
    "                 (sales_total['Month']==lastmonth2.strftime(\"%B\"))].groupby(['Store Group'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':f'{lastmonth2.strftime(\"%B\")} {lastmonth2.year}'}))\n",
    "    col6=sales_total[(sales_total['Year']==lastmonth3.year)&\n",
    "                 (sales_total['Month']==lastmonth3.strftime(\"%B\"))].groupby(['Store Group'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':f'{lastmonth3.strftime(\"%B\")} {lastmonth3.year}'}))\n",
    "    tblall=col1.merge(col2,how='left').merge(col3,how='left').merge(col4,how='left').merge(col5,how='left').merge(col6,how='left')\n",
    "    tblall=tblall.fillna(int(0))\n",
    "    tblall=tblall.sort_values('Store Group',ascending=False).reset_index(drop=True)\n",
    "\n",
    "    total_row=tblall.sum(numeric_only=True)\n",
    "\n",
    "    tblall=tblall.append(total_row,ignore_index=True)\n",
    "    tblall.loc[tblall['Store Group'].isnull(),'Store Group']='<b>Total Ecommerce Sales</b>'\n",
    "    tblall.rename(columns={'Store Group':\"\"})\n",
    "    for i in tblall.columns[1:]:\n",
    "        tblall[i] = tblall[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        tblall[i][tblall.index.max()] = \"<b> {} </b>\".format(tblall[i][tblall.index.max()])\n",
    "\n",
    "    tblall = tblall[tblall['Store Group'].isin(['<b>Total Ecommerce Sales</b>'])]   \n",
    "    \n",
    "    \n",
    "    ###############################################################\n",
    "    sales_region=all_single.groupby(['Year','Month','True datetime','Region Group'],dropna=False)[['Total Net']].sum().reset_index()\n",
    "    mappingarea=pd.read_excel(\"data_supp\\Database Area untuk Report.xlsx\")\n",
    "    mappingarea=mappingarea.rename(columns=({'Region':'Real Region',\"City\":'Region Group'}))\n",
    "    sales_region=sales_region.merge(mappingarea,how='left')\n",
    "    sales_region.loc[sales_region['Region Group'].isnull(),'Real Region']='Retail Online'\n",
    "    \n",
    "    \n",
    "    sales_region['Total Net Before PPN']=sales_region['Total Net']/1.1\n",
    "    sales_region.loc[sales_region['True datetime']>='2022-04-01','Total Net Before PPN']=sales_region['Total Net']/1.11\n",
    "    sales_region['Date']=pd.to_datetime(sales_region['True datetime']).dt.date\n",
    "\n",
    "    tblreg=sales_region[(sales_region['Date']>=(date.today()-timedelta(1)))&\n",
    "                        (sales_region['Date']<(date.today()))].groupby(['Real Region'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':'Yesterday Sales'}))\n",
    "    no_ytd_sales=mappingarea[~mappingarea['Real Region'].isin(tblreg['Real Region'].unique())]['Real Region'].unique()\n",
    "    for i in no_ytd_sales:\n",
    "        tblreg=tblreg.append(pd.DataFrame({'Real Region': [f\"{i}\"], 'Yesterday Sales': [0]}))\n",
    "        tblreg=tblreg.sort_values('Real Region')    \n",
    "    if 'Retail Online' not in tblreg['Real Region'].unique():\n",
    "        tblreg=tblreg.append(pd.DataFrame({'Real Region': [\"Retail Online\"], 'Yesterday Sales': [0]}))\n",
    "\n",
    "    tblreg2=sales_region[(sales_region['Year']==(datetime.now()-timedelta(1)).year)&\n",
    "                         (sales_region['Month']==(datetime.now()-timedelta(1)).strftime(\"%B\"))&\n",
    "                         (sales_region['Date']<(date.today()))].groupby(['Real Region'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':'Local Sales'}))\n",
    "    lastmonth1=(date.today().replace(day=1)-timedelta(1))#.strftime(\"%B\")\n",
    "    lastmonth2=(lastmonth1.replace(day=1)-timedelta(1))#.strftime(\"%B\")\n",
    "    lastmonth3=(lastmonth2.replace(day=1)-timedelta(1))\n",
    "    tblreg3=tblreg2.copy()\n",
    "    maxday=monthrange((datetime.now()-timedelta(1)).year, (datetime.now()-timedelta(1)).month)[1]\n",
    "    tblreg3['Projected']=tblreg3['Local Sales']*maxday/((datetime.now()-timedelta(1)).day)\n",
    "\n",
    "    tblregshopee=tblreg3[tblreg3[\"Real Region\"]=='Retail Online']\n",
    "    tblreg3=tblreg3[tblreg3[\"Real Region\"]!='Retail Online']#.copy()\n",
    "\n",
    "    totprj=tblreg3[tblreg3[\"Real Region\"]!='Retail Online']['Projected'].sum()\n",
    "    tblreg3['Projected %']=tblreg3['Projected']/totprj\n",
    "    tblreg3=tblreg3.append(tblregshopee)\n",
    "\n",
    "    tblreg3=tblreg3[['Real Region','Projected','Projected %']]\n",
    "    tblreg4=sales_region[(sales_region['Year']==lastmonth1.year)&\n",
    "                 (sales_region['Month']==lastmonth1.strftime(\"%B\"))].groupby(['Real Region'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':f'{lastmonth1.strftime(\"%B\")} {lastmonth1.year}'}))\n",
    "    tblreg5=sales_region[(sales_region['Year']==lastmonth2.year)&\n",
    "                 (sales_region['Month']==lastmonth2.strftime(\"%B\"))].groupby(['Real Region'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':f'{lastmonth2.strftime(\"%B\")} {lastmonth2.year}'}))\n",
    "    tblreg6=sales_region[(sales_region['Year']==lastmonth3.year)&\n",
    "                 (sales_region['Month']==lastmonth3.strftime(\"%B\"))].groupby(['Real Region'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':f'{lastmonth3.strftime(\"%B\")} {lastmonth3.year}'}))\n",
    "    tblreg=tblreg.merge(tblreg2,how='left').merge(tblreg3,how='left').merge(tblreg4,how='left').merge(tblreg5,how='left').merge(tblreg6,how='left')\n",
    "    tblreg=tblreg.rename(columns={'Real Region':'Region'})\n",
    "\n",
    "    total_row=tblreg.sum(numeric_only=True)\n",
    "    sub_total_row=tblreg[tblreg[\"Region\"]!='Retail Online'].sum(numeric_only=True)\n",
    "    # tblreg.loc[(tblreg[\"Region\"].isnull()),\"Region\"]='<b>Total Sales</b>'\n",
    "    res=pd.DataFrame()\n",
    "    res=res.append(tblreg[tblreg[\"Region\"]!='Retail Online']).append(sub_total_row,ignore_index=True).append(tblreg[tblreg[\"Region\"]=='Retail Online'])\n",
    "    res.loc[res[\"Region\"].isnull(),'Region']='<b>Sub Total Sales</b>'\n",
    "    res=res.append(total_row,ignore_index=True)\n",
    "    res.loc[res[\"Region\"].isnull(),'Region']='<b>Total Sales</b>'\n",
    "\n",
    "    res.loc[(res['Region']=='Retail Online')&\n",
    "               (res['Local Sales'].isnull()),'Local Sales']=0\n",
    "    res.loc[(res['Region']=='Retail Online')&\n",
    "               (res['Projected'].isnull()),'Projected']=0\n",
    "\n",
    "    tblreg=res.copy()\n",
    "    tblreg=tblreg.fillna(0)\n",
    "    for i in tblreg.columns[1:4]:\n",
    "        tblreg[i] = tblreg[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        tblreg[i][tblreg.index.max()] = \"<b> {} </b>\".format(tblreg[i][tblreg.index.max()])\n",
    "\n",
    "    for i in tblreg.columns[4:5]:\n",
    "        tblreg[i] = tblreg[i].apply(lambda x: \"{:.2f} %\".format(x*100))#.str.replace(',','.', regex = False)\n",
    "        tblreg[i][tblreg.index.max()] = \"<b> {} </b>\".format(tblreg[i][tblreg.index.max()])\n",
    "\n",
    "\n",
    "    for i in tblreg.columns[5:]:\n",
    "        tblreg[i] = tblreg[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        tblreg[i][tblreg.index.max()] = \"<b> {} </b>\".format(tblreg[i][tblreg.index.max()])\n",
    "\n",
    "    for i in tblreg.columns[1:]:\n",
    "        tblreg[i][tblreg.index.max()-2] = \"<b> {} </b>\".format(tblreg[i][tblreg.index.max()-2])\n",
    "\n",
    "    tblreg.loc[(tblreg[\"Projected %\"]==\"nan %\"),\"Projected %\"]=''\n",
    "\n",
    "\n",
    "    tblreg\n",
    "\n",
    "    ###################################################################################\n",
    "\n",
    "    for i in table_brand.columns[2:]:\n",
    "        table_brand[i] = table_brand[i].fillna(0).astype('int64')\n",
    "\n",
    "    table_brand_hilo = table_brand[table_brand['Brand'] == 'HiLo'].reset_index(drop = True)\n",
    "    table_brand_hilo = table_brand_hilo.append(table_brand_hilo.sum(numeric_only=True), ignore_index=True)\n",
    "    table_brand_hilo['Sub Brand'][table_brand_hilo.index.max()] = '<b>TOTAL<b>'\n",
    "    table_brand_hilo['Brand'][table_brand_hilo.index.max()] = ''\n",
    "\n",
    "\n",
    "    table_brand_ns= table_brand[table_brand['Brand'] == 'NS'].reset_index(drop = True)\n",
    "    table_brand_ns = table_brand_ns.append(table_brand_ns.sum(numeric_only=True), ignore_index=True)\n",
    "    table_brand_ns['Sub Brand'][table_brand_ns.index.max()] = '<b>TOTAL<b>'\n",
    "    table_brand_ns['Brand'][table_brand_ns.index.max()] = ''\n",
    "\n",
    "\n",
    "    table_brand_lmen = table_brand[table_brand['Brand'] == 'L-Men'].reset_index(drop = True)\n",
    "    table_brand_lmen = table_brand_lmen.append(table_brand_lmen.sum(numeric_only=True), ignore_index=True)\n",
    "    table_brand_lmen['Sub Brand'][table_brand_lmen.index.max()] = '<b>TOTAL<b>'\n",
    "    table_brand_lmen['Brand'][table_brand_lmen.index.max()] = ''\n",
    "\n",
    "\n",
    "    table_brand_ts = table_brand[table_brand['Brand'] == 'TS'].reset_index(drop = True)\n",
    "    table_brand_ts = table_brand_ts.append(table_brand_ts.sum(numeric_only=True), ignore_index=True)\n",
    "    table_brand_ts['Sub Brand'][table_brand_ts.index.max()] = '<b>TOTAL<b>'\n",
    "    table_brand_ts['Brand'][table_brand_ts.index.max()] = ''\n",
    "\n",
    "\n",
    "    for i in table_brand_hilo.columns[2:]:\n",
    "        table_brand_hilo[i] = table_brand_hilo[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        table_brand_hilo[i][table_brand_hilo.index.max()] = \"<b> {} </b>\".format(table_brand_hilo[i][table_brand_hilo.index.max()])\n",
    "\n",
    "    for i in table_brand_lmen.columns[2:]:\n",
    "        table_brand_lmen[i] = table_brand_lmen[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        table_brand_lmen[i][table_brand_lmen.index.max()] = \"<b> {} </b>\".format(table_brand_lmen[i][table_brand_lmen.index.max()])\n",
    "\n",
    "    for i in table_brand_ns.columns[2:]:\n",
    "        table_brand_ns[i] = table_brand_ns[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        table_brand_ns[i][table_brand_ns.index.max()] = \"<b> {} </b>\".format(table_brand_ns[i][table_brand_ns.index.max()])\n",
    "\n",
    "    for i in table_brand_ts.columns[2:]:\n",
    "        table_brand_ts[i] = table_brand_ts[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        table_brand_ts[i][table_brand_ts.index.max()] = \"<b> {} </b>\".format(table_brand_ts[i][table_brand_ts.index.max()])\n",
    "\n",
    "    table_brand = table_brand_hilo.append(pd.Series(), ignore_index = True, sort = False)\n",
    "    table_brand = table_brand.append(table_brand_lmen, ignore_index = True, sort = False)\n",
    "    table_brand = table_brand.append(pd.Series(), ignore_index = True, sort = False)\n",
    "    table_brand = table_brand.append(table_brand_ns, ignore_index = True, sort = False)\n",
    "    table_brand = table_brand.append(pd.Series(), ignore_index = True, sort = False)\n",
    "    table_brand = table_brand.append(table_brand_ts, ignore_index = True, sort = False)\n",
    "    for i in table_brand.columns:\n",
    "        table_brand[i] = table_brand[i].fillna('')\n",
    "\n",
    "    table_brand = table_brand[(table_brand == 'Rp 0').sum(1) < 5]\n",
    "    table_brand = table_brand.reset_index(drop = True)\n",
    "\n",
    "\n",
    "    table_item = all_single[['Brand', 'Sub Brand', 'Exported Parent Item']].drop_duplicates().reset_index(drop = True)\n",
    "    all_single['True datetime'] = pd.to_datetime(all_single['True datetime'])\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    today = datetime.today()\n",
    "    yesterday = datetime.today() - timedelta(days=1)\n",
    "\n",
    "    today = pd.to_datetime(today.strftime('%Y-%m-%d'))\n",
    "    yesterday = pd.to_datetime(yesterday.strftime('%Y-%m-%d'))\n",
    "\n",
    "    yesterday_sales = all_single[all_single['True datetime'] >= yesterday][all_single[all_single['True datetime'] >= yesterday]['True datetime']<today]\n",
    "    yesterday_sales = yesterday_sales.groupby(['Brand', 'Sub Brand', 'Exported Parent Item'])['Total Net'].sum().reset_index()\n",
    "    yesterday_sales['Total Net'] = yesterday_sales['Total Net']/1.1\n",
    "    yesterday_sales = yesterday_sales.rename(columns = {'Total Net' : 'Yesterday Sales'})\n",
    "    table_item = table_item.merge(yesterday_sales, how = 'left', on = ['Brand', 'Sub Brand', 'Exported Parent Item'])\n",
    "\n",
    "    if int(today.strftime('%d')) > 1 :\n",
    "        mtd_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)\n",
    "        mtd_date = pd.to_datetime(mtd_date.strftime('%Y-%m-%d'))\n",
    "    else :\n",
    "        mtd_date = datetime.today()-timedelta(days=int(yesterday.strftime('%d')))\n",
    "        mtd_date = pd.to_datetime(mtd_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "    mtd_sales = all_single[all_single['True datetime'] >= mtd_date][all_single[all_single['True datetime'] >= mtd_date]['True datetime']<today]\n",
    "    mtd_sales = mtd_sales.groupby(['Brand', 'Sub Brand', 'Exported Parent Item'])['Total Net'].sum().reset_index()\n",
    "    mtd_sales['Total Net'] = mtd_sales['Total Net']/1.1\n",
    "    mtd_sales = mtd_sales.rename(columns = {'Total Net' : 'Local Sales'})\n",
    "    table_item = table_item.merge(mtd_sales, how = 'left', on = ['Brand', 'Sub Brand', 'Exported Parent Item'])\n",
    "\n",
    "    if int(today.strftime('%d')) > 1 :\n",
    "        table_item['Average This Month'] = table_item['Local Sales']/(int(today.strftime('%d'))-1)\n",
    "        number_of_days = monthrange(today.year, today.month)[1]\n",
    "    else :\n",
    "        table_item['Average This Month'] = table_item['Local Sales']/(int(yesterday.strftime('%d')))\n",
    "        number_of_days = monthrange(yesterday.year, yesterday.month)[1]\n",
    "\n",
    "    table_item['Projected'] = table_item['Average This Month'] * number_of_days\n",
    "\n",
    "    from dateutil import rrule\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "\n",
    "    start_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)-relativedelta(months=3)\n",
    "    start_date = pd.to_datetime(start_date.strftime('%Y-%m-%d'))\n",
    "    end_date = datetime.today()-timedelta(days=int(today.strftime('%d')))\n",
    "    for dt in rrule.rrule(rrule.MONTHLY, dtstart=start_date, until=end_date):\n",
    "        first_date = pd.to_datetime(dt)\n",
    "        last_date = first_date + relativedelta(months=1)\n",
    "        temp_sales = all_single[all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n",
    "        temp_sales = temp_sales.groupby(['Brand', 'Sub Brand', 'Exported Parent Item'])['Total Net'].sum().reset_index()\n",
    "        temp_sales['Total Net'] = temp_sales['Total Net']/1.11\n",
    "        colname = str(first_date.month_name()) + ' ' + str(first_date.year)\n",
    "        temp_sales = temp_sales.rename(columns = {'Total Net' : colname})\n",
    "        table_item = table_item.merge(temp_sales, how = 'left', on = ['Brand', 'Sub Brand', 'Exported Parent Item'])\n",
    "\n",
    "    cols = list(table_item)\n",
    "    cols[len(cols)-1], cols[len(cols)-3] = cols[len(cols)-3], cols[len(cols)-1]\n",
    "    table_item = table_item.loc[:,cols]\n",
    "\n",
    "    #     table_item = table_item[table_item['Local Sales'].notnull()]\n",
    "    table_item['Yesterday Sales'] = pd.to_numeric(table_item['Yesterday Sales'], errors = 'coerce').fillna(0).astype('int64')\n",
    "    table_item['Local Sales'] = pd.to_numeric(table_item['Local Sales'], errors = 'coerce').fillna(0).astype('int64')\n",
    "    table_item = table_item.sort_values(['Brand','Local Sales'], ascending = [True, False])\n",
    "\n",
    "    for i in table_item.columns[3:]:\n",
    "        table_item[i] = table_item[i].fillna(0).apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "\n",
    "    table_item = table_item[(table_item == 'Rp 0').sum(1) < 5]\n",
    "    table_item = table_item.reset_index(drop = True)\n",
    "    table_item = table_item.drop('Average This Month', axis = 1)\n",
    "\n",
    "    all_single = all_single.sort_values('True datetime')\n",
    "\n",
    "    first_product = all_single.groupby('Exported Parent Item')['True datetime'].first().reset_index()\n",
    "\n",
    "    product_launch = first_product[first_product['True datetime'] > pd.to_datetime(datetime.today() - relativedelta(months=3))]['Exported Parent Item'].unique()\n",
    "    non_launch =  [\"PARSEL NATAL TAHUN BARU\",'HAMPER IDUL FITRI TS', 'GETPLUS HAMPERS IDUL FITRI TS', 'PAKET TAKJIL HILO DESSERT',\n",
    "                   'HILO CHOCOLATE PLS 15RX10SX14G', 'HILO TEEN TARO 12DX500G', 'TS SAMBAL TERASI 24BTLX200G',\n",
    "                   'TS AVOCADO COFFEE 12DX4SX20G', 'L-MEN PLATINUM KETAN HITAM 6KLRX800G', 'HILO AVOCADO CHOCOLATE PLS 15RX10SX14G', 'TS SHIRATAKI NOODLES 40PX71G',\n",
    "                   'TS KOREAN GARLIC BUTTERCOOKIES12DX5SX20G','TS AVOCADO COFFEE 12DX4SX14G', 'TS SWT CLASSIC 24DX100G', 'HILO WHITE CHOCOLATE PLS 15RX10SX14G', \n",
    "                   'HILO CHOCO HAZELNUT PLS 15RX10SX14G', 'NS ANGGUR PLS 4PX40SX11G',\"NS JERUK MANADO PLS 4PX40SX11G\",\n",
    "                   \"NS TEA LYCHEE TEA REF 12BAGX500G\",\"NUTRISARI 4 RASA SUMMER PACKAGE 40 SACHET\",\"NUTRISARI 4 RASA LOCAL PACKAGE 40 SACHET\",\n",
    "                   'PAKET NUTRISARI 25 RASA FRESHSTART','PAKET TS BEAT HYPERTENSION 2022','HILO SCHOOL CHOCOLATE CANDY 12SBX20SX8G','HILO ES TELER FC 36PX10SX15G','NS BLEWAH FC 72PX10SX11G','NS JERUK MAROKO 72PX10SX14G',\n",
    "                   'HILO TEEN STRAWBERRY MILKSHAKE 12DX500G','LOKALATE KOPI KAWISTA PLS 12RX10SX15G','LOKALATE KOPI ANDALIMAN 12DX8SX15G',\n",
    "                   'LOKALATE KOPI ALPUKAT FC 36PX10SX15G','GREEN PACKAGING HILO TEEN CHOCOLATE RTD','HILO SCHOOL SUSU COKELAT PLS 12RX10SX35G',\n",
    "                   'GREEN PACKAGING HILO SCHOOL CHOCOLATE RTD','GREEN PACKAGING L-MEN 2GO CHOCOLATE','GREEN PACKAGING NS SQUEEZED ORANGE RTD',\n",
    "                   'NS ASO PLS 16RX10SX14G','NS MADU LEMON PLS 4PX40SX11G','NS LEMON TEA PLS 4PX40SX11G','GREEN PACKAGING OAT DRINK RTD',\n",
    "                   'GREEN PACKAGING MINYAK KANOLA','L-MEN PLANTPROTEIN OGURA 6DX216G','NS MANGGA GANDARIA PLS 4PX40SX11G',\n",
    "                   'NS MADU JERUK PLS 4PX40SX11G','NS LYCHEE TEA PLS 4PX40SX11G', 'NS LEMON TEA REF 12BAGX400G', 'NS LYCHEE TEA REF 12BAGX400G',\n",
    "                   'NS ES CINCAU PLS 4PX40SX11G', 'NS FLORIDA ORANGE PLS 18PX40SX11G', 'NS SEMANGKA PLS 4PX40SX11G', \n",
    "                   'NS FLORIDA ORANGE FC 72OX10SX11G', 'NS MARKISA PLS 4PX40SX11G', 'NS MADU KURMA PLS 4PX40SX11G', 'NS NANAS PLS 4PX40SX11G',\n",
    "                   'NS JERUK MAROKO PLS 4PX40SX11G', 'TS CORN OIL 16PX1L', 'NS JERUK MANIS REF 12DX250G', 'NS COCOPANDAN PLS 4PX40SX11G']\n",
    "    product_launch = [x for x in product_launch if x not in non_launch]\n",
    "\n",
    "    table_launch = table_item[table_item['Exported Parent Item'].isin(product_launch)]\n",
    "    table_item = table_item[~table_item['Exported Parent Item'].isin(product_launch)]\n",
    "\n",
    "    table_hilo = table_item[table_item['Brand'] == 'HiLo'].reset_index(drop = True)\n",
    "    table_ns= table_item[table_item['Brand'] == 'NS'].reset_index(drop = True)\n",
    "    table_ns = table_ns[table_ns['Exported Parent Item'] != \"W'DANK LKLT KOPI DURIAN PLS 12RX10SX15G\"]\n",
    "    table_lmen = table_item[table_item['Brand'] == 'L-Men'].reset_index(drop = True)\n",
    "    table_ts = table_item[table_item['Brand'] == 'TS'].reset_index(drop = True)\n",
    "\n",
    "    new_table_launch = pd.DataFrame()\n",
    "    for i in table_launch['Brand'].unique():\n",
    "        if i != table_launch['Brand'].unique()[-1]:\n",
    "            new_table_launch = new_table_launch.append(table_launch[table_launch['Brand'] == i], ignore_index = True, sort = False).append(pd.Series(), ignore_index = True, sort = False)\n",
    "        else :\n",
    "            new_table_launch = new_table_launch.append(table_launch[table_launch['Brand'] == i], ignore_index = True, sort = False)\n",
    "\n",
    "    for i in new_table_launch.columns:\n",
    "        new_table_launch[i] = new_table_launch[i].fillna('')\n",
    "\n",
    "#     index = data_all[data_all['Sub Brand'] == 'WDANK'][data_all[data_all['Sub Brand'] == 'WDANK']['Bundle Flag'].isnull()].index.to_list()\n",
    "#     data_all['Brand'][index] = 'WDANK'\n",
    "\n",
    "\n",
    "    print(\"Clean Data Finish\")\n",
    "\n",
    "    print(\"Clean Data Non Nubi Finish\")\n",
    "\n",
    "\n",
    "    print(\"Export Data 2020 Finish\")\n",
    "\n",
    "\n",
    "    print(\"Prepare Emailing\")\n",
    "  \n",
    "    import win32com.client\n",
    "    o = win32com.client.Dispatch(\"Outlook.Application\")\n",
    "    for oacc in o.Session.Accounts:\n",
    "        if oacc.SmtpAddress == \"customer@nutrifood.co.id\":\n",
    "            oacctouse = oacc\n",
    "            break\n",
    "    Msg = o.CreateItem(0)\n",
    "    if oacctouse:\n",
    "        Msg._oleobj_.Invoke(*(64209, 0, 8, 0, oacctouse))  # Msg.SendUsingAccount = oacctouseif to:\n",
    "\n",
    "        to = ['steven.nathanael@nutrifood.co.id']\n",
    "\n",
    "        list_to = ';'.join(to)\n",
    "\n",
    "        Msg.To = list_to\n",
    "        Msg.Subject = \"Report E-commerce \" + \\\n",
    "        str(datetime.today().date().strftime('%B %d, %Y'))\n",
    "\n",
    "\n",
    "    html = '''\n",
    "    <html>\n",
    "    <head>\n",
    "    <style>\n",
    "\n",
    "        h2 {\n",
    "            text-align: center;\n",
    "            font-family: Helvetica, Arial, sans-serif;\n",
    "        }\n",
    "        table { \n",
    "            margin-left: auto;\n",
    "            margin-right: auto;\n",
    "        }\n",
    "        table, th, td {\n",
    "            border: 1px solid black;\n",
    "            border-collapse: collapse;\n",
    "        }\n",
    "        th, td {\n",
    "            padding: 5px;\n",
    "            text-align: center;\n",
    "            font-family: Helvetica, Arial, sans-serif;\n",
    "            font-size: 90%;\n",
    "        }\n",
    "        table tbody tr:hover {\n",
    "            background-color: #dddddd;\n",
    "        }\n",
    "        .wide {\n",
    "            width: 90%; \n",
    "        }\n",
    "        p\n",
    "\n",
    "    </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        '''\n",
    "    html = html + \"\"\"\n",
    "        <p> Dear all,</p>\n",
    "        <p> Berikut data penjualan E-Com <b> (Before PPN) tanggal {tanggal} </b> dengan rincian channel sebagai berikut : </p>\n",
    "        <p> Channel Marketplace : Blibli, Bukalapak, Elevenia, JD Indonesia, Lazada, Nutrimart, Order Online, Shopee, Tokopedia, Aladin Mall, TikTok </p>\n",
    "        <p> Channel Retail : Cari Sayur, Emos, Farmaku, Inovasi Digital Niaga, Ritel Bersama Nasional, Sayurbox, Tanihub, Astro, Lifepack, Toko Now   </p>\n",
    "        <p> Notes: Mohon maaf ada keterlambatan data untuk retail online </p>\n",
    "\n",
    "    \"\"\".format(tanggal = str(datetime.today().date().strftime('%B %d, %Y')))\n",
    "\n",
    "    html = html + tblall.to_html(classes='wide', escape=False).replace('&lt;b&gt;', '<b>').replace('&lt;/b&gt;', '</b>')\n",
    "\n",
    "    html = html + \"\"\"\n",
    "        <p> Dan berikut data penjualan E-Com (Before PPN) per Area :</p>\n",
    "        \"\"\"\n",
    "\n",
    "    html = html + tblreg.to_html(classes='wide', escape=False)\n",
    "\n",
    "    html = html + \"\"\"\n",
    "        <p> Dan Berikut data penjualan E-Com <b> (Before PPN) tanggal {tanggal} </b> per Brand :</p>\n",
    "    \"\"\".format(tanggal = str(datetime.today().date().strftime('%B %d, %Y'))) \n",
    "\n",
    "\n",
    "    html = html + table_brand.to_html(classes='wide', escape=False).replace('&lt;b&gt;', '<b>').replace('&lt;/b&gt;', '</b>')\n",
    "\n",
    "\n",
    "\n",
    "    html = html + \"\"\"\n",
    "        <p> Dan berikut data penjualan E-Com (Before PPN) per Item :</p>\n",
    "        <p> Item Launching : </p>\"\"\"\n",
    "\n",
    "    html = html + new_table_launch.to_html(classes='wide', escape=False)\n",
    "\n",
    "    html = html + \"<p> HiLo : </p>\"    \n",
    "\n",
    "    html = html + table_hilo.to_html(classes='wide', escape=False)\n",
    "\n",
    "    html = html + \"<p> L-Men : </p>\"    \n",
    "\n",
    "    html = html + table_lmen.to_html(classes='wide', escape=False)\n",
    "\n",
    "    html = html + \"<p> NutriSari : </p>\"    \n",
    "\n",
    "    html = html + table_ns.to_html(classes='wide', escape=False)\n",
    "\n",
    "    html = html + \"<p> Tropicana Slim : </p>\"    \n",
    "\n",
    "    html = html + table_ts.to_html(classes='wide', escape=False)\n",
    "\n",
    "    html = html + \"\"\"\n",
    "        <p></p>\n",
    "        <p> Best regards, </p>\n",
    "        <p> E-Commerce Nutrifood </p>\n",
    "    <body>\n",
    "    \n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    Msg.HTMLBody = html\n",
    "    Msg.Send()\n",
    "    print('Email Sent')\n",
    "else :\n",
    "    print('Missing Parent Item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b9ba3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order #\n",
      "Sales Order ID\n",
      "AWB\n",
      "Paid Date\n",
      "Order Status\n",
      "Order date\n",
      "Week\n",
      "Date\n",
      "Month\n",
      "Quarter\n",
      "Year\n",
      "Channel\n",
      "SKU\n",
      "Brand\n",
      "Product Name\n",
      "Bundle Name\n",
      "Price List NFI\n",
      "Qty. Invoiced\n",
      "Total Net\n",
      "Sub Brand\n",
      "Real SKU\n",
      "Real Nama Produk\n",
      "Parent Item\n",
      "Parent SKU\n",
      "Bundle Flag\n",
      "Customer Email\n",
      "Customer Name\n",
      "Customer Group\n",
      "Phone\n",
      "Country\n",
      "Region\n",
      "City\n",
      "Kecamatan\n",
      "Kelurahan\n",
      "Address\n",
      "Zip Code\n",
      "Shipping Name\n",
      "Shipping Courier\n",
      "Total\n",
      "Coupon Code\n",
      "Qty. Ordered\n",
      "Qty. Shipped\n",
      "Qty. Refunded\n",
      "Item Price\n",
      "Subtotal\n",
      "Discounts\n",
      "Tax\n",
      "Total incl. Tax\n",
      "Invoiced\n",
      "Tax Invoiced\n",
      "Invoiced incl. Tax\n",
      "Refunded\n",
      "Refunded incl. Tax\n",
      "Cart Name Rule\n",
      "Payment Channel\n",
      "Voucher Amount\n",
      "Discount Poin Reward\n",
      "Ship Date\n",
      "Discount Product\n",
      "Produk 1\n",
      "SKU Produk 1\n",
      "PCS Produk 1\n",
      "Price List NFI 1\n",
      "Subtotal Produk 1\n",
      "Harga Display 1\n",
      "Harga Cost 1\n",
      "Produk 2\n",
      "SKU Produk 2\n",
      "PCS Produk 2\n",
      "Price List NFI 2\n",
      "Subtotal Produk 2\n",
      "Harga Display 2\n",
      "Harga Cost 2\n",
      "Produk 3\n",
      "SKU Produk 3\n",
      "PCS Produk 3\n",
      "Price List NFI 3\n",
      "Subtotal Produk 3\n",
      "Harga Display 3\n",
      "Harga Cost 3\n",
      "Produk 4\n",
      "SKU Produk 4\n",
      "PCS Produk 4\n",
      "Price List NFI 4\n",
      "Subtotal Produk 4\n",
      "Harga Display 4\n",
      "Harga Cost 4\n",
      "Produk 5\n",
      "SKU Produk 5\n",
      "PCS Produk 5\n",
      "Price List NFI 5\n",
      "Subtotal Produk 5\n",
      "Harga Display 5\n",
      "Harga Cost 5\n",
      "Produk 6\n",
      "SKU Produk 6\n",
      "PCS Produk 6\n",
      "Price List NFI 6\n",
      "Subtotal Produk 6\n",
      "Harga Display 6\n",
      "Harga Cost 6\n",
      "Produk 7\n",
      "SKU Produk 7\n",
      "PCS Produk 7\n",
      "Price List NFI 7\n",
      "Subtotal Produk 7\n",
      "Harga Display 7\n",
      "Harga Cost 7\n",
      "Cancelled Date\n",
      "Currency Code\n",
      "Bundle\n",
      "Loc ID\n",
      "Barcode ID\n",
      "Warehouse Name\n",
      "Regular Price\n",
      "Selling Price\n",
      "VAT\n",
      "Shipping\n",
      "Actual Shipping\n",
      "Seller Discount\n",
      "Seller Rebate\n",
      "Gross Sales\n",
      "Shipping Address2\n",
      "Notes\n",
      "Store\n",
      "Qty. Ordered\"\n",
      "Qty. Shipped\"\n",
      "Harga Organik 1\n",
      "Harga Organik 2\n",
      "Harga Organik 3\n",
      "Harga Organik 4\n",
      "Harga Organik 5\n",
      "Harga Organik 6\n",
      "Harga Organik 7\n",
      "Kode SKU\n",
      "Blibli SKU\n",
      "Kode Merchant\n",
      "True datetime\n",
      "Promo\n",
      "Discount MC\n",
      "Harga Cost\n",
      "Total Harga Cost\n",
      "No. Order Item L-Men Blibli\n",
      "Order Voucher Amount\n",
      "Item Voucher Amount\n",
      "Item Voucher Platform\n",
      "Item Voucher Seller\n",
      "nominal\n",
      "btlcost\n",
      "gs\n",
      "commfee\n",
      "fullfee\n",
      "index\n",
      "Phone Condition\n",
      "Warehouse Code\n",
      "Channel Rebate\n",
      "Shipping Province\n",
      "Shipping City\n",
      "Shipping Address1\n",
      "Shipping Phone\n",
      "Hour\n",
      "payment_status\n",
      "Shipping Cost\n",
      "Invoice Number\n",
      "Shopee Order\n",
      "Shopee Cust\n",
      "Store Type\n",
      "Category\n",
      "Real SKU_y\n",
      "Region Group\n",
      "PL Before PPN\n",
      "Total Net Before PPN\n",
      "Payment Status\n",
      "Payment Type\n",
      "Printed Date\n",
      "Fulfilled Date\n",
      "Delivered Date\n",
      "Return ID\n",
      "Return Reference No.\n",
      "Return Date\n",
      "Service Type\n",
      "Bundle SKU Code\n",
      "Location ID\n",
      "Invoice ID\n",
      "Invoice Reference Number\n",
      "Invoice Status\n",
      "Invoice Create Date\n",
      "Fee Amount\n",
      "Invoice Amount\n",
      "Payment Received ID\n",
      "Payment Received Ref. number\n",
      "Category Baru\n",
      "Exported Parent Item\n",
      "Unnamed: 0\n",
      "Price List NFI_x\n",
      "Customer Type\n",
      "Real Region\n",
      "True datetime1\n",
      "Payment Date\n",
      "Shipping Customer Name\n",
      "Shipped Date\n",
      "Note\n",
      "Ready to Ship Date\n",
      "Completed Date\n",
      "Cancelled Reason\n",
      "Item Note\n",
      "Shipping Fee (Cashless)\n",
      "Picklist ID\n",
      "Package ID\n",
      "Shipment ID\n",
      "Bundle SKU\n"
     ]
    }
   ],
   "source": [
    "for i in all_single.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84088e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "752fe9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Order Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Blibli</td>\n",
       "      <td>L-Men Store Blibli</td>\n",
       "      <td>Order Batal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Nutrimart</td>\n",
       "      <td>Nutrimart</td>\n",
       "      <td>pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Nutrimart</td>\n",
       "      <td>Nutrimart</td>\n",
       "      <td>canceled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>Shopee</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>Cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>Lazada</td>\n",
       "      <td>FBL</td>\n",
       "      <td>Cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>Tokopedia</td>\n",
       "      <td>Tokopedia</td>\n",
       "      <td>Cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>Lazada</td>\n",
       "      <td>Lazada</td>\n",
       "      <td>Cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>TikTok</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>Cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>Blibli</td>\n",
       "      <td>Blibli</td>\n",
       "      <td>Cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>JD Indonesia</td>\n",
       "      <td>JD Indonesia</td>\n",
       "      <td>Cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>Lazada</td>\n",
       "      <td>FBL</td>\n",
       "      <td>Cancelled, Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12441</th>\n",
       "      <td>Blibli</td>\n",
       "      <td>Blibli</td>\n",
       "      <td>Return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15457</th>\n",
       "      <td>Bukalapak</td>\n",
       "      <td>Bukalapak</td>\n",
       "      <td>Cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74704</th>\n",
       "      <td>Order Online</td>\n",
       "      <td>Order Online Sumsel</td>\n",
       "      <td>cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82928</th>\n",
       "      <td>Order Online</td>\n",
       "      <td>Order Online Surabaya</td>\n",
       "      <td>cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83073</th>\n",
       "      <td>Order Online</td>\n",
       "      <td>Order Online Makassar</td>\n",
       "      <td>cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83114</th>\n",
       "      <td>Order Online</td>\n",
       "      <td>Order Online Pekanbaru</td>\n",
       "      <td>cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83143</th>\n",
       "      <td>Order Online</td>\n",
       "      <td>Order Online Jabar</td>\n",
       "      <td>cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83340</th>\n",
       "      <td>Nutrimart</td>\n",
       "      <td>Nutrimart</td>\n",
       "      <td>gosend_rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91988</th>\n",
       "      <td>Blibli</td>\n",
       "      <td>Blibli</td>\n",
       "      <td>Pending Payment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93487</th>\n",
       "      <td>Order Online</td>\n",
       "      <td>Order Online Jateng</td>\n",
       "      <td>cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93552</th>\n",
       "      <td>Order Online</td>\n",
       "      <td>Order Online Bali</td>\n",
       "      <td>cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93626</th>\n",
       "      <td>Order Online</td>\n",
       "      <td>Order Online Medan</td>\n",
       "      <td>cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93722</th>\n",
       "      <td>Order Online</td>\n",
       "      <td>Order Online Lampung</td>\n",
       "      <td>cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182864</th>\n",
       "      <td>Order Online</td>\n",
       "      <td>Order Online Banjarmasin</td>\n",
       "      <td>cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690661</th>\n",
       "      <td>Blibli</td>\n",
       "      <td>L-Men Store Blibli</td>\n",
       "      <td>Pengiriman Gagal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887810</th>\n",
       "      <td>Tokopedia</td>\n",
       "      <td>Tokopedia</td>\n",
       "      <td>Not Shipped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896576</th>\n",
       "      <td>Order Online</td>\n",
       "      <td>Order Online Samarinda</td>\n",
       "      <td>cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910202</th>\n",
       "      <td>Nutrimart</td>\n",
       "      <td>Nutrimart</td>\n",
       "      <td>pending_payment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916564</th>\n",
       "      <td>Shopee</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>Failed Delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921584</th>\n",
       "      <td>Nutrimart</td>\n",
       "      <td>Nutrimart</td>\n",
       "      <td>shipment_failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964954</th>\n",
       "      <td>Order Online</td>\n",
       "      <td>Order Online Surabaya</td>\n",
       "      <td>pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999518</th>\n",
       "      <td>Order Online</td>\n",
       "      <td>Order Online Sumsel</td>\n",
       "      <td>Canceled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020185</th>\n",
       "      <td>Lazada</td>\n",
       "      <td>Lazada</td>\n",
       "      <td>Not Shipped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050344</th>\n",
       "      <td>Order Online</td>\n",
       "      <td>Order Online Makassar</td>\n",
       "      <td>Canceled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050346</th>\n",
       "      <td>Order Online</td>\n",
       "      <td>Order Online Medan</td>\n",
       "      <td>Canceled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060368</th>\n",
       "      <td>Order Online</td>\n",
       "      <td>Order Online Jateng</td>\n",
       "      <td>refunded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068956</th>\n",
       "      <td>Order Online</td>\n",
       "      <td>Order Online Lampung</td>\n",
       "      <td>refunded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069142</th>\n",
       "      <td>Order Online</td>\n",
       "      <td>Order Online Samarinda</td>\n",
       "      <td>Canceled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115309</th>\n",
       "      <td>Order Online</td>\n",
       "      <td>Order Online Lampung</td>\n",
       "      <td>Canceled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115310</th>\n",
       "      <td>Order Online</td>\n",
       "      <td>Order Online Jabar</td>\n",
       "      <td>Canceled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140984</th>\n",
       "      <td>Order Online</td>\n",
       "      <td>Order Online Banjarmasin</td>\n",
       "      <td>Canceled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190664</th>\n",
       "      <td>Lazada</td>\n",
       "      <td>Lazada</td>\n",
       "      <td>Failed Delivery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Store                   Channel          Order Status\n",
       "29             Blibli        L-Men Store Blibli           Order Batal\n",
       "169         Nutrimart                 Nutrimart               pending\n",
       "208         Nutrimart                 Nutrimart              canceled\n",
       "435            Shopee                    Shopee             Cancelled\n",
       "583            Lazada                       FBL             Cancelled\n",
       "666         Tokopedia                 Tokopedia             Cancelled\n",
       "738            Lazada                    Lazada             Cancelled\n",
       "742            TikTok                    TikTok             Cancelled\n",
       "1181           Blibli                    Blibli             Cancelled\n",
       "1908     JD Indonesia              JD Indonesia             Cancelled\n",
       "8691           Lazada                       FBL  Cancelled, Completed\n",
       "12441          Blibli                    Blibli                Return\n",
       "15457       Bukalapak                 Bukalapak             Cancelled\n",
       "74704    Order Online       Order Online Sumsel             cancelled\n",
       "82928    Order Online     Order Online Surabaya             cancelled\n",
       "83073    Order Online     Order Online Makassar             cancelled\n",
       "83114    Order Online    Order Online Pekanbaru             cancelled\n",
       "83143    Order Online        Order Online Jabar             cancelled\n",
       "83340       Nutrimart                 Nutrimart       gosend_rejected\n",
       "91988          Blibli                    Blibli       Pending Payment\n",
       "93487    Order Online       Order Online Jateng             cancelled\n",
       "93552    Order Online         Order Online Bali             cancelled\n",
       "93626    Order Online        Order Online Medan             cancelled\n",
       "93722    Order Online      Order Online Lampung             cancelled\n",
       "182864   Order Online  Order Online Banjarmasin             cancelled\n",
       "1690661        Blibli        L-Men Store Blibli      Pengiriman Gagal\n",
       "1887810     Tokopedia                 Tokopedia           Not Shipped\n",
       "1896576  Order Online    Order Online Samarinda             cancelled\n",
       "1910202     Nutrimart                 Nutrimart       pending_payment\n",
       "1916564        Shopee                    Shopee       Failed Delivery\n",
       "1921584     Nutrimart                 Nutrimart       shipment_failed\n",
       "1964954  Order Online     Order Online Surabaya               pending\n",
       "1999518  Order Online       Order Online Sumsel              Canceled\n",
       "2020185        Lazada                    Lazada           Not Shipped\n",
       "2050344  Order Online     Order Online Makassar              Canceled\n",
       "2050346  Order Online        Order Online Medan              Canceled\n",
       "2060368  Order Online       Order Online Jateng              refunded\n",
       "2068956  Order Online      Order Online Lampung              refunded\n",
       "2069142  Order Online    Order Online Samarinda              Canceled\n",
       "2115309  Order Online      Order Online Lampung              Canceled\n",
       "2115310  Order Online        Order Online Jabar              Canceled\n",
       "2140984  Order Online  Order Online Banjarmasin              Canceled\n",
       "2190664        Lazada                    Lazada       Failed Delivery"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CEK ORDER STATUS UPDATE\n",
    "osf=pd.read_excel(r\"data_supp\\order filter.xlsx\")\n",
    "data_all[(~data_all['Order Status'].isin(osf['order filter'].unique()))&data_all['Month'].isin(['December','November','January'])][['Store','Channel','Order Status']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251e13aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b08072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "04fb1b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 1), dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ini cek kalau pembagian region sama total (tbl 1 & 2 Beda) update di file area utk report\n",
    "sales_region[(sales_region['Region Group'].notnull())&(~sales_region['Region Group'].isin(mappingarea['Region Group'].unique()))][['Region Group']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ac15cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real SKU</th>\n",
       "      <th>Real Nama Produk</th>\n",
       "      <th>Category Baru</th>\n",
       "      <th>Exported Parent Item</th>\n",
       "      <th>Store</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2303135</th>\n",
       "      <td>(B)(R)2LH1204172</td>\n",
       "      <td>Sampling - L-Men Bar Strongberry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>Lazada</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303969</th>\n",
       "      <td>(B)(R)2T00806053</td>\n",
       "      <td>Sampling - Tropicana Slim 7 Fruits Fiber Daily</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>Lazada</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303970</th>\n",
       "      <td>(B)2HH1409249</td>\n",
       "      <td>PBI - HiLo Ready to Drink Chocofit 190ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>Lazada</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Real SKU                                Real Nama Produk  \\\n",
       "2303135  (B)(R)2LH1204172                Sampling - L-Men Bar Strongberry   \n",
       "2303969  (B)(R)2T00806053  Sampling - Tropicana Slim 7 Fruits Fiber Daily   \n",
       "2303970     (B)2HH1409249        PBI - HiLo Ready to Drink Chocofit 190ml   \n",
       "\n",
       "        Category Baru Exported Parent Item   Store    Year    Month  \n",
       "2303135           NaN                  nan  Lazada  2024.0  January  \n",
       "2303969           NaN                  nan  Lazada  2024.0  January  \n",
       "2303970           NaN                  nan  Lazada  2024.0  January  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if error missing parent item\n",
    "# listing di kode atas, exported parent item liat tatanama akun admin login user&pass: nutrifood\n",
    "all_single[all_single['Exported Parent Item'] == 'nan'][['Real SKU','Real Nama Produk','Category Baru','Exported Parent Item','Store','Year','Month']].drop_duplicates()#.values\n",
    "#all_single[all_single['Exported Parent Item'] == 'nan']['Real Nama Produk'].unique()#.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09c18d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order #</th>\n",
       "      <th>Sales Order ID</th>\n",
       "      <th>AWB</th>\n",
       "      <th>Paid Date</th>\n",
       "      <th>Order Status</th>\n",
       "      <th>Order date</th>\n",
       "      <th>Week</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>...</th>\n",
       "      <th>Invoice Create Date</th>\n",
       "      <th>Fee Amount</th>\n",
       "      <th>Invoice Amount</th>\n",
       "      <th>Payment Received ID</th>\n",
       "      <th>Payment Received Ref. number</th>\n",
       "      <th>Category Baru</th>\n",
       "      <th>Exported Parent Item</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Price List NFI_x</th>\n",
       "      <th>Customer Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Order #, Sales Order ID, AWB, Paid Date, Order Status, Order date, Week, Date, Month, Quarter, Year, Channel, SKU, Brand, Product Name, Bundle Name, Price List NFI, Qty. Invoiced, Total Net, Sub Brand, Real SKU, Real Nama Produk, Parent Item, Parent SKU, Bundle Flag, Customer Email, Customer Name, Customer Group, Phone, Country, Region, City, Kecamatan, Kelurahan, Address, Zip Code, Shipping Name, Shipping Courier, Total, Coupon Code, Qty. Ordered, Qty. Shipped, Qty. Refunded, Item Price, Subtotal, Discounts, Tax, Total incl. Tax, Invoiced, Tax Invoiced, Invoiced incl. Tax, Refunded, Refunded incl. Tax, Cart Name Rule, Payment Channel, Voucher Amount, Discount Poin Reward, Ship Date, Discount Product, Produk 1, SKU Produk 1, PCS Produk 1, Price List NFI 1, Subtotal Produk 1, Harga Display 1, Harga Cost 1, Produk 2, SKU Produk 2, PCS Produk 2, Price List NFI 2, Subtotal Produk 2, Harga Display 2, Harga Cost 2, Produk 3, SKU Produk 3, PCS Produk 3, Price List NFI 3, Subtotal Produk 3, Harga Display 3, Harga Cost 3, Produk 4, SKU Produk 4, PCS Produk 4, Price List NFI 4, Subtotal Produk 4, Harga Display 4, Harga Cost 4, Produk 5, SKU Produk 5, PCS Produk 5, Price List NFI 5, Subtotal Produk 5, Harga Display 5, Harga Cost 5, Produk 6, SKU Produk 6, PCS Produk 6, Price List NFI 6, Subtotal Produk 6, Harga Display 6, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 195 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nubi[data_nubi['Year'].isin([2024])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb48ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8482cee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order #\n",
      "Sales Order ID\n",
      "AWB\n",
      "Paid Date\n",
      "Order Status\n",
      "Order date\n",
      "Week\n",
      "Date\n",
      "Month\n",
      "Quarter\n",
      "Year\n",
      "Channel\n",
      "SKU\n",
      "Brand\n",
      "Product Name\n",
      "Bundle Name\n",
      "Price List NFI\n",
      "Qty. Invoiced\n",
      "Total Net\n",
      "Sub Brand\n",
      "Real SKU\n",
      "Real Nama Produk\n",
      "Parent Item\n",
      "Parent SKU\n",
      "Bundle Flag\n",
      "Customer Email\n",
      "Customer Name\n",
      "Customer Group\n",
      "Phone\n",
      "Country\n",
      "Region\n",
      "City\n",
      "Kecamatan\n",
      "Kelurahan\n",
      "Address\n",
      "Zip Code\n",
      "Shipping Name\n",
      "Shipping Courier\n",
      "Total\n",
      "Coupon Code\n",
      "Qty. Ordered\n",
      "Qty. Shipped\n",
      "Qty. Refunded\n",
      "Item Price\n",
      "Subtotal\n",
      "Discounts\n",
      "Tax\n",
      "Total incl. Tax\n",
      "Invoiced\n",
      "Tax Invoiced\n",
      "Invoiced incl. Tax\n",
      "Refunded\n",
      "Refunded incl. Tax\n",
      "Cart Name Rule\n",
      "Payment Channel\n",
      "Voucher Amount\n",
      "Discount Poin Reward\n",
      "Ship Date\n",
      "Discount Product\n",
      "Produk 1\n",
      "SKU Produk 1\n",
      "PCS Produk 1\n",
      "Price List NFI 1\n",
      "Subtotal Produk 1\n",
      "Harga Display 1\n",
      "Harga Cost 1\n",
      "Produk 2\n",
      "SKU Produk 2\n",
      "PCS Produk 2\n",
      "Price List NFI 2\n",
      "Subtotal Produk 2\n",
      "Harga Display 2\n",
      "Harga Cost 2\n",
      "Produk 3\n",
      "SKU Produk 3\n",
      "PCS Produk 3\n",
      "Price List NFI 3\n",
      "Subtotal Produk 3\n",
      "Harga Display 3\n",
      "Harga Cost 3\n",
      "Produk 4\n",
      "SKU Produk 4\n",
      "PCS Produk 4\n",
      "Price List NFI 4\n",
      "Subtotal Produk 4\n",
      "Harga Display 4\n",
      "Harga Cost 4\n",
      "Produk 5\n",
      "SKU Produk 5\n",
      "PCS Produk 5\n",
      "Price List NFI 5\n",
      "Subtotal Produk 5\n",
      "Harga Display 5\n",
      "Harga Cost 5\n",
      "Produk 6\n",
      "SKU Produk 6\n",
      "PCS Produk 6\n",
      "Price List NFI 6\n",
      "Subtotal Produk 6\n",
      "Harga Display 6\n",
      "Harga Cost 6\n",
      "Produk 7\n",
      "SKU Produk 7\n",
      "PCS Produk 7\n",
      "Price List NFI 7\n",
      "Subtotal Produk 7\n",
      "Harga Display 7\n",
      "Harga Cost 7\n",
      "Cancelled Date\n",
      "Currency Code\n",
      "Bundle\n",
      "Loc ID\n",
      "Barcode ID\n",
      "Warehouse Name\n",
      "Regular Price\n",
      "Selling Price\n",
      "VAT\n",
      "Shipping\n",
      "Actual Shipping\n",
      "Seller Discount\n",
      "Seller Rebate\n",
      "Gross Sales\n",
      "Shipping Address2\n",
      "Notes\n",
      "Store\n",
      "Qty. Ordered\"\n",
      "Qty. Shipped\"\n",
      "Harga Organik 1\n",
      "Harga Organik 2\n",
      "Harga Organik 3\n",
      "Harga Organik 4\n",
      "Harga Organik 5\n",
      "Harga Organik 6\n",
      "Harga Organik 7\n",
      "Kode SKU\n",
      "Blibli SKU\n",
      "Kode Merchant\n",
      "True datetime\n",
      "Promo\n",
      "Discount MC\n",
      "Harga Cost\n",
      "Total Harga Cost\n",
      "No. Order Item L-Men Blibli\n",
      "Order Voucher Amount\n",
      "Item Voucher Amount\n",
      "Item Voucher Platform\n",
      "Item Voucher Seller\n",
      "nominal\n",
      "btlcost\n",
      "gs\n",
      "commfee\n",
      "fullfee\n",
      "index\n",
      "Phone Condition\n",
      "Warehouse Code\n",
      "Channel Rebate\n",
      "Shipping Province\n",
      "Shipping City\n",
      "Shipping Address1\n",
      "Shipping Phone\n",
      "Hour\n",
      "payment_status\n",
      "Shipping Cost\n",
      "Invoice Number\n",
      "Shopee Order\n",
      "Shopee Cust\n",
      "Store Type\n",
      "Category\n",
      "Real SKU_y\n",
      "Region Group\n",
      "PL Before PPN\n",
      "Total Net Before PPN\n",
      "Payment Status\n",
      "Payment Type\n",
      "Printed Date\n",
      "Fulfilled Date\n",
      "Delivered Date\n",
      "Return ID\n",
      "Return Reference No.\n",
      "Return Date\n",
      "Service Type\n",
      "Bundle SKU Code\n",
      "Location ID\n",
      "Invoice ID\n",
      "Invoice Reference Number\n",
      "Invoice Status\n",
      "Invoice Create Date\n",
      "Fee Amount\n",
      "Invoice Amount\n",
      "Payment Received ID\n",
      "Payment Received Ref. number\n",
      "Category Baru\n",
      "Exported Parent Item\n",
      "Unnamed: 0\n",
      "Price List NFI_x\n",
      "Customer Type\n",
      "Real Region\n",
      "True datetime1\n",
      "Payment Date\n",
      "Shipping Customer Name\n",
      "Shipped Date\n",
      "Note\n",
      "Ready to Ship Date\n",
      "Completed Date\n",
      "Cancelled Reason\n",
      "Item Note\n",
      "Shipping Fee (Cashless)\n",
      "Picklist ID\n",
      "Package ID\n",
      "Shipment ID\n"
     ]
    }
   ],
   "source": [
    "for i in data_all.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4f646d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dcb2af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5ace5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eaae8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b97a7bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### run 12\n",
    "### take out item yang gk masuk email automation\n",
    "buang = ['PAKET HILO']\n",
    "table_brand = table_brand[~table_brand['Sub Brand'].isin(buang)]\n",
    "table_hilo = table_hilo[~table_hilo['Sub Brand'].isin(buang)]\n",
    "\n",
    "buang = ['PAKET TS']\n",
    "table_brand = table_brand[~table_brand['Sub Brand'].isin(buang)]\n",
    "table_ts = table_ts[~table_ts['Sub Brand'].isin(buang)]\n",
    "\n",
    "buang = ['PAKET L-MEN']\n",
    "table_brand = table_brand[~table_brand['Sub Brand'].isin(buang)]\n",
    "table_ts = table_ts[~table_ts['Sub Brand'].isin(buang)]\n",
    "\n",
    "buang = ['PAKET NUTRISARI']\n",
    "table_brand = table_brand[~table_brand['Sub Brand'].isin(buang)]\n",
    "table_ns = table_ns[~table_ns['Sub Brand'].isin(buang)]\n",
    "\n",
    "buang = ['PAKET LOKALATE']\n",
    "table_brand = table_brand[~table_brand['Sub Brand'].isin(buang)]\n",
    "table_ns = table_ns[~table_ns['Sub Brand'].isin(buang)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8a16f6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bundle', 'L-Men', 'Gimmick', 'Bonus Produk', 'TS', 'HiLo', 'NS',\n",
       "       'WRP', 'WDANK', 'L-MEN'], dtype=object)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['Brand'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "833cd208",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Samain Nama Produk\n",
    "data_all.loc[data_all['Real Nama Produk'].isin(['Ex Shopee - HiLo Teen Chocolate 500gr']), 'Real Nama Produk'] = 'HiLo Teen Chocolate 500gr'\n",
    "data_all.loc[data_all['Real Nama Produk'].isin(['Ex Shopee - HiLo Active Chocolate 750gr']), 'Real Nama Produk'] = 'HiLo Active Chocolate 750gr'\n",
    "data_all = data_all[~data_all['Brand'].isin(['nan'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a122e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[data_all['True datetime'] > '2023-08-03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad8b507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc15688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed544a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### run 13\n",
    "### send email automation final ke user\n",
    "\n",
    "import win32com.client\n",
    "\n",
    "o = win32com.client.Dispatch(\"Outlook.Application\")\n",
    "for oacc in o.Session.Accounts:\n",
    "    if oacc.SmtpAddress == \"customer@nutrifood.co.id\":\n",
    "        oacctouse = oacc\n",
    "        break\n",
    "\n",
    "Msg = o.CreateItem(0)\n",
    "if oacctouse:\n",
    "    Msg._oleobj_.Invoke(*(64209, 0, 8, 0, oacctouse))  # Msg.SendUsingAccount = oacctouseif to:\n",
    "    \n",
    "    to=[\"mardi@nutrifood.co.id\", \"Elvina@nutrifood.co.id\", \"susana@nutrifood.co.id\",\n",
    "        \"ignasius.dwi@nutrifood.co.id\", \"may@nutrifood.co.id\", \"Meirza@nutrifood.co.id\", \"christian.jesaya@nutrifood.co.id\",\n",
    "        \"didit@nutrifood.co.id\", \"noviana@nutrifood.co.id\",\"reynald.tjandra@nutrifood.co.id\", \"elvira@nutrifood.co.id\",\n",
    "        \"manthovani.annice@nutrifood.co.id\",\"joshua.suhendro@nutrifood.co.id\",\"stephanie.wonoadi@nutrifood.co.id\",\n",
    "        \"lisa.arianti@nutrifood.co.id\",'charissa.lungkat@nutrifood.co.id','rosariani@nutrifood.co.id',\"zakaria@nutrifood.co.id\",\"geovano.satria@nutrifood.co.id\",\"agus_s@nutrifood.co.id\",\"romi.anggara@nutrifood.co.id\",\n",
    "        \"edward@nutrifood.co.id\", \"elisa.putri@nutrifood.co.id\",\"teddy.andreas@nutrifood.co.id\", \"muroby.rocky@nutrifood.co.id\",\n",
    "        \"evelyn@nutrifood.co.id\",\"sheila.odilia@nutrifood.co.id\",\"timotius.giovandi@nutrifood.co.id\",\n",
    "        'ronaldo.yolanda@nutrifood.co.id','bagus.sindhu@nutrifood.co.id',\"hendi.herdiansyah@nutrifood.co.id\",'christovertand.wim@nutrifood.co.id',\n",
    "        'steven.nathanael@nutrifood.co.id','arbie.hasyim@nutrifood.co.id','ariel.christianto@nutrifood.co.id','raedi.noor@nutrifood.co.id','ignatia.benna@nutrifood.co.id', 'james.michael@nutrifood.co.id']\n",
    "    #to = ['steven.nathanael@nutrifood.co.id']\n",
    "\n",
    "    list_to = ';'.join(to)\n",
    "\n",
    "    Msg.To = list_to\n",
    "    Msg.Subject = \"Report E-commerce \" + \\\n",
    "    str(datetime.today().date().strftime('%B %d, %Y'))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "html = '''\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "\n",
    "    h2 {\n",
    "        text-align: center;\n",
    "        font-family: Helvetica, Arial, sans-serif;\n",
    "    }\n",
    "    table { \n",
    "        margin-left: auto;\n",
    "        margin-right: auto;\n",
    "    }\n",
    "    table, th, td {\n",
    "        border: 1px solid black;\n",
    "        border-collapse: collapse;\n",
    "    }\n",
    "    th, td {\n",
    "        padding: 5px;\n",
    "        text-align: center;\n",
    "        font-family: Helvetica, Arial, sans-serif;\n",
    "        font-size: 90%;\n",
    "    }\n",
    "    table tbody tr:hover {\n",
    "        background-color: #dddddd;\n",
    "    }\n",
    "    .wide {\n",
    "        width: 90%; \n",
    "    }\n",
    "    p\n",
    "\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "    '''\n",
    "html = html + \"\"\"\n",
    "    <p> Dear all,</p>\n",
    "    <p> Berikut data penjualan E-Com <b> (Before PPN) tanggal {tanggal} </b> dengan rincian channel sebagai berikut : </p>\n",
    "    <p> Channel Marketplace : Blibli, Bukalapak, Lazada, Nutrimart, Order Online, Shopee, Tokopedia, Aladin Mall, TikTok </p>\n",
    "    <p> Channel Retail : Cari Sayur, Emos, Farmaku, Inovasi Digital Niaga, Ritel Bersama Nasional, Sayurbox, Tanihub, Astro, Lifepack, Toko Now, Freshbox  </p>\n",
    "\"\"\".format(tanggal = str(datetime.today().date().strftime('%B %d, %Y')))\n",
    "\n",
    "html = html + tblall.to_html(classes='wide', escape=False).replace('&lt;b&gt;', '<b>').replace('&lt;/b&gt;', '</b>')\n",
    "\n",
    "html = html + \"\"\"\n",
    "    <p> Dan berikut data penjualan E-Com (Before PPN) per Area :</p>\n",
    "    \"\"\"\n",
    "\n",
    "html = html + tblreg.to_html(classes='wide', escape=False)\n",
    "\n",
    "html = html + \"\"\"\n",
    "    <p> Dan Berikut data penjualan E-Com <b> (Before PPN) tanggal {tanggal} </b> per Brand :</p>\n",
    "\"\"\".format(tanggal = str(datetime.today().date().strftime('%B %d, %Y'))) \n",
    "\n",
    "\n",
    "html = html + table_brand.to_html(classes='wide', escape=False).replace('&lt;b&gt;', '<b>').replace('&lt;/b&gt;', '</b>')\n",
    "\n",
    "\n",
    "\n",
    "html = html + \"\"\"\n",
    "    <p> Dan berikut data penjualan E-Com (Before PPN) per Item :</p>\n",
    "    <p> Item Launching : </p>\"\"\"\n",
    "\n",
    "html = html + new_table_launch.to_html(classes='wide', escape=False)\n",
    "\n",
    "html = html + \"<p> HiLo : </p>\"    \n",
    "\n",
    "html = html + table_hilo.to_html(classes='wide', escape=False)\n",
    "\n",
    "html = html + \"<p> L-Men : </p>\"    \n",
    "\n",
    "html = html + table_lmen.to_html(classes='wide', escape=False)\n",
    "\n",
    "html = html + \"<p> NutriSari : </p>\"    \n",
    "\n",
    "html = html + table_ns.to_html(classes='wide', escape=False)\n",
    "\n",
    "html = html + \"<p> Tropicana Slim : </p>\"    \n",
    "\n",
    "html = html + table_ts.to_html(classes='wide', escape=False)\n",
    "\n",
    "html = html + \"\"\"\n",
    "    <p></p>\n",
    "    <p> Best regards, </p>\n",
    "    <p> E-Commerce Nutrifood </p>\n",
    "<body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "Msg.HTMLBody = html\n",
    "Msg.Send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "324514f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order #\n",
      "Sales Order ID\n",
      "AWB\n",
      "Paid Date\n",
      "Order Status\n",
      "Order date\n",
      "Week\n",
      "Date\n",
      "Month\n",
      "Quarter\n",
      "Year\n",
      "Channel\n",
      "SKU\n",
      "Brand\n",
      "Product Name\n",
      "Bundle Name\n",
      "Price List NFI\n",
      "Qty. Invoiced\n",
      "Total Net\n",
      "Sub Brand\n",
      "Real SKU\n",
      "Real Nama Produk\n",
      "Parent Item\n",
      "Parent SKU\n",
      "Bundle Flag\n",
      "Customer Email\n",
      "Customer Name\n",
      "Customer Group\n",
      "Phone\n",
      "Country\n",
      "Region\n",
      "City\n",
      "Kecamatan\n",
      "Kelurahan\n",
      "Address\n",
      "Zip Code\n",
      "Shipping Name\n",
      "Shipping Courier\n",
      "Total\n",
      "Coupon Code\n",
      "Qty. Ordered\n",
      "Qty. Shipped\n",
      "Qty. Refunded\n",
      "Item Price\n",
      "Subtotal\n",
      "Discounts\n",
      "Tax\n",
      "Total incl. Tax\n",
      "Invoiced\n",
      "Tax Invoiced\n",
      "Invoiced incl. Tax\n",
      "Refunded\n",
      "Refunded incl. Tax\n",
      "Cart Name Rule\n",
      "Payment Channel\n",
      "Voucher Amount\n",
      "Discount Poin Reward\n",
      "Ship Date\n",
      "Discount Product\n",
      "Produk 1\n",
      "SKU Produk 1\n",
      "PCS Produk 1\n",
      "Price List NFI 1\n",
      "Subtotal Produk 1\n",
      "Harga Display 1\n",
      "Harga Cost 1\n",
      "Produk 2\n",
      "SKU Produk 2\n",
      "PCS Produk 2\n",
      "Price List NFI 2\n",
      "Subtotal Produk 2\n",
      "Harga Display 2\n",
      "Harga Cost 2\n",
      "Produk 3\n",
      "SKU Produk 3\n",
      "PCS Produk 3\n",
      "Price List NFI 3\n",
      "Subtotal Produk 3\n",
      "Harga Display 3\n",
      "Harga Cost 3\n",
      "Produk 4\n",
      "SKU Produk 4\n",
      "PCS Produk 4\n",
      "Price List NFI 4\n",
      "Subtotal Produk 4\n",
      "Harga Display 4\n",
      "Harga Cost 4\n",
      "Produk 5\n",
      "SKU Produk 5\n",
      "PCS Produk 5\n",
      "Price List NFI 5\n",
      "Subtotal Produk 5\n",
      "Harga Display 5\n",
      "Harga Cost 5\n",
      "Produk 6\n",
      "SKU Produk 6\n",
      "PCS Produk 6\n",
      "Price List NFI 6\n",
      "Subtotal Produk 6\n",
      "Harga Display 6\n",
      "Harga Cost 6\n",
      "Produk 7\n",
      "SKU Produk 7\n",
      "PCS Produk 7\n",
      "Price List NFI 7\n",
      "Subtotal Produk 7\n",
      "Harga Display 7\n",
      "Harga Cost 7\n",
      "Cancelled Date\n",
      "Currency Code\n",
      "Bundle\n",
      "Loc ID\n",
      "Barcode ID\n",
      "Warehouse Name\n",
      "Regular Price\n",
      "Selling Price\n",
      "VAT\n",
      "Shipping\n",
      "Actual Shipping\n",
      "Seller Discount\n",
      "Seller Rebate\n",
      "Gross Sales\n",
      "Shipping Address2\n",
      "Notes\n",
      "Store\n",
      "Qty. Ordered\"\n",
      "Qty. Shipped\"\n",
      "Harga Organik 1\n",
      "Harga Organik 2\n",
      "Harga Organik 3\n",
      "Harga Organik 4\n",
      "Harga Organik 5\n",
      "Harga Organik 6\n",
      "Harga Organik 7\n",
      "Kode SKU\n",
      "Blibli SKU\n",
      "Kode Merchant\n",
      "True datetime\n",
      "Promo\n",
      "Discount MC\n",
      "Harga Cost\n",
      "Total Harga Cost\n",
      "No. Order Item L-Men Blibli\n",
      "Order Voucher Amount\n",
      "Item Voucher Amount\n",
      "Item Voucher Platform\n",
      "Item Voucher Seller\n",
      "nominal\n",
      "btlcost\n",
      "gs\n",
      "commfee\n",
      "fullfee\n",
      "index\n",
      "Phone Condition\n",
      "Warehouse Code\n",
      "Channel Rebate\n",
      "Shipping Province\n",
      "Shipping City\n",
      "Shipping Address1\n",
      "Shipping Phone\n",
      "Hour\n",
      "payment_status\n",
      "Shipping Cost\n",
      "Invoice Number\n",
      "Shopee Order\n",
      "Shopee Cust\n",
      "Store Type\n",
      "Category\n",
      "Real SKU_y\n",
      "Region Group\n",
      "PL Before PPN\n",
      "Total Net Before PPN\n",
      "Payment Status\n",
      "Payment Type\n",
      "Printed Date\n",
      "Fulfilled Date\n",
      "Delivered Date\n",
      "Return ID\n",
      "Return Reference No.\n",
      "Return Date\n",
      "Service Type\n",
      "Bundle SKU Code\n",
      "Location ID\n",
      "Invoice ID\n",
      "Invoice Reference Number\n",
      "Invoice Status\n",
      "Invoice Create Date\n",
      "Fee Amount\n",
      "Invoice Amount\n",
      "Payment Received ID\n",
      "Payment Received Ref. number\n",
      "Category Baru\n",
      "Exported Parent Item\n",
      "Unnamed: 0\n",
      "Price List NFI_x\n",
      "Customer Type\n",
      "Real Region\n",
      "True datetime1\n",
      "Payment Date\n",
      "Shipping Customer Name\n"
     ]
    }
   ],
   "source": [
    "for i in data_all.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9b2060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0ffff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624a5b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63de1f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc53e928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be04262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ea8cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9b697f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee7bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e98b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c50c9f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7459902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886fe621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c8ff9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Settlement Finish\n"
     ]
    }
   ],
   "source": [
    "s_sp = pd.read_excel(r\"D:\\Masterdata\\Settlement\\Runningan Shopee Jan 2021 - Nov 22.xlsx\",sheet_name = 'Runningan Shopee',converters = {'Phone' : str, 'Order #' : str})\n",
    "s_sp['Customer Phone']=s_sp['No. Telepon'].str.extract('(\\d+)')\n",
    "s_sp['Real SKU'] = s_sp['Real SKU'].astype(str)\n",
    "s_sp['Order #'] = s_sp['No. Pesanan']\n",
    "s_sp['Order Status'] = s_sp['Status Pesanan']\n",
    "print('Data Settlement Finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "62026746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cancel', 'Selesai', 'Batal', 'Sedang Dikirim', 'Perlu Dikirim',\n",
       "       'Belum Bayar'], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#s_sp['Order Status'] = s_sp['Status Pesanan']\n",
    "s_sp['Order Status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cab71aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['220124MUQE0B2C', '220124N565JVHM', '220124N6JXYQN6', ...,\n",
       "       '220209210HYCVE', '220521REYRSDSW', '220509NWCCXX7P'], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.merge(s_sp[['Order #','Month','Order Status']], data_all['Order #'], on=['Order #'], how='left', indicator='exists')\n",
    "#all_df[all_df['exists'] == 'left_only'].sort_values('Month')\n",
    "#all_df['exists'].unique()\n",
    "mis_inv = all_df[all_df['exists'] == 'left_only']['Order #'].unique()\n",
    "mis_inv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b039273c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['left_only', 'both']\n",
       "Categories (3, object): ['left_only', 'right_only', 'both']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_sp = s_sp[s_tok['Order #'].isin(mis_inv)]\n",
    "mis_tok = mis_tok[mis_sp['Order Status'].str.contains('Dikirim|Selesai|Tiba', case = False, na = False)]\n",
    "mis_tok['day'] = mis_tok['Date'].astype(int)\n",
    "mis_tok['month'] = mis_tok['Month'].apply(lambda x : 9 if x == 'September' else\n",
    "                                                 (10 if x == 'October' else\n",
    "                                                 (11 if x == 'Novebmer' else \n",
    "                                                 (12 if x == 'December' else\n",
    "                                                 (1 if x == 'January' else\n",
    "                                                 (2 if x == 'February' else\n",
    "                                                 (3 if x == 'March' else\n",
    "                                                 (4 if x == 'April' else\n",
    "                                                 (5 if x == 'May' else\n",
    "                                                 (6 if x == 'June' else\n",
    "                                                 (7 if x == 'July' else 8)))))))))))\n",
    "mis_tok['True datetime'] = pd.to_datetime(mis_tok[['Year','month','day']])\n",
    "mis_tok['Phone'] = mis_tok['Customer Phone'].astype(str)\n",
    "mis_tok['Store Type'] = 'Marketplace'\n",
    "mis_tok['Store'] = 'Tokopedia'\n",
    "print('Repairing Table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a2975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_tok = s_tok[s_tok['Order #'].isin(mis_inv)]\n",
    "mis_tok = mis_tok[mis_tok['Order Status'].str.contains('Dikirim|Selesai|Tiba', case = False, na = False)]\n",
    "mis_tok['day'] = mis_tok['Date'].astype(int)\n",
    "mis_tok['month'] = mis_tok['Month'].apply(lambda x : 9 if x == 'September' else\n",
    "                                                 (10 if x == 'October' else\n",
    "                                                 (11 if x == 'Novemer' else \n",
    "                                                 (12 if x == 'December' else\n",
    "                                                 (1 if x == 'January' else\n",
    "                                                 (2 if x == 'February' else\n",
    "                                                 (3 if x == 'March' else\n",
    "                                                 (4 if x == 'April' else\n",
    "                                                 (5 if x == 'May' else\n",
    "                                                 (6 if x == 'June' else\n",
    "                                                 (7 if x == 'July' else 8)))))))))))\n",
    "mis_tok['True datetime'] = pd.to_datetime(mis_tok[['Year','month','day']])\n",
    "mis_tok['Phone'] = mis_tok['Customer Phone'].astype(str)\n",
    "mis_tok['Store Type'] = 'Marketplace'\n",
    "mis_tok['Store'] = 'Tokopedia'\n",
    "print('Repairing Table')\n",
    "\n",
    "kolom = data_all.columns\n",
    "\n",
    "data_all1 = data_all.append(mis_tok)\n",
    "data_all = data_all1[kolom]\n",
    "print('Finish Appending TokPed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1a4a214e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ffee70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31631af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                 Type              Data/Info\n",
      "----------------------------------------------------\n",
      "ActionChains             type              <class 'selenium.webdrive<...>ion_chains.ActionChains'>\n",
      "By                       type              <class 'selenium.webdriver.common.by.By'>\n",
      "ChromeDriverManager      type              <class 'webdriver_manager<...>ome.ChromeDriverManager'>\n",
      "EC                       module            <module 'selenium.webdriv<...>\\expected_conditions.py'>\n",
      "Keys                     type              <class 'selenium.webdriver.common.keys.Keys'>\n",
      "MIMEApplication          type              <class 'email.mime.application.MIMEApplication'>\n",
      "MIMEMultipart            type              <class 'email.mime.multipart.MIMEMultipart'>\n",
      "MIMEText                 type              <class 'email.mime.text.MIMEText'>\n",
      "NoSuchElementException   type              <class 'selenium.common.e<...>.NoSuchElementException'>\n",
      "Options                  type              <class 'selenium.webdrive<...>.chrome.options.Options'>\n",
      "SKU                      DataFrame                           SKU   B<...>[4402 rows x 124 columns]\n",
      "SKU_append               DataFrame                 ID            SKU<...>[3789 rows x 113 columns]\n",
      "SKU_baru                 DataFrame              Brand Category (Saat<...>n\\n[856 rows x 7 columns]\n",
      "SKU_final                DataFrame                         SKU Brand<...>[4402 rows x 130 columns]\n",
      "SMTP                     type              <class 'smtplib.SMTP'>\n",
      "Service                  type              <class 'selenium.webdrive<...>.chrome.service.Service'>\n",
      "WebDriverWait            type              <class 'selenium.webdrive<...>port.wait.WebDriverWait'>\n",
      "actions                  ActionChains      <selenium.webdriver.commo<...>ct at 0x000001F18633AAC0>\n",
      "address                  str               Rendy Gustama\\nJl. Al-Muj<...> Tangerang, Banten\\n15156\n",
      "after                    list              n=414\n",
      "all_single               DataFrame                                  <...>63060 rows x 211 columns]\n",
      "before                   list              n=413\n",
      "bundle_name              list              n=2\n",
      "change                   set               set()\n",
      "city                     DataFrame                         All City <...>\\n[1183 rows x 2 columns]\n",
      "colname                  str               January 2024\n",
      "cols                     list              n=9\n",
      "cond                     bool              True\n",
      "cutoff                   str               2024-01-01\n",
      "data                     dict              n=2\n",
      "data_SKU                 DataFrame                           SKU   B<...>[4402 rows x 124 columns]\n",
      "data_adasku              DataFrame                                  <...>n[63141 rows x 2 columns]\n",
      "data_all                 DataFrame                                  <...>25063 rows x 211 columns]\n",
      "data_bulan               DataFrame                 Bulan  Number\\n0 <...>10\\n11   November      11\n",
      "data_bundle              DataFrame                 Order # No. Order<...>n\\n[78 rows x 89 columns]\n",
      "data_bundle1             DataFrame                  Order # No. Orde<...>n\\n[72 rows x 89 columns]\n",
      "data_bundle2             DataFrame                  Order # No. Orde<...>\\n\\n[6 rows x 89 columns]\n",
      "data_bundle3             DataFrame         Empty DataFrame\\nColumns:<...>\\n\\n[0 rows x 89 columns]\n",
      "data_bundle4             DataFrame         Empty DataFrame\\nColumns:<...>\\n\\n[0 rows x 89 columns]\n",
      "data_bundle5             DataFrame         Empty DataFrame\\nColumns:<...>\\n\\n[0 rows x 89 columns]\n",
      "data_bundle6             DataFrame         Empty DataFrame\\nColumns:<...>\\n\\n[0 rows x 89 columns]\n",
      "data_bundle7             DataFrame         Empty DataFrame\\nColumns:<...>\\n\\n[0 rows x 89 columns]\n",
      "data_magento             DataFrame                 Order #     Order<...>n[564 rows x 124 columns]\n",
      "data_magentoUser         DataFrame                         Order dat<...>[20654 rows x 23 columns]\n",
      "data_magentoUser2        DataFrame                    Order date  Ch<...>\\n[430 rows x 22 columns]\n",
      "data_nosku               DataFrame                                  <...> Strawberry Pop 400g  NaN\n",
      "data_now                 str               5 February With Order Online\n",
      "data_nubi                DataFrame                                  <...>[8948 rows x 195 columns]\n",
      "data_nubinew             DataFrame                               Sal<...>\\n[135 rows x 37 columns]\n",
      "data_success             DataFrame                                  <...>59900 rows x 211 columns]\n",
      "date                     type              <class 'datetime.date'>\n",
      "date_from                WebElement        <selenium.webdriver.remot<...>41836B94099_element_59\")>\n",
      "date_min                 Timestamp         2024-01-24 00:00:00\n",
      "date_to                  WebElement        <selenium.webdriver.remot<...>41836B94099_element_60\")>\n",
      "datefield                WebElement        <selenium.webdriver.remot<...>E0B304AD322_element_71\")>\n",
      "datetime                 type              <class 'datetime.datetime'>\n",
      "diff_date                int               10\n",
      "district                 DataFrame                         All Distr<...>n\\n[792 rows x 2 columns]\n",
      "download                 bool              True\n",
      "driver                   WebDriver         <selenium.webdriver.chrom<...>cfc8332bcd6882d0b094e3\")>\n",
      "dt                       datetime          2023-11-01 00:00:00\n",
      "duplicate                str               Tropicana Slim Susu Skim <...>Bantu Turunkan Kolesterol\n",
      "duration                 int               0\n",
      "email                    str               gus****************\n",
      "end                      time              10:52:00\n",
      "end_date                 datetime          2024-01-31 11:42:27.811639\n",
      "enddate                  str               2024-02-05\n",
      "file_name                str               bulk-order-download-template.csv\n",
      "fin_n_elem               int               1\n",
      "first_date               Timestamp         2023-11-01 00:00:00\n",
      "forstok_all              DataFrame                         Order dat<...>82241 rows x 137 columns]\n",
      "forstok_all_sku          DataFrame                                  <...>\\n[2405 rows x 4 columns]\n",
      "gaada_sku                DataFrame         Empty DataFrame\\nColumns:<...>, Toko/Gudang]\\nIndex: []\n",
      "glob                     module            <module 'glob' from 'C:\\\\<...>Anaconda3\\\\lib\\\\glob.py'>\n",
      "highlight_max            function          <function highlight_max at 0x000001F190199280>\n",
      "hp                       str               081********\n",
      "i                        str               November 2023\n",
      "idx                      list              n=0\n",
      "idx_hd                   list              n=0\n",
      "idx_s                    list              n=0\n",
      "indeks                   list              n=0\n",
      "index                    list              n=39066\n",
      "itemname                 str               Tropicana Slim Susu Skim <...>Bantu Turunkan Kolesterol\n",
      "j                        str               Alias SKU 13\n",
      "k                        int               1629\n",
      "last_date                Timestamp         2023-12-01 00:00:00\n",
      "latest_file              str               data_nubi\\data_nubi_2024-02-02.xlsx\n",
      "link                     str               https://seller.blibli.com<...>5&orderItemNo=12206729469\n",
      "list_alias               list              n=13\n",
      "list_alias_name          list              n=13\n",
      "list_bundle              DataFrame                 Order #          <...>n\\n[214 rows x 4 columns]\n",
      "list_city                list              n=11\n",
      "list_col                 list              n=57\n",
      "list_nobundle            DataFrame                 Order #        Or<...>n[224 rows x 124 columns]\n",
      "list_of_files            list              n=41\n",
      "list_pcs                 list              n=7\n",
      "list_skumiss             list              n=0\n",
      "lmen                     DataFrame                  Order # No. Orde<...>\\n[293 rows x 94 columns]\n",
      "lmen_pure                DataFrame                   No. Order  No. <...>\\n[215 rows x 16 columns]\n",
      "lmen_sku                 DataFrame                    SKU Merchant  <...>\\n\\n[63 rows x 5 columns]\n",
      "lmen_store               DataFrame                   Order date     <...>\\n[31 rows x 137 columns]\n",
      "magentoUser_scrape       bool              True\n",
      "magento_name             str               export_sales_detailed_report_321661.csv\n",
      "magento_pure             DataFrame                 Order #     Order<...>\\n[564 rows x 42 columns]\n",
      "magento_scrape           bool              True\n",
      "magentouser_name         str               export_321662.csv\n",
      "master_map               DataFrame              Kode Prov Province  <...>n\\n[514 rows x 4 columns]\n",
      "master_map2              DataFrame              Kode City  Kode Prov<...>n\\n[514 rows x 3 columns]\n",
      "math                     module            <module 'math' (built-in)>\n",
      "monthrange               function          <function monthrange at 0x000001F1EF9F14C0>\n",
      "mtd_date                 Timestamp         2024-02-01 00:00:00\n",
      "mtd_sales                DataFrame             Brand               S<...>   TS MERAH  2.141939e+08\n",
      "n_elem                   int               2\n",
      "new_name                 str               Blibli 2024-01-22-2024-02-05.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_name                  DataFrame                                  <...>13703 rows x 214 columns]\n",
      "no_pair                  DataFrame                           SKU Bra<...>[4030 rows x 130 columns]\n",
      "non_phone                ndarray           0: 0 elems, type `object`, 0 bytes\n",
      "non_phone1               DataFrame         Empty DataFrame\\nColumns:<...>[Store, Phone]\\nIndex: []\n",
      "np                       module            <module 'numpy' from 'C:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "null_sku                 DataFrame         Empty DataFrame\\nColumns:<...>, Toko/Gudang]\\nIndex: []\n",
      "number_of_days           int               29\n",
      "options                  Options           <selenium.webdriver.chrom<...>ct at 0x000001F187D67D60>\n",
      "orderItemNo              int               12206729469\n",
      "orderNo                  str               12147325855\n",
      "ornum                    DataFrame                    Order # Sales <...>hidin I No.16, RT.00...  \n",
      "os                       module            <module 'os' from 'C:\\\\Us<...>\\\\Anaconda3\\\\lib\\\\os.py'>\n",
      "osf                      DataFrame                                 o<...>\\n\\n[82 rows x 1 columns]\n",
      "output                   BufferedWriter    <_io.BufferedWriter name=<...>an 2024-05 Feb 2024.xls'>\n",
      "password                 WebElement        <selenium.webdriver.remot<...>6E0B304AD322_element_6\")>\n",
      "pd                       module            <module 'pandas' from 'C:<...>es\\\\pandas\\\\__init__.py'>\n",
      "pilih                    int               3\n",
      "product                  ndarray           0: 0 elems, type `object`, 0 bytes\n",
      "province                 DataFrame                All Province  Real<...>\\n\\n[85 rows x 2 columns]\n",
      "quarter                  DataFrame                 Bulan  Quarter\\n0<...>4\\n11   December        4\n",
      "r                        Response          <Response [200]>\n",
      "re                       module            <module 're' from 'C:\\\\Us<...>\\\\Anaconda3\\\\lib\\\\re.py'>\n",
      "relativedelta            type              <class 'dateutil.relativedelta.relativedelta'>\n",
      "requests                 module            <module 'requests' from '<...>\\\\requests\\\\__init__.py'>\n",
      "rrule                    module            <module 'dateutil.rrule' <...>ges\\\\dateutil\\\\rrule.py'>\n",
      "s                        Session           <requests.sessions.Sessio<...>ct at 0x000001F1FF450E80>\n",
      "shopee_bp                DataFrame         Empty DataFrame\\nColumns:<...>n\\n[0 rows x 211 columns]\n",
      "shopee_con               DataFrame                                  <...>\\n\\n[69 rows x 4 columns]\n",
      "sku_exclude              list              n=2\n",
      "skuhd                    DataFrame         Empty DataFrame\\nColumns:<...>\\n\\n[0 rows x 45 columns]\n",
      "skuj                     DataFrame                  Bundle SKU      <...>n\\n[172 rows x 4 columns]\n",
      "skuj1                    ndarray           30: 30 elems, type `object`, 240 bytes\n",
      "skuj2                    DataFrame                  Bundle SKU      <...>\\n[174 rows x 10 columns]\n",
      "skuj3                    ndarray           63: 63 elems, type `object`, 504 bytes\n",
      "skuoff                   DataFrame               Real SKU  Price Lis<...>101907017           14300\n",
      "skushopee                DataFrame         Empty DataFrame\\nColumns:<...>\\n\\n[0 rows x 45 columns]\n",
      "smtplib                  module            <module 'smtplib' from 'C<...>conda3\\\\lib\\\\smtplib.py'>\n",
      "start_date               Timestamp         2023-11-01 00:00:00\n",
      "start_time               float             1707105878.841228\n",
      "startdate                datetime          2024-01-23 11:12:15.111527\n",
      "startdate1               str               2024-01-23\n",
      "sub                      function          <function sub at 0x000001F1ED4609D0>\n",
      "sys                      module            <module 'sys' (built-in)>\n",
      "table_brand              DataFrame             Brand               S<...>      NaN           NaN  \n",
      "table_ecom               DataFrame                                  <...>25890367      183937143  \n",
      "table_ecom2              DataFrame                                  <...>25890367      183937143  \n",
      "temp                     DataFrame                                  <...>25063 rows x 211 columns]\n",
      "temp2                    DataFrame             Shipping Province Shi<...>n\\n[564 rows x 6 columns]\n",
      "temp_all                 DataFrame                                  <...>97163 rows x 211 columns]\n",
      "temp_group               DataFrame                                  <...>n[46293 rows x 2 columns]\n",
      "temp_sales               DataFrame         Empty DataFrame\\nColumns:<...> January 2024]\\nIndex: []\n",
      "tes                      DataFrame                         Order dat<...>n\\n[6 rows x 137 columns]\n",
      "tes1                     DataFrame                      Order date  <...>\\n[33 rows x 136 columns]\n",
      "text                     str               https://forstok-staging-s<...>2024-02-05T16:59:59Z.xlsx\n",
      "time                     module            <module 'time' (built-in)>\n",
      "time_notif               str               10:52\n",
      "time_notif1              str               10:52\n",
      "time_now                 str               10:52\n",
      "timedelta                type              <class 'datetime.timedelta'>\n",
      "to_excel                 NoneType          None\n",
      "today                    Timestamp         2024-02-05 00:00:00\n",
      "username                 WebElement        <selenium.webdriver.remot<...>6E0B304AD322_element_5\")>\n",
      "val                      str               February\n",
      "webdriver                module            <module 'selenium.webdriv<...>\\webdriver\\\\__init__.py'>\n",
      "yesterday                Timestamp         2024-02-04 00:00:00\n",
      "yesterday_sales          DataFrame             Brand               S<...>TS MERAH     3.071924e+07\n",
      "zipnotmapped             ndarray           0: 0 elems, type `object`, 0 bytes\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bc155c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_magentoUser, forstok_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cf68b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b28664c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd. __version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3f8903",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all['Year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c6ae5b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = data_all[data_all['True datetime'] >= '2022-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0653d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "### run 14\n",
    "### export masterdata\n",
    "data_all.to_csv(r'D:\\Masterdata\\Clean Data\\data_all_' + data_now + '.csv', sep = ';', index = False)\n",
    "\n",
    "\n",
    "###OPTIONAL - Temporary Clean Data kalau Python Error\n",
    "#data_all.to_csv(r'D:\\Masterdata\\Clean Data\\data_all_' + data_now + '_temp.csv', sep = ';', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1542d075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "77740625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9964b88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_11088\\425283804.py:20: DtypeWarning: Columns (12,15,20,24,25,27,29,30,31,32,33,34,35,36,37,39,53,54,57,59,60,66,67,73,74,80,81,87,88,94,95,101,102,108,122,123,134,135,136,153,159,161,167,168,169,172,173,174,175,176,180,181,183,196,197,198,199,200,201,202,203,205,209,210) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_all =pd.read_csv(r\"D:\\Masterdata\\Clean Data\\data_all_5 February With Order Online_temp.csv\", sep = ';',converters = {'Phone' : str, 'Order #' : str, 'AWB' : str})\n"
     ]
    }
   ],
   "source": [
    "###Optional\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from smtplib import SMTP\n",
    "import smtplib\n",
    "import sys\n",
    "import requests\n",
    "import os\n",
    "\n",
    "data_all =pd.read_csv(r\"D:\\Masterdata\\Clean Data\\data_all_5 February With Order Online_temp.csv\", sep = ';',converters = {'Phone' : str, 'Order #' : str, 'AWB' : str})\n",
    "\n",
    "data_all['True datetime']=pd.to_datetime(data_all['True datetime'])\n",
    "data_all['Real SKU']=data_all['Real SKU'].astype(str)\n",
    "data_all['Phone']=data_all['Phone'].str.extract('(\\d+)')\n",
    "\n",
    "data_now = '5 February With Order Online'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487548fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f175344a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f68978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e22f1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2899a604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a0ea376",
   "metadata": {},
   "source": [
    "Export Lite Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01d452d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sumatera 1\n",
      "BARA\n",
      "Sumatera 2\n",
      "Jabodetabek\n",
      "Jawa Tengah\n",
      "Kalimantan\n",
      "Sulawesi\n",
      "Jawa Timur\n",
      "Jawa Barat\n",
      "PUMA\n"
     ]
    }
   ],
   "source": [
    "mappingarea=pd.read_excel(\"data_supp\\Database Area untuk Report.xlsx\")\n",
    "mappingarea=mappingarea.rename(columns=({'Region':'Real Region',\"City\":'Region Group'}))\n",
    "# temp=data_all.merge(mappingarea,how='left')\n",
    "# temp.loc[temp['Region Group'].isnull(),'Real Region']='Retail Online'\n",
    "for i in mappingarea['Real Region'].unique():\n",
    "    print(i)\n",
    "    reg=mappingarea[mappingarea['Real Region']==i]['Region Group'].unique()\n",
    "    data_all.loc[data_all['Region Group'].isin(reg),'Real Region']=i\n",
    "data_all.loc[data_all['Region Group'].isnull(),'Real Region']='Retail Online'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41230ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "##NOT USED\n",
    "from datetime import date\n",
    "osf=pd.read_excel(r\"data_supp\\order filter.xlsx\")\n",
    "data_all[(data_all['Year'].isin([2021,2022]))&\n",
    "         (data_all['Order Status'].isin(osf['order filter'].unique()))].groupby(['Year','Month','Store Type','Store','Channel','Real Region','Warehouse Name','Order Status','Region Group','Coupon Code','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name'],dropna=False).agg({'Order #':'nunique','Phone':'nunique','Qty. Invoiced':'sum','Total Net Before PPN':'sum'}).reset_index().to_excel(f'masterdata_{date.today()}_lite.xlsx',index=False)\n",
    "# data_all.groupby(['Year','Month','Date','Store Type','Store','Channel','Order Status'])[['Order #']].nunique().reset_index().to_excel(f'Cek order gerak {date.today()}.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc8d6f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "osf=pd.read_excel(r\"data_supp\\order filter.xlsx\")\n",
    "data_all[(data_all['True datetime'] >= '2023-11-01')&\n",
    "         (data_all['Order Status'].isin(osf['order filter'].unique()))].groupby(['Year','Month','Date','Hour','Store Type','Store','Channel','Warehouse Name','Real Region','City','Coupon Code','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name','Exported Parent Item'],dropna=False).agg({'Order #':'nunique','Phone':'nunique','Qty. Invoiced':'sum','Total Net Before PPN':'sum'}).reset_index().to_excel(f'D:\\Masterdata\\Masterdata Lite\\masterdata_{date.today()}_lite new.xlsx',index=False)\n",
    "# data_all.groupby(['Year','Month','Date','Store Type','Store','Channel','Order Status'])[['Order #']].nunique().reset_index().to_excel(f'Cek order gerak {date.today()}.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e9d4098",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This sheet is too large! Your sheet size is: 1362807, 26 Max sheet size is: 1048576, 16384",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdata_all\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata_all\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrue datetime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2023-01-01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOrder #\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOrder Status\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMonth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWeek\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStore Type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mChannel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBrand\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReal SKU\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReal Nama Produk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBundle Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQty. Invoiced\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTotal Net Before PPN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTotal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCoupon Code\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCustomer Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCustomer Email\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPhone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAddress\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWarehouse Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRegion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRegion Group\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReal Region\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mMasterdata\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mMasterdata Lite\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mMasterdata Lite Order \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoday\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2357\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes, storage_options)\u001b[0m\n\u001b[0;32m   2344\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2346\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2347\u001b[0m     df,\n\u001b[0;32m   2348\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2355\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2356\u001b[0m )\n\u001b[1;32m-> 2357\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2359\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2365\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\excel.py:873\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[0;32m    871\u001b[0m num_rows, num_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_rows \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_rows \u001b[38;5;129;01mor\u001b[39;00m num_cols \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_cols:\n\u001b[1;32m--> 873\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    874\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis sheet is too large! Your sheet size is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_rows\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    875\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax sheet size is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_rows\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    876\u001b[0m     )\n\u001b[0;32m    878\u001b[0m formatted_cells \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_formatted_cells()\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(writer, ExcelWriter):\n",
      "\u001b[1;31mValueError\u001b[0m: This sheet is too large! Your sheet size is: 1362807, 26 Max sheet size is: 1048576, 16384"
     ]
    }
   ],
   "source": [
    "data_all[data_all['True datetime']>'2023-01-01'][['Order #','Order Status','Year','Month','Week','Date','Store Type','Store',\n",
    "                                                  'Channel','Brand','Real SKU','Real Nama Produk','Bundle Name','Qty. Invoiced',\n",
    "                                                  'Total Net Before PPN','Total','Coupon Code','Customer Name','Customer Email',\n",
    "                                                  'Phone','Address','Warehouse Name','City','Region','Region Group','Real Region']].to_excel(f'D:\\Masterdata\\Masterdata Lite\\Masterdata Lite Order {date.today()}.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2798d90",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This sheet is too large! Your sheet size is: 1121077, 26 Max sheet size is: 1048576, 16384",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdata_all\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_all\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrue datetime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2022-04-01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOrder #\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOrder Status\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMonth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWeek\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStore Type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mChannel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBrand\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReal SKU\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReal Nama Produk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBundle Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQty. Invoiced\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTotal Net Before PPN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTotal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCoupon Code\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCustomer Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCustomer Email\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPhone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAddress\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWarehouse Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRegion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRegion Group\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReal Region\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMasterdata Lite Order \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoday\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2374\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes, storage_options)\u001b[0m\n\u001b[0;32m   2361\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2363\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2364\u001b[0m     df,\n\u001b[0;32m   2365\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2372\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2373\u001b[0m )\n\u001b[1;32m-> 2374\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2376\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2382\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\excel.py:907\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[0;32m    905\u001b[0m num_rows, num_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_rows \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_rows \u001b[38;5;129;01mor\u001b[39;00m num_cols \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_cols:\n\u001b[1;32m--> 907\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis sheet is too large! Your sheet size is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_rows\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    909\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax sheet size is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_rows\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    910\u001b[0m     )\n\u001b[0;32m    912\u001b[0m formatted_cells \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_formatted_cells()\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(writer, ExcelWriter):\n",
      "\u001b[1;31mValueError\u001b[0m: This sheet is too large! Your sheet size is: 1121077, 26 Max sheet size is: 1048576, 16384"
     ]
    }
   ],
   "source": [
    "data_all[(data_all['True datetime']>'2022-04-01')][['Order #','Order Status','Year','Month','Week','Date','Store Type','Store',\n",
    "                                                  'Channel','Brand','Real SKU','Real Nama Produk','Bundle Name','Qty. Invoiced',\n",
    "                                                  'Total Net Before PPN','Total','Coupon Code','Customer Name','Customer Email',\n",
    "                                                  'Phone','Address','Warehouse Name','City','Region','Region Group','Real Region']].to_excel(f'Masterdata Lite Order {date.today()}.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc94e314",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tinggal append export\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This sheet is too large! Your sheet size is: 1465547, 23 Max sheet size is: 1048576, 16384",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m resa\u001b[38;5;241m=\u001b[39mdata_all[(data_all[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;241m2023\u001b[39m]))\u001b[38;5;241m&\u001b[39m(data_all[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrder Status\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(osf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder filter\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()))\u001b[38;5;241m&\u001b[39m\n\u001b[0;32m      7\u001b[0m                            (data_all[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStore Type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrganic\u001b[39m\u001b[38;5;124m'\u001b[39m)][[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrder #\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStore Type\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStore\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChannel\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCoupon Code\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBrand\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSub Brand\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReal SKU\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReal Nama Produk\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBundle Name\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQty. Invoiced\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Net\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Net Before PPN\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomer Name\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomer Email\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPhone\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPayment Channel\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCity\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReal Region\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtinggal append export\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mresb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresa\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mMasterdata\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mMasterdata Lite\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmasterdata_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoday\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_custlite v2.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2357\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes, storage_options)\u001b[0m\n\u001b[0;32m   2344\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2346\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2347\u001b[0m     df,\n\u001b[0;32m   2348\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2355\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2356\u001b[0m )\n\u001b[1;32m-> 2357\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2359\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2365\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\excel.py:873\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[0;32m    871\u001b[0m num_rows, num_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_rows \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_rows \u001b[38;5;129;01mor\u001b[39;00m num_cols \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_cols:\n\u001b[1;32m--> 873\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    874\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis sheet is too large! Your sheet size is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_rows\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    875\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax sheet size is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_rows\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    876\u001b[0m     )\n\u001b[0;32m    878\u001b[0m formatted_cells \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_formatted_cells()\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(writer, ExcelWriter):\n",
      "\u001b[1;31mValueError\u001b[0m: This sheet is too large! Your sheet size is: 1465547, 23 Max sheet size is: 1048576, 16384"
     ]
    }
   ],
   "source": [
    "##JANGAN PAKE\n",
    "from datetime import date\n",
    "osf=pd.read_excel(r\"data_supp\\order filter.xlsx\")\n",
    "resb=data_all[(data_all['Year'].isin([2023]))&(data_all['Order Status'].isin(osf['order filter'].unique()))].groupby(['Year','Month','Date','Store Type','Store','Channel','Coupon Code','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name','Payment Channel','City','Real Region'],dropna=False).agg({'Order #':'nunique','Phone':'nunique','Qty. Invoiced':'sum','Total Net Before PPN':'sum','Total Net' : 'sum'}).reset_index()\n",
    "resb=resb[resb['Store Type']!='Organic']#['Store'].unique()\n",
    "resa=data_all[(data_all['Year'].isin([2023]))&(data_all['Order Status'].isin(osf['order filter'].unique()))&\n",
    "                           (data_all['Store Type']=='Organic')][['Order #','Year','Month','Date','Store Type','Store','Channel','Coupon Code','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name','Qty. Invoiced','Total','Total Net','Total Net Before PPN','Customer Name','Customer Email','Phone','Payment Channel','City','Real Region']]\n",
    "print('tinggal append export')\n",
    "resb.append(resa).to_excel(f'D:\\Masterdata\\Masterdata Lite\\masterdata_{date.today()}_custlite v2.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febaf2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ba9114a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "osf=pd.read_excel(r\"data_supp\\order filter.xlsx\")\n",
    "cust_1 = data_all[(data_all['True datetime'] > '2023-10-01') &(data_all['Order Status'].isin(osf['order filter'].unique()))].groupby(['Order #','Year','Month','Date','Store Type','Store','Channel','Coupon Code','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name','Customer Name','Customer Email','Phone','Payment Channel','City','Real Region'], dropna = False).agg({'Qty. Invoiced':'sum','Total Net Before PPN':'sum','Total Net' : 'sum','Total' : 'sum'}).reset_index()\n",
    "#cust_2 = data_all[(data_all['True datetime'] > '2023-08-01')&(data_all['Order Status'].isin(osf['order filter'].unique()))].groupby(['Order #','Year','Month','Date','Store Type','Store','Channel','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name','Customer Name','Customer Email','Phone','Payment Channel','City','Region Group','Real Region'], dropna = False).agg({'Qty. Invoiced':'sum','Total Net Before PPN':'sum','Total Net' : 'sum','Total' : 'sum'}).reset_index()\n",
    "cust_1.to_excel(f'D:\\Masterdata\\Masterdata Lite\\masterdata_{date.today()}_custlite v2.xlsx',index=False)\n",
    "#cust_2.to_excel(f'D:\\Masterdata\\Masterdata Lite\\masterdata_{date.today()}_custlite v3.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c6b418b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Nutrimart', 'Order Online'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all[(data_all['Store Type']=='Organic')]['Store'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6755d6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tinggal append export\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_17104\\4093137161.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  resb.append(resa).to_excel(f'D:\\Masterdata\\Masterdata Lite\\masterdata_{date.today()}_custlite v3.xlsx',index=False)\n"
     ]
    }
   ],
   "source": [
    "##JANGAN PAKE\n",
    "from datetime import date\n",
    "osf=pd.read_excel(r\"data_supp\\order filter.xlsx\")\n",
    "resb=data_all[(data_all['Year'].isin([2023]))&(data_all['Order Status'].isin(osf['order filter'].unique()))].groupby(['Year','Month','Date','Store Type','Store','Channel','Coupon Code','Payment Channel','City','Real Region'],dropna=False).agg({'Order #':'nunique','Phone':'nunique','Qty. Invoiced':'sum','Total Net Before PPN':'sum'}).reset_index()\n",
    "resb=resb[resb['Store Type']!='Organic']#['Store'].unique()\n",
    "resa=data_all[(data_all['Year'].isin([2023]))&(data_all['Order Status'].isin(osf['order filter'].unique()))&\n",
    "                           (data_all['Store Type']=='Organic')][['Order #','Year','Month','Date','Store Type','Store','Channel','Coupon Code','Qty. Invoiced','Total','Total Net','Total Net Before PPN','Customer Name','Customer Email','Phone','Payment Channel','City','Real Region']]\n",
    "print('tinggal append export')\n",
    "resb.append(resa).to_excel(f'D:\\Masterdata\\Masterdata Lite\\masterdata_{date.today()}_custlite v3.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13c54ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WIM\n",
    "osf=pd.read_excel(r\"data_supp\\order filter.xlsx\")\n",
    "from datetime import date\n",
    "data_all.loc[data_all['Store']=='Blibli','Warehouse Name']='Blibli Warehouse'\n",
    "data_all.loc[data_all['Store'].isin(['Shopee', 'TikTok']),'Warehouse Name']='SSI Warehouse'\n",
    "data_all[(data_all['True datetime']>='2023-11-01')&(data_all['Order Status'].isin(osf['order filter'].unique()))][['Sales Order ID','Order #','Order Status','Year','Month','Week','Date','Store Type','Store',\n",
    "                                                  'Channel','Brand','Real SKU','Real Nama Produk','Bundle Name','Qty. Invoiced',\n",
    "                                                  'Total Net Before PPN','Total','Coupon Code','Customer Name','Customer Email',\n",
    "                                                  'Phone','Address','Warehouse Name','City','Region','Region Group','Real Region']].to_excel(f'D:\\Masterdata\\Masterdata Lite\\Masterdata Lite Order {date.today()}.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d1136d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2ad852bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all.loc[data_all['Store']=='Blibli','Warehouse Name']='Blibli Warehouse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4c8913e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Blibli Warehouse'], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.loc[data_all['Store']=='Blibli']['Warehouse Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e390ec81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order #\n",
      "Sales Order ID\n",
      "AWB\n",
      "Paid Date\n",
      "Order Status\n",
      "Order date\n",
      "Week\n",
      "Date\n",
      "Month\n",
      "Quarter\n",
      "Year\n",
      "Channel\n",
      "SKU\n",
      "Brand\n",
      "Product Name\n",
      "Bundle Name\n",
      "Price List NFI\n",
      "Qty. Invoiced\n",
      "Total Net\n",
      "Sub Brand\n",
      "Real SKU\n",
      "Real Nama Produk\n",
      "Parent Item\n",
      "Parent SKU\n",
      "Bundle Flag\n",
      "Customer Email\n",
      "Customer Name\n",
      "Customer Group\n",
      "Phone\n",
      "Country\n",
      "Region\n",
      "City\n",
      "Kecamatan\n",
      "Kelurahan\n",
      "Address\n",
      "Zip Code\n",
      "Shipping Name\n",
      "Shipping Courier\n",
      "Total\n",
      "Coupon Code\n",
      "Qty. Ordered\n",
      "Qty. Shipped\n",
      "Qty. Refunded\n",
      "Item Price\n",
      "Subtotal\n",
      "Discounts\n",
      "Tax\n",
      "Total incl. Tax\n",
      "Invoiced\n",
      "Tax Invoiced\n",
      "Invoiced incl. Tax\n",
      "Refunded\n",
      "Refunded incl. Tax\n",
      "Cart Name Rule\n",
      "Payment Channel\n",
      "Voucher Amount\n",
      "Discount Poin Reward\n",
      "Ship Date\n",
      "Discount Product\n",
      "Produk 1\n",
      "SKU Produk 1\n",
      "PCS Produk 1\n",
      "Price List NFI 1\n",
      "Subtotal Produk 1\n",
      "Harga Display 1\n",
      "Harga Cost 1\n",
      "Produk 2\n",
      "SKU Produk 2\n",
      "PCS Produk 2\n",
      "Price List NFI 2\n",
      "Subtotal Produk 2\n",
      "Harga Display 2\n",
      "Harga Cost 2\n",
      "Produk 3\n",
      "SKU Produk 3\n",
      "PCS Produk 3\n",
      "Price List NFI 3\n",
      "Subtotal Produk 3\n",
      "Harga Display 3\n",
      "Harga Cost 3\n",
      "Produk 4\n",
      "SKU Produk 4\n",
      "PCS Produk 4\n",
      "Price List NFI 4\n",
      "Subtotal Produk 4\n",
      "Harga Display 4\n",
      "Harga Cost 4\n",
      "Produk 5\n",
      "SKU Produk 5\n",
      "PCS Produk 5\n",
      "Price List NFI 5\n",
      "Subtotal Produk 5\n",
      "Harga Display 5\n",
      "Harga Cost 5\n",
      "Produk 6\n",
      "SKU Produk 6\n",
      "PCS Produk 6\n",
      "Price List NFI 6\n",
      "Subtotal Produk 6\n",
      "Harga Display 6\n",
      "Harga Cost 6\n",
      "Produk 7\n",
      "SKU Produk 7\n",
      "PCS Produk 7\n",
      "Price List NFI 7\n",
      "Subtotal Produk 7\n",
      "Harga Display 7\n",
      "Harga Cost 7\n",
      "Cancelled Date\n",
      "Currency Code\n",
      "Bundle\n",
      "Loc ID\n",
      "Barcode ID\n",
      "Warehouse Name\n",
      "Regular Price\n",
      "Selling Price\n",
      "VAT\n",
      "Shipping\n",
      "Actual Shipping\n",
      "Seller Discount\n",
      "Seller Rebate\n",
      "Gross Sales\n",
      "Shipping Address2\n",
      "Notes\n",
      "Store\n",
      "Qty. Ordered\"\n",
      "Qty. Shipped\"\n",
      "Harga Organik 1\n",
      "Harga Organik 2\n",
      "Harga Organik 3\n",
      "Harga Organik 4\n",
      "Harga Organik 5\n",
      "Harga Organik 6\n",
      "Harga Organik 7\n",
      "Kode SKU\n",
      "Blibli SKU\n",
      "Kode Merchant\n",
      "True datetime\n",
      "Promo\n",
      "Discount MC\n",
      "Harga Cost\n",
      "Total Harga Cost\n",
      "No. Order Item L-Men Blibli\n",
      "Order Voucher Amount\n",
      "Item Voucher Amount\n",
      "Item Voucher Platform\n",
      "Item Voucher Seller\n",
      "nominal\n",
      "btlcost\n",
      "gs\n",
      "commfee\n",
      "fullfee\n",
      "index\n",
      "Phone Condition\n",
      "Warehouse Code\n",
      "Channel Rebate\n",
      "Shipping Province\n",
      "Shipping City\n",
      "Shipping Address1\n",
      "Shipping Phone\n",
      "Hour\n",
      "payment_status\n",
      "Shipping Cost\n",
      "Invoice Number\n",
      "Shopee Order\n",
      "Shopee Cust\n",
      "Store Type\n",
      "Category\n",
      "Real SKU_y\n",
      "Region Group\n",
      "PL Before PPN\n",
      "Total Net Before PPN\n",
      "Payment Status\n",
      "Payment Type\n",
      "Printed Date\n",
      "Fulfilled Date\n",
      "Delivered Date\n",
      "Return ID\n",
      "Return Reference No.\n",
      "Return Date\n",
      "Service Type\n",
      "Bundle SKU Code\n",
      "Location ID\n",
      "Invoice ID\n",
      "Invoice Reference Number\n",
      "Invoice Status\n",
      "Invoice Create Date\n",
      "Fee Amount\n",
      "Invoice Amount\n",
      "Payment Received ID\n",
      "Payment Received Ref. number\n",
      "Category Baru\n",
      "Exported Parent Item\n",
      "Unnamed: 0\n",
      "Price List NFI_x\n",
      "Customer Type\n",
      "Real Region\n",
      "True datetime1\n"
     ]
    }
   ],
   "source": [
    "for i in data_all.columns :\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89af68c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "data_all[(data_all['Order Status'].isin(osf['order filter'].unique()))].groupby(['Year','Month','Store Type','Store','Channel','Brand','Sub Brand','Real SKU','Parent Item','Real Nama Produk','Bundle Name','Exported Parent Item'],dropna=False).agg({'Qty. Invoiced':'sum','Total Net Before PPN':'sum'}).reset_index().to_excel(f'Data All Aggregat {date.today()}.xlsx',index=False)\n",
    "# data_all.groupby(['Year','Month','Date','Store Type','Store','Channel','Order Status'])[['Order #']].nunique().reset_index().to_excel(f'Cek order gerak {date.today()}.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69389930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Sales Order ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JD Indonesia</td>\n",
       "      <td>2609.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nutrimart</td>\n",
       "      <td>690.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shopee</td>\n",
       "      <td>9558.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Store  Sales Order ID\n",
       "0  JD Indonesia     2609.083333\n",
       "1     Nutrimart      690.416667\n",
       "2        Shopee     9558.666667"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coret = data_all[(data_all['Store'].isin(['Shopee','Nutrimart','JD Indonesia']))&\n",
    "                 (data_all['Order Status'].isin(osf['order filter']))&\n",
    "                 (data_all['Brand'].isin(['HiLo','TS','NS','WDANK','L-Men']))&\n",
    "                 (data_all['Year'] == 2022)]\n",
    "coret['Sales Order ID'].fillna(coret['Order #'], inplace = True)\n",
    "coret1 = coret.groupby(['Month','Store','Sales Order ID']).agg({'Total Net Before PPN' : 'sum'}).reset_index()\n",
    "coret2 = coret1[coret1['Total Net Before PPN'] > 100000].groupby(['Store','Month']).agg({'Sales Order ID' : 'nunique'}).reset_index()\n",
    "coret3 = coret2.groupby('Store').agg({'Sales Order ID' : 'mean'}).reset_index()\n",
    "coret3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70097be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100400.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coret2['Total Net Before PPN'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d86897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "osf=pd.read_excel(r\"data_supp\\order filter.xlsx\")\n",
    "resb=data_all[(data_all['Year'].isin([2023,2022]))&(data_all['Order Status'].isin(osf['order filter'].unique()))].groupby(['Year','Month','Date','Store Type','Store','Coupon Code','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name','Region','Real Region'],dropna=False).agg({'Order #':'nunique','Phone':'nunique','Qty. Invoiced':'sum','Total Net Before PPN':'sum'}).reset_index()\n",
    "resb=resb[resb['Store Type']!='Organic']#['Store'].unique()\n",
    "resa=data_all[(data_all['Year'].isin([2022,2023]))&(data_all['Order Status'].isin(osf['order filter'].unique()))&\n",
    "                           (data_all['Store Type']=='Organic')][['Year','Month','Date','Store Type','Store','Channel','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name','Qty. Invoiced','Total Net Before PPN','Region','Real Region']]\n",
    "print('tinggal append export')\n",
    "resb.to_excel(f'D:\\Masterdata\\Masterdata Lite\\masterdata_{date.today()}_lite_v3.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b563d737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d74d06b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order #\n",
      "Sales Order ID\n",
      "AWB\n",
      "Paid Date\n",
      "Order Status\n",
      "Order date\n",
      "Week\n",
      "Date\n",
      "Month\n",
      "Quarter\n",
      "Year\n",
      "Channel\n",
      "SKU\n",
      "Brand\n",
      "Product Name\n",
      "Bundle Name\n",
      "Price List NFI\n",
      "Qty. Invoiced\n",
      "Total Net\n",
      "Sub Brand\n",
      "Real SKU\n",
      "Real Nama Produk\n",
      "Parent Item\n",
      "Parent SKU\n",
      "Bundle Flag\n",
      "Customer Email\n",
      "Customer Name\n",
      "Customer Group\n",
      "Phone\n",
      "Country\n",
      "Region\n",
      "City\n",
      "Kecamatan\n",
      "Kelurahan\n",
      "Address\n",
      "Zip Code\n",
      "Shipping Name\n",
      "Shipping Courier\n",
      "Total\n",
      "Coupon Code\n",
      "Qty. Ordered\n",
      "Qty. Shipped\n",
      "Qty. Refunded\n",
      "Item Price\n",
      "Subtotal\n",
      "Discounts\n",
      "Tax\n",
      "Total incl. Tax\n",
      "Invoiced\n",
      "Tax Invoiced\n",
      "Invoiced incl. Tax\n",
      "Refunded\n",
      "Refunded incl. Tax\n",
      "Cart Name Rule\n",
      "Payment Channel\n",
      "Voucher Amount\n",
      "Discount Poin Reward\n",
      "Ship Date\n",
      "Discount Product\n",
      "Produk 1\n",
      "SKU Produk 1\n",
      "PCS Produk 1\n",
      "Price List NFI 1\n",
      "Subtotal Produk 1\n",
      "Harga Display 1\n",
      "Harga Cost 1\n",
      "Produk 2\n",
      "SKU Produk 2\n",
      "PCS Produk 2\n",
      "Price List NFI 2\n",
      "Subtotal Produk 2\n",
      "Harga Display 2\n",
      "Harga Cost 2\n",
      "Produk 3\n",
      "SKU Produk 3\n",
      "PCS Produk 3\n",
      "Price List NFI 3\n",
      "Subtotal Produk 3\n",
      "Harga Display 3\n",
      "Harga Cost 3\n",
      "Produk 4\n",
      "SKU Produk 4\n",
      "PCS Produk 4\n",
      "Price List NFI 4\n",
      "Subtotal Produk 4\n",
      "Harga Display 4\n",
      "Harga Cost 4\n",
      "Produk 5\n",
      "SKU Produk 5\n",
      "PCS Produk 5\n",
      "Price List NFI 5\n",
      "Subtotal Produk 5\n",
      "Harga Display 5\n",
      "Harga Cost 5\n",
      "Produk 6\n",
      "SKU Produk 6\n",
      "PCS Produk 6\n",
      "Price List NFI 6\n",
      "Subtotal Produk 6\n",
      "Harga Display 6\n",
      "Harga Cost 6\n",
      "Produk 7\n",
      "SKU Produk 7\n",
      "PCS Produk 7\n",
      "Price List NFI 7\n",
      "Subtotal Produk 7\n",
      "Harga Display 7\n",
      "Harga Cost 7\n",
      "Cancelled Date\n",
      "Currency Code\n",
      "Bundle\n",
      "Loc ID\n",
      "Barcode ID\n",
      "Warehouse Name\n",
      "Regular Price\n",
      "Selling Price\n",
      "VAT\n",
      "Shipping\n",
      "Actual Shipping\n",
      "Seller Discount\n",
      "Seller Rebate\n",
      "Gross Sales\n",
      "Shipping Address2\n",
      "Notes\n",
      "Store\n",
      "Qty. Ordered\"\n",
      "Qty. Shipped\"\n",
      "Harga Organik 1\n",
      "Harga Organik 2\n",
      "Harga Organik 3\n",
      "Harga Organik 4\n",
      "Harga Organik 5\n",
      "Harga Organik 6\n",
      "Harga Organik 7\n",
      "Kode SKU\n",
      "Blibli SKU\n",
      "Kode Merchant\n",
      "True datetime\n",
      "Promo\n",
      "Discount MC\n",
      "Harga Cost\n",
      "Total Harga Cost\n",
      "No. Order Item L-Men Blibli\n",
      "Order Voucher Amount\n",
      "Item Voucher Amount\n",
      "Item Voucher Platform\n",
      "Item Voucher Seller\n",
      "nominal\n",
      "btlcost\n",
      "gs\n",
      "commfee\n",
      "fullfee\n",
      "index\n",
      "Phone Condition\n",
      "Warehouse Code\n",
      "Channel Rebate\n",
      "Shipping Province\n",
      "Shipping City\n",
      "Shipping Address1\n",
      "Shipping Phone\n",
      "Hour\n",
      "payment_status\n",
      "Shipping Cost\n",
      "Invoice Number\n",
      "Shopee Order\n",
      "Shopee Cust\n",
      "Store Type\n",
      "Category\n",
      "Real SKU_y\n",
      "Region Group\n",
      "PL Before PPN\n",
      "Total Net Before PPN\n",
      "Payment Status\n",
      "Payment Type\n",
      "Printed Date\n",
      "Fulfilled Date\n",
      "Delivered Date\n",
      "Return ID\n",
      "Return Reference No.\n",
      "Return Date\n",
      "Service Type\n",
      "Bundle SKU Code\n",
      "Location ID\n",
      "Invoice ID\n",
      "Invoice Reference Number\n",
      "Invoice Status\n",
      "Invoice Create Date\n",
      "Fee Amount\n",
      "Invoice Amount\n",
      "Payment Received ID\n",
      "Payment Received Ref. number\n",
      "Category Baru\n",
      "Exported Parent Item\n",
      "Unnamed: 0\n",
      "Price List NFI_x\n",
      "Customer Type\n",
      "Real Region\n",
      "True datetime1\n",
      "Payment Date\n",
      "Shipping Customer Name\n"
     ]
    }
   ],
   "source": [
    "for i in data_all.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae44034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CORET2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ce7735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA BENNA\n",
    "nm = data_all[data_all['Store'].isin(['Nutrimart']) & (~data_all['Coupon Code'].str.startswith('ORGRSL|BODETARSL', na = False))]\n",
    "nm = nm[(nm['True datetime'] >= '2022-03-20') & (nm['True datetime'] < '2023-03-21')]\n",
    "nm['u_cust'] = nm['Customer Email'] + nm['Phone']\n",
    "\n",
    "NR = nm.drop_duplicates('Order #')[['Order #','Year','Month','Date','u_cust']].sort_values(by = ['Year', 'Month', 'Date'], ascending = True)\n",
    "NR['cust_time'] = NR.groupby(['u_cust']).cumcount()\n",
    "nm = pd.merge(nm,\n",
    "              NR[['Order #','cust_time']], \n",
    "              on ='Order #',\n",
    "              how = 'left')\n",
    "\n",
    "R = nm.groupby(['u_cust']).agg({'True datetime' : 'max'}).reset_index()\n",
    "time_A = datetime(2022, 12, 20)\n",
    "R['Recency'] = R['True datetime'].apply(lambda x : 'Active' if x > time_A else 'Not Active')\n",
    "nm = pd.merge(nm,\n",
    "              R[['u_cust','Recency']], \n",
    "              on ='u_cust',\n",
    "              how = 'left')\n",
    "\n",
    "F = nm.groupby(['u_cust']).agg({'cust_time' : 'max'}).reset_index()\n",
    "F['Frequency'] = F['cust_time'].apply(lambda x : 'Loyal' if x > 2 else 'Not Loyal')\n",
    "nm = pd.merge(nm,\n",
    "              F[['u_cust','Frequency']], \n",
    "              on ='u_cust',\n",
    "              how = 'left')\n",
    "\n",
    "nm_al = nm[nm['Recency'].isin(['Active']) & nm['Frequency'].isin(['Loyal'])]\n",
    "nm_al = nm_al[nm_al['Bundle Name'].isnull()]\n",
    "benna = nm_al.groupby(['Brand','Real Nama Produk']).agg({'u_cust' : 'nunique'}).reset_index()\n",
    "benna = benna[benna['Brand'].isin(['L-Men', 'NS', 'TS', 'Bundle', 'HiLo', 'WDANK', 'Lain Lain'])].sort_values('u_cust', ascending = False)\n",
    "\n",
    "benna_2 = nm.groupby('Phone').agg({'Customer Email' : 'nunique'}).reset_index().sort_values('Customer Email', ascending = False)\n",
    "\n",
    "with pd.ExcelWriter(\"benna.xlsx\") as writer:\n",
    "    benna.to_excel(writer, sheet_name=\"Top 10 SKU\",index = False)\n",
    "    benna_2.to_excel(writer, sheet_name=\"Account Badungan\",index = False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d7b0dbe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0100bb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bundle Tokped\n",
    "tokped = data_all[data_all['Store Type'].isin(['Marketplace']) & data_all['Store'].isin(['Tokopedia']) & data_all['Bundle Name'].isnull()]\n",
    "tokped = tokped[(tokped['True datetime'] >= '2022-09-01') & (tokped['True datetime'] < '2023-03-01')]\n",
    "tokped1 = tokped.groupby(['Brand','Real Nama Produk']).agg({'Price List NFI' : 'max'}).reset_index()\n",
    "tokped1 = tokped1[(tokped1['Price List NFI'] < 100000) & (tokped1['Price List NFI'] >= 50000)]['Real Nama Produk'].unique()\n",
    "tokped2 = tokped[tokped['Real Nama Produk'].isin(tokped1)]\n",
    "tokped2\n",
    "\n",
    "nt = data_all[data_all['Store Type'].isin(['Marketplace']) & (~data_all['Store'].isin(['Tokopedia'])) & data_all['Bundle Name'].isnull()]\n",
    "nt = nt[(nt['True datetime'] >= '2022-09-01') & (nt['True datetime'] < '2023-03-01')]\n",
    "nt1 = nt.groupby(['Brand','Real Nama Produk']).agg({'Price List NFI' : 'max'}).reset_index()\n",
    "nt1 = nt1[(nt1['Price List NFI'] < 100000) & (nt1['Price List NFI'] >= 50000)]['Real Nama Produk'].unique()\n",
    "nt2 = nt[nt['Real Nama Produk'].isin(nt1)]\n",
    "nt2\n",
    "\n",
    "with pd.ExcelWriter(\"bundle tokped.xlsx\") as writer:\n",
    "    tokped2.to_excel(writer, sheet_name=\"Tokped\",index = False)\n",
    "    nt2.to_excel(writer, sheet_name=\"Non-Tokped\",index = False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510698b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ac9f6ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Store</th>\n",
       "      <th>Order #</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>December</td>\n",
       "      <td>Blibli</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>December</td>\n",
       "      <td>Bukalapak</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>December</td>\n",
       "      <td>JD Indonesia</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>December</td>\n",
       "      <td>Lazada</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>December</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>December</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>December</td>\n",
       "      <td>Tokopedia</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>February</td>\n",
       "      <td>Aladin Mall</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>February</td>\n",
       "      <td>Blibli</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>February</td>\n",
       "      <td>Bukalapak</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>February</td>\n",
       "      <td>Lazada</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>February</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>February</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>February</td>\n",
       "      <td>Tokopedia</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>January</td>\n",
       "      <td>Blibli</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>January</td>\n",
       "      <td>Bukalapak</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>January</td>\n",
       "      <td>JD Indonesia</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>January</td>\n",
       "      <td>Lazada</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>January</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>January</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>January</td>\n",
       "      <td>Tokopedia</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Month         Store  Order #\n",
       "0   December        Blibli      211\n",
       "1   December     Bukalapak       33\n",
       "2   December  JD Indonesia       73\n",
       "3   December        Lazada      354\n",
       "4   December        Shopee      465\n",
       "5   December        TikTok       93\n",
       "6   December     Tokopedia      347\n",
       "7   February   Aladin Mall        2\n",
       "8   February        Blibli      217\n",
       "9   February     Bukalapak       19\n",
       "10  February        Lazada      355\n",
       "11  February        Shopee      466\n",
       "12  February        TikTok       83\n",
       "13  February     Tokopedia      501\n",
       "14   January        Blibli      181\n",
       "15   January     Bukalapak        8\n",
       "16   January  JD Indonesia       45\n",
       "17   January        Lazada      196\n",
       "18   January        Shopee      596\n",
       "19   January        TikTok      172\n",
       "20   January     Tokopedia      434"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PESANAN > 500K\n",
    "df = data_all[(data_all['True datetime'] >= '2022-12-01') & (data_all['True datetime'] < '2023-03-01')]\n",
    "df = df[df['Store Type'].isin(['Marketplace']) & df['Bundle Name'].isnull()]\n",
    "\n",
    "df1 = df.groupby(['Month','Store','Order #']).agg({'Total Net Before PPN' : 'sum',\n",
    "                                                          'Total' : 'sum'}).reset_index()\n",
    "df1 = df1[df1['Total'] >= 500000]\n",
    "\n",
    "df1.groupby(['Month','Store']).agg({'Order #' : 'nunique'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "367106bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Order #</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>December</td>\n",
       "      <td>1576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>February</td>\n",
       "      <td>1643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>January</td>\n",
       "      <td>1632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Month  Order #\n",
       "0  December     1576\n",
       "1  February     1643\n",
       "2   January     1632"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.groupby(['Month']).agg({'Order #' : 'nunique'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "511149c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order #</th>\n",
       "      <th>Sales Order ID</th>\n",
       "      <th>AWB</th>\n",
       "      <th>Paid Date</th>\n",
       "      <th>Order Status</th>\n",
       "      <th>Order date</th>\n",
       "      <th>Week</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>...</th>\n",
       "      <th>Payment Received Ref. number</th>\n",
       "      <th>Category Baru</th>\n",
       "      <th>Exported Parent Item</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Price List NFI_x</th>\n",
       "      <th>Customer Type</th>\n",
       "      <th>Real Region</th>\n",
       "      <th>True datetime1</th>\n",
       "      <th>Payment Date</th>\n",
       "      <th>Shipping Customer Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220101KF9CRRPJ</td>\n",
       "      <td>#SO-115792812</td>\n",
       "      <td>JP9221384040</td>\n",
       "      <td>2022-01-01 00:01:00</td>\n",
       "      <td>Cancelled</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HILO TRADITIONAL</td>\n",
       "      <td>HILO CHOCOLATE TARO PLS 15RX10SX14G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jabodetabek</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220101KF8V3UF6</td>\n",
       "      <td>#SO-115792804</td>\n",
       "      <td>JP2821530627</td>\n",
       "      <td>2022-01-01 00:01:00</td>\n",
       "      <td>Cancelled</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HILO TEEN</td>\n",
       "      <td>HILO TEEN COKLAT 500G (12D)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jawa Barat</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220101KF86KYT6</td>\n",
       "      <td>#SO-115792769</td>\n",
       "      <td>JP0117026545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cancelled</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HILO TEEN</td>\n",
       "      <td>HILO TEEN POPCORN CARAMEL 12DX500G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jabodetabek</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220101KF99MQ6H</td>\n",
       "      <td>#SO-115792810</td>\n",
       "      <td>JP6646092620</td>\n",
       "      <td>2022-01-01 00:01:00</td>\n",
       "      <td>Cancelled</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L-MEN POWDER</td>\n",
       "      <td>L-MEN GM CHOCOLATE 6DX500G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jawa Tengah</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220101KF7SYVTJ</td>\n",
       "      <td>#SO-115792738</td>\n",
       "      <td>JP5713456513</td>\n",
       "      <td>2022-01-01 00:05:00</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L-MEN POWDER</td>\n",
       "      <td>L-MEN GM TARO 12DX225G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jabodetabek</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Order # Sales Order ID           AWB            Paid Date  \\\n",
       "0  220101KF9CRRPJ  #SO-115792812  JP9221384040  2022-01-01 00:01:00   \n",
       "1  220101KF8V3UF6  #SO-115792804  JP2821530627  2022-01-01 00:01:00   \n",
       "2  220101KF86KYT6  #SO-115792769  JP0117026545                  NaN   \n",
       "3  220101KF99MQ6H  #SO-115792810  JP6646092620  2022-01-01 00:01:00   \n",
       "4  220101KF7SYVTJ  #SO-115792738  JP5713456513  2022-01-01 00:05:00   \n",
       "\n",
       "  Order Status           Order date  Week  Date    Month  Quarter  ...  \\\n",
       "0    Cancelled  2022-01-01 00:00:00  52.0   1.0  January      1.0  ...   \n",
       "1    Cancelled  2022-01-01 00:00:00  52.0   1.0  January      1.0  ...   \n",
       "2    Cancelled  2022-01-01 00:00:00  52.0   1.0  January      1.0  ...   \n",
       "3    Cancelled  2022-01-01 00:00:00  52.0   1.0  January      1.0  ...   \n",
       "4    Delivered  2022-01-01 00:00:00  52.0   1.0  January      1.0  ...   \n",
       "\n",
       "   Payment Received Ref. number     Category Baru  \\\n",
       "0                           NaN  HILO TRADITIONAL   \n",
       "1                           NaN         HILO TEEN   \n",
       "2                           NaN         HILO TEEN   \n",
       "3                           NaN      L-MEN POWDER   \n",
       "4                           NaN      L-MEN POWDER   \n",
       "\n",
       "                  Exported Parent Item Unnamed: 0 Price List NFI_x  \\\n",
       "0  HILO CHOCOLATE TARO PLS 15RX10SX14G        NaN              NaN   \n",
       "1          HILO TEEN COKLAT 500G (12D)        NaN              NaN   \n",
       "2   HILO TEEN POPCORN CARAMEL 12DX500G        NaN              NaN   \n",
       "3           L-MEN GM CHOCOLATE 6DX500G        NaN              NaN   \n",
       "4               L-MEN GM TARO 12DX225G        NaN              NaN   \n",
       "\n",
       "  Customer Type  Real Region       True datetime1  Payment Date  \\\n",
       "0           NaN  Jabodetabek  2022-01-01 00:00:00           NaN   \n",
       "1           NaN   Jawa Barat  2022-01-01 00:00:00           NaN   \n",
       "2           NaN  Jabodetabek  2022-01-01 00:00:00           NaN   \n",
       "3           NaN  Jawa Tengah  2022-01-01 00:00:00           NaN   \n",
       "4           NaN  Jabodetabek  2022-01-01 00:00:00           NaN   \n",
       "\n",
       "  Shipping Customer Name  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4                    NaN  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b76afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HILO GOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e386764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_all[data_all['Year'].isin([2023]) & data_all['Store'].isin(['Shopee','TikTok']) & data_all['Month'].isin(['January', 'February', 'March'])][['Order #','Year','Month','Date','Store Type','Store','Channel','Coupon Code','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name','Customer Name','Customer Email','Phone','Payment Channel','City','Real Region','Qty. Invoiced','Total Net Before PPN']]\n",
    "df = df[df['Real SKU'].isin(['2101524180','2101500180','2101500190','2101551180','2101551190','2101584180','2101500195','2101578180','2101551195',\n",
    "                            '2101524180P2','2101500180P2','2101500190P2','2101551180P2','2101551190P2','2101584180P2','2101500195P2','2101578180P2','2101551195P2',\n",
    "                            '2101751112','2101700166','2101751112P2','2101700166P2']) & df['Bundle Name'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c99c1343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Store</th>\n",
       "      <th>Order #</th>\n",
       "      <th>Real Nama Produk</th>\n",
       "      <th>Total Net Before PPN</th>\n",
       "      <th>Qty. Invoiced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>February</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>230201TF7RU4E6</td>\n",
       "      <td>HiLo Gold Plain 1000 gr</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>February</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>230201TJ2HPS0H</td>\n",
       "      <td>HiLo Platinum Swiss Chocolate 420gr</td>\n",
       "      <td>82000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>February</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>230201TMMBJS3S</td>\n",
       "      <td>HiLo Gold Vanilla 500gr</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>February</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>230201TNDS152P</td>\n",
       "      <td>HiLo Gold Chocolate 1000g</td>\n",
       "      <td>118000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>February</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>230201TNGDXV9U</td>\n",
       "      <td>HiLo Platinum Swiss Chocolate 420gr</td>\n",
       "      <td>82000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3877</th>\n",
       "      <td>March</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>577154099018304156</td>\n",
       "      <td>HiLo Platinum Original 360g (12 Sachet)</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3878</th>\n",
       "      <td>March</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>577154946022672437</td>\n",
       "      <td>HiLo Platinum Swiss Chocolate 420gr</td>\n",
       "      <td>82000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879</th>\n",
       "      <td>March</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>577155028714752967</td>\n",
       "      <td>Twin Pack: HiLo Platinum Swiss Chocolate (12 Sch)</td>\n",
       "      <td>164000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880</th>\n",
       "      <td>March</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>577155570277583494</td>\n",
       "      <td>HiLo Platinum Swiss Chocolate 420gr</td>\n",
       "      <td>82000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>March</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>577155640494623691</td>\n",
       "      <td>HiLo Platinum Swiss Chocolate 420gr</td>\n",
       "      <td>82000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3882 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Month   Store             Order #  \\\n",
       "0     February  Shopee      230201TF7RU4E6   \n",
       "1     February  Shopee      230201TJ2HPS0H   \n",
       "2     February  Shopee      230201TMMBJS3S   \n",
       "3     February  Shopee      230201TNDS152P   \n",
       "4     February  Shopee      230201TNGDXV9U   \n",
       "...        ...     ...                 ...   \n",
       "3877     March  TikTok  577154099018304156   \n",
       "3878     March  TikTok  577154946022672437   \n",
       "3879     March  TikTok  577155028714752967   \n",
       "3880     March  TikTok  577155570277583494   \n",
       "3881     March  TikTok  577155640494623691   \n",
       "\n",
       "                                       Real Nama Produk  Total Net Before PPN  \\\n",
       "0                               HiLo Gold Plain 1000 gr              125000.0   \n",
       "1                   HiLo Platinum Swiss Chocolate 420gr               82000.0   \n",
       "2                               HiLo Gold Vanilla 500gr              140000.0   \n",
       "3                             HiLo Gold Chocolate 1000g              118000.0   \n",
       "4                   HiLo Platinum Swiss Chocolate 420gr               82000.0   \n",
       "...                                                 ...                   ...   \n",
       "3877            HiLo Platinum Original 360g (12 Sachet)              100000.0   \n",
       "3878                HiLo Platinum Swiss Chocolate 420gr               82000.0   \n",
       "3879  Twin Pack: HiLo Platinum Swiss Chocolate (12 Sch)              164000.0   \n",
       "3880                HiLo Platinum Swiss Chocolate 420gr               82000.0   \n",
       "3881                HiLo Platinum Swiss Chocolate 420gr               82000.0   \n",
       "\n",
       "      Qty. Invoiced  \n",
       "0               1.0  \n",
       "1               1.0  \n",
       "2               2.0  \n",
       "3               1.0  \n",
       "4               1.0  \n",
       "...             ...  \n",
       "3877            1.0  \n",
       "3878            1.0  \n",
       "3879            1.0  \n",
       "3880            1.0  \n",
       "3881            1.0  \n",
       "\n",
       "[3882 rows x 6 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.groupby(['Month','Store','Order #','Real Nama Produk']).agg({'Total Net Before PPN' : 'sum','Qty. Invoiced' : 'sum'}).reset_index()\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4f6361b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Store</th>\n",
       "      <th>Order #</th>\n",
       "      <th>Total Net Before PPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>February</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>230201TF7RU4E6</td>\n",
       "      <td>125000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>February</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>230201TJ2HPS0H</td>\n",
       "      <td>82000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>February</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>230201TMMBJS3S</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>February</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>230201TNDS152P</td>\n",
       "      <td>118000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>February</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>230201TNGDXV9U</td>\n",
       "      <td>82000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3743</th>\n",
       "      <td>March</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>577154099018304156</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3744</th>\n",
       "      <td>March</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>577154946022672437</td>\n",
       "      <td>82000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3745</th>\n",
       "      <td>March</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>577155028714752967</td>\n",
       "      <td>164000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3746</th>\n",
       "      <td>March</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>577155570277583494</td>\n",
       "      <td>82000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3747</th>\n",
       "      <td>March</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>577155640494623691</td>\n",
       "      <td>82000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3748 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Month   Store             Order #  Total Net Before PPN\n",
       "0     February  Shopee      230201TF7RU4E6              125000.0\n",
       "1     February  Shopee      230201TJ2HPS0H               82000.0\n",
       "2     February  Shopee      230201TMMBJS3S              140000.0\n",
       "3     February  Shopee      230201TNDS152P              118000.0\n",
       "4     February  Shopee      230201TNGDXV9U               82000.0\n",
       "...        ...     ...                 ...                   ...\n",
       "3743     March  TikTok  577154099018304156              100000.0\n",
       "3744     March  TikTok  577154946022672437               82000.0\n",
       "3745     March  TikTok  577155028714752967              164000.0\n",
       "3746     March  TikTok  577155570277583494               82000.0\n",
       "3747     March  TikTok  577155640494623691               82000.0\n",
       "\n",
       "[3748 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df1.groupby(['Month','Store','Order #']).agg({'Total Net Before PPN' : 'sum'}).reset_index()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b3c5224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_22732\\880581587.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  d250 = df2[df2['Store'].isin(['Shopee'])][df2['Total Net Before PPN'] >= 250000]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "351"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d250 = df2[df2['Store'].isin(['Shopee'])][df2['Total Net Before PPN'] >= 250000]\n",
    "d250['Order #'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "544cc42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_22732\\1205806559.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  d250 = df2[df2['Store'].isin(['TikTok'])][df2['Total Net Before PPN'] >= 250000]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d250 = df2[df2['Store'].isin(['TikTok'])][df2['Total Net Before PPN'] >= 250000]\n",
    "d250['Order #'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eb645752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_22732\\2433765209.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  d200250 = df2[df2['Store'].isin(['Shopee'])][(df2['Total Net Before PPN'] >= 200000) & (df2['Total Net Before PPN'] < 250000)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d200250 = df2[df2['Store'].isin(['Shopee'])][(df2['Total Net Before PPN'] >= 200000) & (df2['Total Net Before PPN'] < 250000)]\n",
    "d200250['Order #'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "26e8ab36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_22732\\3574678150.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  d200250 = df2[df2['Store'].isin(['TikTok'])][(df2['Total Net Before PPN'] >= 200000) & (df2['Total Net Before PPN'] < 250000)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d200250 = df2[df2['Store'].isin(['TikTok'])][(df2['Total Net Before PPN'] >= 200000) & (df2['Total Net Before PPN'] < 250000)]\n",
    "d200250['Order #'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "234c1844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_22732\\4176157121.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  d200 = df2[df2['Store'].isin(['Shopee'])][(df2['Total Net Before PPN'] >= 200000)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "548"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d200 = df2[df2['Store'].isin(['Shopee'])][(df2['Total Net Before PPN'] >= 200000)]\n",
    "d200['Order #'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9bf56237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_22732\\3249763760.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  d200 = df2[df2['Store'].isin(['TikTok'])][(df2['Total Net Before PPN'] >= 200000)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d200 = df2[df2['Store'].isin(['TikTok'])][(df2['Total Net Before PPN'] >= 200000)]\n",
    "d200['Order #'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "25863604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Month</th>\n",
       "      <th>Real Nama Produk</th>\n",
       "      <th>Qty. Invoiced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shopee</td>\n",
       "      <td>February</td>\n",
       "      <td>BUY 1 GET 1 - HiLo Platinum Original 360 gram</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shopee</td>\n",
       "      <td>February</td>\n",
       "      <td>Buy 1 Get 1 Free - HiLo Gold Biscuit Cereal 500g</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shopee</td>\n",
       "      <td>February</td>\n",
       "      <td>HiLo Gold Biscuit Cereal 500g</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shopee</td>\n",
       "      <td>February</td>\n",
       "      <td>HiLo Gold Chocolate 1000g</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shopee</td>\n",
       "      <td>February</td>\n",
       "      <td>HiLo Gold Chocolate 1000g x 2 pcs</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>TikTok</td>\n",
       "      <td>March</td>\n",
       "      <td>HiLo Gold Sweet Potato 500 gram</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>TikTok</td>\n",
       "      <td>March</td>\n",
       "      <td>HiLo Gold Vanilla 500gr</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>TikTok</td>\n",
       "      <td>March</td>\n",
       "      <td>HiLo Platinum Original 360g (12 Sachet)</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>TikTok</td>\n",
       "      <td>March</td>\n",
       "      <td>HiLo Platinum Swiss Chocolate 420gr</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>TikTok</td>\n",
       "      <td>March</td>\n",
       "      <td>Twin Pack: HiLo Platinum Swiss Chocolate (12 Sch)</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Store     Month                                   Real Nama Produk  \\\n",
       "0   Shopee  February      BUY 1 GET 1 - HiLo Platinum Original 360 gram   \n",
       "1   Shopee  February   Buy 1 Get 1 Free - HiLo Gold Biscuit Cereal 500g   \n",
       "2   Shopee  February                      HiLo Gold Biscuit Cereal 500g   \n",
       "3   Shopee  February                          HiLo Gold Chocolate 1000g   \n",
       "4   Shopee  February                  HiLo Gold Chocolate 1000g x 2 pcs   \n",
       "..     ...       ...                                                ...   \n",
       "89  TikTok     March                    HiLo Gold Sweet Potato 500 gram   \n",
       "90  TikTok     March                            HiLo Gold Vanilla 500gr   \n",
       "91  TikTok     March            HiLo Platinum Original 360g (12 Sachet)   \n",
       "92  TikTok     March                HiLo Platinum Swiss Chocolate 420gr   \n",
       "93  TikTok     March  Twin Pack: HiLo Platinum Swiss Chocolate (12 Sch)   \n",
       "\n",
       "    Qty. Invoiced  \n",
       "0            67.0  \n",
       "1            15.0  \n",
       "2            17.0  \n",
       "3           149.0  \n",
       "4            45.0  \n",
       "..            ...  \n",
       "89            2.0  \n",
       "90           45.0  \n",
       "91           25.0  \n",
       "92          132.0  \n",
       "93           46.0  \n",
       "\n",
       "[94 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = df1.groupby(['Store','Month','Real Nama Produk']).agg({'Qty. Invoiced' : 'sum'}).reset_index()\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "561069e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(\"HiLo Gold Platinum.xlsx\") as writer:\n",
    "    df1.to_excel(writer, sheet_name=\"Raw Data\",index = False)\n",
    "    d2.to_excel(writer, sheet_name=\"Unit Sold per Month\",index = False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "97ba3747",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_single[all_single['Brand'].isin(['TS','NS','HiLo','L-Men','WDANK'])].groupby(['Year','Month','Date','Store']).agg({'Total Net Before PPN' : 'sum'}).reset_index().to_excel(f'D:\\Masterdata\\Masterdata Lite\\cek.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7224c10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Total Net Before PPN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2021.0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">April</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th>ECOM RETAIL - TANIHUB</th>\n",
       "      <td>3.883200e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shopee Sell-In</th>\n",
       "      <td>2.511588e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <th>ECOM RETAIL - TANIHUB</th>\n",
       "      <td>3.376800e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <th>ECOM RETAIL - TANIHUB</th>\n",
       "      <td>2.712000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <th>ECOM RETAIL - TANIHUB</th>\n",
       "      <td>2.983200e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2023.0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">May</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">31.0</th>\n",
       "      <th>Nutrimart</th>\n",
       "      <td>5.385176e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Order Online</th>\n",
       "      <td>4.501239e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shopee</th>\n",
       "      <td>7.141970e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TikTok</th>\n",
       "      <td>7.400273e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tokopedia</th>\n",
       "      <td>8.295434e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2320 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Total Net Before PPN\n",
       "Year   Month Date Store                                      \n",
       "2021.0 April 1.0  ECOM RETAIL - TANIHUB          3.883200e+06\n",
       "                  Shopee Sell-In                 2.511588e+08\n",
       "             3.0  ECOM RETAIL - TANIHUB          3.376800e+06\n",
       "             6.0  ECOM RETAIL - TANIHUB          2.712000e+06\n",
       "             7.0  ECOM RETAIL - TANIHUB          2.983200e+06\n",
       "...                                                       ...\n",
       "2023.0 May   31.0 Nutrimart                      5.385176e+06\n",
       "                  Order Online                   4.501239e+06\n",
       "                  Shopee                         7.141970e+07\n",
       "                  TikTok                         7.400273e+07\n",
       "                  Tokopedia                      8.295434e+07\n",
       "\n",
       "[2320 rows x 1 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_single[all_single['Brand'].isin(['TS','NS','HiLo','L-Men','WDANK'])].groupby(['Year','Month','Date','Store']).agg({'Total Net Before PPN' : 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aded1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MEMBERSHIP LAZADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66b6580e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order #</th>\n",
       "      <th>Sales Order ID</th>\n",
       "      <th>AWB</th>\n",
       "      <th>Paid Date</th>\n",
       "      <th>Order Status</th>\n",
       "      <th>Order date</th>\n",
       "      <th>Week</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>...</th>\n",
       "      <th>Payment Received Ref. number</th>\n",
       "      <th>Category Baru</th>\n",
       "      <th>Exported Parent Item</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Price List NFI_x</th>\n",
       "      <th>Customer Type</th>\n",
       "      <th>Real Region</th>\n",
       "      <th>True datetime1</th>\n",
       "      <th>Payment Date</th>\n",
       "      <th>Shipping Customer Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>448881</th>\n",
       "      <td>827778692482369</td>\n",
       "      <td>#SO-119116543</td>\n",
       "      <td>JNAP-0102131728</td>\n",
       "      <td>2022-01-04 00:02:00</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>2022-01-04 00:02:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>April</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NS TRADITIONAL</td>\n",
       "      <td>NS JERUK PERAS PLS 18PX40SX14G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jawa Tengah</td>\n",
       "      <td>2022-04-01 00:02:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448887</th>\n",
       "      <td>827787666149552</td>\n",
       "      <td>#SO-119116575</td>\n",
       "      <td>LXAD-2539085327</td>\n",
       "      <td>2022-01-04 00:04:00</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>2022-01-04 00:04:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>April</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jabodetabek</td>\n",
       "      <td>2022-04-01 00:04:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448899</th>\n",
       "      <td>834678119603713</td>\n",
       "      <td>#SO-119116663</td>\n",
       "      <td>NLIDAT0003674738</td>\n",
       "      <td>2022-01-04 00:11:00</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>2022-01-04 00:11:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>April</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L-MEN POWDER</td>\n",
       "      <td>L-MEN PLATINUM CHOCO LATTE 6KLRX800G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sumatera 1</td>\n",
       "      <td>2022-04-01 00:11:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448900</th>\n",
       "      <td>834678119603713</td>\n",
       "      <td>#SO-119116663</td>\n",
       "      <td>NLIDAT0003674738</td>\n",
       "      <td>2022-01-04 00:11:00</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>2022-01-04 00:11:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>April</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TS KUNING OTHERS</td>\n",
       "      <td>TS KOREAN GOGUMA COOKIES 12DX5SX20G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sumatera 1</td>\n",
       "      <td>2022-04-01 00:11:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448913</th>\n",
       "      <td>834679921264717</td>\n",
       "      <td>#SO-119116684</td>\n",
       "      <td>JNAP-0102131354</td>\n",
       "      <td>2022-01-04 00:14:00</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>2022-01-04 00:14:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>April</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NS TRADITIONAL</td>\n",
       "      <td>NS JERUK PERAS PLS 18PX40SX14G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jawa Tengah</td>\n",
       "      <td>2022-04-01 00:14:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364928</th>\n",
       "      <td>1129869781744420</td>\n",
       "      <td>SO-130882094</td>\n",
       "      <td>LXAT-8002069211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2023-03-31 00:20:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>March</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jabodetabek</td>\n",
       "      <td>2023-03-31 00:20:00</td>\n",
       "      <td>2023-03-31 00:20:00</td>\n",
       "      <td>ANGGIA ASMAWI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364932</th>\n",
       "      <td>1129875703360057</td>\n",
       "      <td>SO-130881775</td>\n",
       "      <td>LXAT-8002068822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2023-03-31 00:09:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>March</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TS KUNING OTHERS</td>\n",
       "      <td>TS SYRUP ORANGE 12BTLX750ML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jabodetabek</td>\n",
       "      <td>2023-03-31 00:09:00</td>\n",
       "      <td>2023-03-31 00:09:00</td>\n",
       "      <td>Urip Widodo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364933</th>\n",
       "      <td>1119587245660057</td>\n",
       "      <td>SO-130881735</td>\n",
       "      <td>LXAT-8002068905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2023-03-31 00:08:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>March</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TS KUNING OTHERS</td>\n",
       "      <td>TS SYRUP COCOPANDAN 12BTLX750ML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jabodetabek</td>\n",
       "      <td>2023-03-31 00:08:00</td>\n",
       "      <td>2023-03-31 00:08:00</td>\n",
       "      <td>Urip Widodo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364934</th>\n",
       "      <td>1129868553833734</td>\n",
       "      <td>SO-130881733</td>\n",
       "      <td>LXAT-8002068824, LXAT-8002068878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2023-03-31 00:08:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>March</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jabodetabek</td>\n",
       "      <td>2023-03-31 00:08:00</td>\n",
       "      <td>2023-03-31 00:08:00</td>\n",
       "      <td>yonna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364935</th>\n",
       "      <td>1129868553833734</td>\n",
       "      <td>SO-130881733</td>\n",
       "      <td>LXAT-8002068824, LXAT-8002068878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2023-03-31 00:08:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>March</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jabodetabek</td>\n",
       "      <td>2023-03-31 00:08:00</td>\n",
       "      <td>2023-03-31 00:08:00</td>\n",
       "      <td>yonna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196397 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Order # Sales Order ID                               AWB  \\\n",
       "448881    827778692482369  #SO-119116543                   JNAP-0102131728   \n",
       "448887    827787666149552  #SO-119116575                   LXAD-2539085327   \n",
       "448899    834678119603713  #SO-119116663                  NLIDAT0003674738   \n",
       "448900    834678119603713  #SO-119116663                  NLIDAT0003674738   \n",
       "448913    834679921264717  #SO-119116684                   JNAP-0102131354   \n",
       "...                   ...            ...                               ...   \n",
       "2364928  1129869781744420   SO-130882094                   LXAT-8002069211   \n",
       "2364932  1129875703360057   SO-130881775                   LXAT-8002068822   \n",
       "2364933  1119587245660057   SO-130881735                   LXAT-8002068905   \n",
       "2364934  1129868553833734   SO-130881733  LXAT-8002068824, LXAT-8002068878   \n",
       "2364935  1129868553833734   SO-130881733  LXAT-8002068824, LXAT-8002068878   \n",
       "\n",
       "                   Paid Date Order Status           Order date  Week  Date  \\\n",
       "448881   2022-01-04 00:02:00    Delivered  2022-01-04 00:02:00  13.0   1.0   \n",
       "448887   2022-01-04 00:04:00    Delivered  2022-01-04 00:04:00  13.0   1.0   \n",
       "448899   2022-01-04 00:11:00    Delivered  2022-01-04 00:11:00  13.0   1.0   \n",
       "448900   2022-01-04 00:11:00    Delivered  2022-01-04 00:11:00  13.0   1.0   \n",
       "448913   2022-01-04 00:14:00    Delivered  2022-01-04 00:14:00  13.0   1.0   \n",
       "...                      ...          ...                  ...   ...   ...   \n",
       "2364928                  NaN    Completed  2023-03-31 00:20:00  13.0  31.0   \n",
       "2364932                  NaN    Completed  2023-03-31 00:09:00  13.0  31.0   \n",
       "2364933                  NaN    Completed  2023-03-31 00:08:00  13.0  31.0   \n",
       "2364934                  NaN    Completed  2023-03-31 00:08:00  13.0  31.0   \n",
       "2364935                  NaN    Completed  2023-03-31 00:08:00  13.0  31.0   \n",
       "\n",
       "         Month  Quarter  ...  Payment Received Ref. number     Category Baru  \\\n",
       "448881   April      2.0  ...                           NaN    NS TRADITIONAL   \n",
       "448887   April      2.0  ...                           NaN               NaN   \n",
       "448899   April      2.0  ...                           NaN      L-MEN POWDER   \n",
       "448900   April      2.0  ...                           NaN  TS KUNING OTHERS   \n",
       "448913   April      2.0  ...                           NaN    NS TRADITIONAL   \n",
       "...        ...      ...  ...                           ...               ...   \n",
       "2364928  March      1.0  ...                           NaN               NaN   \n",
       "2364932  March      1.0  ...                           NaN  TS KUNING OTHERS   \n",
       "2364933  March      1.0  ...                           NaN  TS KUNING OTHERS   \n",
       "2364934  March      1.0  ...                           NaN               NaN   \n",
       "2364935  March      1.0  ...                           NaN               NaN   \n",
       "\n",
       "                         Exported Parent Item Unnamed: 0 Price List NFI_x  \\\n",
       "448881         NS JERUK PERAS PLS 18PX40SX14G        NaN              NaN   \n",
       "448887                                    NaN        NaN              NaN   \n",
       "448899   L-MEN PLATINUM CHOCO LATTE 6KLRX800G        NaN              NaN   \n",
       "448900    TS KOREAN GOGUMA COOKIES 12DX5SX20G        NaN              NaN   \n",
       "448913         NS JERUK PERAS PLS 18PX40SX14G        NaN              NaN   \n",
       "...                                       ...        ...              ...   \n",
       "2364928                                   NaN        NaN              NaN   \n",
       "2364932           TS SYRUP ORANGE 12BTLX750ML        NaN              NaN   \n",
       "2364933       TS SYRUP COCOPANDAN 12BTLX750ML        NaN              NaN   \n",
       "2364934                                   NaN        NaN              NaN   \n",
       "2364935                                   NaN        NaN              NaN   \n",
       "\n",
       "        Customer Type  Real Region       True datetime1         Payment Date  \\\n",
       "448881            NaN  Jawa Tengah  2022-04-01 00:02:00                  NaN   \n",
       "448887            NaN  Jabodetabek  2022-04-01 00:04:00                  NaN   \n",
       "448899            NaN   Sumatera 1  2022-04-01 00:11:00                  NaN   \n",
       "448900            NaN   Sumatera 1  2022-04-01 00:11:00                  NaN   \n",
       "448913            NaN  Jawa Tengah  2022-04-01 00:14:00                  NaN   \n",
       "...               ...          ...                  ...                  ...   \n",
       "2364928           NaN  Jabodetabek  2023-03-31 00:20:00  2023-03-31 00:20:00   \n",
       "2364932           NaN  Jabodetabek  2023-03-31 00:09:00  2023-03-31 00:09:00   \n",
       "2364933           NaN  Jabodetabek  2023-03-31 00:08:00  2023-03-31 00:08:00   \n",
       "2364934           NaN  Jabodetabek  2023-03-31 00:08:00  2023-03-31 00:08:00   \n",
       "2364935           NaN  Jabodetabek  2023-03-31 00:08:00  2023-03-31 00:08:00   \n",
       "\n",
       "        Shipping Customer Name  \n",
       "448881                     NaN  \n",
       "448887                     NaN  \n",
       "448899                     NaN  \n",
       "448900                     NaN  \n",
       "448913                     NaN  \n",
       "...                        ...  \n",
       "2364928         ANGGIA ASMAWI   \n",
       "2364932           Urip Widodo   \n",
       "2364933           Urip Widodo   \n",
       "2364934                 yonna   \n",
       "2364935                 yonna   \n",
       "\n",
       "[196397 rows x 200 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osf=pd.read_excel(r\"data_supp\\order filter.xlsx\")\n",
    "df = data_all[(data_all['True datetime'] >= '2022-04-01') & (data_all['True datetime'] < '2023-04-01') &\n",
    "              (data_all['Store'].isin(['Lazada'])) &\n",
    "              (data_all['Order Status'].isin(osf['order filter'].unique())) &\n",
    "              (data_all['Bundle Name'].isnull())]\n",
    "itemlist = ['2102040225P2', '2305551028', '2104405', '2104251230', '2101453195P2', '2102200208', '2101453195',\n",
    "            '2105084180P2', '2101452195', '2101651195P2', '2104228230', '2101459180', '2101452195P2', '2101151180',\n",
    "            '2105028180']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "390905a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448881     085644827518\n",
       "448887     085884908776\n",
       "448899     081276399664\n",
       "448900     081276399664\n",
       "448913     081734986553\n",
       "               ...     \n",
       "2364928    087788805505\n",
       "2364932    081953344033\n",
       "2364933    081953344033\n",
       "2364934    085881618464\n",
       "2364935    085881618464\n",
       "Name: Phone, Length: 196397, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Phone'] = df['Phone'].str.replace('=\"', '')\n",
    "df['Phone'] = df['Phone'].str.replace('\"', '')\n",
    "df['Phone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dc7c0fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.groupby(['Phone']).agg({'True datetime' : 'max',\n",
    "                                 'Total Net Before PPN' : 'sum',\n",
    "                                 'Order #' : 'nunique'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dc3ede90",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(\"data customer laz.xlsx\") as writer:\n",
    "    df1.to_excel(writer,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9ab3739f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phone</th>\n",
       "      <th>True datetime</th>\n",
       "      <th>Total Net Before PPN</th>\n",
       "      <th>Order #</th>\n",
       "      <th>Last Order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-29 23:31:00</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0213852000</td>\n",
       "      <td>2022-10-24 18:37:00</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0215533041</td>\n",
       "      <td>2022-12-02 21:11:00</td>\n",
       "      <td>342000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0215915811</td>\n",
       "      <td>2022-11-28 14:25:00</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0217443172</td>\n",
       "      <td>2023-01-28 13:28:00</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96094</th>\n",
       "      <td>18632799172</td>\n",
       "      <td>2022-08-18 05:10:00</td>\n",
       "      <td>260000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96095</th>\n",
       "      <td>447795550112</td>\n",
       "      <td>2023-03-27 08:55:00</td>\n",
       "      <td>92500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96096</th>\n",
       "      <td>6582035798</td>\n",
       "      <td>2022-04-30 12:29:00</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96097</th>\n",
       "      <td>6586200749</td>\n",
       "      <td>2022-06-02 15:01:00</td>\n",
       "      <td>118000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96098</th>\n",
       "      <td>660988059883</td>\n",
       "      <td>2022-07-21 20:55:00</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96099 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Phone       True datetime  Total Net Before PPN  Order #  \\\n",
       "0                 0 2023-01-29 23:31:00               15000.0        1   \n",
       "1        0213852000 2022-10-24 18:37:00               44000.0        2   \n",
       "2        0215533041 2022-12-02 21:11:00              342000.0        1   \n",
       "3        0215915811 2022-11-28 14:25:00               56000.0        1   \n",
       "4        0217443172 2023-01-28 13:28:00               85000.0        4   \n",
       "...             ...                 ...                   ...      ...   \n",
       "96094   18632799172 2022-08-18 05:10:00              260000.0        1   \n",
       "96095  447795550112 2023-03-27 08:55:00               92500.0        1   \n",
       "96096    6582035798 2022-04-30 12:29:00               78000.0        1   \n",
       "96097    6586200749 2022-06-02 15:01:00              118000.0        1   \n",
       "96098  660988059883 2022-07-21 20:55:00               52000.0        1   \n",
       "\n",
       "       Last Order  \n",
       "0              85  \n",
       "1             182  \n",
       "2             143  \n",
       "3             148  \n",
       "4              87  \n",
       "...           ...  \n",
       "96094         250  \n",
       "96095          29  \n",
       "96096         360  \n",
       "96097         327  \n",
       "96098         277  \n",
       "\n",
       "[96099 rows x 5 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Last Order'] = datetime.today() - df1['True datetime']\n",
    "df1['Last Order'] = df1['Last Order'].dt.days\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4a5975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REPAIRING ORAMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e486bdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "orami2 = data_all[data_all['Store'].isin(['Orami Shopping'])].drop_duplicates(subset = ['Order #','Order Status','Brand','Real Nama Produk','Qty. Invoiced'], keep = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0c75ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "orami2 = orami2[~orami2['Month'].isin(['May'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e1d5df07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order #</th>\n",
       "      <th>Sales Order ID</th>\n",
       "      <th>AWB</th>\n",
       "      <th>Paid Date</th>\n",
       "      <th>Order Status</th>\n",
       "      <th>Order date</th>\n",
       "      <th>Week</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>...</th>\n",
       "      <th>Exported Parent Item</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Price List NFI_x</th>\n",
       "      <th>Customer Type</th>\n",
       "      <th>Real Region</th>\n",
       "      <th>True datetime1</th>\n",
       "      <th>Payment Date</th>\n",
       "      <th>Shipping Customer Name</th>\n",
       "      <th>Shipped Date</th>\n",
       "      <th>Note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>579847</th>\n",
       "      <td>20498202</td>\n",
       "      <td>20498202</td>\n",
       "      <td>001567505362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Selesai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>March</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Retail Online</td>\n",
       "      <td>2023-03-27 10:27:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579848</th>\n",
       "      <td>20497942</td>\n",
       "      <td>20497942</td>\n",
       "      <td>001567505361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Selesai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>March</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Retail Online</td>\n",
       "      <td>2023-03-27 10:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579849</th>\n",
       "      <td>20497942</td>\n",
       "      <td>20497942</td>\n",
       "      <td>001567505361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Selesai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>March</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NS JERUK PERAS REF 12DX500G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Retail Online</td>\n",
       "      <td>2023-03-27 10:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579850</th>\n",
       "      <td>20497942</td>\n",
       "      <td>20497942</td>\n",
       "      <td>001567505361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Selesai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>March</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Retail Online</td>\n",
       "      <td>2023-03-27 10:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579851</th>\n",
       "      <td>20419898</td>\n",
       "      <td>20419898</td>\n",
       "      <td>001567505350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Selesai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>March</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Retail Online</td>\n",
       "      <td>2023-03-23 09:03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612881</th>\n",
       "      <td>20993712</td>\n",
       "      <td>20993712</td>\n",
       "      <td>147802300000448.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Selesai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>April</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>HILO THAI TEA PLS 8RX10SX15G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Retail Online</td>\n",
       "      <td>2023-04-28 23:55:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612882</th>\n",
       "      <td>21023564</td>\n",
       "      <td>21023564</td>\n",
       "      <td>147952300000276.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Selesai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>April</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>HILO SCHOOL RTD COTTON CANDY 24TPKX200ML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Retail Online</td>\n",
       "      <td>2023-04-30 23:57:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612884</th>\n",
       "      <td>21016839</td>\n",
       "      <td>21016839</td>\n",
       "      <td>1567505456.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Selesai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>April</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>TS RTD ALMOND DRINK CHOCOLICIOUS 24TPKX190ML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Retail Online</td>\n",
       "      <td>2023-04-30 14:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612885</th>\n",
       "      <td>21015765</td>\n",
       "      <td>21015765</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dibatalkan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>April</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>TS RTD ALMOND DRINK CHOCOLICIOUS 24TPKX190ML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Retail Online</td>\n",
       "      <td>2023-04-30 13:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612886</th>\n",
       "      <td>21015765</td>\n",
       "      <td>21015765</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dibatalkan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>April</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>TS RTD ALMOND DRINK CHOCOLICIOUS 24TPKX190ML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Retail Online</td>\n",
       "      <td>2023-04-30 13:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Order # Sales Order ID                AWB  Paid Date Order Status  \\\n",
       "579847  20498202       20498202       001567505362        NaN      Selesai   \n",
       "579848  20497942       20497942       001567505361        NaN      Selesai   \n",
       "579849  20497942       20497942       001567505361        NaN      Selesai   \n",
       "579850  20497942       20497942       001567505361        NaN      Selesai   \n",
       "579851  20419898       20419898       001567505350        NaN      Selesai   \n",
       "...          ...            ...                ...        ...          ...   \n",
       "612881  20993712       20993712  147802300000448.0        NaN      Selesai   \n",
       "612882  21023564       21023564  147952300000276.0        NaN      Selesai   \n",
       "612884  21016839       21016839       1567505456.0        NaN      Selesai   \n",
       "612885  21015765       21015765                           NaN   Dibatalkan   \n",
       "612886  21015765       21015765                           NaN   Dibatalkan   \n",
       "\n",
       "       Order date  Week  Date  Month  Quarter  ...  \\\n",
       "579847        NaN   NaN  27.0  March      NaN  ...   \n",
       "579848        NaN   NaN  27.0  March      NaN  ...   \n",
       "579849        NaN   NaN  27.0  March      NaN  ...   \n",
       "579850        NaN   NaN  27.0  March      NaN  ...   \n",
       "579851        NaN   NaN  23.0  March      NaN  ...   \n",
       "...           ...   ...   ...    ...      ...  ...   \n",
       "612881        NaN   NaN  28.0  April      NaN  ...   \n",
       "612882        NaN   NaN  30.0  April      NaN  ...   \n",
       "612884        NaN   NaN  30.0  April      NaN  ...   \n",
       "612885        NaN   NaN  30.0  April      NaN  ...   \n",
       "612886        NaN   NaN  30.0  April      NaN  ...   \n",
       "\n",
       "                                 Exported Parent Item Unnamed: 0  \\\n",
       "579847                                            NaN        NaN   \n",
       "579848                                            NaN        NaN   \n",
       "579849                    NS JERUK PERAS REF 12DX500G        NaN   \n",
       "579850                                            NaN        NaN   \n",
       "579851                                            NaN        NaN   \n",
       "...                                               ...        ...   \n",
       "612881                   HILO THAI TEA PLS 8RX10SX15G        NaN   \n",
       "612882       HILO SCHOOL RTD COTTON CANDY 24TPKX200ML        NaN   \n",
       "612884  TS RTD ALMOND DRINK CHOCOLICIOUS 24TPKX190ML         NaN   \n",
       "612885  TS RTD ALMOND DRINK CHOCOLICIOUS 24TPKX190ML         NaN   \n",
       "612886  TS RTD ALMOND DRINK CHOCOLICIOUS 24TPKX190ML         NaN   \n",
       "\n",
       "       Price List NFI_x Customer Type    Real Region      True datetime1  \\\n",
       "579847              NaN           NaN  Retail Online 2023-03-27 10:27:00   \n",
       "579848              NaN           NaN  Retail Online 2023-03-27 10:15:00   \n",
       "579849              NaN           NaN  Retail Online 2023-03-27 10:15:00   \n",
       "579850              NaN           NaN  Retail Online 2023-03-27 10:15:00   \n",
       "579851              NaN           NaN  Retail Online 2023-03-23 09:03:00   \n",
       "...                 ...           ...            ...                 ...   \n",
       "612881              NaN           NaN  Retail Online 2023-04-28 23:55:00   \n",
       "612882              NaN           NaN  Retail Online 2023-04-30 23:57:00   \n",
       "612884              NaN           NaN  Retail Online 2023-04-30 14:45:00   \n",
       "612885              NaN           NaN  Retail Online 2023-04-30 13:10:00   \n",
       "612886              NaN           NaN  Retail Online 2023-04-30 13:10:00   \n",
       "\n",
       "        Payment Date  Shipping Customer Name  Shipped Date Note  \n",
       "579847           NaN                     NaN           NaN  NaN  \n",
       "579848           NaN                     NaN           NaN  NaN  \n",
       "579849           NaN                     NaN           NaN  NaN  \n",
       "579850           NaN                     NaN           NaN  NaN  \n",
       "579851           NaN                     NaN           NaN  NaN  \n",
       "...              ...                     ...           ...  ...  \n",
       "612881           NaN                     NaN           NaN  NaN  \n",
       "612882           NaN                     NaN           NaN  NaN  \n",
       "612884           NaN                     NaN           NaN  NaN  \n",
       "612885           NaN                     NaN           NaN  NaN  \n",
       "612886           NaN                     NaN           NaN  NaN  \n",
       "\n",
       "[137 rows x 202 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orami2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04f8c78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Total Net Before PPN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2023.0</th>\n",
       "      <th>April</th>\n",
       "      <td>4.507432e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>February</th>\n",
       "      <td>1.729000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>January</th>\n",
       "      <td>1.240100e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>March</th>\n",
       "      <td>1.974600e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Total Net Before PPN\n",
       "Year   Month                         \n",
       "2023.0 April             4.507432e+06\n",
       "       February          1.729000e+06\n",
       "       January           1.240100e+07\n",
       "       March             1.974600e+06"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orami2[orami2['Brand'].isin(['HiLo','L-Men','TS','NS','WDANK']) & orami2['Order Status'].isin(['Selesai'])].groupby(['Year','Month']).agg({'Total Net Before PPN' : 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f91f7dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Order #</th>\n",
       "      <th>Order Status</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Real Nama Produk</th>\n",
       "      <th>Qty. Invoiced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>636445</th>\n",
       "      <td>5.0</td>\n",
       "      <td>21091370</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>TS</td>\n",
       "      <td>Tropicana Slim Classic (50 sch)</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646743</th>\n",
       "      <td>5.0</td>\n",
       "      <td>21091370</td>\n",
       "      <td>Selesai</td>\n",
       "      <td>TS</td>\n",
       "      <td>Tropicana Slim Classic (50 sch)</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668116</th>\n",
       "      <td>14.0</td>\n",
       "      <td>21217267</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>Bundle</td>\n",
       "      <td>Twin Pack: HiLo School Chocolate 1000gr</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668117</th>\n",
       "      <td>14.0</td>\n",
       "      <td>21217267</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>HiLo</td>\n",
       "      <td>HiLo School Chocolate 1000 gr</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676057</th>\n",
       "      <td>14.0</td>\n",
       "      <td>21217267</td>\n",
       "      <td>Selesai</td>\n",
       "      <td>Bundle</td>\n",
       "      <td>Twin Pack: HiLo School Chocolate 1000gr</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676058</th>\n",
       "      <td>14.0</td>\n",
       "      <td>21217267</td>\n",
       "      <td>Selesai</td>\n",
       "      <td>HiLo</td>\n",
       "      <td>HiLo School Chocolate 1000 gr</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724248</th>\n",
       "      <td>23.0</td>\n",
       "      <td>21340223</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>L-Men</td>\n",
       "      <td>L-Men Platinum Kacang Hijau 800g</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778797</th>\n",
       "      <td>23.0</td>\n",
       "      <td>21340223</td>\n",
       "      <td>Selesai</td>\n",
       "      <td>L-Men</td>\n",
       "      <td>L-Men Platinum Kacang Hijau 800g</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724247</th>\n",
       "      <td>26.0</td>\n",
       "      <td>21385948</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>Bundle</td>\n",
       "      <td>Paket HiLo School 3+ - HiLo School 3+ Strawber...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724249</th>\n",
       "      <td>26.0</td>\n",
       "      <td>21385948</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>HiLo</td>\n",
       "      <td>HiLo School 3+ Strawberry Pop 400g</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724250</th>\n",
       "      <td>26.0</td>\n",
       "      <td>21385948</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>HiLo</td>\n",
       "      <td>HiLo School 3+ Soya Vanilla Malt 400g</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778796</th>\n",
       "      <td>26.0</td>\n",
       "      <td>21385948</td>\n",
       "      <td>Selesai</td>\n",
       "      <td>Bundle</td>\n",
       "      <td>Paket HiLo School 3+ - HiLo School 3+ Strawber...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778800</th>\n",
       "      <td>26.0</td>\n",
       "      <td>21385948</td>\n",
       "      <td>Selesai</td>\n",
       "      <td>HiLo</td>\n",
       "      <td>HiLo School 3+ Strawberry Pop 400g</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778802</th>\n",
       "      <td>26.0</td>\n",
       "      <td>21385948</td>\n",
       "      <td>Selesai</td>\n",
       "      <td>HiLo</td>\n",
       "      <td>HiLo School 3+ Soya Vanilla Malt 400g</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   Order # Order Status   Brand  \\\n",
       "636445   5.0  21091370     Canceled      TS   \n",
       "646743   5.0  21091370      Selesai      TS   \n",
       "668116  14.0  21217267     Canceled  Bundle   \n",
       "668117  14.0  21217267     Canceled    HiLo   \n",
       "676057  14.0  21217267      Selesai  Bundle   \n",
       "676058  14.0  21217267      Selesai    HiLo   \n",
       "724248  23.0  21340223     Canceled   L-Men   \n",
       "778797  23.0  21340223      Selesai   L-Men   \n",
       "724247  26.0  21385948     Canceled  Bundle   \n",
       "724249  26.0  21385948     Canceled    HiLo   \n",
       "724250  26.0  21385948     Canceled    HiLo   \n",
       "778796  26.0  21385948      Selesai  Bundle   \n",
       "778800  26.0  21385948      Selesai    HiLo   \n",
       "778802  26.0  21385948      Selesai    HiLo   \n",
       "\n",
       "                                         Real Nama Produk  Qty. Invoiced  \n",
       "636445                    Tropicana Slim Classic (50 sch)            2.0  \n",
       "646743                    Tropicana Slim Classic (50 sch)            2.0  \n",
       "668116            Twin Pack: HiLo School Chocolate 1000gr            3.0  \n",
       "668117                      HiLo School Chocolate 1000 gr            6.0  \n",
       "676057            Twin Pack: HiLo School Chocolate 1000gr            3.0  \n",
       "676058                      HiLo School Chocolate 1000 gr            6.0  \n",
       "724248                   L-Men Platinum Kacang Hijau 800g            2.0  \n",
       "778797                   L-Men Platinum Kacang Hijau 800g            2.0  \n",
       "724247  Paket HiLo School 3+ - HiLo School 3+ Strawber...            1.0  \n",
       "724249                 HiLo School 3+ Strawberry Pop 400g            1.0  \n",
       "724250              HiLo School 3+ Soya Vanilla Malt 400g            1.0  \n",
       "778796  Paket HiLo School 3+ - HiLo School 3+ Strawber...            1.0  \n",
       "778800                 HiLo School 3+ Strawberry Pop 400g            1.0  \n",
       "778802              HiLo School 3+ Soya Vanilla Malt 400g            1.0  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orami2[orami2['Month'].isin(['May'])][['Date','Order #','Order Status','Brand','Real Nama Produk','Qty. Invoiced']].drop_duplicates(subset = ['Order #','Order Status','Brand','Real Nama Produk','Qty. Invoiced'], keep = 'last').sort_values(by = 'Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d8e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "osf=pd.read_excel(r\"data_supp\\order filter.xlsx\")\n",
    "orami2[(orami2['True datetime'] >= '2023-01-01')&\n",
    "         (orami2['Order Status'].isin(osf['order filter'].unique()))].groupby(['Year','Month','Date','Hour','Store Type','Store','Channel','Warehouse Name','Real Region','City','Coupon Code','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name'],dropna=False).agg({'Order #':'nunique','Phone':'nunique','Qty. Invoiced':'sum','Total Net Before PPN':'sum'}).reset_index().to_excel(f'D:\\Masterdata\\Masterdata Lite\\orami_{date.today()}_lite new.xlsx',index=False)\n",
    "# data_all.groupby(['Year','Month','Date','Store Type','Store','Channel','Order Status'])[['Order #']].nunique().reset_index().to_excel(f'Cek order gerak {date.today()}.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e81b6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_21228\\2713276997.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_all = data_all.append(orami2, ignore_index = True, sort = False)\n"
     ]
    }
   ],
   "source": [
    "data_all = data_all[~data_all['Store'].isin(['Orami Shopping'])]\n",
    "data_all = data_all.append(orami2, ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8a00de33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CROSS BASKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1140ba13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real Nama Produk</th>\n",
       "      <th>Order #</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Hilo Chocolate Taro (10 sch)</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>W'Dank Bajigur (10 sch)</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>HiLo Thai Tea (10 sch)</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>HiLo Teh Tarik 10 Sch</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>HiLo Swiss Chocolate (10 sch) Renceng</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Tropicana Slim Minyak Jagung 946ml</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>L-Men Gain Mass Chocolate 225gr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>L-Men Gain Mass Banana 225gr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HiLo School Chocolate 500gr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HiLo School 3+ Strawberry Pop 400g</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Real Nama Produk  Order #\n",
       "39            Hilo Chocolate Taro (10 sch)       99\n",
       "108                W'Dank Bajigur (10 sch)       92\n",
       "36                  HiLo Thai Tea (10 sch)       63\n",
       "35                   HiLo Teh Tarik 10 Sch       59\n",
       "28   HiLo Swiss Chocolate (10 sch) Renceng       41\n",
       "..                                     ...      ...\n",
       "84      Tropicana Slim Minyak Jagung 946ml        1\n",
       "44         L-Men Gain Mass Chocolate 225gr        1\n",
       "43            L-Men Gain Mass Banana 225gr        1\n",
       "16             HiLo School Chocolate 500gr        1\n",
       "15      HiLo School 3+ Strawberry Pop 400g        1\n",
       "\n",
       "[110 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osf=pd.read_excel(r\"data_supp\\order filter.xlsx\")\n",
    "df = data_all[data_all['Order Status'].isin(osf['order filter'].unique()) &\n",
    "              data_all['Brand'].isin(['HiLo','NS','TS','L-Men','WDANK']) &\n",
    "              data_all['Store Type'].isin(['Marketplace'])&\n",
    "              data_all['Store'].isin(['Lazada'])]\n",
    "#order = df[df['Real SKU'].str.contains('1101909331|1101569326', case = False, na = False)]['Order #'].unique()\n",
    "order = df[df['Brand'].isin(['NS'])]['Order #'].unique()\n",
    "df1 = df[(df['True datetime'] >= '2023-05-01') & df['Order #'].isin(order) & (~df['Real SKU'].str.startswith('(E)')) & df['Brand'].isin(['WDANK','HiLo','TS','L-Men'])]\n",
    "df2 = df1.groupby(['Real Nama Produk']).agg({'Order #' : 'nunique'}).reset_index().sort_values(by = ['Order #'], ascending = False)\n",
    "#df2[~df2['Real Nama Produk'].str.contains('RTD')].head(12)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "810e1c4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real Nama Produk</th>\n",
       "      <th>Order #</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hilo Chocolate Taro (10 sch)</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>W'Dank Bajigur (10 sch)</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HiLo Thai Tea (10 sch)</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HiLo Teh Tarik 10 Sch</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HiLo Swiss Chocolate (10 sch) Renceng</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HiLo Es Teler 10 sch</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hilo Es Ketan Hitam 10 sch</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>W'Dank Bandrek 10 sachet Renceng</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HiLo Es Pisang Ijo 10 Sch</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Tropicana Slim DIABTX (50 sch)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Lokalate Kopi Alpukat 10's</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Lokalate Kopi Pisang Bakar Epe 10 sch</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HiLo School Milk Choco Bites 10 Sachet</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lokalate Kopi Aren 10 sachet Renceng</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Tropicana Slim Classic (50 sch)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Tropicana Slim Oat Drink 190 ml (RTD)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Tropicana Slim Minyak Kanola 946ml</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Tropicana Slim Salted Caramel Cocoa 4 Sachet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Tropicana Slim Cafe Latte (10 sch)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Tropicana Slim Minyak Jagung 946ml</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Tropicana Slim Stevia (50 sch)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Tropicana Slim Madu 350ml</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Real Nama Produk  Order #\n",
       "14                  Hilo Chocolate Taro (10 sch)       32\n",
       "35                       W'Dank Bajigur (10 sch)       21\n",
       "12                        HiLo Thai Tea (10 sch)       19\n",
       "11                         HiLo Teh Tarik 10 Sch       15\n",
       "8          HiLo Swiss Chocolate (10 sch) Renceng       11\n",
       "3                           HiLo Es Teler 10 sch        9\n",
       "15                    Hilo Es Ketan Hitam 10 sch        5\n",
       "36              W'Dank Bandrek 10 sachet Renceng        5\n",
       "2                      HiLo Es Pisang Ijo 10 Sch        5\n",
       "27                Tropicana Slim DIABTX (50 sch)        4\n",
       "16                    Lokalate Kopi Alpukat 10's        3\n",
       "23         Lokalate Kopi Pisang Bakar Epe 10 sch        3\n",
       "7         HiLo School Milk Choco Bites 10 Sachet        2\n",
       "19          Lokalate Kopi Aren 10 sachet Renceng        2\n",
       "26               Tropicana Slim Classic (50 sch)        2\n",
       "32         Tropicana Slim Oat Drink 190 ml (RTD)        1\n",
       "31            Tropicana Slim Minyak Kanola 946ml        1\n",
       "33  Tropicana Slim Salted Caramel Cocoa 4 Sachet        1\n",
       "24            Tropicana Slim Cafe Latte (10 sch)        1\n",
       "30            Tropicana Slim Minyak Jagung 946ml        1\n",
       "34                Tropicana Slim Stevia (50 sch)        1\n",
       "29                     Tropicana Slim Madu 350ml        1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba1eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#L-MEN GOES TO EUROPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9117629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "andrean_gan@yahoo.com1000114414\n",
      "andrean_gan@yahoo.com1000114524\n",
      "andrean_gan@yahoo.com1000114677\n",
      "andrean_gan@yahoo.com1000114951\n",
      "andrean_gan@yahoo.com1000115067\n",
      "andrean_gan@yahoo.com1000115168\n",
      "andrean_gan@yahoo.com1000115297\n",
      "andrean_gan@yahoo.com1000115421\n"
     ]
    }
   ],
   "source": [
    "import requests,json\n",
    "import pandas as pd\n",
    "osf=pd.read_excel(r\"data_supp\\order filter.xlsx\")  ### jgn lupa ganti yang ini\n",
    "allorder=requests.get(\"http://event.l-men.com/apiv1?type=lmen\").json()\n",
    "for i in requests.get(\"http://event.l-men.com/apiv1?type=lmenvoucheruser\").json():\n",
    "    if len(i['voucher'])>0:\n",
    "        email=i['email']\n",
    "        voulist=json.loads(i['voucher'].replace(\"'\",'\"'))\n",
    "        user_ord=[x['orderid'] for x in allorder if x['email']==email]\n",
    "        ord_detail=data_all[(data_all['Coupon Code'].isin(voulist))&\n",
    "                            ~(data_all['Order #'].isin(user_ord))&\n",
    "                            (data_all['Order Status'].isin(osf['order filter'].unique()))&\n",
    "                            (data_all['Brand']=='L-Men')].groupby(['Order #'])[['Total Net Before PPN']].sum().reset_index()\n",
    "        for orderid in ord_detail['Order #'].unique():\n",
    "            val=ord_detail[ord_detail['Order #']==orderid]['Total Net Before PPN'].sum()\n",
    "            requests.post(\"http://event.l-men.com/apiv1?id={0}&value={1}&rsl_email={2}\".format(orderid,val,email))\n",
    "            print(email+orderid)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eed8f47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290000.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56a178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOKOPEDIA ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bcc5246",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok=pd.read_excel(r\"C:\\Users\\steven.nathanael\\Downloads\\Tokopedia_Order_20230530-20230531.xlsx\")\n",
    "tok.rename(columns = {'Nomor Invoice' : 'Order #',\n",
    "                      'Nomor SKU' : 'Real SKU',\n",
    "                      'Jumlah Produk Dibeli' : 'Qty. Invoiced',\n",
    "                      'Nama Produk' : 'Product Name',\n",
    "                      'Nama Pembeli' : 'Customer Name',\n",
    "                      'No Telp Pembeli' : 'Phone',\n",
    "                      'Alamat Pengiriman' : 'Address',\n",
    "                      'Kota' : 'City',\n",
    "                      'Provinsi' : 'Region',\n",
    "                      'Gudang Pengiriman' : 'Warehouse Name',\n",
    "                      'Nama Kurir' : 'Shipping Courier',\n",
    "                      'No Resi / Kode Booking' : 'AWB',\n",
    "                      'Status Terakhir' : 'Order Status',\n",
    "                      'Total Penjualan' : 'Total',\n",
    "                      'Harga Jual' : 'Selling Price'}, inplace = True)\n",
    "\n",
    "tok['Day'] = tok['Tanggal Pembayaran'].str.slice(0, 2).astype(int)\n",
    "tok['Month'] = tok['Tanggal Pembayaran'].str.slice(3, 5).astype(int)\n",
    "tok['Year'] = tok['Tanggal Pembayaran'].str.slice(6, 10).astype(int)\n",
    "tok['Hour'] = tok['Tanggal Pembayaran'].str.slice(11, 13).astype(int)\n",
    "tok['Minute'] = tok['Tanggal Pembayaran'].str.slice(14, 16).astype(int)\n",
    "tok['Second'] = tok['Tanggal Pembayaran'].str.slice(17, 20).astype(int)\n",
    "tok['True datetime'] = pd.to_datetime(tok[['Year','Month','Day','Hour','Minute','Second']])\n",
    "tok['Month'] = tok['Month'].apply(lambda x : 'September' if x == 9 else\n",
    "                                            ('October' if x == 10 else\n",
    "                                            ('November' if x == 11 else \n",
    "                                            ('December' if x == 12 else\n",
    "                                            ('January' if x == 1 else\n",
    "                                            ('February' if x == 2 else\n",
    "                                            ('March' if x == 3 else\n",
    "                                            ('April' if x == 4 else\n",
    "                                            ('May' if x == 5 else\n",
    "                                            ('June' if x == 6 else\n",
    "                                            ('July' if x == 7 else 'August')))))))))))\n",
    "tok.rename(columns = {'Day' : 'Date'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e537124d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order #</th>\n",
       "      <th>Sales Order ID</th>\n",
       "      <th>AWB</th>\n",
       "      <th>Paid Date</th>\n",
       "      <th>Order Status</th>\n",
       "      <th>Order date</th>\n",
       "      <th>Week</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>...</th>\n",
       "      <th>Exported Parent Item</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Price List NFI_x</th>\n",
       "      <th>Customer Type</th>\n",
       "      <th>Real Region</th>\n",
       "      <th>True datetime1</th>\n",
       "      <th>Payment Date</th>\n",
       "      <th>Shipping Customer Name</th>\n",
       "      <th>Shipped Date</th>\n",
       "      <th>Note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12121413238</td>\n",
       "      <td>12170350531</td>\n",
       "      <td>BLI2209226577020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sudah Settlement</td>\n",
       "      <td>02/01/2023 09:21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jabodetabek</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12121409053</td>\n",
       "      <td>12170344246</td>\n",
       "      <td>BLI2209227755413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sudah Settlement</td>\n",
       "      <td>02/01/2023 08:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jabodetabek</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12121396731</td>\n",
       "      <td>12170324721</td>\n",
       "      <td>BLIGI00049654681-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>01/01/2023 23:38</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>L-MEN PLATINUM CHOCO LATTE 6KLRX800G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jabodetabek</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12121385758</td>\n",
       "      <td>12170309208</td>\n",
       "      <td>BLI1510222741567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sudah Settlement</td>\n",
       "      <td>01/01/2023 19:53</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jabodetabek</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12121385635</td>\n",
       "      <td>12170309027</td>\n",
       "      <td>8811622233348591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sudah Settlement</td>\n",
       "      <td>01/01/2023 19:51</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>L-MEN ADV CAPPUCINO 12DX250G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kalimantan</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Order # Sales Order ID                 AWB  Paid Date  \\\n",
       "0  12121413238    12170350531    BLI2209226577020        NaN   \n",
       "1  12121409053    12170344246    BLI2209227755413        NaN   \n",
       "2  12121396731    12170324721  BLIGI00049654681-1        NaN   \n",
       "3  12121385758    12170309208    BLI1510222741567        NaN   \n",
       "4  12121385635    12170309027    8811622233348591        NaN   \n",
       "\n",
       "       Order Status        Order date  Week  Date    Month  Quarter  ...  \\\n",
       "0  Sudah Settlement  02/01/2023 09:21   1.0   2.0  January      1.0  ...   \n",
       "1  Sudah Settlement  02/01/2023 08:19   1.0   2.0  January      1.0  ...   \n",
       "2         Delivered  01/01/2023 23:38  52.0   1.0  January      1.0  ...   \n",
       "3  Sudah Settlement  01/01/2023 19:53  52.0   1.0  January      1.0  ...   \n",
       "4  Sudah Settlement  01/01/2023 19:51  52.0   1.0  January      1.0  ...   \n",
       "\n",
       "                   Exported Parent Item Unnamed: 0 Price List NFI_x  \\\n",
       "0                                   NaN        NaN              NaN   \n",
       "1                                   NaN        NaN              NaN   \n",
       "2  L-MEN PLATINUM CHOCO LATTE 6KLRX800G        NaN              NaN   \n",
       "3                                   NaN        NaN              NaN   \n",
       "4          L-MEN ADV CAPPUCINO 12DX250G        NaN              NaN   \n",
       "\n",
       "  Customer Type  Real Region True datetime1  Payment Date  \\\n",
       "0           NaN  Jabodetabek     2023-01-02           NaN   \n",
       "1           NaN  Jabodetabek     2023-01-02           NaN   \n",
       "2           NaN  Jabodetabek     2023-01-01           NaN   \n",
       "3           NaN  Jabodetabek     2023-01-01           NaN   \n",
       "4           NaN   Kalimantan     2023-01-01           NaN   \n",
       "\n",
       "   Shipping Customer Name  Shipped Date Note  \n",
       "0                     NaN           NaN  NaN  \n",
       "1                     NaN           NaN  NaN  \n",
       "2                     NaN           NaN  NaN  \n",
       "3                     NaN           NaN  NaN  \n",
       "4                     NaN           NaN  NaN  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279e87c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "239a910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Optional\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from smtplib import SMTP\n",
    "import smtplib\n",
    "import sys\n",
    "import requests\n",
    "import os\n",
    "\n",
    "df =pd.read_csv(r\"C:\\Users\\steven.nathanael\\Downloads\\Nutrifood - Compas Dashboard_Page 4_Table (1).csv\", sep = ',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3675047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('compass lazada.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6084eb04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "964b568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Customer Collagen Lazada\n",
    "osf=pd.read_excel(r\"data_supp\\order filter.xlsx\")\n",
    "df = data_all[data_all['Store'].isin(['Lazada']) & data_all['Brand'].isin(['TS']) &\n",
    "              data_all['Real Nama Produk'].str.contains('Collagen', na = False, case = False) &\n",
    "              data_all['Order Status'].isin(osf['order filter'].unique())]\n",
    "df = df[(df['True datetime'] > '2023-06-25')][['Customer Name','Phone','Customer Email']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "89f63f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('Cust Laz Collagen.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "88ae2fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order #</th>\n",
       "      <th>Sales Order ID</th>\n",
       "      <th>AWB</th>\n",
       "      <th>Paid Date</th>\n",
       "      <th>Order Status</th>\n",
       "      <th>Order date</th>\n",
       "      <th>Week</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>...</th>\n",
       "      <th>Shipped Date</th>\n",
       "      <th>Note</th>\n",
       "      <th>Ready to Ship Date</th>\n",
       "      <th>Completed Date</th>\n",
       "      <th>Cancelled Reason</th>\n",
       "      <th>Item Note</th>\n",
       "      <th>Shipping Fee (Cashless)</th>\n",
       "      <th>Picklist ID</th>\n",
       "      <th>Package ID</th>\n",
       "      <th>Shipment ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1261386</th>\n",
       "      <td>1236898690108757</td>\n",
       "      <td>SO-135260117</td>\n",
       "      <td>LXAD-3072139802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>2023-08-27 04:42:00</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>August</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SHP-51958023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Order # Sales Order ID              AWB  Paid Date  \\\n",
       "1261386  1236898690108757   SO-135260117  LXAD-3072139802        NaN   \n",
       "\n",
       "        Order Status           Order date  Week  Date   Month  Quarter  ...  \\\n",
       "1261386    Delivered  2023-08-27 04:42:00  34.0  27.0  August      3.0  ...   \n",
       "\n",
       "         Shipped Date Note Ready to Ship Date Completed Date Cancelled Reason  \\\n",
       "1261386           NaN  NaN                NaN            NaN              NaN   \n",
       "\n",
       "        Item Note  Shipping Fee (Cashless)  Picklist ID  Package ID  \\\n",
       "1261386       NaN                      0.0          NaN         NaN   \n",
       "\n",
       "          Shipment ID  \n",
       "1261386  SHP-51958023  \n",
       "\n",
       "[1 rows x 210 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all[data_all['Order #'].isin(['1236898690108757'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a84323f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>January</td>\n",
       "      <td>=\"085174064002\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>January</td>\n",
       "      <td>=\"087809969138\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>January</td>\n",
       "      <td>=\"081287876336\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>January</td>\n",
       "      <td>=\"085217701160\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>January</td>\n",
       "      <td>=\"08119781899\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199781</th>\n",
       "      <td>August</td>\n",
       "      <td>=\"089603101288\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199794</th>\n",
       "      <td>August</td>\n",
       "      <td>=\"08121220706\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199810</th>\n",
       "      <td>August</td>\n",
       "      <td>=\"088220283866\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199879</th>\n",
       "      <td>August</td>\n",
       "      <td>=\"089603101288\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199898</th>\n",
       "      <td>August</td>\n",
       "      <td>=\"089603101288\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Month            Phone\n",
       "437      January  =\"085174064002\"\n",
       "483      January  =\"087809969138\"\n",
       "500      January  =\"081287876336\"\n",
       "545      January  =\"085217701160\"\n",
       "583      January   =\"08119781899\"\n",
       "...          ...              ...\n",
       "1199781   August  =\"089603101288\"\n",
       "1199794   August   =\"08121220706\"\n",
       "1199810   August  =\"088220283866\"\n",
       "1199879   August  =\"089603101288\"\n",
       "1199898   August  =\"089603101288\"\n",
       "\n",
       "[226102 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all[data_all['Store'].isin(['Lazada']) & data_all['Year'].isin([2023])][['Month','Phone']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74431c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5e97f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUSTOMER LAZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8c5b6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Total Net Before PPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>August</td>\n",
       "      <td>=\"02292547038\"</td>\n",
       "      <td>114000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>August</td>\n",
       "      <td>=\"0266211066\"</td>\n",
       "      <td>106000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>August</td>\n",
       "      <td>=\"0275322798\"</td>\n",
       "      <td>152000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>August</td>\n",
       "      <td>=\"0318941957\"</td>\n",
       "      <td>76000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>August</td>\n",
       "      <td>=\"062 85848469352\"</td>\n",
       "      <td>46000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39932</th>\n",
       "      <td>June</td>\n",
       "      <td>=\"08999936656\"</td>\n",
       "      <td>378600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39933</th>\n",
       "      <td>June</td>\n",
       "      <td>=\"08999951788\"</td>\n",
       "      <td>400800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39934</th>\n",
       "      <td>June</td>\n",
       "      <td>=\"08999958787\"</td>\n",
       "      <td>34000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39935</th>\n",
       "      <td>June</td>\n",
       "      <td>=\"08999996239\"</td>\n",
       "      <td>3877200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39936</th>\n",
       "      <td>June</td>\n",
       "      <td>=\"08999997936\"</td>\n",
       "      <td>246000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39937 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Month               Phone  Total Net Before PPN\n",
       "0      August      =\"02292547038\"              114000.0\n",
       "1      August       =\"0266211066\"              106000.0\n",
       "2      August       =\"0275322798\"              152000.0\n",
       "3      August       =\"0318941957\"               76000.0\n",
       "4      August  =\"062 85848469352\"               46000.0\n",
       "...       ...                 ...                   ...\n",
       "39932    June      =\"08999936656\"              378600.0\n",
       "39933    June      =\"08999951788\"              400800.0\n",
       "39934    June      =\"08999958787\"               34000.0\n",
       "39935    June      =\"08999996239\"             3877200.0\n",
       "39936    June      =\"08999997936\"              246000.0\n",
       "\n",
       "[39937 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data_all[data_all['Store'].isin(['Lazada']) & data_all['Bundle Name'].isnull() & (data_all['Month']).isin(['August', 'June', 'July'])].groupby(['Month','Phone']).agg({'Total Net Before PPN' : 'sum'}).reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9c717f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.groupby(['Phone']).agg({'Total Net Before PPN' : 'mean'}).reset_index()\n",
    "df11 = df1[df1['Phone'].isin(cust)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "45151c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   =\"\"\n",
       "63       =\"08111001700\"\n",
       "74       =\"08111082494\"\n",
       "94        =\"0811118020\"\n",
       "115      =\"08111393992\"\n",
       "              ...      \n",
       "32239    =\"08998389654\"\n",
       "32266    =\"08999061396\"\n",
       "32282    =\"08999351635\"\n",
       "32309    =\"08999996239\"\n",
       "32311            =\"nan\"\n",
       "Name: Phone, Length: 1330, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust = df1[(df1['Total Net Before PPN'] >= 500000)]['Phone']\n",
    "cust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c976e3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True datetime</th>\n",
       "      <th>Order #</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phone</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>=\"\"</th>\n",
       "      <td>2023-06-27 23:57:00</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>=\"08111001700\"</th>\n",
       "      <td>2023-07-07 18:05:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>=\"08111082494\"</th>\n",
       "      <td>2023-08-27 21:20:00</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>=\"0811118020\"</th>\n",
       "      <td>2023-08-29 12:06:00</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>=\"08111393992\"</th>\n",
       "      <td>2023-06-26 23:24:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>=\"08998389654\"</th>\n",
       "      <td>2023-08-26 14:02:00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>=\"08999061396\"</th>\n",
       "      <td>2023-08-05 11:05:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>=\"08999351635\"</th>\n",
       "      <td>2023-07-11 06:43:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>=\"08999996239\"</th>\n",
       "      <td>2023-08-10 07:48:00</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>=\"nan\"</th>\n",
       "      <td>2023-08-31 08:32:00</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1330 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     True datetime  Order #\n",
       "Phone                                      \n",
       "=\"\"            2023-06-27 23:57:00       65\n",
       "=\"08111001700\" 2023-07-07 18:05:00        5\n",
       "=\"08111082494\" 2023-08-27 21:20:00      101\n",
       "=\"0811118020\"  2023-08-29 12:06:00       25\n",
       "=\"08111393992\" 2023-06-26 23:24:00        4\n",
       "...                            ...      ...\n",
       "=\"08998389654\" 2023-08-26 14:02:00       10\n",
       "=\"08999061396\" 2023-08-05 11:05:00        3\n",
       "=\"08999351635\" 2023-07-11 06:43:00        3\n",
       "=\"08999996239\" 2023-08-10 07:48:00       38\n",
       "=\"nan\"         2023-08-31 08:32:00       35\n",
       "\n",
       "[1330 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = data_all[data_all['Phone'].isin(cust) & data_all['Store'].isin(['Lazada']) & data_all['Bundle Name'].isnull() & (data_all['Month']).isin(['August', 'June', 'July'])]\n",
    "df2.groupby(['Phone']).agg({'True datetime' : 'max',\n",
    "                            'Order #' : 'nunique'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cabc53b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2199: FutureWarning: The parsing of 'now' in pd.to_datetime without `utc=True` is deprecated. In a future version, this will match Timestamp('now') and Timestamp.now()\n",
      "  result, tz_parsed = tslib.array_to_datetime(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phone</th>\n",
       "      <th>True datetime</th>\n",
       "      <th>Order #</th>\n",
       "      <th>Last Order (Days)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>=\"\"</td>\n",
       "      <td>2023-06-27 23:57:00</td>\n",
       "      <td>65</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>=\"08111001700\"</td>\n",
       "      <td>2023-07-07 18:05:00</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>=\"08111082494\"</td>\n",
       "      <td>2023-08-27 21:20:00</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>=\"0811118020\"</td>\n",
       "      <td>2023-08-29 12:06:00</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>=\"08111393992\"</td>\n",
       "      <td>2023-06-26 23:24:00</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>=\"08998389654\"</td>\n",
       "      <td>2023-08-26 14:02:00</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>=\"08999061396\"</td>\n",
       "      <td>2023-08-05 11:05:00</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>=\"08999351635\"</td>\n",
       "      <td>2023-07-11 06:43:00</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>=\"08999996239\"</td>\n",
       "      <td>2023-08-10 07:48:00</td>\n",
       "      <td>38</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>=\"nan\"</td>\n",
       "      <td>2023-08-31 08:32:00</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1330 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Phone       True datetime  Order #  Last Order (Days)\n",
       "0                =\"\" 2023-06-27 23:57:00       65                 64\n",
       "1     =\"08111001700\" 2023-07-07 18:05:00        5                 54\n",
       "2     =\"08111082494\" 2023-08-27 21:20:00      101                  3\n",
       "3      =\"0811118020\" 2023-08-29 12:06:00       25                  1\n",
       "4     =\"08111393992\" 2023-06-26 23:24:00        4                 65\n",
       "...              ...                 ...      ...                ...\n",
       "1325  =\"08998389654\" 2023-08-26 14:02:00       10                  4\n",
       "1326  =\"08999061396\" 2023-08-05 11:05:00        3                 25\n",
       "1327  =\"08999351635\" 2023-07-11 06:43:00        3                 51\n",
       "1328  =\"08999996239\" 2023-08-10 07:48:00       38                 21\n",
       "1329          =\"nan\" 2023-08-31 08:32:00       35                  0\n",
       "\n",
       "[1330 rows x 4 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df2.groupby(['Phone']).agg({'True datetime' : 'max',\n",
    "                                  'Order #' : 'nunique'}).reset_index()\n",
    "df3['Last Order (Days)'] = (pd.to_datetime(\"now\")-df3['True datetime']).dt.days\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "568ec619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phone</th>\n",
       "      <th>Total Net Before PPN</th>\n",
       "      <th>True datetime</th>\n",
       "      <th>Order #</th>\n",
       "      <th>Last Order (Days)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>=\"\"</td>\n",
       "      <td>1.764750e+07</td>\n",
       "      <td>2023-06-27 23:57:00</td>\n",
       "      <td>65</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>=\"08111001700\"</td>\n",
       "      <td>7.770000e+05</td>\n",
       "      <td>2023-07-07 18:05:00</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>=\"08111082494\"</td>\n",
       "      <td>1.246667e+07</td>\n",
       "      <td>2023-08-27 21:20:00</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>=\"0811118020\"</td>\n",
       "      <td>2.446333e+06</td>\n",
       "      <td>2023-08-29 12:06:00</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>=\"08111393992\"</td>\n",
       "      <td>1.680000e+06</td>\n",
       "      <td>2023-06-26 23:24:00</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>=\"08998389654\"</td>\n",
       "      <td>1.570000e+06</td>\n",
       "      <td>2023-08-26 14:02:00</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>=\"08999061396\"</td>\n",
       "      <td>5.614498e+05</td>\n",
       "      <td>2023-08-05 11:05:00</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>=\"08999351635\"</td>\n",
       "      <td>5.310000e+05</td>\n",
       "      <td>2023-07-11 06:43:00</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>=\"08999996239\"</td>\n",
       "      <td>2.655067e+06</td>\n",
       "      <td>2023-08-10 07:48:00</td>\n",
       "      <td>38</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>=\"nan\"</td>\n",
       "      <td>4.127243e+06</td>\n",
       "      <td>2023-08-31 08:32:00</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1330 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Phone  Total Net Before PPN       True datetime  Order #  \\\n",
       "0                =\"\"          1.764750e+07 2023-06-27 23:57:00       65   \n",
       "1     =\"08111001700\"          7.770000e+05 2023-07-07 18:05:00        5   \n",
       "2     =\"08111082494\"          1.246667e+07 2023-08-27 21:20:00      101   \n",
       "3      =\"0811118020\"          2.446333e+06 2023-08-29 12:06:00       25   \n",
       "4     =\"08111393992\"          1.680000e+06 2023-06-26 23:24:00        4   \n",
       "...              ...                   ...                 ...      ...   \n",
       "1325  =\"08998389654\"          1.570000e+06 2023-08-26 14:02:00       10   \n",
       "1326  =\"08999061396\"          5.614498e+05 2023-08-05 11:05:00        3   \n",
       "1327  =\"08999351635\"          5.310000e+05 2023-07-11 06:43:00        3   \n",
       "1328  =\"08999996239\"          2.655067e+06 2023-08-10 07:48:00       38   \n",
       "1329          =\"nan\"          4.127243e+06 2023-08-31 08:32:00       35   \n",
       "\n",
       "      Last Order (Days)  \n",
       "0                    64  \n",
       "1                    54  \n",
       "2                     3  \n",
       "3                     1  \n",
       "4                    65  \n",
       "...                 ...  \n",
       "1325                  4  \n",
       "1326                 25  \n",
       "1327                 51  \n",
       "1328                 21  \n",
       "1329                  0  \n",
       "\n",
       "[1330 rows x 5 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.merge(df11,\n",
    "               df3,\n",
    "               on = 'Phone',\n",
    "               how = 'inner')\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "95692f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_excel(\"Customer Lazada.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca54441",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Kak Hen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dc10063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order #</th>\n",
       "      <th>Sales Order ID</th>\n",
       "      <th>AWB</th>\n",
       "      <th>Paid Date</th>\n",
       "      <th>Order Status</th>\n",
       "      <th>Order date</th>\n",
       "      <th>Week</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>...</th>\n",
       "      <th>Shipped Date</th>\n",
       "      <th>Note</th>\n",
       "      <th>Ready to Ship Date</th>\n",
       "      <th>Completed Date</th>\n",
       "      <th>Cancelled Reason</th>\n",
       "      <th>Item Note</th>\n",
       "      <th>Shipping Fee (Cashless)</th>\n",
       "      <th>Picklist ID</th>\n",
       "      <th>Package ID</th>\n",
       "      <th>Shipment ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1000109597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NTRM1000109597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2023-02-01 00:47:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1000109597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NTRM1000109597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2023-02-01 00:47:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1000109598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0125432300000234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>completed_with_awb</td>\n",
       "      <td>2023-02-01 00:51:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1000109599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0125432300000242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>completed_with_awb</td>\n",
       "      <td>2023-02-01 03:58:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1000109600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0125432300000259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>completed_with_awb</td>\n",
       "      <td>2023-02-01 08:01:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573989</th>\n",
       "      <td>Nubi -ECOM RETAIL - EMOS</td>\n",
       "      <td>Nubi -ECOM RETAIL - EMOS</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>2023-08-01 00:00:00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>August</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573990</th>\n",
       "      <td>Nubi -ECOM RETAIL - EMOS</td>\n",
       "      <td>Nubi -ECOM RETAIL - EMOS</td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>2023-08-03 00:00:00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>August</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573991</th>\n",
       "      <td>Nubi -ECOM RETAIL - EMOS</td>\n",
       "      <td>Nubi -ECOM RETAIL - EMOS</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>2023-08-01 00:00:00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>August</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573992</th>\n",
       "      <td>Nubi -ECOM RETAIL - EMOS</td>\n",
       "      <td>Nubi -ECOM RETAIL - EMOS</td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>2023-08-03 00:00:00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>August</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573993</th>\n",
       "      <td>Nubi -ECOM RETAIL - TOKO NOW</td>\n",
       "      <td>Nubi -ECOM RETAIL - TOKO NOW</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>2023-08-02 00:00:00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>August</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450393 rows × 210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Order #                Sales Order ID  \\\n",
       "176                        1000109597                           NaN   \n",
       "177                        1000109597                           NaN   \n",
       "179                        1000109598                           NaN   \n",
       "181                        1000109599                           NaN   \n",
       "183                        1000109600                           NaN   \n",
       "...                               ...                           ...   \n",
       "1573989      Nubi -ECOM RETAIL - EMOS      Nubi -ECOM RETAIL - EMOS   \n",
       "1573990      Nubi -ECOM RETAIL - EMOS      Nubi -ECOM RETAIL - EMOS   \n",
       "1573991      Nubi -ECOM RETAIL - EMOS      Nubi -ECOM RETAIL - EMOS   \n",
       "1573992      Nubi -ECOM RETAIL - EMOS      Nubi -ECOM RETAIL - EMOS   \n",
       "1573993  Nubi -ECOM RETAIL - TOKO NOW  Nubi -ECOM RETAIL - TOKO NOW   \n",
       "\n",
       "                      AWB  Paid Date        Order Status           Order date  \\\n",
       "176        NTRM1000109597        NaN           delivered  2023-02-01 00:47:00   \n",
       "177        NTRM1000109597        NaN           delivered  2023-02-01 00:47:00   \n",
       "179      0125432300000234        NaN  completed_with_awb  2023-02-01 00:51:00   \n",
       "181      0125432300000242        NaN  completed_with_awb  2023-02-01 03:58:00   \n",
       "183      0125432300000259        NaN  completed_with_awb  2023-02-01 08:01:00   \n",
       "...                   ...        ...                 ...                  ...   \n",
       "1573989                          1.0           Delivered  2023-08-01 00:00:00   \n",
       "1573990                          3.0           Delivered  2023-08-03 00:00:00   \n",
       "1573991                          1.0           Delivered  2023-08-01 00:00:00   \n",
       "1573992                          3.0           Delivered  2023-08-03 00:00:00   \n",
       "1573993                          2.0           Delivered  2023-08-02 00:00:00   \n",
       "\n",
       "         Week  Date    Month  Quarter  ...  Shipped Date Note  \\\n",
       "176       1.0   2.0  January      1.0  ...           NaN  NaN   \n",
       "177       1.0   2.0  January      1.0  ...           NaN  NaN   \n",
       "179       1.0   2.0  January      1.0  ...           NaN  NaN   \n",
       "181       1.0   2.0  January      1.0  ...           NaN  NaN   \n",
       "183       1.0   2.0  January      1.0  ...           NaN  NaN   \n",
       "...       ...   ...      ...      ...  ...           ...  ...   \n",
       "1573989  31.0   1.0   August      3.0  ...           NaN  NaN   \n",
       "1573990  31.0   3.0   August      3.0  ...           NaN  NaN   \n",
       "1573991  31.0   1.0   August      3.0  ...           NaN  NaN   \n",
       "1573992  31.0   3.0   August      3.0  ...           NaN  NaN   \n",
       "1573993  31.0   2.0   August      3.0  ...           NaN  NaN   \n",
       "\n",
       "        Ready to Ship Date Completed Date Cancelled Reason Item Note  \\\n",
       "176                    NaN            NaN              NaN       NaN   \n",
       "177                    NaN            NaN              NaN       NaN   \n",
       "179                    NaN            NaN              NaN       NaN   \n",
       "181                    NaN            NaN              NaN       NaN   \n",
       "183                    NaN            NaN              NaN       NaN   \n",
       "...                    ...            ...              ...       ...   \n",
       "1573989                NaN            NaN              NaN       NaN   \n",
       "1573990                NaN            NaN              NaN       NaN   \n",
       "1573991                NaN            NaN              NaN       NaN   \n",
       "1573992                NaN            NaN              NaN       NaN   \n",
       "1573993                NaN            NaN              NaN       NaN   \n",
       "\n",
       "         Shipping Fee (Cashless)  Picklist ID  Package ID Shipment ID  \n",
       "176                          NaN          NaN         NaN         NaN  \n",
       "177                          NaN          NaN         NaN         NaN  \n",
       "179                          NaN          NaN         NaN         NaN  \n",
       "181                          NaN          NaN         NaN         NaN  \n",
       "183                          NaN          NaN         NaN         NaN  \n",
       "...                          ...          ...         ...         ...  \n",
       "1573989                      NaN          NaN         NaN         NaN  \n",
       "1573990                      NaN          NaN         NaN         NaN  \n",
       "1573991                      NaN          NaN         NaN         NaN  \n",
       "1573992                      NaN          NaN         NaN         NaN  \n",
       "1573993                      NaN          NaN         NaN         NaN  \n",
       "\n",
       "[450393 rows x 210 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data_all[(data_all['True datetime'] > '2023-01-01') & (data_all['True datetime'] < '2023-09-01') &\n",
    "              data_all['Order Status'].isin(osf['order filter'].unique()) &\n",
    "              data_all['Brand'].isin(['TS'])]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e77a633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_16816\\3392195210.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['Unique Cust'] = df1['Customer Name'] + '_' + df1['Phone']\n"
     ]
    }
   ],
   "source": [
    "prod = ['Tropicana Slim Collagen Drink Strawberry 200 gram','Tropicana Slim 7 Fruits Fiber Daily 12 sachet',\n",
    "        'Tropicana Slim RTD Almond Drink Chocolicious 190 ml','Tropicana Slim Oat Drink 190 ml (RTD)', 'Tropicana Slim RTD Oat Drink Melon 190 ml',\n",
    "        'Tropicana Slim Milk Low Fat Vanilla 500gr','Tropicana Slim Low Fat Milk Korean Strawberry 500g','Tropicana Slim Susu Low Fat Macchiato Coffee 500 gram']\n",
    "\n",
    "df1 = df[df['Real Nama Produk'].isin(prod) & df['Store'].isin(['Tokopedia','TikTok','Shopee','Lazada','Nutrimart','Blibli','Bukalapak'])]\n",
    "df1['Unique Cust'] = df1['Customer Name'] + '_' + df1['Phone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c0097ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order #\n",
      "Sales Order ID\n",
      "AWB\n",
      "Paid Date\n",
      "Order Status\n",
      "Order date\n",
      "Week\n",
      "Date\n",
      "Month\n",
      "Quarter\n",
      "Year\n",
      "Channel\n",
      "SKU\n",
      "Brand\n",
      "Product Name\n",
      "Bundle Name\n",
      "Price List NFI\n",
      "Qty. Invoiced\n",
      "Total Net\n",
      "Sub Brand\n",
      "Real SKU\n",
      "Real Nama Produk\n",
      "Parent Item\n",
      "Parent SKU\n",
      "Bundle Flag\n",
      "Customer Email\n",
      "Customer Name\n",
      "Customer Group\n",
      "Phone\n",
      "Country\n",
      "Region\n",
      "City\n",
      "Kecamatan\n",
      "Kelurahan\n",
      "Address\n",
      "Zip Code\n",
      "Shipping Name\n",
      "Shipping Courier\n",
      "Total\n",
      "Coupon Code\n",
      "Qty. Ordered\n",
      "Qty. Shipped\n",
      "Qty. Refunded\n",
      "Item Price\n",
      "Subtotal\n",
      "Discounts\n",
      "Tax\n",
      "Total incl. Tax\n",
      "Invoiced\n",
      "Tax Invoiced\n",
      "Invoiced incl. Tax\n",
      "Refunded\n",
      "Refunded incl. Tax\n",
      "Cart Name Rule\n",
      "Payment Channel\n",
      "Voucher Amount\n",
      "Discount Poin Reward\n",
      "Ship Date\n",
      "Discount Product\n",
      "Produk 1\n",
      "SKU Produk 1\n",
      "PCS Produk 1\n",
      "Price List NFI 1\n",
      "Subtotal Produk 1\n",
      "Harga Display 1\n",
      "Harga Cost 1\n",
      "Produk 2\n",
      "SKU Produk 2\n",
      "PCS Produk 2\n",
      "Price List NFI 2\n",
      "Subtotal Produk 2\n",
      "Harga Display 2\n",
      "Harga Cost 2\n",
      "Produk 3\n",
      "SKU Produk 3\n",
      "PCS Produk 3\n",
      "Price List NFI 3\n",
      "Subtotal Produk 3\n",
      "Harga Display 3\n",
      "Harga Cost 3\n",
      "Produk 4\n",
      "SKU Produk 4\n",
      "PCS Produk 4\n",
      "Price List NFI 4\n",
      "Subtotal Produk 4\n",
      "Harga Display 4\n",
      "Harga Cost 4\n",
      "Produk 5\n",
      "SKU Produk 5\n",
      "PCS Produk 5\n",
      "Price List NFI 5\n",
      "Subtotal Produk 5\n",
      "Harga Display 5\n",
      "Harga Cost 5\n",
      "Produk 6\n",
      "SKU Produk 6\n",
      "PCS Produk 6\n",
      "Price List NFI 6\n",
      "Subtotal Produk 6\n",
      "Harga Display 6\n",
      "Harga Cost 6\n",
      "Produk 7\n",
      "SKU Produk 7\n",
      "PCS Produk 7\n",
      "Price List NFI 7\n",
      "Subtotal Produk 7\n",
      "Harga Display 7\n",
      "Harga Cost 7\n",
      "Cancelled Date\n",
      "Currency Code\n",
      "Bundle\n",
      "Loc ID\n",
      "Barcode ID\n",
      "Warehouse Name\n",
      "Regular Price\n",
      "Selling Price\n",
      "VAT\n",
      "Shipping\n",
      "Actual Shipping\n",
      "Seller Discount\n",
      "Seller Rebate\n",
      "Gross Sales\n",
      "Shipping Address2\n",
      "Notes\n",
      "Store\n",
      "Qty. Ordered\"\n",
      "Qty. Shipped\"\n",
      "Harga Organik 1\n",
      "Harga Organik 2\n",
      "Harga Organik 3\n",
      "Harga Organik 4\n",
      "Harga Organik 5\n",
      "Harga Organik 6\n",
      "Harga Organik 7\n",
      "Kode SKU\n",
      "Blibli SKU\n",
      "Kode Merchant\n",
      "True datetime\n",
      "Promo\n",
      "Discount MC\n",
      "Harga Cost\n",
      "Total Harga Cost\n",
      "No. Order Item L-Men Blibli\n",
      "Order Voucher Amount\n",
      "Item Voucher Amount\n",
      "Item Voucher Platform\n",
      "Item Voucher Seller\n",
      "nominal\n",
      "btlcost\n",
      "gs\n",
      "commfee\n",
      "fullfee\n",
      "index\n",
      "Phone Condition\n",
      "Warehouse Code\n",
      "Channel Rebate\n",
      "Shipping Province\n",
      "Shipping City\n",
      "Shipping Address1\n",
      "Shipping Phone\n",
      "Hour\n",
      "payment_status\n",
      "Shipping Cost\n",
      "Invoice Number\n",
      "Shopee Order\n",
      "Shopee Cust\n",
      "Store Type\n",
      "Category\n",
      "Real SKU_y\n",
      "Region Group\n",
      "PL Before PPN\n",
      "Total Net Before PPN\n",
      "Payment Status\n",
      "Payment Type\n",
      "Printed Date\n",
      "Fulfilled Date\n",
      "Delivered Date\n",
      "Return ID\n",
      "Return Reference No.\n",
      "Return Date\n",
      "Service Type\n",
      "Bundle SKU Code\n",
      "Location ID\n",
      "Invoice ID\n",
      "Invoice Reference Number\n",
      "Invoice Status\n",
      "Invoice Create Date\n",
      "Fee Amount\n",
      "Invoice Amount\n",
      "Payment Received ID\n",
      "Payment Received Ref. number\n",
      "Category Baru\n",
      "Exported Parent Item\n",
      "Unnamed: 0\n",
      "Price List NFI_x\n",
      "Customer Type\n",
      "Real Region\n",
      "True datetime1\n",
      "Payment Date\n",
      "Shipping Customer Name\n",
      "Shipped Date\n",
      "Note\n",
      "Ready to Ship Date\n",
      "Completed Date\n",
      "Cancelled Reason\n",
      "Item Note\n",
      "Shipping Fee (Cashless)\n",
      "Picklist ID\n",
      "Package ID\n",
      "Shipment ID\n"
     ]
    }
   ],
   "source": [
    "for i in df1.columns :\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e561b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kahen = df1[['Order #','Store','Date','Month','Year','Real SKU','Real Nama Produk','Unique Cust', 'Customer Name','Phone',\n",
    "             'Qty. Invoiced', 'Total Net Before PPN', 'Real Region', 'City','Address']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f07d44db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order #</th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Real SKU</th>\n",
       "      <th>Real Nama Produk</th>\n",
       "      <th>Unique Cust</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Qty. Invoiced</th>\n",
       "      <th>Total Net Before PPN</th>\n",
       "      <th>Real Region</th>\n",
       "      <th>City</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>2301028FG081CD</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>1.0</td>\n",
       "      <td>January</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2105084180</td>\n",
       "      <td>Tropicana Slim Milk Low Fat Vanilla 500gr</td>\n",
       "      <td>C******a_=\"88\"</td>\n",
       "      <td>C******a</td>\n",
       "      <td>=\"88\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Jawa Timur</td>\n",
       "      <td>Kota Surabaya</td>\n",
       "      <td>Jalan Nginden VI D no. 01 (Kos putri), KOTA SU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>2301028F745M1X</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>1.0</td>\n",
       "      <td>January</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2105028180</td>\n",
       "      <td>Tropicana Slim Low Fat Milk Korean Strawberry ...</td>\n",
       "      <td>L******i_=\"84\"</td>\n",
       "      <td>L******i</td>\n",
       "      <td>=\"84\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>Jabodetabek</td>\n",
       "      <td>Kota Jakarta Barat</td>\n",
       "      <td>Jalan Tosiga III Dalam No.63, RT.1/RW.4, Kebon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>2301028EK70V9T</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>1.0</td>\n",
       "      <td>January</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2105084180</td>\n",
       "      <td>Tropicana Slim Milk Low Fat Vanilla 500gr</td>\n",
       "      <td>S******a_=\"58\"</td>\n",
       "      <td>S******a</td>\n",
       "      <td>=\"58\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Kalimantan</td>\n",
       "      <td>Kota Pontianak</td>\n",
       "      <td>Jl. Imam bonjol no 2/134, toko bangunan PD Mit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>2301028EK70V9T</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>1.0</td>\n",
       "      <td>January</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2105055180</td>\n",
       "      <td>Tropicana Slim Susu Low Fat Macchiato Coffee 5...</td>\n",
       "      <td>S******a_=\"58\"</td>\n",
       "      <td>S******a</td>\n",
       "      <td>=\"58\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Kalimantan</td>\n",
       "      <td>Kota Pontianak</td>\n",
       "      <td>Jl. Imam bonjol no 2/134, toko bangunan PD Mit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>2301028CPAKT99</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>1.0</td>\n",
       "      <td>January</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2105028180</td>\n",
       "      <td>Tropicana Slim Low Fat Milk Korean Strawberry ...</td>\n",
       "      <td>G**n_=\"09\"</td>\n",
       "      <td>G**n</td>\n",
       "      <td>=\"09\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>Jabodetabek</td>\n",
       "      <td>Kota Jakarta Timur</td>\n",
       "      <td>Jl Delima IV No 5C RT 05 RW 08 Curug Pondok Ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535921</th>\n",
       "      <td>2309233RWRXU5Y</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>23.0</td>\n",
       "      <td>September</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2T00805043</td>\n",
       "      <td>Tropicana Slim Collagen Drink Strawberry 200 gram</td>\n",
       "      <td>L******P_=\"******71\"</td>\n",
       "      <td>L******P</td>\n",
       "      <td>=\"******71\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165000.0</td>\n",
       "      <td>Jawa Tengah</td>\n",
       "      <td>Kabupaten Sleman</td>\n",
       "      <td>Nglengkong Sukoharjo, RT.1/RW.24, Suko Harjo, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535931</th>\n",
       "      <td>2309233RVC4GQX</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>23.0</td>\n",
       "      <td>September</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2105028180</td>\n",
       "      <td>Tropicana Slim Low Fat Milk Korean Strawberry ...</td>\n",
       "      <td>S******K_=\"******56\"</td>\n",
       "      <td>S******K</td>\n",
       "      <td>=\"******56\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76000.0</td>\n",
       "      <td>Jawa Tengah</td>\n",
       "      <td>Kabupaten Semarang</td>\n",
       "      <td>Dsn. Kedesen Rt. 01/Rw.06, Ds. Kradenan, Kec. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536068</th>\n",
       "      <td>2309233P5J2BAK</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>23.0</td>\n",
       "      <td>September</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2T00805043</td>\n",
       "      <td>Tropicana Slim Collagen Drink Strawberry 200 gram</td>\n",
       "      <td>N**i_=\"******64\"</td>\n",
       "      <td>N**i</td>\n",
       "      <td>=\"******64\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165000.0</td>\n",
       "      <td>Jabodetabek</td>\n",
       "      <td>Kota Tangerang Selatan</td>\n",
       "      <td>Pondok Maharta V, Blok a 14 No.18, RT.16/RW.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536271</th>\n",
       "      <td>2309233FMVDESV</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>23.0</td>\n",
       "      <td>September</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2105084180</td>\n",
       "      <td>Tropicana Slim Milk Low Fat Vanilla 500gr</td>\n",
       "      <td>S****h_=\"******20\"</td>\n",
       "      <td>S****h</td>\n",
       "      <td>=\"******20\"</td>\n",
       "      <td>2.0</td>\n",
       "      <td>148000.0</td>\n",
       "      <td>Jawa Barat</td>\n",
       "      <td>Kota Cimahi</td>\n",
       "      <td>Jalan Kebon Kopi no.17/186, RT 06 RW 09, Kelur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536399</th>\n",
       "      <td>230923317812YP</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>23.0</td>\n",
       "      <td>September</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2105028180</td>\n",
       "      <td>Tropicana Slim Low Fat Milk Korean Strawberry ...</td>\n",
       "      <td>Y****a_=\"******76\"</td>\n",
       "      <td>Y****a</td>\n",
       "      <td>=\"******76\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76000.0</td>\n",
       "      <td>Jabodetabek</td>\n",
       "      <td>Kabupaten Tangerang</td>\n",
       "      <td>Kampung Cisauk No. 36, RT.1/RW.3, Ds. Sampora,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7504 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Order #   Store  Date      Month    Year    Real SKU  \\\n",
       "438      2301028FG081CD  Shopee   1.0    January  2023.0  2105084180   \n",
       "478      2301028F745M1X  Shopee   1.0    January  2023.0  2105028180   \n",
       "504      2301028EK70V9T  Shopee   1.0    January  2023.0  2105084180   \n",
       "505      2301028EK70V9T  Shopee   1.0    January  2023.0  2105055180   \n",
       "605      2301028CPAKT99  Shopee   1.0    January  2023.0  2105028180   \n",
       "...                 ...     ...   ...        ...     ...         ...   \n",
       "1535921  2309233RWRXU5Y  Shopee  23.0  September  2023.0  2T00805043   \n",
       "1535931  2309233RVC4GQX  Shopee  23.0  September  2023.0  2105028180   \n",
       "1536068  2309233P5J2BAK  Shopee  23.0  September  2023.0  2T00805043   \n",
       "1536271  2309233FMVDESV  Shopee  23.0  September  2023.0  2105084180   \n",
       "1536399  230923317812YP  Shopee  23.0  September  2023.0  2105028180   \n",
       "\n",
       "                                          Real Nama Produk  \\\n",
       "438              Tropicana Slim Milk Low Fat Vanilla 500gr   \n",
       "478      Tropicana Slim Low Fat Milk Korean Strawberry ...   \n",
       "504              Tropicana Slim Milk Low Fat Vanilla 500gr   \n",
       "505      Tropicana Slim Susu Low Fat Macchiato Coffee 5...   \n",
       "605      Tropicana Slim Low Fat Milk Korean Strawberry ...   \n",
       "...                                                    ...   \n",
       "1535921  Tropicana Slim Collagen Drink Strawberry 200 gram   \n",
       "1535931  Tropicana Slim Low Fat Milk Korean Strawberry ...   \n",
       "1536068  Tropicana Slim Collagen Drink Strawberry 200 gram   \n",
       "1536271          Tropicana Slim Milk Low Fat Vanilla 500gr   \n",
       "1536399  Tropicana Slim Low Fat Milk Korean Strawberry ...   \n",
       "\n",
       "                  Unique Cust Customer Name        Phone  Qty. Invoiced  \\\n",
       "438            C******a_=\"88\"      C******a        =\"88\"            1.0   \n",
       "478            L******i_=\"84\"      L******i        =\"84\"            1.0   \n",
       "504            S******a_=\"58\"      S******a        =\"58\"            1.0   \n",
       "505            S******a_=\"58\"      S******a        =\"58\"            1.0   \n",
       "605                G**n_=\"09\"          G**n        =\"09\"            1.0   \n",
       "...                       ...           ...          ...            ...   \n",
       "1535921  L******P_=\"******71\"      L******P  =\"******71\"            1.0   \n",
       "1535931  S******K_=\"******56\"      S******K  =\"******56\"            1.0   \n",
       "1536068      N**i_=\"******64\"          N**i  =\"******64\"            1.0   \n",
       "1536271    S****h_=\"******20\"        S****h  =\"******20\"            2.0   \n",
       "1536399    Y****a_=\"******76\"        Y****a  =\"******76\"            1.0   \n",
       "\n",
       "         Total Net Before PPN  Real Region                    City  \\\n",
       "438                   70000.0   Jawa Timur           Kota Surabaya   \n",
       "478                   72000.0  Jabodetabek      Kota Jakarta Barat   \n",
       "504                   70000.0   Kalimantan          Kota Pontianak   \n",
       "505                   70000.0   Kalimantan          Kota Pontianak   \n",
       "605                   72000.0  Jabodetabek      Kota Jakarta Timur   \n",
       "...                       ...          ...                     ...   \n",
       "1535921              165000.0  Jawa Tengah        Kabupaten Sleman   \n",
       "1535931               76000.0  Jawa Tengah      Kabupaten Semarang   \n",
       "1536068              165000.0  Jabodetabek  Kota Tangerang Selatan   \n",
       "1536271              148000.0   Jawa Barat             Kota Cimahi   \n",
       "1536399               76000.0  Jabodetabek     Kabupaten Tangerang   \n",
       "\n",
       "                                                   Address  \n",
       "438      Jalan Nginden VI D no. 01 (Kos putri), KOTA SU...  \n",
       "478      Jalan Tosiga III Dalam No.63, RT.1/RW.4, Kebon...  \n",
       "504      Jl. Imam bonjol no 2/134, toko bangunan PD Mit...  \n",
       "505      Jl. Imam bonjol no 2/134, toko bangunan PD Mit...  \n",
       "605      Jl Delima IV No 5C RT 05 RW 08 Curug Pondok Ke...  \n",
       "...                                                    ...  \n",
       "1535921  Nglengkong Sukoharjo, RT.1/RW.24, Suko Harjo, ...  \n",
       "1535931  Dsn. Kedesen Rt. 01/Rw.06, Ds. Kradenan, Kec. ...  \n",
       "1536068  Pondok Maharta V, Blok a 14 No.18, RT.16/RW.10...  \n",
       "1536271  Jalan Kebon Kopi no.17/186, RT 06 RW 09, Kelur...  \n",
       "1536399  Kampung Cisauk No. 36, RT.1/RW.3, Ds. Sampora,...  \n",
       "\n",
       "[7504 rows x 15 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kahen[kahen['Store'].isin(['Shopee'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbea931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31b1515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kahen.to_excel('Kahen.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3fd7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f3e6f14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['L-Men Store Blibli', 'Nutrimart', 'Tokopedia', 'Shopee', 'FBL',\n",
       "       'Blibli', 'TikTok', 'Lazada', 'JD Indonesia', 'Bukalapak',\n",
       "       'Aladin Mall', 'Order Online Surabaya', 'Order Online Sumsel',\n",
       "       'Order Online Jateng', 'Order Online Bali', 'Order Online Medan',\n",
       "       'Order Online Lampung', 'Order Online Pekanbaru',\n",
       "       'Order Online Jabar', 'Order Online Makassar',\n",
       "       'Order Online Samarinda', 'Order Online Banjarmasin',\n",
       "       'Orami Shopping', 'GENERAL', 'GARUDA TIMUR PACIFIC, PT',\n",
       "       'SHOPEE INTERNATIONAL INDONESIA, PT', 'TANI SUPPLY INDONESIA, PT',\n",
       "       'WICAKSANA OVERSEAS INDONESIA, PT', 'RITEL BERSAMA NASIONAL, PT',\n",
       "       'WARUNG PINTAR DISTRIBUSI, PT',\n",
       "       'ENSEVAL PUTERA MEGATRADING TBK, PT', 'TEMPO, PT',\n",
       "       'KREASI TANI LAKSMI, PT', 'BINTANG ASET INDONESIA, PT',\n",
       "       'CHILIBELI BAGUS INDONESIA, PT', 'NATA GERAI ERABARU, PT',\n",
       "       'KONEKSI NIAGA SOLUSINDO, PT', 'PASKOMNAS NIAGA UTAMA, PT',\n",
       "       'RITEL BERSAMA NASIONAL', 'ENSEVAL PUTERA MEGATRD',\n",
       "       'ASTRO TECHNOLOGIES, PT', 'ECOM RETAIL - ASTRO',\n",
       "       'ECOM RETAIL - BAYI NINJA', 'ECOM RETAIL - JD ID',\n",
       "       'ECOM RETAIL - SAYUR BOX', 'ECOM RETAIL - EMOS',\n",
       "       'ECOM RETAIL - LIFEPACK', nan, 'ECOM RETAIL - SWIFT',\n",
       "       'ECOM RETAIL - INDOPASIFIK FARMA MEDIKA INDONESIA',\n",
       "       'ECOM RETAIL - TOKO NOW', 'ECOM RETAIL - JOYBOX(COSMART)',\n",
       "       'ECOM RETAIL - FRESHBOX', 'ECOM RETAIL - HAKUNA MATATA PELAUT'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['Channel'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "14c0d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_all[data_all['Store Type'].isin(['Marketplace']) & (~data_all['Store'].isin(['Orami Shopping'])) & (~data_all['Channel'].isin(['L-Men Store Blibli'])) & data_all['Bundle Name'].isnull() & (data_all['Year']).isin([2023])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cec563f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.groupby(['Month','Store']).agg({'Order #' : 'nunique'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d6de0090",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_excel('forstok.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42e8a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278ce0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BLIBLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44aa43ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_all[data_all['Store'].isin(['Blibli'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8f2842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df['Channel'].isin(['Blibli'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9ccb8d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.groupby(['Phone','Month','Order #']).agg({'Total Net Before PPN' : 'sum'}).reset_index()\n",
    "df2 =df2[~df2['Phone'].isin(['=\"\"', '=\"nan\"'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6d79639d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Total Net Before PPN</th>\n",
       "      <th>Month_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>April</td>\n",
       "      <td>=\"0213160455\"</td>\n",
       "      <td>292000.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>April</td>\n",
       "      <td>=\"08111020124\"</td>\n",
       "      <td>74000.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>April</td>\n",
       "      <td>=\"08111029855\"</td>\n",
       "      <td>595200.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>April</td>\n",
       "      <td>=\"08111032966\"</td>\n",
       "      <td>127000.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>April</td>\n",
       "      <td>=\"08111082494\"</td>\n",
       "      <td>2420000.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13296</th>\n",
       "      <td>September</td>\n",
       "      <td>=\"08999204542\"</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13297</th>\n",
       "      <td>September</td>\n",
       "      <td>=\"08999304012\"</td>\n",
       "      <td>292000.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13298</th>\n",
       "      <td>September</td>\n",
       "      <td>=\"08999760200\"</td>\n",
       "      <td>234000.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13299</th>\n",
       "      <td>September</td>\n",
       "      <td>=\"08999911192\"</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13300</th>\n",
       "      <td>September</td>\n",
       "      <td>=\"08999980774\"</td>\n",
       "      <td>297600.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13301 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Month           Phone  Total Net Before PPN  Month_N\n",
       "0          April   =\"0213160455\"              292000.0        4\n",
       "1          April  =\"08111020124\"               74000.0        4\n",
       "2          April  =\"08111029855\"              595200.0        4\n",
       "3          April  =\"08111032966\"              127000.0        4\n",
       "4          April  =\"08111082494\"             2420000.0        4\n",
       "...          ...             ...                   ...      ...\n",
       "13296  September  =\"08999204542\"                7500.0        9\n",
       "13297  September  =\"08999304012\"              292000.0        9\n",
       "13298  September  =\"08999760200\"              234000.0        9\n",
       "13299  September  =\"08999911192\"               25000.0        9\n",
       "13300  September  =\"08999980774\"              297600.0        9\n",
       "\n",
       "[13301 rows x 4 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df2.groupby(['Month','Phone']).agg({'Total Net Before PPN' : 'mean'}).reset_index()\n",
    "df3\n",
    "\n",
    "df3['Month_N'] = df3['Month'].apply(lambda x : 9 if x == \"September\" else\n",
    "                                            (10 if x == \"October\" else\n",
    "                                            (11 if x == \"November\" else \n",
    "                                            (12 if x == \"December\" else\n",
    "                                            (1 if x == \"January\" else\n",
    "                                            (2 if x == \"February\" else\n",
    "                                            (3 if x == \"March\" else\n",
    "                                            (4 if x == \"April\" else\n",
    "                                            (5 if x == \"May\" else\n",
    "                                            (6 if x == \"June\" else\n",
    "                                            (7 if x == \"July\" else 8)))))))))))\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3fd7623d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Order #</th>\n",
       "      <th>Total Net Before PPN</th>\n",
       "      <th>Month_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>April</td>\n",
       "      <td>12127573992</td>\n",
       "      <td>580000.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>April</td>\n",
       "      <td>12127574775</td>\n",
       "      <td>290000.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>April</td>\n",
       "      <td>12127581930</td>\n",
       "      <td>945600.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>April</td>\n",
       "      <td>12127584455</td>\n",
       "      <td>192000.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>April</td>\n",
       "      <td>12127593315</td>\n",
       "      <td>2292000.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>September</td>\n",
       "      <td>12139349149</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942</th>\n",
       "      <td>September</td>\n",
       "      <td>12139352252</td>\n",
       "      <td>528000.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>September</td>\n",
       "      <td>12139361182</td>\n",
       "      <td>792000.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>September</td>\n",
       "      <td>12139365049</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>September</td>\n",
       "      <td>12139370311</td>\n",
       "      <td>116000.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1946 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Month      Order #  Total Net Before PPN  Month_N\n",
       "0         April  12127573992              580000.0        4\n",
       "1         April  12127574775              290000.0        4\n",
       "2         April  12127581930              945600.0        4\n",
       "3         April  12127584455              192000.0        4\n",
       "4         April  12127593315             2292000.0        4\n",
       "...         ...          ...                   ...      ...\n",
       "1941  September  12139349149              300000.0        9\n",
       "1942  September  12139352252              528000.0        9\n",
       "1943  September  12139361182              792000.0        9\n",
       "1944  September  12139365049              300000.0        9\n",
       "1945  September  12139370311              116000.0        9\n",
       "\n",
       "[1946 rows x 4 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = df[~df['Channel'].isin(['Blibli'])]\n",
    "df5 = df4.groupby(['Month','Order #']).agg({'Total Net Before PPN' : 'sum'}).reset_index()\n",
    "df5['Month_N'] = df5['Month'].apply(lambda x : 9 if x == \"September\" else\n",
    "                                            (10 if x == \"October\" else\n",
    "                                            (11 if x == \"November\" else \n",
    "                                            (12 if x == \"December\" else\n",
    "                                            (1 if x == \"January\" else\n",
    "                                            (2 if x == \"February\" else\n",
    "                                            (3 if x == \"March\" else\n",
    "                                            (4 if x == \"April\" else\n",
    "                                            (5 if x == \"May\" else\n",
    "                                            (6 if x == \"June\" else\n",
    "                                            (7 if x == \"July\" else 8)))))))))))\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a607795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(\"Persebaran Data Blibli.xlsx\") as writer:\n",
    "    df3.to_excel(writer, sheet_name=\"NM\",index = False)\n",
    "    df5.to_excel(writer,sheet_name=\"LMS\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc4bbf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59313b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99686826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRISL UNBUNDLING J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "682a0f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real SKU</th>\n",
       "      <th>Real Nama Produk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>(J)71110130</td>\n",
       "      <td>Parsel Tropicana Slim Chill Out Kit - 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24914</th>\n",
       "      <td>(J)71110131</td>\n",
       "      <td>Paket NutriSari 35 Rasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204896</th>\n",
       "      <td>(J)71110133</td>\n",
       "      <td>Paket Valentine NutriSari Squeezed Orange - Fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406104</th>\n",
       "      <td>(J)71110138</td>\n",
       "      <td>Box Packing NutriMart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409676</th>\n",
       "      <td>(J)71110134</td>\n",
       "      <td>Paket Sobat Melek Lokalate (Segitiga)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425955</th>\n",
       "      <td>(J)71110146</td>\n",
       "      <td>Hampers Exclusive Ramadan - Tropicana Slim Pac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781642</th>\n",
       "      <td>(J)71110147</td>\n",
       "      <td>SPECIAL 6.6 - Brand Box Nutrimart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917902</th>\n",
       "      <td>(J)71110143</td>\n",
       "      <td>Green Packing - L-Men Hi Protein 2 Go Chocolat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921750</th>\n",
       "      <td>(J)71110141</td>\n",
       "      <td>Green Packing - Tropicana Slim Oat Drink 190 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922185</th>\n",
       "      <td>(J)71110144</td>\n",
       "      <td>Green Packing - HiLo School Chocolate Ready To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928732</th>\n",
       "      <td>(J)71110139</td>\n",
       "      <td>Green Packing - Tropicana Slim Minyak Kanola 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934296</th>\n",
       "      <td>(J)71110145</td>\n",
       "      <td>Green Packing - Hilo Teen Chocolate Ready To D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953937</th>\n",
       "      <td>(J)71110142</td>\n",
       "      <td>Green Packing - 4 pack - NutriSari RTD Squeeze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287805</th>\n",
       "      <td>(J)71110152</td>\n",
       "      <td>Paket Khusus Anniversary Nutrimart Tokopedia x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679721</th>\n",
       "      <td>(J)71110155</td>\n",
       "      <td>VB SSI -  Tropicana Slim RTD Almond Drink Choc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679965</th>\n",
       "      <td>(J)71110154</td>\n",
       "      <td>VB SSI - Tropicana Slim Oat Drink 190 ml (RTD)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685327</th>\n",
       "      <td>(J)71110153</td>\n",
       "      <td>Paket 45 Rasa NutriSari - 2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Real SKU                                   Real Nama Produk\n",
       "1409     (J)71110130         Parsel Tropicana Slim Chill Out Kit - 2022\n",
       "24914    (J)71110131                            Paket NutriSari 35 Rasa\n",
       "204896   (J)71110133  Paket Valentine NutriSari Squeezed Orange - Fe...\n",
       "406104   (J)71110138                              Box Packing NutriMart\n",
       "409676   (J)71110134              Paket Sobat Melek Lokalate (Segitiga)\n",
       "425955   (J)71110146  Hampers Exclusive Ramadan - Tropicana Slim Pac...\n",
       "781642   (J)71110147                  SPECIAL 6.6 - Brand Box Nutrimart\n",
       "917902   (J)71110143  Green Packing - L-Men Hi Protein 2 Go Chocolat...\n",
       "921750   (J)71110141  Green Packing - Tropicana Slim Oat Drink 190 m...\n",
       "922185   (J)71110144  Green Packing - HiLo School Chocolate Ready To...\n",
       "928732   (J)71110139  Green Packing - Tropicana Slim Minyak Kanola 9...\n",
       "934296   (J)71110145  Green Packing - Hilo Teen Chocolate Ready To D...\n",
       "953937   (J)71110142  Green Packing - 4 pack - NutriSari RTD Squeeze...\n",
       "1287805  (J)71110152  Paket Khusus Anniversary Nutrimart Tokopedia x...\n",
       "1679721  (J)71110155  VB SSI -  Tropicana Slim RTD Almond Drink Choc...\n",
       "1679965  (J)71110154  VB SSI - Tropicana Slim Oat Drink 190 ml (RTD)...\n",
       "1685327  (J)71110153                     Paket 45 Rasa NutriSari - 2023"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all[data_all['Real SKU'].str.contains('J', na= False, case = False)][['Real SKU','Real Nama Produk']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00896e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analisis Lazada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "efc14615",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_all[data_all['Store'].isin(['Lazada']) & data_all['Order Status'].isin(osf['order filter'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1b157642",
   "metadata": {},
   "outputs": [],
   "source": [
    "laz = df.groupby(['Order #','Year','Month','Date','Store Type','Store','Channel','Coupon Code','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name','Customer Name','Customer Email','Phone','Payment Channel','City','Real Region'], dropna = False).agg({'Qty. Invoiced':'sum','Total Net Before PPN':'sum','Total Net' : 'sum','Total' : 'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d04159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c6400749",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\Masterdata\\\\Clean Data\\\\data_all_20 February With Order Online.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m date\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#Read CSV\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m df22 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mMasterdata\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mClean Data\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdata_all_20 February With Order Online.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPhone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOrder #\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAWB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m df22[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue datetime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mto_datetime(df22[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue datetime\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     14\u001b[0m df22[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReal SKU\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mdf22[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReal SKU\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\Masterdata\\\\Clean Data\\\\data_all_20 February With Order Online.csv'"
     ]
    }
   ],
   "source": [
    "#DATA TAHUN 2022\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xlwt\n",
    "import datetime as dt\n",
    "pd.options.mode.chained_assignment = None\n",
    "import datetime\n",
    "from datetime import date\n",
    "\n",
    "#Read CSV\n",
    "df22 = pd.read_csv(r\"D:\\Masterdata\\Clean Data\\data_all_20 February With Order Online.csv\", sep = ';',converters = {'Phone' : str, 'Order #' : str, 'AWB' : str})\n",
    "\n",
    "df22['True datetime']=pd.to_datetime(df22['True datetime'])\n",
    "df22['Real SKU']=df22['Real SKU'].astype(str)\n",
    "df22['Phone']=df22['Phone'].str.extract('(\\d+)')\n",
    "df22 = df22[df22['Year'].isin([2022])]\n",
    "df22 = df22[['Order #','Sales Order ID','Order Status','Order date','True datetime','Date','Month','Year','Store Type','Store','Customer Name','Phone','Brand','Sub Brand','Real SKU','Real Nama Produk','Parent Item','Bundle Name','Qty. Invoiced','Total Net Before PPN','Total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4afc7a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order #\n",
      "Sales Order ID\n",
      "AWB\n",
      "Paid Date\n",
      "Order Status\n",
      "Order date\n",
      "Week\n",
      "Date\n",
      "Month\n",
      "Quarter\n",
      "Year\n",
      "Channel\n",
      "SKU\n",
      "Brand\n",
      "Product Name\n",
      "Bundle Name\n",
      "Price List NFI\n",
      "Qty. Invoiced\n",
      "Total Net\n",
      "Sub Brand\n",
      "Real SKU\n",
      "Real Nama Produk\n",
      "Parent Item\n",
      "Parent SKU\n",
      "Bundle Flag\n",
      "Customer Email\n",
      "Customer Name\n",
      "Customer Group\n",
      "Phone\n",
      "Country\n",
      "Region\n",
      "City\n",
      "Kecamatan\n",
      "Kelurahan\n",
      "Address\n",
      "Zip Code\n",
      "Shipping Name\n",
      "Shipping Courier\n",
      "Total\n",
      "Coupon Code\n",
      "Qty. Ordered\n",
      "Qty. Shipped\n",
      "Qty. Refunded\n",
      "Item Price\n",
      "Subtotal\n",
      "Discounts\n",
      "Tax\n",
      "Total incl. Tax\n",
      "Invoiced\n",
      "Tax Invoiced\n",
      "Invoiced incl. Tax\n",
      "Refunded\n",
      "Refunded incl. Tax\n",
      "Cart Name Rule\n",
      "Payment Channel\n",
      "Voucher Amount\n",
      "Discount Poin Reward\n",
      "Ship Date\n",
      "Discount Product\n",
      "Produk 1\n",
      "SKU Produk 1\n",
      "PCS Produk 1\n",
      "Price List NFI 1\n",
      "Subtotal Produk 1\n",
      "Harga Display 1\n",
      "Harga Cost 1\n",
      "Produk 2\n",
      "SKU Produk 2\n",
      "PCS Produk 2\n",
      "Price List NFI 2\n",
      "Subtotal Produk 2\n",
      "Harga Display 2\n",
      "Harga Cost 2\n",
      "Produk 3\n",
      "SKU Produk 3\n",
      "PCS Produk 3\n",
      "Price List NFI 3\n",
      "Subtotal Produk 3\n",
      "Harga Display 3\n",
      "Harga Cost 3\n",
      "Produk 4\n",
      "SKU Produk 4\n",
      "PCS Produk 4\n",
      "Price List NFI 4\n",
      "Subtotal Produk 4\n",
      "Harga Display 4\n",
      "Harga Cost 4\n",
      "Produk 5\n",
      "SKU Produk 5\n",
      "PCS Produk 5\n",
      "Price List NFI 5\n",
      "Subtotal Produk 5\n",
      "Harga Display 5\n",
      "Harga Cost 5\n",
      "Produk 6\n",
      "SKU Produk 6\n",
      "PCS Produk 6\n",
      "Price List NFI 6\n",
      "Subtotal Produk 6\n",
      "Harga Display 6\n",
      "Harga Cost 6\n",
      "Produk 7\n",
      "SKU Produk 7\n",
      "PCS Produk 7\n",
      "Price List NFI 7\n",
      "Subtotal Produk 7\n",
      "Harga Display 7\n",
      "Harga Cost 7\n",
      "Cancelled Date\n",
      "Currency Code\n",
      "Bundle\n",
      "Loc ID\n",
      "Barcode ID\n",
      "Warehouse Name\n",
      "Regular Price\n",
      "Selling Price\n",
      "VAT\n",
      "Shipping\n",
      "Actual Shipping\n",
      "Seller Discount\n",
      "Seller Rebate\n",
      "Gross Sales\n",
      "Shipping Address2\n",
      "Notes\n",
      "Store\n",
      "Qty. Ordered\"\n",
      "Qty. Shipped\"\n",
      "Harga Organik 1\n",
      "Harga Organik 2\n",
      "Harga Organik 3\n",
      "Harga Organik 4\n",
      "Harga Organik 5\n",
      "Harga Organik 6\n",
      "Harga Organik 7\n",
      "Kode SKU\n",
      "Blibli SKU\n",
      "Kode Merchant\n",
      "True datetime\n",
      "Promo\n",
      "Discount MC\n",
      "Harga Cost\n",
      "Total Harga Cost\n",
      "No. Order Item L-Men Blibli\n",
      "Order Voucher Amount\n",
      "Item Voucher Amount\n",
      "Item Voucher Platform\n",
      "Item Voucher Seller\n",
      "nominal\n",
      "btlcost\n",
      "gs\n",
      "commfee\n",
      "fullfee\n",
      "index\n",
      "Phone Condition\n",
      "Warehouse Code\n",
      "Channel Rebate\n",
      "Shipping Province\n",
      "Shipping City\n",
      "Shipping Address1\n",
      "Shipping Phone\n",
      "Hour\n",
      "payment_status\n",
      "Shipping Cost\n",
      "Invoice Number\n",
      "Shopee Order\n",
      "Shopee Cust\n",
      "Store Type\n",
      "Category\n",
      "Real SKU_y\n",
      "Region Group\n",
      "PL Before PPN\n",
      "Total Net Before PPN\n",
      "Payment Status\n",
      "Payment Type\n",
      "Printed Date\n",
      "Fulfilled Date\n",
      "Delivered Date\n",
      "Return ID\n",
      "Return Reference No.\n",
      "Return Date\n",
      "Service Type\n",
      "Bundle SKU Code\n",
      "Location ID\n",
      "Invoice ID\n",
      "Invoice Reference Number\n",
      "Invoice Status\n",
      "Invoice Create Date\n",
      "Fee Amount\n",
      "Invoice Amount\n",
      "Payment Received ID\n",
      "Payment Received Ref. number\n",
      "Category Baru\n",
      "Exported Parent Item\n",
      "Unnamed: 0\n",
      "Price List NFI_x\n",
      "Customer Type\n",
      "Real Region\n",
      "True datetime1\n",
      "Payment Date\n",
      "Shipping Customer Name\n",
      "Shipped Date\n",
      "Note\n",
      "Ready to Ship Date\n",
      "Completed Date\n",
      "Cancelled Reason\n",
      "Item Note\n",
      "Shipping Fee (Cashless)\n",
      "Picklist ID\n",
      "Package ID\n",
      "Shipment ID\n",
      "Bundle SKU\n"
     ]
    }
   ],
   "source": [
    "for i in data_all.columns :\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aec9ddb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Jawa Timur', 'Jawa Barat', 'Jabodetabek', 'Di Yogyakarta',\n",
       "       'Kalimantan Tengah', 'Jawa Tengah', 'Kalimantan Timur',\n",
       "       'Sumatera Utara', 'Riau', 'Sulawesi Tengah', 'Sumatera Selatan',\n",
       "       'Jambi', 'Lampung', 'Bali', 'Nusa Tenggara Barat',\n",
       "       'Sumatera Barat', 'Kalimantan Barat', 'Maluku Utara',\n",
       "       'Sulawesi Selatan', 'Kepulauan Riau', 'Kepulauan Bangka Belitung',\n",
       "       'Papua', 'Kalimantan Selatan', 'Aceh', 'Maluku',\n",
       "       'Kalimantan Utara', 'Sulawesi Tenggara', 'Bengkulu',\n",
       "       'Sulawesi Barat', 'Papua Barat', 'Nusa Tenggara Timur',\n",
       "       'Sulawesi Utara', 'Gorontalo'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all[data_all['Store'].isin(['Lazada'])]['Region Group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c245c0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c374ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ph = data_all[data_all['Region Group'].str.contains('Sulawesi Selatan', case = False, na = False) &\n",
    "         data_all['Store'].isin(['Lazada'])&\n",
    "         (data_all['True datetime'] > '2023-01-01')&\n",
    "         (data_all['True datetime'] < '2023-12-01')&     \n",
    "         data_all['Brand'].isin(['HiLo','TS','L-Men','WDANK'])]['Phone'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fd07cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "active = data_all[data_all['Phone'].isin(ph) &\n",
    "                 data_all['Store'].isin(['Lazada'])&\n",
    "                 data_all['Year'].isin([2023])].groupby('Phone').agg({'Order #' : 'nunique'}).reset_index()\n",
    "ph2 = active[active['Order #'] > 3][['Phone']].drop_duplicates()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04815dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamond = data_all[data_all['Phone'].isin(ph2) &\n",
    "                 data_all['Store'].isin(['Lazada'])&\n",
    "                 data_all['Year'].isin([2023])].groupby('Phone').agg({'Total' : 'sum'}).reset_index()\n",
    "ph3 = diamond[(diamond['Total'] > 2000000)]['Phone'].unique()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ece0c5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phs = data_all[data_all['Region Group'].str.contains('Sulawesi Selatan|South Sulawesi', case = False, na = False) &\n",
    "         data_all['Store'].isin(['Lazada']) &\n",
    "         (data_all['True datetime'] > '2023-01-01')&\n",
    "         data_all['Brand'].isin(['HiLo','TS','L-Men','WDANK'])]['Phone'].unique()\n",
    "len(phs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "38a88329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone = np.concatenate((phs, ph3))\n",
    "len(phone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9568e7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phone</th>\n",
       "      <th>Region Group</th>\n",
       "      <th>True datetime</th>\n",
       "      <th>Order #</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08113084107</td>\n",
       "      <td>Jawa Timur</td>\n",
       "      <td>2023-11-12 07:00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>2382100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08113253000</td>\n",
       "      <td>Jawa Timur</td>\n",
       "      <td>2023-11-27 08:09:00</td>\n",
       "      <td>102</td>\n",
       "      <td>42136540.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0811410783</td>\n",
       "      <td>Sulawesi Selatan</td>\n",
       "      <td>2023-05-06 17:53:00</td>\n",
       "      <td>1</td>\n",
       "      <td>313300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>081216247983</td>\n",
       "      <td>Jawa Timur</td>\n",
       "      <td>2023-09-27 08:57:00</td>\n",
       "      <td>8</td>\n",
       "      <td>2737200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08121628388</td>\n",
       "      <td>Jawa Timur</td>\n",
       "      <td>2023-11-15 22:41:00</td>\n",
       "      <td>93</td>\n",
       "      <td>96068600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>08981574760</td>\n",
       "      <td>Sulawesi Selatan</td>\n",
       "      <td>2023-03-10 14:42:00</td>\n",
       "      <td>1</td>\n",
       "      <td>73700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>08982928314</td>\n",
       "      <td>Jawa Timur</td>\n",
       "      <td>2023-10-10 00:05:00</td>\n",
       "      <td>7</td>\n",
       "      <td>2921200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>08986354541</td>\n",
       "      <td>Jawa Timur</td>\n",
       "      <td>2023-09-25 04:26:00</td>\n",
       "      <td>8</td>\n",
       "      <td>3006700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>08990140094</td>\n",
       "      <td>Jawa Timur</td>\n",
       "      <td>2023-08-26 20:04:00</td>\n",
       "      <td>26</td>\n",
       "      <td>11422000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>08993441667</td>\n",
       "      <td>Jawa Timur</td>\n",
       "      <td>2023-11-25 11:42:00</td>\n",
       "      <td>16</td>\n",
       "      <td>5015900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>423 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Phone      Region Group       True datetime  Order #       Total\n",
       "0     08113084107        Jawa Timur 2023-11-12 07:00:00        9   2382100.0\n",
       "1     08113253000        Jawa Timur 2023-11-27 08:09:00      102  42136540.0\n",
       "2      0811410783  Sulawesi Selatan 2023-05-06 17:53:00        1    313300.0\n",
       "3    081216247983        Jawa Timur 2023-09-27 08:57:00        8   2737200.0\n",
       "4     08121628388        Jawa Timur 2023-11-15 22:41:00       93  96068600.0\n",
       "..            ...               ...                 ...      ...         ...\n",
       "418   08981574760  Sulawesi Selatan 2023-03-10 14:42:00        1     73700.0\n",
       "419   08982928314        Jawa Timur 2023-10-10 00:05:00        7   2921200.0\n",
       "420   08986354541        Jawa Timur 2023-09-25 04:26:00        8   3006700.0\n",
       "421   08990140094        Jawa Timur 2023-08-26 20:04:00       26  11422000.0\n",
       "422   08993441667        Jawa Timur 2023-11-25 11:42:00       16   5015900.0\n",
       "\n",
       "[423 rows x 5 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data_all[data_all['Phone'].isin(phone)].groupby(['Phone','Region Group']).agg({'True datetime' : 'max',\n",
    "                                                              'Order #' : 'nunique',\n",
    "                                                              'Total' : 'sum'}).reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167996b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42db2669",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(\"HP Laz Makasar.xlsx\") as writer:\n",
    "    ph2.to_excel(writer, sheet_name=\"NM\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0ac42ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order #</th>\n",
       "      <th>Sales Order ID</th>\n",
       "      <th>AWB</th>\n",
       "      <th>Paid Date</th>\n",
       "      <th>Order Status</th>\n",
       "      <th>Order date</th>\n",
       "      <th>Week</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>...</th>\n",
       "      <th>Note</th>\n",
       "      <th>Ready to Ship Date</th>\n",
       "      <th>Completed Date</th>\n",
       "      <th>Cancelled Reason</th>\n",
       "      <th>Item Note</th>\n",
       "      <th>Shipping Fee (Cashless)</th>\n",
       "      <th>Picklist ID</th>\n",
       "      <th>Package ID</th>\n",
       "      <th>Shipment ID</th>\n",
       "      <th>Bundle SKU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1861976</th>\n",
       "      <td>1000118049</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>ready_to_ship</td>\n",
       "      <td>2023-11-28 08:42:00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>November</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861978</th>\n",
       "      <td>1000118050</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>pending_payment</td>\n",
       "      <td>2023-11-28 09:56:00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>November</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861980</th>\n",
       "      <td>1000118051</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>processing</td>\n",
       "      <td>2023-11-28 09:58:00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>November</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861982</th>\n",
       "      <td>1000118052</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>processing</td>\n",
       "      <td>2023-11-28 10:05:00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>November</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861984</th>\n",
       "      <td>1000118052</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>processing</td>\n",
       "      <td>2023-11-28 10:05:00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>November</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861986</th>\n",
       "      <td>1000118052</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>processing</td>\n",
       "      <td>2023-11-28 10:05:00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>November</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861988</th>\n",
       "      <td>1000118052</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>processing</td>\n",
       "      <td>2023-11-28 10:05:00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>November</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861990</th>\n",
       "      <td>1000118052</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>processing</td>\n",
       "      <td>2023-11-28 10:05:00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>November</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861992</th>\n",
       "      <td>1000118052</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>processing</td>\n",
       "      <td>2023-11-28 10:05:00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>November</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861995</th>\n",
       "      <td>1000118052</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>processing</td>\n",
       "      <td>2023-11-28 10:05:00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>November</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861997</th>\n",
       "      <td>1000118053</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>processing</td>\n",
       "      <td>2023-11-28 10:24:00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>November</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861999</th>\n",
       "      <td>1000118054</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>processing</td>\n",
       "      <td>2023-11-28 10:41:00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>November</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Order # Sales Order ID AWB  Paid Date     Order Status  \\\n",
       "1861976  1000118049            NaN            NaN    ready_to_ship   \n",
       "1861978  1000118050            NaN            NaN  pending_payment   \n",
       "1861980  1000118051            NaN            NaN       processing   \n",
       "1861982  1000118052            NaN            NaN       processing   \n",
       "1861984  1000118052            NaN            NaN       processing   \n",
       "1861986  1000118052            NaN            NaN       processing   \n",
       "1861988  1000118052            NaN            NaN       processing   \n",
       "1861990  1000118052            NaN            NaN       processing   \n",
       "1861992  1000118052            NaN            NaN       processing   \n",
       "1861995  1000118052            NaN            NaN       processing   \n",
       "1861997  1000118053            NaN            NaN       processing   \n",
       "1861999  1000118054            NaN            NaN       processing   \n",
       "\n",
       "                  Order date  Week  Date     Month  Quarter  ...  Note  \\\n",
       "1861976  2023-11-28 08:42:00  48.0  28.0  November      4.0  ...   NaN   \n",
       "1861978  2023-11-28 09:56:00  48.0  28.0  November      4.0  ...   NaN   \n",
       "1861980  2023-11-28 09:58:00  48.0  28.0  November      4.0  ...   NaN   \n",
       "1861982  2023-11-28 10:05:00  48.0  28.0  November      4.0  ...   NaN   \n",
       "1861984  2023-11-28 10:05:00  48.0  28.0  November      4.0  ...   NaN   \n",
       "1861986  2023-11-28 10:05:00  48.0  28.0  November      4.0  ...   NaN   \n",
       "1861988  2023-11-28 10:05:00  48.0  28.0  November      4.0  ...   NaN   \n",
       "1861990  2023-11-28 10:05:00  48.0  28.0  November      4.0  ...   NaN   \n",
       "1861992  2023-11-28 10:05:00  48.0  28.0  November      4.0  ...   NaN   \n",
       "1861995  2023-11-28 10:05:00  48.0  28.0  November      4.0  ...   NaN   \n",
       "1861997  2023-11-28 10:24:00  48.0  28.0  November      4.0  ...   NaN   \n",
       "1861999  2023-11-28 10:41:00  48.0  28.0  November      4.0  ...   NaN   \n",
       "\n",
       "        Ready to Ship Date Completed Date Cancelled Reason Item Note  \\\n",
       "1861976                NaN            NaN              NaN       NaN   \n",
       "1861978                NaN            NaN              NaN       NaN   \n",
       "1861980                NaN            NaN              NaN       NaN   \n",
       "1861982                NaN            NaN              NaN       NaN   \n",
       "1861984                NaN            NaN              NaN       NaN   \n",
       "1861986                NaN            NaN              NaN       NaN   \n",
       "1861988                NaN            NaN              NaN       NaN   \n",
       "1861990                NaN            NaN              NaN       NaN   \n",
       "1861992                NaN            NaN              NaN       NaN   \n",
       "1861995                NaN            NaN              NaN       NaN   \n",
       "1861997                NaN            NaN              NaN       NaN   \n",
       "1861999                NaN            NaN              NaN       NaN   \n",
       "\n",
       "        Shipping Fee (Cashless)  Picklist ID  Package ID  Shipment ID  \\\n",
       "1861976                     NaN          NaN         NaN          NaN   \n",
       "1861978                     NaN          NaN         NaN          NaN   \n",
       "1861980                     NaN          NaN         NaN          NaN   \n",
       "1861982                     NaN          NaN         NaN          NaN   \n",
       "1861984                     NaN          NaN         NaN          NaN   \n",
       "1861986                     NaN          NaN         NaN          NaN   \n",
       "1861988                     NaN          NaN         NaN          NaN   \n",
       "1861990                     NaN          NaN         NaN          NaN   \n",
       "1861992                     NaN          NaN         NaN          NaN   \n",
       "1861995                     NaN          NaN         NaN          NaN   \n",
       "1861997                     NaN          NaN         NaN          NaN   \n",
       "1861999                     NaN          NaN         NaN          NaN   \n",
       "\n",
       "        Bundle SKU  \n",
       "1861976        NaN  \n",
       "1861978        NaN  \n",
       "1861980        NaN  \n",
       "1861982        NaN  \n",
       "1861984        NaN  \n",
       "1861986        NaN  \n",
       "1861988        NaN  \n",
       "1861990        NaN  \n",
       "1861992        NaN  \n",
       "1861995        NaN  \n",
       "1861997        NaN  \n",
       "1861999        NaN  \n",
       "\n",
       "[12 rows x 211 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all[data_all['Store'].isin(['Nutrimart']) & (data_all['True datetime'] >= \"2023-11-28\")\n",
    "         & data_all['Brand'].isin(['NS','TS','HiLo','L-Men','WDANK'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c89c5e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['02/01/2023 09:21', '02/01/2023 08:19', '01/01/2023 23:38', ...,\n",
       "       Timestamp('2023-11-09 00:00:00'), Timestamp('2023-11-16 00:00:00'),\n",
       "       Timestamp('2023-12-01 00:00:00')], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "00a08880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mangoove\n",
    "df = data_all[data_all['Store'].isin(['Lazada','Shopee','TikTok','Tokopedia','Nutrimart','Blibli','Bukalapak']) &\n",
    "              data_all['Order Status'].isin(osf['order filter'].unique()) &\n",
    "              data_all['Brand'].isin(['NS','TS','WDANK','HiLo','Lokalate'])]\n",
    "df['datetime'] = df['True datetime'].astype(str)\n",
    "df = df[df['datetime'].str.contains('2023-11-11|2023-12-12|2023-10-10', case = False, na = False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8aa00699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Store</th>\n",
       "      <th>Order #</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>December</td>\n",
       "      <td>Blibli</td>\n",
       "      <td>12144450802</td>\n",
       "      <td>47000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>December</td>\n",
       "      <td>Blibli</td>\n",
       "      <td>12144455080</td>\n",
       "      <td>560785.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>December</td>\n",
       "      <td>Blibli</td>\n",
       "      <td>12144456902</td>\n",
       "      <td>642600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>December</td>\n",
       "      <td>Blibli</td>\n",
       "      <td>12144457003</td>\n",
       "      <td>213000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>December</td>\n",
       "      <td>Blibli</td>\n",
       "      <td>12144457500</td>\n",
       "      <td>142002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32996</th>\n",
       "      <td>October</td>\n",
       "      <td>Tokopedia</td>\n",
       "      <td>INV/20231010/MPL/3503928802</td>\n",
       "      <td>82100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32997</th>\n",
       "      <td>October</td>\n",
       "      <td>Tokopedia</td>\n",
       "      <td>INV/20231010/MPL/3503929861</td>\n",
       "      <td>69300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32998</th>\n",
       "      <td>October</td>\n",
       "      <td>Tokopedia</td>\n",
       "      <td>INV/20231010/MPL/3503929913</td>\n",
       "      <td>23300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32999</th>\n",
       "      <td>October</td>\n",
       "      <td>Tokopedia</td>\n",
       "      <td>INV/20231010/MPL/3503934947</td>\n",
       "      <td>317400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33000</th>\n",
       "      <td>October</td>\n",
       "      <td>Tokopedia</td>\n",
       "      <td>INV/20231010/MPL/3503942378</td>\n",
       "      <td>9900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33001 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Month      Store                      Order #     Total\n",
       "0      December     Blibli                  12144450802   47000.0\n",
       "1      December     Blibli                  12144455080  560785.0\n",
       "2      December     Blibli                  12144456902  642600.0\n",
       "3      December     Blibli                  12144457003  213000.0\n",
       "4      December     Blibli                  12144457500  142002.0\n",
       "...         ...        ...                          ...       ...\n",
       "32996   October  Tokopedia  INV/20231010/MPL/3503928802   82100.0\n",
       "32997   October  Tokopedia  INV/20231010/MPL/3503929861   69300.0\n",
       "32998   October  Tokopedia  INV/20231010/MPL/3503929913   23300.0\n",
       "32999   October  Tokopedia  INV/20231010/MPL/3503934947  317400.0\n",
       "33000   October  Tokopedia  INV/20231010/MPL/3503942378    9900.0\n",
       "\n",
       "[33001 rows x 4 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.groupby(['Month','Store','Order #']).agg({'Total' : 'sum'}).reset_index()\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "101aa397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_233b3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_233b3_level0_col0\" class=\"col_heading level0 col0\" >Store</th>\n",
       "      <th id=\"T_233b3_level0_col1\" class=\"col_heading level0 col1\" >Order #</th>\n",
       "      <th id=\"T_233b3_level0_col2\" class=\"col_heading level0 col2\" >Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_233b3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_233b3_row0_col0\" class=\"data row0 col0\" >Blibli</td>\n",
       "      <td id=\"T_233b3_row0_col1\" class=\"data row0 col1\" >259</td>\n",
       "      <td id=\"T_233b3_row0_col2\" class=\"data row0 col2\" >72,449,110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_233b3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_233b3_row1_col0\" class=\"data row1 col0\" >Bukalapak</td>\n",
       "      <td id=\"T_233b3_row1_col1\" class=\"data row1 col1\" >5</td>\n",
       "      <td id=\"T_233b3_row1_col2\" class=\"data row1 col2\" >740,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_233b3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_233b3_row2_col0\" class=\"data row2 col0\" >Lazada</td>\n",
       "      <td id=\"T_233b3_row2_col1\" class=\"data row2 col1\" >7,581</td>\n",
       "      <td id=\"T_233b3_row2_col2\" class=\"data row2 col2\" >2,140,297,320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_233b3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_233b3_row3_col0\" class=\"data row3 col0\" >Nutrimart</td>\n",
       "      <td id=\"T_233b3_row3_col1\" class=\"data row3 col1\" >13</td>\n",
       "      <td id=\"T_233b3_row3_col2\" class=\"data row3 col2\" >23,272,394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_233b3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_233b3_row4_col0\" class=\"data row4 col0\" >Shopee</td>\n",
       "      <td id=\"T_233b3_row4_col1\" class=\"data row4 col1\" >5,845</td>\n",
       "      <td id=\"T_233b3_row4_col2\" class=\"data row4 col2\" >1,141,436,884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_233b3_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_233b3_row5_col0\" class=\"data row5 col0\" >TikTok</td>\n",
       "      <td id=\"T_233b3_row5_col1\" class=\"data row5 col1\" >92</td>\n",
       "      <td id=\"T_233b3_row5_col2\" class=\"data row5 col2\" >14,639,355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_233b3_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_233b3_row6_col0\" class=\"data row6 col0\" >Tokopedia</td>\n",
       "      <td id=\"T_233b3_row6_col1\" class=\"data row6 col1\" >2,132</td>\n",
       "      <td id=\"T_233b3_row6_col2\" class=\"data row6 col2\" >413,116,246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15ffaa42550>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df1[df1['Total'] >= 100000].groupby(['Store']).agg({'Order #' : 'nunique', 'Total' : 'sum'}).reset_index()#.style.format({\"Total\": \"{:.2f}\"})\n",
    "df2['Total'] = df2['Total'].astype(int)\n",
    "df2.style.format({\"Order #\" : \"{:,d}\",\"Total\" : \"{:,d}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1557c059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15927"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Order #'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4cbfb74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3805952009"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Total'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4a4f1a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2023-10-10 00:00:00', '2023-10-10 23:59:00',\n",
       "       '2023-10-10 23:58:00', ..., '2023-12-12 03:13:00',\n",
       "       '2023-12-12 01:46:00', '2023-12-12 01:44:00'], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['datetime'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07228fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5d21ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ci Evelyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dca0f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "osf=pd.read_excel(r\"data_supp\\order filter.xlsx\")\n",
    "df = data_all[data_all['Store'].isin(['Lazada','Shopee']) &\n",
    "              data_all['Order Status'].isin(osf['order filter'].unique()) &\n",
    "              data_all['Brand'].isin(['NS','TS','WDANK','HiLo','L-Men']) &\n",
    "              (data_all['True datetime'] >= '2023-06-01')]\n",
    "orderNS = data_all[data_all['Brand'].isin(['NS'])]['Order #'].unique()\n",
    "df = df[~df['Order #'].isin(orderNS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0052445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##SHOPEE\n",
    "dfs = df[df['Store'].isin(['Shopee'])]\n",
    "orders = dfs['Order #'].nunique()\n",
    "totals = dfs['Total'].sum()\n",
    "aovs = totals/orders\n",
    "aovs\n",
    "\n",
    "orders = dfs.groupby('Order #').agg({'Total' : 'sum'}).reset_index()\n",
    "orders = orders[orders['Total'] > aovs]['Order #'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaf73052",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Lazada\n",
    "dfl = df[df['Store'].isin(['Lazada'])]\n",
    "orderl = dfl['Order #'].nunique()\n",
    "totall = dfl['Total'].sum()\n",
    "aovl = totall/orderl\n",
    "aovl\n",
    "\n",
    "orderl = dfl.groupby('Order #').agg({'Total' : 'sum'}).reset_index()\n",
    "orderl = orderl[orderl['Total'] > aovl]['Order #'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7edbd385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2306017BBHYMHW', '2306017BDWADY9', '2306017BF2FM0K', ...,\n",
       "       '1340582734667883', '1340599144156819', '1340600909359390'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = np.concatenate((orders, orderl))\n",
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c4ca94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eve = df[df['Order #'].isin(order)][['Month','Store','Brand','Real Nama Produk','Qty. Invoiced']]\n",
    "with pd.ExcelWriter(\"Ci Eve.xlsx\") as writer:\n",
    "    eve.to_excel(writer, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d3401c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131888.56502567287\n",
      "137631.3005585275\n"
     ]
    }
   ],
   "source": [
    "print(aovs)\n",
    "print(aovl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77908b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2HH1409249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2HG0103050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2HC0113021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2HC0112021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2101609180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2LH1204172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2LC0903181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2304515112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2304008180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2LM0801029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1N01402250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1101182250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1N00838454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1N03301456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1N00804229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1NC1402055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1101656318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1101677318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2T00805043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2T00806053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2T01403249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2T01705024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2104148024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2106023014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2105028180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2T03201001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2104241210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2104394210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2102300105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2T01812126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2T02603203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SKU\n",
       "0   2HH1409249\n",
       "1   2HG0103050\n",
       "2   2HC0113021\n",
       "3   2HC0112021\n",
       "4   2101609180\n",
       "5   2LH1204172\n",
       "6   2LC0903181\n",
       "7   2304515112\n",
       "8   2304008180\n",
       "9   2LM0801029\n",
       "10  1N01402250\n",
       "11  1101182250\n",
       "12  1N00838454\n",
       "13  1N03301456\n",
       "14  1N00804229\n",
       "15  1NC1402055\n",
       "16  1101656318\n",
       "17  1101677318\n",
       "18  2T00805043\n",
       "19  2T00806053\n",
       "20  2T01403249\n",
       "21  2T01705024\n",
       "22  2104148024\n",
       "23  2106023014\n",
       "24  2105028180\n",
       "25  2T03201001\n",
       "26  2104241210\n",
       "27  2104394210\n",
       "28  2102300105\n",
       "29  2T01812126\n",
       "30  2T02603203"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hut = pd.read_excel(r\"C:\\Users\\steven.nathanael\\OneDrive - PT Nutrifood Indonesia\\hut.xlsx\")\n",
    "hut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8e30a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order #</th>\n",
       "      <th>Sales Order ID</th>\n",
       "      <th>AWB</th>\n",
       "      <th>Paid Date</th>\n",
       "      <th>Order Status</th>\n",
       "      <th>Order date</th>\n",
       "      <th>Week</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>...</th>\n",
       "      <th>Note</th>\n",
       "      <th>Ready to Ship Date</th>\n",
       "      <th>Completed Date</th>\n",
       "      <th>Cancelled Reason</th>\n",
       "      <th>Item Note</th>\n",
       "      <th>Shipping Fee (Cashless)</th>\n",
       "      <th>Picklist ID</th>\n",
       "      <th>Package ID</th>\n",
       "      <th>Shipment ID</th>\n",
       "      <th>Bundle SKU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12121427924</td>\n",
       "      <td>12170372672</td>\n",
       "      <td>BLIRA0000049663675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>02/01/2023 11:49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>12121553450</td>\n",
       "      <td>12170552392</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Order Batal</td>\n",
       "      <td>03/01/2023 23:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>12121660419</td>\n",
       "      <td>12170707342</td>\n",
       "      <td>BLI1411228674113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>05/01/2023 12:53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>12121969124</td>\n",
       "      <td>12171149264</td>\n",
       "      <td>BLI2209226677605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>09/01/2023 23:29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>12122067474</td>\n",
       "      <td>12171289228</td>\n",
       "      <td>BLI2209227928380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sudah Settlement</td>\n",
       "      <td>11/01/2023 10:24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425036</th>\n",
       "      <td>Nubi -ECOM RETAIL - TOKO NOW</td>\n",
       "      <td>Nubi -ECOM RETAIL - TOKO NOW</td>\n",
       "      <td></td>\n",
       "      <td>13.0</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>2024-01-13 00:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425037</th>\n",
       "      <td>Nubi -ECOM RETAIL - TOKO NOW</td>\n",
       "      <td>Nubi -ECOM RETAIL - TOKO NOW</td>\n",
       "      <td></td>\n",
       "      <td>13.0</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>2024-01-13 00:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425043</th>\n",
       "      <td>Nubi -ECOM RETAIL - TOKO NOW</td>\n",
       "      <td>Nubi -ECOM RETAIL - TOKO NOW</td>\n",
       "      <td></td>\n",
       "      <td>13.0</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>2024-01-13 00:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425050</th>\n",
       "      <td>Nubi -ECOM RETAIL - TOKO NOW</td>\n",
       "      <td>Nubi -ECOM RETAIL - TOKO NOW</td>\n",
       "      <td></td>\n",
       "      <td>13.0</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>2024-01-13 00:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425053</th>\n",
       "      <td>Nubi -ECOM RETAIL - ASTRO</td>\n",
       "      <td>Nubi -ECOM RETAIL - ASTRO</td>\n",
       "      <td></td>\n",
       "      <td>12.0</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>2024-01-12 00:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185251 rows × 211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Order #                Sales Order ID  \\\n",
       "27                        12121427924                   12170372672   \n",
       "36                        12121553450                   12170552392   \n",
       "65                        12121660419                   12170707342   \n",
       "106                       12121969124                   12171149264   \n",
       "119                       12122067474                   12171289228   \n",
       "...                               ...                           ...   \n",
       "2425036  Nubi -ECOM RETAIL - TOKO NOW  Nubi -ECOM RETAIL - TOKO NOW   \n",
       "2425037  Nubi -ECOM RETAIL - TOKO NOW  Nubi -ECOM RETAIL - TOKO NOW   \n",
       "2425043  Nubi -ECOM RETAIL - TOKO NOW  Nubi -ECOM RETAIL - TOKO NOW   \n",
       "2425050  Nubi -ECOM RETAIL - TOKO NOW  Nubi -ECOM RETAIL - TOKO NOW   \n",
       "2425053     Nubi -ECOM RETAIL - ASTRO     Nubi -ECOM RETAIL - ASTRO   \n",
       "\n",
       "                        AWB  Paid Date      Order Status           Order date  \\\n",
       "27       BLIRA0000049663675        NaN         Delivered     02/01/2023 11:49   \n",
       "36                      nan        NaN       Order Batal     03/01/2023 23:00   \n",
       "65         BLI1411228674113        NaN         Delivered     05/01/2023 12:53   \n",
       "106        BLI2209226677605        NaN         Delivered     09/01/2023 23:29   \n",
       "119        BLI2209227928380        NaN  Sudah Settlement     11/01/2023 10:24   \n",
       "...                     ...        ...               ...                  ...   \n",
       "2425036                           13.0         Delivered  2024-01-13 00:00:00   \n",
       "2425037                           13.0         Delivered  2024-01-13 00:00:00   \n",
       "2425043                           13.0         Delivered  2024-01-13 00:00:00   \n",
       "2425050                           13.0         Delivered  2024-01-13 00:00:00   \n",
       "2425053                           12.0         Delivered  2024-01-12 00:00:00   \n",
       "\n",
       "         Week  Date    Month  Quarter  ...  Note Ready to Ship Date  \\\n",
       "27        1.0   2.0  January      1.0  ...   NaN                NaN   \n",
       "36        1.0   3.0  January      1.0  ...   NaN                NaN   \n",
       "65        1.0   5.0  January      1.0  ...   NaN                NaN   \n",
       "106       2.0   9.0  January      1.0  ...   NaN                NaN   \n",
       "119       2.0  11.0  January      1.0  ...   NaN                NaN   \n",
       "...       ...   ...      ...      ...  ...   ...                ...   \n",
       "2425036   2.0  13.0  January      1.0  ...   NaN                NaN   \n",
       "2425037   2.0  13.0  January      1.0  ...   NaN                NaN   \n",
       "2425043   2.0  13.0  January      1.0  ...   NaN                NaN   \n",
       "2425050   2.0  13.0  January      1.0  ...   NaN                NaN   \n",
       "2425053   2.0  12.0  January      1.0  ...   NaN                NaN   \n",
       "\n",
       "        Completed Date Cancelled Reason Item Note Shipping Fee (Cashless)  \\\n",
       "27                 NaN              NaN       NaN                     NaN   \n",
       "36                 NaN              NaN       NaN                     NaN   \n",
       "65                 NaN              NaN       NaN                     NaN   \n",
       "106                NaN              NaN       NaN                     NaN   \n",
       "119                NaN              NaN       NaN                     NaN   \n",
       "...                ...              ...       ...                     ...   \n",
       "2425036            NaN              NaN       NaN                     NaN   \n",
       "2425037            NaN              NaN       NaN                     NaN   \n",
       "2425043            NaN              NaN       NaN                     NaN   \n",
       "2425050            NaN              NaN       NaN                     NaN   \n",
       "2425053            NaN              NaN       NaN                     NaN   \n",
       "\n",
       "         Picklist ID  Package ID  Shipment ID Bundle SKU  \n",
       "27               NaN         NaN          NaN        NaN  \n",
       "36               NaN         NaN          NaN        NaN  \n",
       "65               NaN         NaN          NaN        NaN  \n",
       "106              NaN         NaN          NaN        NaN  \n",
       "119              NaN         NaN          NaN        NaN  \n",
       "...              ...         ...          ...        ...  \n",
       "2425036          NaN         NaN          NaN        NaN  \n",
       "2425037          NaN         NaN          NaN        NaN  \n",
       "2425043          NaN         NaN          NaN        NaN  \n",
       "2425050          NaN         NaN          NaN        NaN  \n",
       "2425053          NaN         NaN          NaN        NaN  \n",
       "\n",
       "[185251 rows x 211 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = data_all[data_all['Real SKU'].isin(hut['SKU'])]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcb29988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "osf=pd.read_excel(r\"data_supp\\order filter.xlsx\")\n",
    "df1[(df1['True datetime'] >= '2023-11-01')&\n",
    "         (df1['Order Status'].isin(osf['order filter'].unique()))].groupby(['Year','Month','Date','Hour','Store Type','Store','Channel','Warehouse Name','Real Region','City','Coupon Code','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name','Exported Parent Item'],dropna=False).agg({'Order #':'nunique','Phone':'nunique','Qty. Invoiced':'sum','Total Net Before PPN':'sum'}).reset_index().to_excel(f'D:\\Masterdata\\Masterdata Lite\\sales hut.xlsx',index=False)\n",
    "# df1.groupby(['Year','Month','Date','Store Type','Store','Channel','Order Status'])[['Order #']].nunique().reset_index().to_excel(f'Cek order gerak {date.today()}.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d7ae21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
