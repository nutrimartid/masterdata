{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cfbe88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data SKU\n",
      "Scrapping Tatanama\n",
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\242614043.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(SKU_append, ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data SKU done\n"
     ]
    }
   ],
   "source": [
    "## run-1\n",
    "## download data sku dari tatanama\n",
    "## common problems: slow server pyany & make sure path to file\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from smtplib import SMTP\n",
    "import smtplib\n",
    "import sys\n",
    "import requests\n",
    "import os\n",
    "\n",
    "\n",
    "print('Reading Data SKU')\n",
    "data_SKU = pd.read_excel('SKU_File\\data_SKU.xlsx')\n",
    "print('Scrapping Tatanama')\n",
    "s = requests.Session()\n",
    "s.get(\"https://tatanama.pythonanywhere.com\")\n",
    "s.post(\"https://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "r = s.get(\"https://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "with open('SKU_File\\Master tatanama.xlsx', 'wb') as output:\n",
    "    output.write(r.content)\n",
    "    \n",
    "print('ok')\n",
    "\n",
    "if os.path.isfile('SKU_File\\Master tatanama.xlsx') :    \n",
    "    SKU_append = pd.read_excel('SKU_File\\Master tatanama.xlsx')\n",
    "    SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "    data_SKU = data_SKU[~data_SKU['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "    data_SKU = data_SKU.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "to_excel = data_SKU.to_excel('SKU_File\\data_SKU.xlsx', index = False)\n",
    "print('data SKU done')\n",
    "data_SKU['Price List NFI'] = data_SKU['Price List NFI'].astype(float).astype('int64')\n",
    "\n",
    "download = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c25dfc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314138c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec7ed68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run-2\n",
    "## belum scrap dari forstok\n",
    "download = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6e0bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25dd088a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Forstok Date\n",
      "2022-10-24-2022-11-03\n",
      "Opening Chrome\n",
      "Login Forstok\n",
      "Forstok Downloaded\n",
      "Download Data SKU\n",
      "Waiting to Download Forstok\n",
      "https://forstok-staging-storage.s3.ap-southeast-1.amazonaws.com/items_import/nutrifood--forstok-sales_orders-version_1-2022-10-24-2022-11-03.xls\n",
      "Waiting to Download Forstok\n",
      "Waiting to Download Forstok\n",
      "Waiting to Download Forstok\n",
      "Waiting to Download Forstok\n",
      "200\n",
      "Import Data ====== 1/10\n",
      "--- 9.711962699890137 seconds ---\n",
      "Formatting Data ====== 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\Anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:48: UserWarning: Parsing '21-12-2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  return self._cmp_method(other, operator.lt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 15.360673427581787 seconds ---\n",
      "Fulfilling SKU ====== 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2310284871.py:255: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_forstok['Item Name'] = data_forstok['Item Name'].str.replace(r' - $', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 45.35828757286072 seconds ---\n",
      "Listing SKU Missing ====== 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2310284871.py:365: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_forstok = data_forstok.append(skushopee, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2310284871.py:398: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  to_excel = data_forstok.to_excel(r'forstok_new.xls', index = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 108.45292067527771 seconds ---\n",
      "Filling Brand ====== 5/10\n",
      "--- 109.0015001296997 seconds ---\n",
      "Unbundling ====== 6/10\n",
      "--- 109.66720247268677 seconds ---\n",
      "Filling Date ====== 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2310284871.py:568: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  data_forstok['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Location ===== 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2310284871.py:619: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  forstok_all['City'] = forstok_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbundling ===== 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2310284871.py:732: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pricing ===== 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2310284871.py:750: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  forstok_all = forstok_all.append(data_bundle, ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "click 1\n",
      "click 2\n",
      "click 3\n",
      "08:54\n",
      "08:54:00\n",
      "2\n",
      "Blibli LMS Downloaded\n",
      "bulk-order-download-template (4).csv\n",
      "Import Data ====== 1/10\n",
      "--- 394.33877897262573 seconds ---\n",
      "Formatting Data ====== 2/10\n",
      "--- 394.4386990070343 seconds ---\n",
      "Listing SKU ====== 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2310284871.py:916: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  lmen['No. Order'] = lmen['No. Order'].astype(str).str.replace('^=\"','')\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2310284871.py:917: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  lmen['No. Order'] = lmen['No. Order'].astype(str).str.replace('\"$','')\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2310284871.py:918: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  lmen['No. Order Item'] = lmen['No. Order Item'].astype(str).str.replace('^=\"','')\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2310284871.py:919: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  lmen['No. Order Item'] = lmen['No. Order Item'].astype(str).str.replace('\"$','')\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2310284871.py:920: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  lmen['No. Awb'] = lmen['No. Awb'].astype(str).str.replace('^=\"','')\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2310284871.py:921: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  lmen['No. Awb'] = lmen['No. Awb'].astype(str).str.replace('\"$','')\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2310284871.py:922: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  lmen['Merchant SKU'] = lmen['Merchant SKU'].astype(str).str.replace('^=\"','')\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2310284871.py:923: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  lmen['Merchant SKU'] = lmen['Merchant SKU'].astype(str).str.replace('\"$','')\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2310284871.py:946: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  lmen = lmen.append(null_sku, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2310284871.py:954: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  lmen = lmen.append(gaada_sku, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2310284871.py:1002: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  lmen['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2310284871.py:1087: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2310284871.py:1092: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  lmen = lmen.append(data_bundle, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2310284871.py:1100: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  forstok_all = forstok_all.append(lmen, ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               SKU                                 Product Name\n",
      "595    (B)71210147                          (FREE) Masker L-Men\n",
      "844  (B)2309005305  (PBS) L-Men Protein Crunch BBQ Beef 20BX20G\n",
      "859    (B)71210295            Sampling - HiLo Multigrain Sachet\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "## run-3\n",
    "## scrap data forstok & blibli lmen\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from datetime import datetime, timedelta\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import requests\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "diff_date = 10\n",
    "# diff_date = 40## sementara\n",
    "# diff_date2 = 30## sementara\n",
    "# data_prev = '7 Juli'\n",
    "data_now = str(datetime.today().day) + ' ' + str(datetime.today().strftime(\"%B\"))\n",
    "\n",
    "print('Input Forstok Date')\n",
    "start_date = datetime.today() - timedelta(days=diff_date)\n",
    "end_date = datetime.today()\n",
    "# end_date = datetime.today() - timedelta(days=diff_date2)### sementara\n",
    "date = start_date.strftime('%Y-%m-%d') + '-' + end_date.strftime('%Y-%m-%d')\n",
    "print(date)\n",
    "\n",
    "if not download:\n",
    "    print('Opening Chrome')\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    actions = ActionChains(driver)\n",
    "    driver.get(\"https://www.forstok.com/dashboard/users/login\")\n",
    "    print('Login Forstok')\n",
    "    username = driver.find_element_by_id(\"dashboard_user_email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"timotius.giovandi@nutrifood.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_id(\"dashboard_user_password\")\n",
    "    password.send_keys(\"timo123\")\n",
    "    \n",
    "    driver.find_element_by_name(\"commit\").click()\n",
    "    \n",
    "    time.sleep(20)\n",
    "    datefield = WebDriverWait(driver, 100).until(EC.element_to_be_clickable((By.XPATH,'//*[@type=\"button\" and contains(text(),\"Last 30 days\")]')))\n",
    "    datef = WebDriverWait(driver, 200).until(EC.element_to_be_clickable((By.XPATH,'//*[@id=\"root\"]/section/section[2]/article/div/div/aside/div/div[1]/section[5]/section[1]/h2')))\n",
    "    driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datef)\n",
    "    time.sleep(30)\n",
    "    driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "    time.sleep(10)\n",
    "    datefield.click()\n",
    "    pilih=0\n",
    "    while pilih < 3:    \n",
    "            n_elem=0\n",
    "            for i in driver.find_elements_by_xpath('(//*[@class=\"DateRangePicker__MonthHeaderLabel DateRangePicker__MonthHeaderLabel--month\"])'):\n",
    "                val=(driver.find_elements_by_xpath('(//*[@class=\"DateRangePicker__MonthHeaderLabel DateRangePicker__MonthHeaderLabel--month\"])')[n_elem].text.split()[0])\n",
    "                if val==start_date.strftime('%B'):\n",
    "                    # print(n_elem)\n",
    "                    fin_n_elem=n_elem\n",
    "                n_elem=n_elem+1\n",
    "            if fin_n_elem==0:\n",
    "                text = '(//*[@class=\"DateRangePicker__Month\"])[1]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(start_date.day) + '\")]'\n",
    "                if len(driver.find_elements_by_xpath(text))==2:\n",
    "                    text = '('+text+')[2]'\n",
    "            else:\n",
    "                text = '(//*[@class=\"DateRangePicker__Month\"])[2]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(start_date.day) + '\")]'\n",
    "                if len(driver.find_elements_by_xpath(text))==2:\n",
    "                    text = '('+text+')[1]'\n",
    "            driver.find_element_by_xpath(text).click()\n",
    "            time.sleep(10)\n",
    "\n",
    "            n_elem=0\n",
    "            for i in driver.find_elements_by_xpath('(//*[@class=\"DateRangePicker__MonthHeaderLabel DateRangePicker__MonthHeaderLabel--month\"])'):\n",
    "                val=(driver.find_elements_by_xpath('(//*[@class=\"DateRangePicker__MonthHeaderLabel DateRangePicker__MonthHeaderLabel--month\"])')[n_elem].text.split()[0])\n",
    "                if val==end_date.strftime('%B'):\n",
    "                    fin_n_elem=n_elem\n",
    "                n_elem=n_elem+1\n",
    "            if fin_n_elem==0:\n",
    "                text = '(//*[@class=\"DateRangePicker__Month\"])[1]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(end_date.day) + '\")]'\n",
    "                if len(driver.find_elements_by_xpath(text))==2:\n",
    "                    text = '('+text+')[2]'\n",
    "            else:\n",
    "                text = '(//*[@class=\"DateRangePicker__Month\"])[2]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(end_date.day) + '\")]'\n",
    "                if end_date.strftime('%B')==start_date.strftime('%B'):\n",
    "                    text = '('+text+')[2]'\n",
    "                else :\n",
    "                    text = '('+text+')[1]'\n",
    "            driver.find_element_by_xpath(text).click()\n",
    "            time.sleep(10)\n",
    "            pilih=pilih+1\n",
    "    driver.find_element_by_xpath('//*[@type=\"button\" and contains(text(),\"Apply\")]').click()\n",
    "    time.sleep(100)\n",
    "    WebDriverWait(driver, 30).until(EC.element_to_be_clickable((By.XPATH, \"(//*[@type='button' and contains(text(),'Export')])[1]\"))).click()\n",
    "    driver.find_element_by_xpath('//span[text()=\"Sales Order\"]').click()\n",
    "    driver.find_element_by_xpath('//span[text()=\"Sales Order\"]').click()\n",
    "    WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"(//*[@type='button' and contains(text(),'Export')])[2]\"))).click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    driver.quit()\n",
    "    \n",
    "    print('Forstok Downloaded')\n",
    "    download = True\n",
    "\n",
    "print('Download Data SKU')\n",
    "# Import library\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import smtplib \n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from smtplib import SMTP\n",
    "import smtplib\n",
    "import sys\n",
    "import requests\n",
    "import os\n",
    "\n",
    "print('Waiting to Download Forstok')\n",
    "s = requests.Session()\n",
    "r = s.get(\"https://www.forstok.com/dashboard/users/login\")\n",
    "data = {'dashboard_user_email' : 'andra.miftah@nutrifood.co.id', \"dashboard_user_password\" : 'nutrimart1234'}\n",
    "r = s.post(\"https://www.forstok.com/dashboard/users/login\", data = data)\n",
    "\n",
    "text = 'https://forstok-staging-storage.s3.ap-southeast-1.amazonaws.com/items_import/nutrifood--forstok-sales_orders-version_1-' + date + '.xls'\n",
    "print(text)\n",
    "while True:\n",
    "    r = s.get(text)\n",
    "    print('Waiting to Download Forstok')\n",
    "    \n",
    "    if r.status_code == requests.codes.ok:\n",
    "        print(r.status_code)\n",
    "        with open('Input Data/Forstok_new_input.xls', 'wb') as output:\n",
    "            output.write(r.content)\n",
    "        break\n",
    "    else :\n",
    "        time.sleep(60)\n",
    "           \n",
    "with open('Input Data/nutrifood--forstok-sales_orders-' + date + '.xls', 'wb') as output:\n",
    "    output.write(r.content)\n",
    "    \n",
    "# Import data\n",
    "start_time = time.time()\n",
    "print(\"Import Data ====== 1/10\")\n",
    "\n",
    "data_forstok = pd.read_excel(r'Input Data/Forstok_new_input.xls')\n",
    "data_forstok_pure = data_forstok.copy()\n",
    "\n",
    "data_forstok = data_forstok.dropna(how = 'all')\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "# Forstok formatting\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Formatting Data ====== 2/10\")\n",
    "\n",
    "if 'Unnamed: 35' in data_forstok:\n",
    "    data_forstok = data_forstok.drop(['Unnamed: 35'], axis = 'columns')\n",
    "if 'Unnamed: 36' in data_forstok:\n",
    "    data_forstok = data_forstok.rename(columns={'Unnamed: 36' : 'Comment'})\n",
    "if 'Unnamed: 37' in data_forstok:\n",
    "    data_forstok = data_forstok.drop(['Unnamed: 37'], axis = 'columns')\n",
    "if 'Unnamed: 38' in data_forstok:\n",
    "    data_forstok = data_forstok.drop(['Unnamed: 38'], axis = 'columns')\n",
    "if 'Unnamed: 39' in data_forstok:\n",
    "    data_forstok = data_forstok.drop(['Unnamed: 39'], axis = 'columns')\n",
    "if 'Unnamed: 40' in data_forstok:\n",
    "    data_forstok = data_forstok.drop(['Unnamed: 40'], axis = 'columns')\n",
    "if 'Unnamed: 41' in data_forstok:\n",
    "    data_forstok = data_forstok.drop(['Unnamed: 41'], axis = 'columns')\n",
    "    \n",
    "data_forstok[\"Order Date\"] = pd.to_datetime(data_forstok[\"Order Date\"], errors = 'coerce')\n",
    "data_forstok[\"Paid Date\"] = pd.to_datetime(data_forstok[\"Paid Date\"], errors = 'coerce')\n",
    "data_forstok[\"Cancelled Date\"] = pd.to_datetime(data_forstok[\"Cancelled Date\"], errors = 'coerce')\n",
    "data_forstok['Customer Name'] = data_forstok['Customer Name'].fillna(data_forstok['Shipping Name'])\n",
    "data_forstok = data_forstok.rename(columns = {'Seller Voucher' : 'Seller Discount'})\n",
    "data_forstok = data_forstok[~((data_forstok['Store']=='Shopee')&(data_forstok['Order Date']<'21-12-2021'))] ###TMO###\n",
    "\n",
    "# Phone formatting\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('=','', regex = False)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('\"','', regex = False)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('(','', regex = False)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace(')','', regex = False)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('-','', regex = False)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('+','', regex = False)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('^620','0', regex = True)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('^62','0', regex = True)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('^620','0', regex = True)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('^8','08', regex = True)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('^21','021', regex = True)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('^008','08', regex = True)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('(021)','021', regex = False)\n",
    "data_forstok['Shipping Phone'] = data_forstok['Shipping Phone'].astype(str).str.replace('+62','0', regex = False)\n",
    "\n",
    "# Forstok SKU\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Fulfilling SKU ====== 3/10\")\n",
    "indeks = data_forstok[data_forstok['Item Name'].astype(str) == 'Buy 1 Get 1 FREE Tropicana Slim Goldenmil Vanilla Manuka Honey (6 Sch)'][data_forstok[data_forstok['Item Name'].astype(str) == 'Buy 1 Get 1 FREE Tropicana Slim Goldenmil Vanilla Manuka Honey (6 Sch)']['SKU'] == 'PE8B27'].index.to_list()\n",
    "data_forstok['SKU'][indeks] = '2101384106P2'\n",
    "data_forstok.loc[data_forstok['SKU']==\"(E)2101492P04\",'SKU']=\"(E)2101492P4\"\n",
    "data_forstok.loc[data_forstok['SKU']==\"P2101151180P2\",'SKU']=\"PT7(2)B65\"\n",
    "data_forstok.loc[data_forstok['SKU']==' PT28(2)B65','SKU']='PT28(2)B65'\n",
    "data_forstok.loc[data_forstok['SKU']==' PT6(2)B65','SKU']='PT6(2)B65'\n",
    "data_forstok.loc[data_forstok['SKU']==' PT1(2)B65','SKU']='PT1(2)B65'\n",
    "data_forstok.loc[(data_forstok['SKU']=='2101865450P3')&(data_forstok['Item Name'].astype(str)=='Tropicana Slim White Coffee 4 Sachet x 3 pcs - Kopi Susu Nikmat Tanpa Gula Pasir'),'SKU']='2104170164P3'\n",
    "data_forstok.loc[(data_forstok['SKU']=='2104170104P3')&(data_forstok['Item Name'].astype(str)=='Triple Pack: Tropicana Slim White Coffee - Kopi Bebas Gula'),'SKU']='2104170164P3'\n",
    "data_forstok.loc[(data_forstok['SKU']=='COLLETTEP24')&(data_forstok['Item Name'].astype(str)=='HiLo School Cotton Candy 200ml - Ready to Drink (24 Pcs)'),'SKU']='2HF1403250P24'\n",
    "data_forstok.loc[(data_forstok['SKU']=='COLLETTEP4')&(data_forstok['Item Name'].astype(str)=='HiLo School Cotton Candy 200ml - Ready to Drink (4 Pcs) Tinggi Kalsium'),'SKU']='2HF1403250P4'\n",
    "\n",
    "skushopee = data_forstok[data_forstok['SKU'].astype(str).str.contains('(S)',regex = False)]\n",
    "data_forstok = data_forstok[~data_forstok['SKU'].astype(str).isin(skushopee['SKU'].astype(str))]\n",
    "\n",
    "skushopee = skushopee.reset_index(drop = True)\n",
    "data_forstok = data_forstok.reset_index(drop = True)\n",
    "\n",
    "forstok_all_sku = pd.read_excel(r'SKU_File\\forstok_all_sku.xlsx')\n",
    "indeks = data_forstok[data_forstok['SKU'].isnull()].index.to_list()\n",
    "\n",
    "for i in indeks:\n",
    "    if str(data_forstok['Item Name'][i]).lower() in data_SKU['Nama Produk'].astype(str).str.lower().values:\n",
    "        data_forstok['SKU'][i] = data_SKU['SKU'].loc[str(data_forstok['Item Name'][i]).lower() == data_SKU['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "indeks = data_forstok[data_forstok['SKU'].isnull()].index.to_list()\n",
    "for i in indeks:\n",
    "    if str(data_forstok['Item Name'][i]).lower() in forstok_all_sku['Item Name'].astype(str).str.lower().values:\n",
    "        data_forstok['SKU'][i] = forstok_all_sku['SKU'].loc[str(data_forstok['Item Name'][i]).lower() == forstok_all_sku['Item Name'].astype(str).str.lower()].values[0]\n",
    "\n",
    "indeks = data_forstok[data_forstok['Item Name'].astype(str).str.contains(' - ')].index.to_list()\n",
    "\n",
    "# Formatting double name\n",
    "for i in indeks:\n",
    "    if data_forstok['Item Name'][i].count(' - ') == 1 :\n",
    "        if (data_forstok['Item Name'][i].split(' - ')[0] == data_forstok['Item Name'][i].split(' - ')[1]):\n",
    "            data_forstok['Item Name'][i] = data_forstok['Item Name'][i].split(' - ')[0]\n",
    "    elif data_forstok['Item Name'][i].count(' - ') > 1:\n",
    "        temp = math.ceil(data_forstok['Item Name'][i].count(' - ')/2)\n",
    "        itemname = ''\n",
    "        duplicate = ''\n",
    "        for j in range(temp):\n",
    "            if j == 0:\n",
    "                itemname = itemname + data_forstok['Item Name'][i].split(' - ')[j]\n",
    "                duplicate = duplicate + data_forstok['Item Name'][i].split(' - ')[temp+j]\n",
    "            else :\n",
    "                itemname = itemname + ' ' +data_forstok['Item Name'][i].split(' - ')[j]\n",
    "                duplicate = duplicate + ' ' +data_forstok['Item Name'][i].split(' - ')[temp+j]\n",
    "        if itemname == duplicate:\n",
    "            data_forstok['Item Name'][i] = itemname\n",
    "        \n",
    "data_forstok['Item Name'] = data_forstok['Item Name'].str.replace(r' - $', '')\n",
    "data_forstok[\"Item Name\"] = data_forstok[\"Item Name\"].str.replace('Special Promo by Nutrimart Serba 12 RIBU Varian:', '', regex=False)\n",
    "data_forstok[\"Item Name\"] = data_forstok[\"Item Name\"].str.replace('Khusus Jabodetabek', '- Khusus Jabodetabek', regex=False)\n",
    "data_forstok['Item Name'] = data_forstok['Item Name'].str.replace('Buy 1 Get F', 'Buy 1 Get 1 F')\n",
    "data_forstok['Item Name'] = data_forstok['Item Name'].str.replace('Buy 1 Get H', 'Buy 1 Get 1 H')\n",
    "data_forstok['Item Name'] = data_forstok['Item Name'].str.replace('Buy 12 FREE', 'Buy 12 FREE 12')\n",
    "\n",
    "# Formatting SKU based on name\n",
    "indeks = data_forstok[data_forstok['SKU'].isnull()].index.to_list()\n",
    "for i in indeks:\n",
    "    if str(data_forstok['Item Name'][i]).lower().strip() in data_SKU['Nama Produk'].astype(str).str.lower().str.strip().values:\n",
    "        data_forstok['SKU'][i] = data_SKU['SKU'].loc[str(data_forstok['Item Name'][i]).lower().strip() == data_SKU['Nama Produk'].astype(str).str.lower().str.strip()].values[0]\n",
    "\n",
    "indeks = data_forstok[data_forstok['SKU'].isnull()].index.to_list()\n",
    "for i in indeks:\n",
    "    if str(data_forstok['Item Name'][i]).lower() in forstok_all_sku['Item Name'].astype(str).str.lower().values:\n",
    "        data_forstok['SKU'][i] = forstok_all_sku['SKU'].loc[str(data_forstok['Item Name'][i]).lower() == forstok_all_sku['Item Name'].astype(str).str.lower()].values[0]\n",
    "\n",
    "indeks = data_forstok[data_forstok['SKU'].isnull()].index.tolist()\n",
    "\n",
    "data_adasku = data_forstok[['Item Name', 'SKU']]\n",
    "data_adasku = data_adasku[data_adasku['SKU'].notnull()]\n",
    "\n",
    "data_nosku = data_forstok[['Item Name', 'SKU']]\n",
    "data_nosku = data_nosku[data_nosku['SKU'].isnull()]\n",
    "\n",
    "for i in indeks:\n",
    "    if data_adasku['SKU'].loc[data_nosku['Item Name'][i] == data_adasku['Item Name']].size != 0:\n",
    "        data_forstok['SKU'][i] = data_adasku['SKU'].loc[data_nosku['Item Name'][i] == data_adasku['Item Name']].values[0]\n",
    "\n",
    "for i in indeks:\n",
    "    if data_forstok['Item Name'][i] == 'Lokalate Kopi Durian 10s':\n",
    "        data_forstok['SKU'][i] = '1101675318'\n",
    "    elif data_forstok['Item Name'][i] == 'Nutrisari Madu Kurma Isi 16 Renceng X 10 Sachet Karton' or data_forstok['Item Name'][i] =='Nutrisari Madu Kurma Isi 16 Renceng X 10 SachetKarton': \n",
    "        data_forstok['SKU'][i] = 'PN30(16)'\n",
    "    elif data_forstok['Item Name'][i] == 'L-Men Protein Bar Crunchy Chocolate Isi X12 (Exp Date:10-Apr-2019)':\n",
    "        data_forstok['SKU'][i] = '2306592173'\n",
    "    elif data_forstok['Item Name'][i] == 'FS Hilo Active Chocolate Minuman Kesehatan [750 gr]' or data_forstok['Item Name'][i] == 'FSHilo Active Chocolate Minuman Kesehatan [750 gr]':\n",
    "        data_forstok['SKU'][i] = '2101452190'\n",
    "    elif data_forstok['Item Name'][i] == 'FS L-Men Platinum Suplemen Kesehatan + Free Spider Bottle [800 g] Hitam' or data_forstok['Item Name'][i] == 'FSL-Men Platinum Suplemen Kesehatan + Free Spider Bottle [800 g] Hitam':\n",
    "        data_forstok['SKU'][i] = '2305551288P1G26'\n",
    "    elif data_forstok['Item Name'][i] == 'NutriSari Premium ala Jus Mangga':\n",
    "        data_forstok['SKU'][i] = '1100534104'\n",
    "    elif data_forstok['Item Name'][i] == 'Buy 1 Get 1 FREE Tropicana Slim Sweetener Honey (50 Sch) - FS':\n",
    "        data_forstok['SKU'][i] = '2102501125P1G53'\n",
    "\n",
    "indeks = data_forstok[~data_forstok['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "for i in indeks:\n",
    "    if str(data_forstok['Item Name'][i]).lower() in forstok_all_sku['Item Name'].astype(str).str.lower().values:\n",
    "        data_forstok['SKU'][i] = forstok_all_sku['SKU'].loc[str(data_forstok['Item Name'][i]).lower() == forstok_all_sku['Item Name'].astype(str).str.lower()].values[0]\n",
    "\n",
    "list_alias = []\n",
    "list_alias_name = []\n",
    "for colname in data_SKU.columns:\n",
    "    if 'Alias SKU' in colname:\n",
    "        list_alias.append(colname)\n",
    "    if 'Alias Nama' in colname:\n",
    "        list_alias_name.append(colname)\n",
    "\n",
    "\n",
    "for i in indeks:\n",
    "    for j in list_alias:\n",
    "        if str(data_forstok['SKU'][i]) in data_SKU[j].astype(str).values:\n",
    "            idx = data_SKU[str(data_forstok['SKU'][i]) == data_SKU[j].astype(str)].index.to_list()\n",
    "            for k in idx:\n",
    "                if str(data_forstok['Item Name'][i]) == data_SKU[j.replace('SKU', 'Nama')][k]:\n",
    "                    data_forstok['SKU'][i] = data_SKU['SKU'][k]\n",
    "                        \n",
    "indeks = data_forstok[~data_forstok['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "\n",
    "for i in indeks:\n",
    "    for j in list_alias_name:\n",
    "        if str(data_forstok['Item Name'][i]).lower() in data_SKU[j].astype(str).str.lower().values:\n",
    "            data_forstok['SKU'][i] = data_SKU['SKU'].loc[str(data_forstok['Item Name'][i]).lower() == data_SKU[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "indeks = data_forstok[~data_forstok['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "\n",
    "for i in indeks:\n",
    "    if str(data_forstok['Item Name'][i]).lower() in data_SKU['Nama Produk'].astype(str).str.lower().values:\n",
    "        data_forstok['SKU'][i] = data_SKU['SKU'].loc[str(data_forstok['Item Name'][i]).lower() == data_SKU['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "indeks = skushopee[~skushopee['SKU'].astype(str).str.replace('(S)','', regex = False).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "for i in indeks:\n",
    "    if str(skushopee['Item Name'][i]).lower() in data_SKU['Nama Produk'].astype(str).str.lower().values:\n",
    "        skushopee['SKU'][i] = data_SKU['SKU'].loc[str(skushopee['Item Name'][i]).lower() == data_SKU['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "        skushopee['SKU'][i] = '(S)' + str(skushopee['SKU'][i])\n",
    "\n",
    "indeks = skushopee[~skushopee['SKU'].astype(str).str.replace('(S)','', regex = False).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "for i in indeks:\n",
    "    for j in list_alias:\n",
    "        if str(skushopee['SKU'][i]).replace('(S)','') in data_SKU[j].astype(str).values:\n",
    "            idx = data_SKU[str(skushopee['SKU'][i]).replace('(S)','') == data_SKU[j].astype(str)].index.to_list()\n",
    "            for k in idx:\n",
    "                if str(skushopee['Item Name'][i]) == data_SKU[j.replace('SKU', 'Nama')][k]:\n",
    "                    skushopee['SKU'][i] = data_SKU['SKU'][k]\n",
    "\n",
    "indeks = data_forstok[data_forstok['SKU'].astype(str) == 'Gift Sosro'].index.to_list()\n",
    "data_forstok = data_forstok.drop(indeks, axis = 0).reset_index(drop = True)\n",
    "\n",
    "indeks = data_forstok[data_forstok['Item Name'].astype(str).str.contains('Fricella')].index.to_list()\n",
    "data_forstok = data_forstok.drop(indeks, axis = 0).reset_index(drop = True)\n",
    "\n",
    "indeks = data_forstok[data_forstok['Item Name'].astype(str).str.contains('Zaskia Mecca')].index.to_list()\n",
    "data_forstok = data_forstok.drop(indeks, axis = 0).reset_index(drop = True)\n",
    "\n",
    "\n",
    "# display(data_forstok.groupby(['Store'])[['Order Date']].max().reset_index())#########################\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Listing SKU Missing ====== 4/10\")\n",
    "\n",
    "data_forstok = data_forstok.append(skushopee, ignore_index = True, sort = False)\n",
    "data_forstok = data_forstok.reset_index(drop = True)\n",
    "\n",
    "indeks = data_forstok[data_forstok['SKU'].astype(str) == '71210111'].index.to_list()\n",
    "data_forstok['SKU'][indeks] = 'PN28N29N34(2)N53N54N55'\n",
    "\n",
    "indeks = data_forstok[data_forstok['SKU'].astype(str) == '71210112'].index.to_list()\n",
    "data_forstok['SKU'][indeks] = 'PN19N22N30N34(2)N53N55'\n",
    "\n",
    "indeks = data_forstok[data_forstok['SKU'].astype(str) == '(B) 2101656'].index.to_list()\n",
    "data_forstok['SKU'][indeks] = '(B)2101656'\n",
    "\n",
    "indeks = data_forstok[data_forstok['Item Name'].astype(str) == 'PRE ORDER NutriSari NUTRI-C1000 40sch Suplemen Kesehatan Vit C 1000mg '].index.to_list()\n",
    "data_forstok['SKU'][indeks] = '1102110453'\n",
    "\n",
    "# data_forstok.loc[data_forstok['Item Name']==\"Tropicana Slim Minyak Sunflower 946ml (3pcs) Free Apron Celemek Minyak Baik 100% Pure Sunflower Oil\",'SKU']=\"PT46(3)G145\"\n",
    "# data_forstok.loc[data_forstok['Item Name']==\"Buy 1 Get 1 FREE HiLo Active Caramel Latte 500gr - Susu Tinggi Kalsium\",'SKU']=\"2101478180C2\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"HiLo Active Caramel Latte 500gr - Susu Tinggi Kalsium\",'SKU']=\"2101478180\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"NutriSari Es Rujak 40 Sachet - Minuman Buah Vitamin C - Expired 4 Bulan\",'SKU']=\"(E)1101984453\"\n",
    "data_forstok.loc[data_forstok['SKU']=='PH39(12)U8(12) ','SKU']='PH39(12)U8(12)'\n",
    "\n",
    "# display(data_forstok[(data_forstok['SKU']=='COLLETTEP4')])\n",
    "\n",
    "\n",
    "shopee_con = pd.read_excel(r'data_supp\\Shopee Converter.xlsx')\n",
    "indeks = data_forstok[data_forstok['SKU'].astype(str).str.replace('(S)','', regex = False).isin(shopee_con['SKU'].astype(str))][data_forstok[data_forstok['SKU'].astype(str).str.replace('(S)','', regex = False).isin(shopee_con['SKU'].astype(str))]['Item Name'].astype(str).str.lower().isin(shopee_con['Product Name'].astype(str).str.lower())].index.to_list()\n",
    "product = data_forstok[data_forstok['SKU'].astype(str).str.replace('(S)','', regex = False).isin(shopee_con['SKU'].astype(str))][data_forstok[data_forstok['SKU'].astype(str).str.replace('(S)','', regex = False).isin(shopee_con['SKU'].astype(str))]['Item Name'].astype(str).str.lower().isin(shopee_con['Product Name'].astype(str).str.lower())]['Item Name'].unique()\n",
    "\n",
    "for i in product:\n",
    "    indeks_shopee = data_forstok.iloc[indeks][data_forstok.iloc[indeks]['Item Name'].astype(str).str.lower() == str(i).lower()].index.to_list()\n",
    "    data_forstok['SKU'][indeks_shopee] = shopee_con[shopee_con['Product Name'].astype(str).str.lower() == str(i).lower()]['Real SKU'].values[0]\n",
    "\n",
    "\n",
    "to_excel = data_forstok.to_excel(r'forstok_new.xls', index = False)\n",
    "\n",
    "skushopee = data_forstok[data_forstok['SKU'].astype(str).str.contains('(S)',regex = False)]\n",
    "data_forstok = data_forstok[~data_forstok['SKU'].astype(str).isin(skushopee['SKU'].astype(str))]\n",
    "\n",
    "skushopee = skushopee.reset_index(drop = True)\n",
    "data_forstok = data_forstok.reset_index(drop = True)\n",
    "\n",
    "sku_exclude = ['5337754001-1623228299159-0',\"TESSS\"]\n",
    "data_forstok = data_forstok[~data_forstok['SKU'].isin(sku_exclude)]\n",
    "\n",
    "data_forstok.loc[data_forstok['Item Name']==\"HiLo Teen Strawberry Milkshake 500 gram – Susu Tinggi Kalsium - Milkshake\",'SKU']=\"2101683180\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"Paket Minyak Hemat – Tropicana Slim Canola Oil & Tropicana Slim Sunflower Oil - Package\",'SKU']=\"PT3T46\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"Buy 2 Get 1 - L-Men Protein Crunch BBQ Beef (20gr) - Triplepack\",'SKU']=\"2309005300P3\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"Paket Kecap Sehat - Topicana Slim Kecap Manis & Tropicana Slim Kecap Asin - Package\",\"SKU\"]=\"PT26T44\"\n",
    "data_forstok.loc[(data_forstok['Item Name']==\"(Free Gift) 3pcs L-Men Protein Crunch BBQ Beef 20g\")&\n",
    "                 (data_forstok['Store']==\"Lazada\"),\"SKU\"]=\"(B)2309005305P3\"\n",
    "data_forstok.loc[data_forstok['Item Name']==\"WHS - Paket NutriSari Jeruk Peras, HiLo Es Ketan Hitam, dan HiLo Klepon Latte Powder Drink Refill 500 gram\",'SKU']=\"PH81H82N60G187\"\n",
    "\n",
    "idx = []\n",
    "idx = idx + data_forstok[data_forstok['SKU'].isnull()].drop_duplicates().index.to_list()\n",
    "idx = idx + data_forstok[~data_forstok['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "idx = list(dict.fromkeys(idx))\n",
    "idx_s = skushopee[~skushopee['SKU'].astype(str).str.replace('(S)','', regex = False).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "idx_s = list(dict.fromkeys(idx_s))\n",
    "\n",
    "\n",
    "for i in product:\n",
    "    indeks_shopee = data_forstok.iloc[indeks][data_forstok.iloc[indeks]['Item Name'].astype(str).str.lower() == str(i).lower()].index.to_list()\n",
    "    data_forstok['SKU'][indeks_shopee] = shopee_con[shopee_con['Product Name'].astype(str).str.lower() == str(i).lower()]['Real SKU'].values[0]\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "if len(idx) != 0 or len(idx_s) != 0:\n",
    "# if len(idx) != 0:\n",
    "    alert = data_forstok.iloc[idx, ][['SKU', 'Item Name', 'Channel']].drop_duplicates()\n",
    "    alert = alert.append(skushopee.iloc[idx_s][['SKU', 'Item Name', 'Channel', 'Selling Price']].drop_duplicates(), ignore_index = True, sort = False)\n",
    "    alert['SKU'] = alert['SKU'].astype(str)\n",
    "    alert['SKU Valid'] = np.nan\n",
    "    to_excel = alert.to_excel('ALERT_FORSTOK_SKU_MISSING.xlsx')\n",
    "    print(\"Some SKU Missing Please Complete It ====== 5/10\")\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    # creates SMTP session \n",
    "    s = smtplib.SMTP('smtp.gmail.com', 587) \n",
    "\n",
    "    # start TLS for security \n",
    "    s.starttls() \n",
    "\n",
    "    # Authentication \n",
    "    s.login(\"automationnfi@gmail.com\", \"nutrifood2020\") \n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['Subject'] = \"ALERT SKU FORSTOK MISSING\"\n",
    "\n",
    "\n",
    "    html = \"\"\"\\\n",
    "    <html>\n",
    "      <head></head>\n",
    "      <body>\n",
    "        {0}\n",
    "      </body>\n",
    "    </html>\n",
    "    \"\"\".format(alert.to_html())\n",
    "\n",
    "    part1 = MIMEText(html, 'html')\n",
    "    msg.attach(part1)\n",
    "\n",
    "    # sending the mail \n",
    "    s.sendmail(\"automationnfi@gmail.com\", \"andra.miftah@nutrifood.co.id\", msg.as_string()) \n",
    "\n",
    "    # terminating the session \n",
    "    s.quit() \n",
    "else :\n",
    "    print(\"Filling Brand ====== 5/10\")\n",
    "    data_forstok['SKU'] = data_forstok['SKU'].astype(str)\n",
    "    data_forstok['Item Name'] = data_forstok['Item Name'].astype(str)\n",
    "    data_SKU['Real SKU'] = data_SKU['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "    data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "    \n",
    "    data_forstok = data_forstok.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "    temp = data_forstok[data_forstok['Real SKU'].isnull()].copy()\n",
    "    temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "    temp = temp.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "    temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "    temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "    temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "    temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "    indeks = data_forstok[data_forstok['Real SKU'].isnull()].index.to_list()\n",
    "    data_forstok['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "    data_forstok['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "    temp = data_forstok[data_forstok['Real SKU'].isnull()].copy()\n",
    "    temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "    temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "    temp = temp.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "    temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "    temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "    temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "    temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "    indeks = data_forstok[data_forstok['Real SKU'].isnull()].index.to_list()\n",
    "    data_forstok['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "    data_forstok['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "    data_forstok['Real SKU'] = data_forstok['Real SKU'].astype(str)\n",
    "    data_forstok = data_forstok.merge(data_SKU[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "    data_forstok = data_forstok.drop(['SKU_y'], axis = 1)\n",
    "    data_forstok = data_forstok.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"Unbundling ====== 6/10\")        \n",
    "    # Forstok Unbundling    \n",
    "    list_col = ['SKU'] + data_SKU.columns[data_SKU.columns.get_loc('Produk 1'):data_SKU.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "    data_forstok = data_forstok.merge(data_SKU[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "    list_pcs = [x for x in data_forstok.columns if 'PCS' in x]\n",
    "    for i in list_pcs:\n",
    "        data_forstok[i] = data_forstok[i] * data_forstok['Quantity']\n",
    "    data_forstok = data_forstok.drop(['SKU_y'], axis = 1)\n",
    "    data_forstok = data_forstok.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "    indeks = data_forstok[data_forstok['Brand'] == 'Bundle'].index.to_list()\n",
    "    data_forstok['Bundle Flag'] = np.nan\n",
    "    data_forstok['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "    indeks = data_forstok[data_forstok['Brand'] == 'Bundle'][data_forstok[data_forstok['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "    data_forstok['SKU Produk 1'][indeks] = '(S)' + data_forstok['SKU Produk 1'][indeks].astype(str)\n",
    "    data_forstok['SKU Produk 2'][indeks] = '(S)' + data_forstok['SKU Produk 2'][indeks].astype(str)\n",
    "    data_forstok['SKU Produk 3'][indeks] = '(S)' + data_forstok['SKU Produk 3'][indeks].astype(str)\n",
    "    data_forstok['SKU Produk 4'][indeks] = '(S)' + data_forstok['SKU Produk 4'][indeks].astype(str)\n",
    "    data_forstok['SKU Produk 5'][indeks] = '(S)' + data_forstok['SKU Produk 5'][indeks].astype(str)\n",
    "    data_forstok['SKU Produk 6'][indeks] = '(S)' + data_forstok['SKU Produk 6'][indeks].astype(str)\n",
    "    data_forstok['SKU Produk 7'][indeks] = '(S)' + data_forstok['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"Filling Date ====== 7/10\")\n",
    "    data_forstok['Date'] = np.nan\n",
    "    data_forstok['Month'] = np.nan\n",
    "    data_forstok['Year'] = np.nan\n",
    "\n",
    "    for i in range(data_forstok.shape[0]):\n",
    "        if int(data_forstok['Order Date'][i].strftime('%d')) <= 12:\n",
    "            data_forstok['Date'][i] = pd.to_datetime(data_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "            data_forstok['Month'][i] = pd.to_datetime(data_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "            data_forstok['Year'][i] = pd.to_datetime(data_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "        else :\n",
    "            data_forstok['Date'][i] = pd.to_datetime(data_forstok['Order Date'][i]).day\n",
    "            data_forstok['Month'][i] = pd.to_datetime(data_forstok['Order Date'][i]).month_name()\n",
    "            data_forstok['Year'][i] = pd.to_datetime(data_forstok['Order Date'][i]).year\n",
    "\n",
    "    quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "            ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "    data_forstok = data_forstok.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "    data_forstok = data_forstok.drop(['Bulan'], axis = 1)\n",
    "    data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "            {'Bulan' : 'January' , 'Number': 1},\n",
    "            {'Bulan' : 'February' , 'Number': 2},\n",
    "            {'Bulan' : 'March' , 'Number': 3},\n",
    "            {'Bulan' : 'April' , 'Number': 4},\n",
    "            {'Bulan' : 'May' , 'Number': 5},\n",
    "            {'Bulan' : 'June', 'Number': 6},\n",
    "            {'Bulan' : 'July' , 'Number': 7},\n",
    "            {'Bulan' : 'August', 'Number' : 8},\n",
    "            {'Bulan' : 'September', 'Number' : 9},\n",
    "            {'Bulan' : 'October' , 'Number': 10},\n",
    "            {'Bulan' : 'November' , 'Number': 11}])\n",
    "    temp = data_forstok.copy()\n",
    "    temp['Day'] = temp['Date']\n",
    "    temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "    temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "    data_forstok['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "    temp['Hour'] = pd.to_datetime(data_forstok['Order Date']).dt.hour\n",
    "    temp['Minute'] = pd.to_datetime(data_forstok['Order Date']).dt.minute\n",
    "    temp['Second'] = pd.to_datetime(data_forstok['Order Date']).dt.second\n",
    "    data_forstok['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "    \n",
    "    \n",
    "    forstok_all = data_forstok\n",
    "    forstok_all['Total'] = forstok_all['Sub Total']\n",
    "    forstok_all['Price List NFI'] = np.nan\n",
    "    forstok_all['Total Net'] = np.nan\n",
    "\n",
    "    forstok_all = forstok_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                            'Status' : 'Order Status',\n",
    "                                            'Order Date' : 'Order date',\n",
    "                                            'Item Name' :'Product Name',\n",
    "                                            'Bundle Name' : 'Bundle',\n",
    "                                            'Shipping Country' : 'Country',\n",
    "                                            'Shipping Province' : 'Region',\n",
    "                                            'Shipping City' : 'City',\n",
    "                                            'Shipping Zip' : 'Zip Code',\n",
    "                                            'Shipping Address1' : 'Address',\n",
    "                                            'Shipping Phone' : 'Phone',\n",
    "                                            'Quantity' : 'Qty. Invoiced',\n",
    "                                            'Item Price' : 'Regular Price',\n",
    "                                            'Sub Total' : 'Subtotal'})\n",
    "    forstok_all['Kecamatan'] = np.nan\n",
    "    forstok_all['Kelurahan'] = np.nan\n",
    "    forstok_all['Store'] = forstok_all['Channel']\n",
    "\n",
    "    print(\"Filling Location ===== 7/10\")\n",
    "    indeks = forstok_all[forstok_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        forstok_all['Kecamatan'][indeks] = forstok_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "        forstok_all['City'][indeks] = forstok_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "    indeks = forstok_all[forstok_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        forstok_all['Kelurahan'][indeks] = forstok_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "        forstok_all['Kecamatan'][indeks] = forstok_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "    indeks = forstok_all[forstok_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        forstok_all['Kecamatan'][indeks] = forstok_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "        forstok_all['City'][indeks] = forstok_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "    indeks = forstok_all[forstok_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        forstok_all['Kelurahan'][indeks] = forstok_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "        forstok_all['Kecamatan'][indeks] = forstok_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "    forstok_all['City'] = forstok_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "    master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "    master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "    master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "    master_map['Kode Prov'][515] = 14\n",
    "    master_map['Province'][515] = 'Riau'\n",
    "    master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "    master_map['Province'] = master_map['Province'].str.title()\n",
    "    master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "    city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "    temp = forstok_all.copy()\n",
    "    temp['City'] = temp['City'].astype(str).str.lower()\n",
    "    temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "    city['All City'] = city['All City'].astype(str).str.lower()\n",
    "    temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "    indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "    forstok_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "    province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "    temp = forstok_all.copy()\n",
    "    temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "    province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "    temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "    indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "    forstok_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "    temp = forstok_all.copy()\n",
    "    temp = temp[temp['Region'].isnull()]\n",
    "    temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "    forstok_all['Region'][temp.index] = temp['Region']  \n",
    "    \n",
    "    district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "    temp = forstok_all.copy()\n",
    "    temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "    district['All District'] = district['All District'].astype(str).str.lower()\n",
    "    temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "    indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "    forstok_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "    temp = forstok_all.copy()\n",
    "    temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "    indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "    forstok_all['City'][indeks] = np.nan\n",
    "\n",
    "    data_SKU['Real SKU'] = data_SKU['SKU'].astype(str)\n",
    "    data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "\n",
    "    print(\"Unbundling ===== 9/10\")\n",
    "    data_bundle1 = forstok_all[~forstok_all['Produk 1'].isnull()]\n",
    "    data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "    data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "    data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "    data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "    data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "    data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "    data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "    data_bundle2 = forstok_all[~forstok_all['Produk 2'].isnull()]\n",
    "    data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "    data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "    data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "    data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "    data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "    data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "    data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "    data_bundle3 = forstok_all[~forstok_all['Produk 3'].isnull()]\n",
    "    data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "    data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "    data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "    data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "    data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "    data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "    data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "    data_bundle4 = forstok_all[~forstok_all['Produk 4'].isnull()]\n",
    "    data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "    data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "    data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "    data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "    data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "    data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "    data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "    data_bundle5 = forstok_all[~forstok_all['Produk 5'].isnull()]\n",
    "    data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "    data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "    data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "    data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "    data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "    data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "    data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "    data_bundle6 = forstok_all[~forstok_all['Produk 6'].isnull()]\n",
    "    data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "    data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "    data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "    data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "    data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "    data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "    data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "    data_bundle7 = forstok_all[~forstok_all['Produk 7'].isnull()]\n",
    "    data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "    data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "    data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "    data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "    data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "    data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "    data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "    data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "    data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "    data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "    data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "    temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "    temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "    temp = temp.merge(data_SKU[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "    indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "    data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "    data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "    data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "    data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "    data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "    data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "    print(\"Pricing ===== 10/10\")\n",
    "    forstok_all = forstok_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "    \n",
    "#     temp = forstok_all[forstok_all['Brand'] == 'L-Men'].drop_duplicates('Sales Order ID').copy()\n",
    "#     idx = data_SKU[data_SKU['SKU'].astype(str) == '(B)71210138'].index[0]\n",
    "#     temp['Item Name'] = data_SKU['Nama Produk'][idx]\n",
    "#     temp['Quantity'] = 1\n",
    "#     temp['SKU'] = '(B)71210138'\n",
    "#     temp['Brand'] = data_SKU['Brand'][idx]\n",
    "#     temp['Product Name'] = data_SKU['Nama Produk'][idx]\n",
    "#     temp['Real Nama Produk'] = data_SKU['Nama Produk'][idx]\n",
    "#     temp['Brand'] = data_SKU['Brand'][idx]\n",
    "#     temp['Bundle Name'] = np.nan\n",
    "#     temp['Price List NFI'] = data_SKU['Price List NFI'][idx]\n",
    "#     temp['Total Net'] = temp['Price List NFI'] * temp['Qty. Invoiced']\n",
    "#     temp['Sub Brand'] = data_SKU['Sub Brand'][idx]\n",
    "#     temp['SKU'] = data_SKU['SKU'][idx]\n",
    "#     temp['Real SKU'] = data_SKU['SKU'][idx]\n",
    "#     temp['Parent SKU'] = data_SKU['Parent SKU'][idx]\n",
    "#     temp['Parent Item'] = data_SKU['Parent Item'][idx]\n",
    "#     temp['Subtotal'] = 0\n",
    "#     temp['Total'] = 0\n",
    "#     temp['Regular Price'] = 0\n",
    "#     temp['Selling Price'] = 0\n",
    "#     temp['Gross Sales'] = 0\n",
    "#     temp['Seller Discount'] = 0\n",
    "#     colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "#     colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "#     colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "#     for i in colname_str:\n",
    "#         temp[i] = np.nan\n",
    "\n",
    "#     for i in colname_int:\n",
    "#         temp[i] = 0\n",
    "    \n",
    "#     data_forstok = data_forstok.append(temp , ignore_index = True, sort = False)\n",
    "    \n",
    "    \n",
    "    forstok_all = forstok_all.merge(data_SKU[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(forstok_all.index)\n",
    "    forstok_all['Price List NFI_x'] = forstok_all['Price List NFI_x'].fillna(forstok_all['Price List NFI_y'])\n",
    "    forstok_all =  forstok_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "    forstok_all = forstok_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "    forstok_all['Price List NFI'] = pd.to_numeric(forstok_all['Price List NFI']).astype(int)\n",
    "    forstok_all['Harga Cost'] = pd.to_numeric(forstok_all['Harga Cost']).astype(int)\n",
    "    forstok_all['Qty. Invoiced'] = pd.to_numeric(forstok_all['Qty. Invoiced']).astype(int)\n",
    "    \n",
    "    forstok_all['Total Net'] = forstok_all['Price List NFI'] * forstok_all['Qty. Invoiced']\n",
    "    forstok_all['Total Harga Cost'] = forstok_all['Harga Cost'] * forstok_all['Qty. Invoiced']\n",
    "    \n",
    "    forstok_all = forstok_all.reset_index(drop = True)\n",
    "    forstok_all['Order #'] = forstok_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.maximize_window()\n",
    "    driver.get(\"https://seller.blibli.com/sign-in\")\n",
    "    time.sleep(40)\n",
    "\n",
    "    username = driver.find_element_by_id(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customer1@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_id(\"password\")\n",
    "    password.send_keys(\"Nutrimart12345\")\n",
    "\n",
    "    driver.find_element_by_id(\"sign-in\").click()\n",
    "    time.sleep(30)\n",
    "#     WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'close-announcement-button'))).click()\n",
    "#     WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, 'remind-me-later-button'))).click()\n",
    "#     WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, 'nav-wrapper-ORDER'))).click()\n",
    "#     driver.find_element_by_id(\"sub-nav-item-0\").click()\n",
    "    driver.get(\"https://seller.blibli.com/MTA/order/summary\")\n",
    "    time.sleep(50)\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'btn-primary-mta'))).click()\n",
    "    time.sleep(10)\n",
    "    driver.find_element_by_id(\"semuaFilter\").click()\n",
    "\n",
    "    driver.find_element_by_class_name(\"order-filter-input\").click()\n",
    "    start_date = datetime.today() - timedelta(days=14)\n",
    "    end_date = datetime.today()\n",
    "    date = start_date.strftime('%Y-%m-%d') + '-' + end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    if start_date.month == end_date.month:\n",
    "        text = \"//div[@class='calendar left']//td[@class = 'available' or @class='weekend available'][text() = \" + str(start_date.day) + \"]\"\n",
    "        driver.find_element_by_xpath(text).click()\n",
    "        text = \"//div[@class='calendar left']//td[contains(@class, 'today')][text() = \" + str(end_date.day) + \"]\"\n",
    "        driver.find_element_by_xpath(text).click()\n",
    "    else :\n",
    "        driver.find_element_by_css_selector(\"th.prev.available\").click()\n",
    "        text = \"//div[@class='calendar left']//td[@class = 'available' or @class='weekend available'][text() = \" + str(start_date.day) + \"]\"\n",
    "        driver.find_element_by_xpath(text).click()\n",
    "        text = \"//div[@class='calendar right']//td[contains(@class, 'today')][text() = \" + str(end_date.day) + \"]\"\n",
    "        driver.find_element_by_xpath(text).click()\n",
    "    driver.find_element_by_css_selector('button.btn.col-sm-3.btn-default.order-option-buttons.dropdown-toggle').click()\n",
    "    driver.find_element_by_xpath(\"/html/body/div[3]/div[2]/div/div/div[1]/div[3]/div[2]/ul\").click()\n",
    "    try:\n",
    "        time.sleep(2)\n",
    "        driver.find_element_by_class_name(\"btn-primary-mta\").click()\n",
    "        time.sleep(2)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    cond = False\n",
    "    while not cond:\n",
    "        time.sleep(30)\n",
    "        driver.find_element_by_class_name('fa-bell-o').click()\n",
    "        print('click 1')\n",
    "        time.sleep(10)\n",
    "        driver.find_element_by_class_name('fa-bell-o').click()\n",
    "        print('click 2')\n",
    "        time.sleep(10)\n",
    "        driver.find_element_by_class_name('fa-bell-o').click()\n",
    "        print('click 3')\n",
    "\n",
    "        time_now = str(datetime.now().hour) + ':' + str(datetime.now().minute)\n",
    "        time.sleep(10)\n",
    "        time_notif = driver.find_element_by_xpath('//*[@id=\"viewNotification\"]/div[2]/div[2]/ul/li[1]/span[2]').text\n",
    "        print(time_notif)\n",
    "        time_notif1 = driver.find_element_by_css_selector('li.ng-scope.notification-unread').text[-5:]\n",
    "        end = datetime.strptime(time_notif, '%H:%M').time()\n",
    "        print(end)\n",
    "        duration = int((datetime.today() - timedelta(hours=end.hour, minutes=end.minute)).strftime('%M'))\n",
    "        print(duration)\n",
    "        if duration < 3:\n",
    "            time.sleep(1)\n",
    "            driver.find_element_by_xpath('//ul[@class = \"notification-item-container\"]//li[@class = \"ng-scope notification-unread\"]').click()\n",
    "            cond = True\n",
    "        else :\n",
    "            driver.find_element_by_class_name('fa-bell-o').click()\n",
    "            time.sleep(30)\n",
    "            \n",
    "    print('Blibli LMS Downloaded')     \n",
    "\n",
    "   \n",
    "    time.sleep(15)\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    else:\n",
    "        print(\"More than one file or no file downloaded\")\n",
    "    print(file_name)\n",
    "    new_name = 'Blibli ' + str(date) + '.csv'\n",
    "    if os.path.isfile('Input Data/' + str(new_name)) :\n",
    "        os.remove('Input Data/' + str(new_name))\n",
    "    os.rename('Input Data/' + str(file_name), 'Input Data/' + str(new_name))\n",
    "    driver.quit()\n",
    "    print(\"Import Data ====== 1/10\")\n",
    "    \n",
    "#     new_name = 'Blibli 2021-03-09-2021-03-15.csv'\n",
    "    lmen = pd.read_csv(r'Input Data/' + str(new_name) , dayfirst = True)\n",
    "    lmen = lmen.dropna(how = 'all')\n",
    "    lmen_pure = lmen.copy()\n",
    "\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"Formatting Data ====== 2/10\")\n",
    "    lmen['No. Order'] = lmen['No. Order'].astype(str).str.replace('^=\"','')\n",
    "    lmen['No. Order'] = lmen['No. Order'].astype(str).str.replace('\"$','')\n",
    "    lmen['No. Order Item'] = lmen['No. Order Item'].astype(str).str.replace('^=\"','')\n",
    "    lmen['No. Order Item'] = lmen['No. Order Item'].astype(str).str.replace('\"$','')\n",
    "    lmen['No. Awb'] = lmen['No. Awb'].astype(str).str.replace('^=\"','')\n",
    "    lmen['No. Awb'] = lmen['No. Awb'].astype(str).str.replace('\"$','')\n",
    "    lmen['Merchant SKU'] = lmen['Merchant SKU'].astype(str).str.replace('^=\"','')\n",
    "    lmen['Merchant SKU'] = lmen['Merchant SKU'].astype(str).str.replace('\"$','')\n",
    "    \n",
    "    #INPUT SKU BLIBLI LMS ERROR\n",
    "    lmen.loc[lmen['Nama Produk']=='Daily Protein Package - L-Men Daily Popcorn Caramel 250g & L-Men Protein Bar Crunchy Chocolate 12 Sachet','Merchant SKU']='PL19L23'\n",
    "    lmen.loc[lmen['Nama Produk']=='[Tebus Murah] L-Men Lose Weight Mango Sticky Rice 300g - Suplemen Penurun Berat Badan Tinggi Whey Protein ','Merchant SKU']='2304576112'\n",
    "    for i in lmen[lmen['Merchant SKU']=='nan']['Blibli SKU'].unique():\n",
    "        print(i)\n",
    "        skunfi=lmen[(lmen['Blibli SKU']==i)&(lmen['Merchant SKU']!='nan')].reset_index()['Merchant SKU'][0]\n",
    "        lmen.loc[(lmen['Blibli SKU']==i)&(lmen['Merchant SKU']=='nan'),'Merchant SKU']=skunfi\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"Listing SKU ====== 3/10\")\n",
    "    lmen_sku = pd.read_excel(r'SKU_File/Converter Paket Blibli.xlsx')\n",
    "\n",
    "    lmen['Merchant SKU'] = lmen['Merchant SKU'].astype(str).str.replace('\\.0$','', regex = True)\n",
    "\n",
    "    null_sku = lmen[lmen['Merchant SKU'] == 'nan'].copy()\n",
    "    lmen = lmen[lmen['Merchant SKU'] != 'nan']\n",
    "\n",
    "    null_sku['Nama Produk'] = null_sku['Nama Produk'].astype(str).str.strip()\n",
    "    lmen_sku['Nama Produk'] = lmen_sku['Nama Produk'].astype(str).str.strip()\n",
    "    null_sku['Merchant SKU'] = null_sku.merge(lmen_sku[['SKU Merchant', 'Nama Produk']].drop_duplicates(['Nama Produk']), how = 'left', on = 'Nama Produk').set_index(null_sku.index)['SKU Merchant']\n",
    "\n",
    "    lmen = lmen.append(null_sku, ignore_index = True, sort = False)\n",
    "\n",
    "    gaada_sku = lmen[~lmen['Merchant SKU'].astype(str).isin(data_SKU['SKU'].astype(str))].copy()\n",
    "    lmen = lmen[lmen['Merchant SKU'].astype(str).isin(data_SKU['SKU'].astype(str))]\n",
    "\n",
    "    gaada_sku['Nama Produk'] = gaada_sku['Nama Produk'].astype(str).str.strip()\n",
    "    lmen_sku['Nama Produk'] = lmen_sku['Nama Produk'].astype(str).str.strip()\n",
    "    gaada_sku['Merchant SKU'] = gaada_sku.merge(lmen_sku[['SKU Merchant', 'Nama Produk']].drop_duplicates(['Nama Produk']), how = 'left', on = 'Nama Produk').set_index(gaada_sku.index)['SKU Merchant']\n",
    "    lmen = lmen.append(gaada_sku, ignore_index = True, sort = False)\n",
    "\n",
    "    indeks = []\n",
    "    indeks = indeks + lmen[lmen['Merchant SKU'].isnull()].index.to_list()\n",
    "    indeks = indeks + lmen[~lmen['Merchant SKU'].astype(str).str.replace('\\.0$','', regex = True).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0 :\n",
    "        alert = lmen.iloc[indeks][['Blibli SKU','Merchant SKU', 'Nama Produk']].drop_duplicates()\n",
    "        alert['SKU Valid'] = np.nan\n",
    "        to_excel = alert.to_excel('ALERT_LMEN-STORE_SKU_MISSING.xlsx')\n",
    "        print(\"Some SKU Missing Please Complete It ====== 4/10\")\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    else :\n",
    "        data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "        data_SKU['Real SKU'] = data_SKU['SKU'].astype(str)\n",
    "        lmen['Merchant SKU'] = lmen['Merchant SKU'].astype(str)\n",
    "        data_SKU['Price List NFI'] = data_SKU['Price List NFI'].astype(float).astype('int64')\n",
    "        lmen = lmen.merge(data_SKU[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU', 'Price List NFI']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'Merchant SKU', right_on = 'Real SKU')\n",
    "        lmen['Total Net'] = lmen['Price List NFI'] * lmen['Total Barang']\n",
    "\n",
    "        indeks = lmen[lmen['Brand'] == 'Bundle'].index.to_list()\n",
    "        lmen['Bundle Flag'] = np.nan\n",
    "        lmen['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        lmen['Date'] = pd.to_datetime(lmen['Tanggal Order'], format = '%d/%m/%Y %H:%M').dt.day\n",
    "        lmen['Month'] = pd.to_datetime(lmen['Tanggal Order'], format = '%d/%m/%Y %H:%M').dt.month_name()\n",
    "        lmen['Year'] = pd.to_datetime(lmen['Tanggal Order'], format = '%d/%m/%Y %H:%M').dt.year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                    ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        lmen = lmen.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        lmen = lmen.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = lmen.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        lmen['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        lmen['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day']])\n",
    "\n",
    "        lmen = lmen.rename(columns = {'No. Order' : 'Order #', 'No. Order Item' : 'No. Order Item L-Men Blibli',\n",
    "                                    'Tanggal Order' : 'Order date', 'Nama Pemesan' : 'Customer Name',\n",
    "                                    'Merchant SKU' : 'SKU', 'Nama Produk' : 'Product Name', 'Total Barang':'Qty. Invoiced',\n",
    "                                    'Harga Produk' : 'Selling Price', 'Servis Logistik' : 'Shipping Courier', 'Nama Store' : 'Channel',\n",
    "                                    'Toko/Gudang' : 'Warehouse Name', 'No. Awb' : 'AWB'\n",
    "                                    })\n",
    "\n",
    "        lmen['Channel'] = 'L-Men Store Blibli'\n",
    "        lmen['Store'] = 'Blibli'\n",
    "\n",
    "        data_SKU['Real SKU'] = data_SKU['SKU'].astype(str)\n",
    "        data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "\n",
    "        lmen['SKU'] = lmen['SKU'].astype(str)\n",
    "        list_col = ['SKU'] + data_SKU.columns[data_SKU.columns.get_loc('Produk 1'):data_SKU.columns.get_loc('Harga Cost 7')+1].to_list()\n",
    "        lmen = lmen.merge(data_SKU[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        lmen = lmen.drop(['SKU_y'], axis = 1)\n",
    "        lmen = lmen.rename(columns = {'SKU_x':'SKU'})\n",
    "        data_bundle1 = lmen[~lmen['Produk 1'].isnull()]\n",
    "\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1'] * data_bundle1['Qty. Invoiced']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1'] * data_bundle1['Qty. Invoiced']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = lmen[~lmen['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2'] * data_bundle2['Qty. Invoiced']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] * data_bundle2['Qty. Invoiced']\n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = lmen[~lmen['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']* data_bundle3['Qty. Invoiced']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] * data_bundle3['Qty. Invoiced']\n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = lmen[~lmen['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']* data_bundle4['Qty. Invoiced']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] * data_bundle4['Qty. Invoiced']\n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = lmen[~lmen['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']* data_bundle5['Qty. Invoiced']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5'] * data_bundle5['Qty. Invoiced']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = lmen[~lmen['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']* data_bundle6['Qty. Invoiced']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6'] * data_bundle6['Qty. Invoiced']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = lmen[~lmen['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']* data_bundle7['Qty. Invoiced']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7'] * data_bundle7['Qty. Invoiced']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        lmen = lmen.append(data_bundle, ignore_index = True, sort = False)\n",
    "        lmen = lmen.merge(data_SKU[['Real SKU', 'Harga Cost']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "        lmen['Total Harga Cost'] = pd.to_numeric(lmen['Harga Cost'], errors = 'coerce') * lmen['Qty. Invoiced']\n",
    "        print(lmen[lmen['Harga Cost'] == 0][['SKU','Product Name']].drop_duplicates())\n",
    "        lmen['Total'] = lmen['Selling Price'] * lmen['Qty. Invoiced']\n",
    "        lmen['Subtotal'] = lmen['Selling Price'] * lmen['Qty. Invoiced']\n",
    "        lmen = lmen.rename(columns = {'Real SKU_x' : 'Real SKU'})\n",
    "\n",
    "        forstok_all = forstok_all.append(lmen, ignore_index = True, sort = False)\n",
    "\n",
    "        list_bundle = forstok_all[forstok_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = forstok_all[forstok_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        forstok_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        forstok_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = forstok_all[forstok_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        forstok_all['Total'][temp.index] = temp['Total']\n",
    "        forstok_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        forstok_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "        \n",
    "\n",
    "        forstok_all['Order #'] = forstok_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = forstok_all[forstok_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = forstok_all[forstok_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        forstok_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = forstok_all[forstok_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        forstok_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = forstok_all[forstok_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = forstok_all.merge(temp_group, how = 'left', on = 'Order #').set_index(forstok_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        forstok_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = forstok_all[forstok_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = forstok_all[forstok_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        forstok_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = forstok_all[forstok_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        forstok_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        forstok_all['True datetime'] = pd.to_datetime(forstok_all['True datetime'])\n",
    "        forstok_all['Promo'] = np.nan\n",
    "        forstok_all['Discount MC'] = np.nan\n",
    "        \n",
    "        # indeks = forstok_all[forstok_all['Channel'] == 'Shopee'].index.to_list()\n",
    "        # forstok_all['Warehouse Name'][indeks] = 'Shopee Warehouse'\n",
    "        \n",
    "#         print(\"Marketing Calendar JD\")\n",
    "#         iterator = pd.ExcelFile(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/JD (baru).xlsx')\n",
    "\n",
    "#         MC_JD = pd.DataFrame()\n",
    "\n",
    "#         for i in iterator.sheet_names:\n",
    "#             temp = pd.read_excel(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/JD (baru).xlsx', sheet_name = i)\n",
    "#             temp = temp.drop(0)\n",
    "#             MC_JD = MC_JD.append(temp, ignore_index = True, sort = False)\n",
    "\n",
    "#         MC_JD['Start Date'] = pd.to_datetime(MC_JD['Start Date'])\n",
    "#         MC_JD['End Date'] = pd.to_datetime(MC_JD['End Date'])\n",
    "\n",
    "#         MC_JD = MC_JD.dropna(subset = ['Promo'])\n",
    "#         MC_JD = MC_JD.reset_index(drop = True)\n",
    "\n",
    "#         JD = forstok_all[forstok_all['Channel'] == 'JD Indonesia']\n",
    "\n",
    "#         for i in range(MC_JD.shape[0]):\n",
    "#             promo = MC_JD['Promo'][i]\n",
    "#             start = MC_JD['Start Date'][i]\n",
    "#             end = MC_JD['End Date'][i]+ timedelta(days=1)\n",
    "#             SKU = MC_JD['SKU'][i]\n",
    "#             diskon = MC_JD['Diskon'][i]\n",
    "#             if '(S)' in str(SKU):\n",
    "#                 temp = JD[JD['SKU'].astype(str) == str(SKU)]\n",
    "#             else :\n",
    "#                 temp = JD[JD['Real SKU'].astype(str) == str(SKU)]\n",
    "#             temp = temp[temp['True datetime'] >= start]\n",
    "#             temp = temp[temp['True datetime'] < end]\n",
    "#             temp['Promo'] = promo\n",
    "#             temp['Discount MC'] = diskon\n",
    "#             forstok_all['Promo'][temp.index] = promo\n",
    "#             forstok_all['Discount MC'][temp.index] = diskon\n",
    "\n",
    "#         print(\"Marketing Calendar Blibli\")\n",
    "#         iterator = pd.ExcelFile(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Blibli.xlsx')\n",
    "\n",
    "#         MC_Blibli = pd.DataFrame()\n",
    "\n",
    "#         for i in iterator.sheet_names:\n",
    "#             temp = pd.read_excel(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Blibli.xlsx', sheet_name = i)\n",
    "#             temp = temp.drop(0)\n",
    "#             MC_Blibli = MC_Blibli.append(temp, ignore_index = True, sort = False)\n",
    "\n",
    "#         MC_Blibli['Start Date'] = pd.to_datetime(MC_Blibli['Start Date'])\n",
    "#         MC_Blibli['End Date'] = pd.to_datetime(MC_Blibli['End Date'])\n",
    "\n",
    "#         MC_Blibli = MC_Blibli.dropna(subset = ['Promo'])\n",
    "#         MC_Blibli = MC_Blibli.reset_index(drop = True)\n",
    "\n",
    "#         Blibli = forstok_all[forstok_all['Channel'] == 'Blibli']\n",
    "\n",
    "#         for i in range(MC_Blibli.shape[0]):\n",
    "#             promo = MC_Blibli['Promo'][i]\n",
    "#             start = MC_Blibli['Start Date'][i]\n",
    "#             end = MC_Blibli['End Date'][i] + timedelta(days=1)\n",
    "#             SKU = MC_Blibli['SKU'][i]\n",
    "#             diskon = MC_Blibli['Diskon'][i]\n",
    "#             if '(S)' in str(SKU):\n",
    "#                 temp = Blibli[Blibli['SKU'].astype(str) == str(SKU)]\n",
    "#             else :\n",
    "#                 temp = Blibli[Blibli['Real SKU'].astype(str) == str(SKU)]\n",
    "#             temp = temp[temp['True datetime'] >= start]\n",
    "#             temp = temp[temp['True datetime'] < end]\n",
    "#             temp['Promo'] = promo\n",
    "#             temp['Discount MC'] = diskon\n",
    "#             forstok_all['Promo'][temp.index] = promo\n",
    "#             forstok_all['Discount MC'][temp.index] = diskon\n",
    "\n",
    "#         Blibli = forstok_all[forstok_all['Channel'] == 'L-Men Store Blibli']\n",
    "\n",
    "#         for i in range(MC_Blibli.shape[0]):\n",
    "#             promo = MC_Blibli['Promo'][i]\n",
    "#             start = MC_Blibli['Start Date'][i]\n",
    "#             end = MC_Blibli['End Date'][i]+ timedelta(days=1)\n",
    "#             SKU = MC_Blibli['SKU'][i]\n",
    "#             diskon = MC_Blibli['Diskon'][i]\n",
    "#             if '(S)' in str(SKU):\n",
    "#                 temp = Blibli[Blibli['SKU'].astype(str) == str(SKU)]\n",
    "#             else :\n",
    "#                 temp = Blibli[Blibli['Real SKU'].astype(str) == str(SKU)]\n",
    "#             temp = temp[temp['True datetime'] >= start]\n",
    "#             temp = temp[temp['True datetime'] < end]\n",
    "#             temp['Promo'] = promo\n",
    "#             temp['Discount MC'] = diskon\n",
    "#             forstok_all['Promo'][temp.index] = promo\n",
    "#             forstok_all['Discount MC'][temp.index] = diskon\n",
    "\n",
    "#         print(\"Marketing Calendar Lazada\")\n",
    "#         iterator = pd.ExcelFile(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Lazada 10 Mei.xlsx')\n",
    "\n",
    "#         MC_Lazada = pd.DataFrame()\n",
    "\n",
    "#         for i in iterator.sheet_names:\n",
    "#             temp = pd.read_excel(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Lazada 10 Mei.xlsx', sheet_name = i)\n",
    "#             temp = temp.drop(0)\n",
    "#             MC_Lazada = MC_Lazada.append(temp, ignore_index = True, sort = False)\n",
    "\n",
    "#         MC_Lazada['Start Date'] = pd.to_datetime(MC_Lazada['Start Date'])\n",
    "#         MC_Lazada['End Date'] = pd.to_datetime(MC_Lazada['End Date'])\n",
    "\n",
    "#         MC_Lazada = MC_Lazada.dropna(subset = ['Promo'])\n",
    "#         MC_Lazada = MC_Lazada.reset_index(drop = True)\n",
    "\n",
    "#         Lazada = forstok_all[forstok_all['Channel'] == 'Lazada']\n",
    "\n",
    "#         for i in range(MC_Lazada.shape[0]):\n",
    "#             promo = MC_Lazada['Promo'][i]\n",
    "#             start = MC_Lazada['Start Date'][i]\n",
    "#             end = MC_Lazada['End Date'][i]+ timedelta(days=1)\n",
    "#             SKU = MC_Lazada['SKU'][i]\n",
    "#             diskon = MC_Lazada['Diskon'][i]\n",
    "#             if '(S)' in str(SKU):\n",
    "#                 temp = Lazada[Lazada['SKU'].astype(str) == str(SKU)]\n",
    "#             else :\n",
    "#                 temp = Lazada[Lazada['Real SKU'].astype(str) == str(SKU)]\n",
    "#             temp = temp[temp['True datetime'] >= start]\n",
    "#             temp = temp[temp['True datetime'] < end]\n",
    "#             temp['Promo'] = promo\n",
    "#             temp['Discount MC'] = diskon\n",
    "#             forstok_all['Promo'][temp.index] = promo\n",
    "#             forstok_all['Discount MC'][temp.index] = diskon\n",
    "\n",
    "#         print(\"Marketing Calendar Tokopedia\")\n",
    "#         iterator = pd.ExcelFile(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Tokopedia.xlsx')\n",
    "\n",
    "#         MC_Tokopedia = pd.DataFrame()\n",
    "\n",
    "#         for i in iterator.sheet_names[:2]:\n",
    "#             print(i)\n",
    "#             temp = pd.read_excel(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Tokopedia.xlsx', sheet_name = i)\n",
    "#             temp = temp.drop(0)\n",
    "#             MC_Tokopedia = MC_Tokopedia.append(temp, ignore_index = True, sort = False)\n",
    "\n",
    "#         MC_Tokopedia['Start Date'] = pd.to_datetime(MC_Tokopedia['Start Date'])\n",
    "#         MC_Tokopedia['End Date'] = pd.to_datetime(MC_Tokopedia['End Date'])\n",
    "\n",
    "#         MC_Tokopedia['Promo'] = MC_Tokopedia['Promo'].fillna('Promo Februari 2020')\n",
    "#         MC_Tokopedia = MC_Tokopedia.reset_index(drop = True)\n",
    "\n",
    "#         Tokopedia = forstok_all[forstok_all['Channel'] == 'Tokopedia']\n",
    "\n",
    "#         for i in range(MC_Tokopedia.shape[0]):\n",
    "#             promo = MC_Tokopedia['Promo'][i]\n",
    "#             start = MC_Tokopedia['Start Date'][i]\n",
    "#             end = MC_Tokopedia['End Date'][i]+ timedelta(days=1)\n",
    "#             SKU = MC_Tokopedia['SKU'][i]\n",
    "#             diskon = MC_Tokopedia['Diskon'][i]\n",
    "#             if '(S)' in str(SKU):\n",
    "#                 temp = Tokopedia[Tokopedia['SKU'].astype(str) == str(SKU)]\n",
    "#             else :\n",
    "#                 temp = Tokopedia[Tokopedia['Real SKU'].astype(str) == str(SKU)]\n",
    "#             temp = temp[temp['True datetime'] >= start]\n",
    "#             temp = temp[temp['True datetime'] < end]\n",
    "#             temp['Promo'] = promo\n",
    "#             temp['Discount MC'] = diskon\n",
    "#             forstok_all['Promo'][temp.index] = promo\n",
    "#             forstok_all['Discount MC'][temp.index] = diskon\n",
    "\n",
    "#         print(\"Marketing Calendar Bukalapak\")\n",
    "#         iterator = pd.ExcelFile(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Bukalapak.xlsx')\n",
    "\n",
    "#         MC_Bukalapak = pd.DataFrame()\n",
    "\n",
    "#         for i in iterator.sheet_names:\n",
    "#             temp = pd.read_excel(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Bukalapak.xlsx', sheet_name = i)\n",
    "#             temp = temp.drop(0)\n",
    "#             MC_Bukalapak = MC_Bukalapak.append(temp, ignore_index = True, sort = False)\n",
    "\n",
    "#         MC_Bukalapak['Start Date'] = pd.to_datetime(MC_Bukalapak['Start Date'])\n",
    "#         MC_Bukalapak['End Date'] = pd.to_datetime(MC_Bukalapak['End Date'])\n",
    "\n",
    "#         MC_Bukalapak = MC_Bukalapak.dropna(subset = ['Promo'])\n",
    "#         MC_Bukalapak = MC_Bukalapak.reset_index(drop = True)\n",
    "\n",
    "#         Bukalapak = forstok_all[forstok_all['Channel'] == 'Bukalapak']\n",
    "\n",
    "#         for i in range(MC_Bukalapak.shape[0]):\n",
    "#             promo = MC_Bukalapak['Promo'][i]\n",
    "#             start = MC_Bukalapak['Start Date'][i]\n",
    "#             end = MC_Bukalapak['End Date'][i]+ timedelta(days=1)\n",
    "#             SKU = MC_Bukalapak['SKU'][i]\n",
    "#             diskon = MC_Bukalapak['Diskon'][i]\n",
    "#             if '(S)' in str(SKU):\n",
    "#                 temp = Bukalapak[Bukalapak['SKU'].astype(str) == str(SKU)]\n",
    "#             else :\n",
    "#                 temp = Bukalapak[Bukalapak['Real SKU'].astype(str) == str(SKU)]\n",
    "#             temp = temp[temp['True datetime'] >= start]\n",
    "#             temp = temp[temp['True datetime'] < end]\n",
    "#             temp['Promo'] = promo\n",
    "#             temp['Discount MC'] = diskon\n",
    "#             forstok_all['Promo'][temp.index] = promo\n",
    "#             forstok_all['Discount MC'][temp.index] = diskon\n",
    "\n",
    "#         print(\"Marketing Calendar FBL\")\n",
    "#         iterator = pd.ExcelFile(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Lazada 10 Mei.xlsx')\n",
    "\n",
    "#         MC_Lazada = pd.DataFrame()\n",
    "\n",
    "#         for i in iterator.sheet_names:\n",
    "#             temp = pd.read_excel(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Lazada 10 Mei.xlsx', sheet_name = i)\n",
    "#             temp = temp.drop(0)\n",
    "#             MC_Lazada = MC_Lazada.append(temp, ignore_index = True, sort = False)\n",
    "\n",
    "#         MC_Lazada['Start Date'] = pd.to_datetime(MC_Lazada['Start Date'])\n",
    "#         MC_Lazada['End Date'] = pd.to_datetime(MC_Lazada['End Date'])\n",
    "\n",
    "#         MC_Lazada = MC_Lazada.dropna(subset = ['Promo'])\n",
    "#         MC_Lazada = MC_Lazada.reset_index(drop = True)\n",
    "\n",
    "#         Lazada = forstok_all[forstok_all['Channel'] == 'FBL']\n",
    "\n",
    "#         for i in range(MC_Lazada.shape[0]):\n",
    "#             promo = MC_Lazada['Promo'][i]\n",
    "#             start = MC_Lazada['Start Date'][i]\n",
    "#             end = MC_Lazada['End Date'][i]+ timedelta(days=1)\n",
    "#             SKU = MC_Lazada['SKU'][i]\n",
    "#             diskon = MC_Lazada['Diskon'][i]\n",
    "#             if '(S)' in str(SKU):\n",
    "#                 temp = Lazada[Lazada['SKU'].astype(str) == str(SKU)]\n",
    "#             else :\n",
    "#                 temp = Lazada[Lazada['Real SKU'].astype(str) == str(SKU)]\n",
    "#             temp = temp[temp['True datetime'] >= start]\n",
    "#             temp = temp[temp['True datetime'] < end]\n",
    "#             temp['Promo'] = promo\n",
    "#             temp['Discount MC'] = diskon\n",
    "#             forstok_all['Promo'][temp.index] = promo\n",
    "#             forstok_all['Discount MC'][temp.index] = diskon\n",
    "        \n",
    "#         forstok_all_final = forstok_all.copy()\n",
    "#         from datetime import datetime\n",
    "\n",
    "#         print(\"Starting Magento\")\n",
    "#         before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "#         # Download the file using Selenium here\n",
    "\n",
    "#         options = Options()\n",
    "#         options.add_experimental_option(\"prefs\", {\n",
    "#                 \"download.default_directory\": os.path.abspath(\"C:/Users/andra.miftah/Demo 9/Input Data\"),\n",
    "#                 \"download.directory_upgrade\": True,\n",
    "#                 \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "#                 \"safebrowsing.enabled\": False\n",
    "#         })\n",
    "\n",
    "#         print('Opening Chrome')\n",
    "#         driver = webdriver.Chrome(options=options)\n",
    "#         driver.get(\"https://bo.nutrimart.co.id/backoffice\")\n",
    "#         print('Login Magento')\n",
    "#         username = driver.find_element_by_id(\"username\")\n",
    "#         username.clear()\n",
    "#         username.send_keys(\"andra\")\n",
    "#         password = driver.find_element_by_id(\"login\")\n",
    "#         password.send_keys(\"andra123\")\n",
    "\n",
    "#         print('Go To Sales Form')\n",
    "#         driver.find_element_by_xpath(\"//button[@class = 'action-login action-primary']\").click()\n",
    "#         WebDriverWait(driver, 300).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"menu-magento-sales-sales\"]'))).click()\n",
    "#         time.sleep(1)\n",
    "#         driver.find_element_by_xpath('//*[@id=\"menu-magento-sales-sales\"]/div/ul/li[3]/ul/li[1]/div/ul/li[1]/a').click()\n",
    "#         driver.find_element_by_xpath('//*[@id=\"profile_id\"]').click()\n",
    "#         driver.find_element_by_xpath('//*[@id=\"profile_id\"]/optgroup[2]/option[2]').click()\n",
    "        \n",
    "#         start_date = datetime.today() - timedelta(days=14)\n",
    "#         end_date = datetime.today()\n",
    "#         date = start_date.strftime('%d %b %Y') + '-' + end_date.strftime('%d %b %Y')\n",
    "\n",
    "#         print('Input Date')\n",
    "#         date_from = driver.find_element_by_name('daterange_from')\n",
    "#         date_from.clear()\n",
    "#         date_from.send_keys(start_date.strftime('%m/%d/%Y'))\n",
    "\n",
    "#         date_to = driver.find_element_by_name('daterange_to')\n",
    "#         date_to.clear()\n",
    "#         date_to.send_keys(end_date.strftime('%m/%d/%Y'))\n",
    "#         print('Download Magento')\n",
    "#         driver.find_element_by_xpath('//*[@id=\"export_button\"]').click()\n",
    "\n",
    "#         time.sleep(60)\n",
    "#         after = os.listdir(os.getcwd() + '/Input Data')\n",
    "#         change = set(after) - set(before)\n",
    "#         if len(change) == 1:\n",
    "#             file_name = change.pop()\n",
    "#         else:\n",
    "#             print(\"More than one file or no file downloaded\")\n",
    "\n",
    "#         data_magento = pd.read_csv('Input Data/' + file_name, sep = ',', index_col = False)\n",
    "#         before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "#         driver.find_element_by_xpath('//*[@id=\"profile_id\"]').click()\n",
    "#         driver.find_element_by_xpath('//*[@id=\"profile_id\"]/optgroup[2]/option[1]').click()\n",
    "\n",
    "#         start_date = datetime.today() - timedelta(days=7)\n",
    "#         end_date = datetime.today()\n",
    "#         date = start_date.strftime('%d %b %Y') + '-' + end_date.strftime('%d %b %Y')\n",
    "\n",
    "#         date_from = driver.find_element_by_name('daterange_from')\n",
    "#         date_from.clear()\n",
    "#         date_from.send_keys(start_date.strftime('%m/%d/%Y'))\n",
    "\n",
    "#         date_to = driver.find_element_by_name('daterange_to')\n",
    "#         date_to.clear()\n",
    "#         date_to.send_keys(end_date.strftime('%m/%d/%Y'))\n",
    "\n",
    "#         driver.find_element_by_xpath('//*[@id=\"export_button\"]').click()\n",
    "#         time.sleep(60)\n",
    "#         after = os.listdir(os.getcwd() + '/Input Data')\n",
    "#         change = set(after) - set(before)\n",
    "#         if len(change) == 1:\n",
    "#             file_name = change.pop()\n",
    "#             print(file_name)\n",
    "#         else:\n",
    "#             print(\"More than one file or no file downloaded\")\n",
    "#             print(change)\n",
    "#         driver.quit()\n",
    "\n",
    "#         data_SKU = pd.read_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/data_SKU.xlsx')\n",
    "\n",
    "#         s = requests.Session()\n",
    "#         s.get(\"https://tatanama.pythonanywhere.com\")\n",
    "#         s.post(\"https://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "#         r = s.get(\"https://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "#         with open(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx', 'wb') as output:\n",
    "#             output.write(r.content)\n",
    "\n",
    "#         if os.path.isfile(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx') :    \n",
    "#             SKU_append = pd.read_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx')\n",
    "#             SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "#             data_SKU = data_SKU[~data_SKU['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "#             data_SKU = data_SKU.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "#         to_excel = data_SKU.to_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/data_SKU.xlsx', index = False)\n",
    "#         data_magentoUser2 = pd.read_csv('Input Data/' + file_name, sep = ',', index_col = False)\n",
    "#         for i in range(data_magentoUser2.shape[1]):\n",
    "#             data_magentoUser2 = data_magentoUser2.rename(columns={ data_magentoUser2.columns[i] : data_magentoUser2.columns[i].replace(\"    \",\" \")})\n",
    "\n",
    "#         # Import library\n",
    "#         import time\n",
    "#         import pandas as pd\n",
    "#         import numpy as np\n",
    "#         import datetime\n",
    "#         import math\n",
    "#         import os\n",
    "\n",
    "#         # Import data\n",
    "#         start_time = time.time()\n",
    "#         print(\"Import Data ====== 1/10\")\n",
    "#         # data_magento = pd.read_excel(r'magento_new.xls')\n",
    "#         data_magentoUser = pd.read_excel('All Data\\data_magentoUser_2020.xlsx', index_col = False)\n",
    "#         data_magentoUser = data_magentoUser[~data_magentoUser['Sales Order Id'].astype(str).isin(data_magentoUser2['Sales Order Id'].astype(str))]\n",
    "#         data_magentoUser = data_magentoUser.append(data_magentoUser2, ignore_index = True, sort = False)\n",
    "#         magento_pure = data_magento.copy()\n",
    "\n",
    "#         list_skumiss = []\n",
    "\n",
    "#         # Formatting Magento\n",
    "#         print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#         print(\"Formatting Data ====== 2/10\")\n",
    "\n",
    "#         pd.options.mode.chained_assignment = None\n",
    "#         if set(['Qty. Ordered\"', 'Qty. Shipped\"']).issubset(data_magento.columns):\n",
    "#             data_magento = data_magento.rename(columns={'Qty. Ordered\"' : 'Qty. Ordered', \n",
    "#                                                     'Qty. Shipped\"' : 'Qty. Shipped'})\n",
    "#         if \"Manufacturer\" in data_magento.columns:\n",
    "#             data_magento= data_magento.drop([\"Manufacturer\"], axis=1)\n",
    "#         if \"Item Cost\" in data_magento.columns:\n",
    "#             data_magento= data_magento.drop([\"Item Cost\"], axis=1)\n",
    "#         if \"Package Name\" in data_magento.columns:\n",
    "#             data_magento= data_magento.drop([\"Package Name\"], axis=1)\n",
    "#         if \"Tax Refunded\" in data_magento.columns:\n",
    "#             data_magento= data_magento.drop([\"Tax Refunded\"], axis=1)\n",
    "#         if \"Catalog Name Rule\" in data_magento.columns:\n",
    "#             data_magento= data_magento.drop([\"Catalog Name Rule\"], axis=1)\n",
    "#         if \"Order date\" in data_magento.columns:\n",
    "#             data_magento[\"Order date\"] = pd.to_datetime(data_magento[\"Order date\"], errors = 'coerce')\n",
    "#         if \"Customer Email\" in data_magento.columns:\n",
    "#             data_magento[\"Customer Email\"] = data_magento[\"Customer Email\"].replace(regex = r'\"', value=\"\")\n",
    "#         if \"Qty. Ordered\" in data_magento.columns:\n",
    "#             data_magento['Qty. Ordered'] = data_magento['Qty. Ordered'].fillna(0)\n",
    "#             if \"Qty. Invoiced\" in data_magento.columns:\n",
    "#                 data_magento['Qty. Invoiced'] = data_magento['Qty. Invoiced'].fillna(0)\n",
    "#             if \"Qty. Shipped\" in data_magento.columns:\n",
    "#                 data_magento['Qty. Shipped'] = data_magento['Qty. Shipped'].fillna(0)\n",
    "#             if \"Qty. Refunded\" in data_magento.columns:\n",
    "#                 data_magento['Qty. Refunded'] = data_magento['Qty. Refunded'].fillna(0)\n",
    "#             if \"Item Price\" in data_magento.columns:\n",
    "#                 data_magento['Item Price'] = data_magento['Item Price'].fillna(0)\n",
    "#             if \"Subtotal\" in data_magento.columns:\n",
    "#                 data_magento['Subtotal'] = data_magento['Subtotal'].fillna(0)\n",
    "#             if \"Discounts\" in data_magento.columns:\n",
    "#                 data_magento['Discounts'] = data_magento['Discounts'].fillna(0)\n",
    "#             if \"Invoiced\" in data_magento.columns:\n",
    "#                 data_magento['Invoiced'] = data_magento['Invoiced'].fillna(0)\n",
    "#             if \"Tax Invoiced\" in data_magento.columns:\n",
    "#                 data_magento['Tax Invoiced'] = data_magento['Tax Invoiced'].fillna(0)\n",
    "#             if \"Voucher Amount\" in data_magento.columns:\n",
    "#                 data_magento[data_magento['Voucher Amount'].astype(str).str.isdigit()]['Voucher Amount'] = data_magento[data_magento['Voucher Amount'].fillna(0).astype(str).str.isdigit()]['Voucher Amount'].astype(float).div(10000)\n",
    "#             if \"Discount Poin Reward\" in data_magento.columns:\n",
    "#                 data_magento['Discount Poin Reward'] = data_magento['Discount Poin Reward'].fillna(0)\n",
    "#             if \"Discount Product\" in data_magento.columns:\n",
    "#                 data_magento['Discount Product'] = data_magento['Discount Product'].fillna(0)\n",
    "#         if \"Tax\" in data_magento.columns:\n",
    "#             data_magento['Tax'] = data_magento['Tax'].astype('Float32')\n",
    "#         if \"Total\" in data_magento.columns:\n",
    "#             data_magento['Total'] = data_magento['Total'].astype('Float32')\n",
    "#         if \"Total incl. Tax\" in data_magento.columns:\n",
    "#             data_magento['Total incl. Tax'] = pd.to_numeric(data_magento['Total incl. Tax'], errors = 'coerce').astype('Float32')\n",
    "#         if \"Invoiced incl. Tax\" in data_magento.columns:\n",
    "#             data_magento['Invoiced incl. Tax'] = data_magento['Invoiced incl. Tax'].astype('Float32')\n",
    "#         if \"Refunded\" in data_magento.columns:\n",
    "#             data_magento['Refunded'] = data_magento['Refunded'].astype('Float32')\n",
    "#         if \"Refunded incl. Tax\" in data_magento.columns:\n",
    "#             data_magento['Refunded incl. Tax'] = data_magento['Refunded incl. Tax'].astype('Float32')\n",
    "#         if \"Ship Date\" in data_magento.columns:\n",
    "#             data_magento['Ship Date'] = data_magento['Ship Date'].astype(str).str.replace('false', '')\n",
    "\n",
    "#         # Customer Information Filling  \n",
    "#         for i in range(data_magentoUser.shape[1]):\n",
    "#             data_magentoUser = data_magentoUser.rename(columns={ data_magentoUser.columns[i] : data_magentoUser.columns[i].replace(\"    \",\" \")})\n",
    "\n",
    "#         for i in range(data_magento.shape[0]):\n",
    "#             if str(data_magento[\"Customer Group\"][i]) == 'nan':\n",
    "#                 if str(data_magento[\"Order #\"][i]) in data_magentoUser[\"Sales Order Id\"].astype(str).values:\n",
    "#                     data_magento[\"Customer Name\"][i] = data_magentoUser[\"Shipping Name\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "#                     data_magento[\"Customer Group\"][i] = \"Not Logged In\"\n",
    "#                     data_magento[\"Country\"][i] = data_magentoUser[\"Shipping Country\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "#                     data_magento[\"Region\"][i] = data_magentoUser[\"Shipping Province\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "#                     data_magento[\"City\"][i] = data_magentoUser[\"Shipping City\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "#                     data_magento[\"Zip Code\"][i] = data_magentoUser[\"Shipping Zip\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "#                     data_magento[\"Address\"][i] = data_magentoUser[\"Shipping Address1\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "#                     data_magento[\"Phone\"][i] = data_magentoUser[\"Shipping Phone\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "\n",
    "#         indeks = data_magento[data_magento['Phone'].isnull()].index.to_list()\n",
    "#         data_magento['Phone Condition'] = np.nan\n",
    "#         data_magento['Phone Condition'][indeks] = 'X'\n",
    "\n",
    "#         data_magentoUser['Sales Order Id'] = data_magentoUser['Sales Order Id'].astype(str)\n",
    "#         data_magento['Order #'] = data_magento['Order #'].astype(str)\n",
    "\n",
    "#         temp2 = data_magento.merge(data_magentoUser[['Sales Order Id', 'AWB', 'Shipping Cost', 'Shipping Address1', 'Shipping City', 'Shipping Province', 'Shipping Phone']].drop_duplicates('Sales Order Id'), how = 'left', left_on = 'Order #', right_on = 'Sales Order Id').set_index(data_magento.index)\n",
    "\n",
    "#         data_magento['Shipping'] = np.nan\n",
    "#         data_magento['AWB'] = np.nan\n",
    "\n",
    "#         data_magento['Shipping'][temp2.index] = temp2['Shipping Cost']\n",
    "#         data_magento['AWB'][temp2.index] = temp2['AWB']\n",
    "\n",
    "\n",
    "#         # Phone formatting\n",
    "#         data_magento[\"Phone\"] = data_magento[\"Phone\"].fillna(0.0)\n",
    "#         data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\" \",\"\")\n",
    "#         data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"-\",\"\")\n",
    "#         temp = data_magento[\"Phone\"].astype(str).str.split(\",\", expand = True)\n",
    "#         data_magento[\"Phone\"] = temp[0]\n",
    "#         temp = data_magento[\"Phone\"].astype(str).str.split(\"/\", expand = True)\n",
    "#         data_magento[\"Phone\"] = temp[0]\n",
    "#         data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^\\+620\", \"0\", regex = True)\n",
    "#         data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^\\+62\", \"0\")\n",
    "#         data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^620\", \"0\", regex = True)\n",
    "#         data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^62\", \"0\", regex = True)\n",
    "#         data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^8\", \"08\", regex = True)\n",
    "#         data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^62\", \"0\", regex = True)\n",
    "#         data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"(021)\", \"021\")\n",
    "#         data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^21\", \"021\", regex = True)\n",
    "        \n",
    "        \n",
    "#         data_magento['Shipping Address1'] = np.nan\n",
    "#         data_magento['Shipping City'] = np.nan\n",
    "#         data_magento['Shipping Province'] = np.nan\n",
    "#         data_magento['Shipping Phone'] = np.nan\n",
    "\n",
    "#         data_magento['Shipping Address1'][temp2.index] = temp2['Shipping Address1']\n",
    "#         data_magento['Shipping City'][temp2.index] = temp2['Shipping City']\n",
    "#         data_magento['Shipping Province'][temp2.index] = temp2['Shipping Province']\n",
    "#         data_magento['Shipping Phone'][temp2.index] = temp2['Shipping Phone']\n",
    "        \n",
    "        \n",
    "#         data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].fillna(0.0)\n",
    "#         data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\" \",\"\")\n",
    "#         data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"-\",\"\")\n",
    "#         temp = data_magento[\"Shipping Phone\"].astype(str).str.split(\",\", expand = True)\n",
    "#         data_magento[\"Shipping Phone\"] = temp[0]\n",
    "#         temp = data_magento[\"Shipping Phone\"].astype(str).str.split(\"/\", expand = True)\n",
    "#         data_magento[\"Shipping Phone\"] = temp[0]\n",
    "#         data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^\\+620\", \"0\", regex = True)\n",
    "#         data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^\\+62\", \"0\")\n",
    "#         data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^620\", \"0\", regex = True)\n",
    "#         data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^62\", \"0\", regex = True)\n",
    "#         data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^8\", \"08\", regex = True)\n",
    "#         data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^62\", \"0\", regex = True)\n",
    "#         data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"(021)\", \"021\")\n",
    "#         data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^21\", \"021\", regex = True)\n",
    "\n",
    "#         # Master tatanama\n",
    "#         print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#         print(\"Fulfilling SKU ====== 3/10\")\n",
    "\n",
    "#         data_magento['SKU'] = data_magento['SKU'].astype(str).str.split('-').str[0]\n",
    "#         indeks = data_magento[~data_magento['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))]['SKU'].index.to_list()\n",
    "\n",
    "#         skuhd = data_magento[data_magento['SKU'].astype(str).str.contains('hd', case = False)]\n",
    "#         skushopee = data_magento[data_magento['SKU'].astype(str).str.contains('(S)',regex = False)]\n",
    "#         data_magento = data_magento[~data_magento['SKU'].astype(str).isin(skushopee['SKU'].astype(str))]\n",
    "#         data_magento = data_magento[~data_magento['SKU'].astype(str).isin(skuhd['SKU'].astype(str))]\n",
    "\n",
    "#         skuhd = skuhd.reset_index(drop = True)\n",
    "#         skushopee = skushopee.reset_index(drop = True)\n",
    "#         data_magento = data_magento.reset_index(drop = True)\n",
    "\n",
    "#         indeks = data_magento[~data_magento['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))]['SKU'].index.to_list()\n",
    "#         for i in indeks:\n",
    "#             if data_magento['Product Name'][i].lower() in data_SKU['Nama Produk'].str.lower().values:\n",
    "#                 data_magento['SKU'][i] = data_SKU['SKU'].loc[data_SKU['Nama Produk'].str.lower() == str(data_magento['Product Name'][i]).lower()].values[0]\n",
    "\n",
    "#         list_alias = []\n",
    "#         list_alias_name = []\n",
    "#         for colname in data_SKU.columns:\n",
    "#             if 'Alias SKU' in colname:\n",
    "#                 list_alias.append(colname)\n",
    "#             if 'Alias Nama' in colname:\n",
    "#                 list_alias_name.append(colname)\n",
    "\n",
    "#         for i in indeks:\n",
    "#             for j in list_alias:\n",
    "#                 if str(data_magento['SKU'][i]) in data_SKU[j].astype(str).values:\n",
    "#                     idx = data_SKU[str(data_magento['SKU'][i]) == data_SKU[j].astype(str)].index.to_list()\n",
    "#                     for k in idx:\n",
    "#                         if str(data_magento['SKU'][i]) == data_SKU[j.replace('SKU', 'Nama')][k]:\n",
    "#                             data_magento['SKU'][i] = data_SKU['SKU'][k]\n",
    "\n",
    "#         indeks = data_magento[~data_magento['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))]['SKU'].index.to_list()\n",
    "\n",
    "#         for i in indeks:\n",
    "#             for j in list_alias_name:\n",
    "#                 if str(data_magento['Product Name'][i]).lower() in data_SKU[j].astype(str).str.lower().values:\n",
    "#                     data_magento['SKU'][i] = data_SKU['SKU'].loc[str(data_magento['Product Name'][i]).lower() == data_SKU[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "#         data_magento = data_magento[data_magento['Product Name'].astype(str) != 'WRP Everyday Low Fat Milk Coklat 4 Pillow Bag']\n",
    "#         data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Kitchen Japanese Matcha Latte (12 Sch)']\n",
    "#         data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Kitchen Vietnamese Coffee Latte (12 Sch)']\n",
    "#         data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Blush Yo Raspberry Pumpkin (24 pcs)']\n",
    "#         data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Blush Yo Raspberry Pumpkin (1 pc)']\n",
    "        \n",
    "#         data_magento['SKU'] = data_magento['SKU'].astype(str).str.replace('7300281P24', '7300281')\n",
    "        \n",
    "#         data_magento = data_magento[~data_magento['Product Name'].astype(str).str.contains('JANGAN DIORDER INI TESTING')]\n",
    "#         data_magento = data_magento[~data_magento['SKU'].astype(str).str.contains('7300851')]\n",
    "        \n",
    "        \n",
    "#         print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#         print(\"Listing SKU Missing ====== 4/10\")   \n",
    "#         idx = data_magento[['SKU']][data_magento['SKU'].isnull()].drop_duplicates().index.to_list()\n",
    "#         idx = idx + data_magento[['SKU', 'Product Name']][~data_magento['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "#         idx = list(dict.fromkeys(idx))\n",
    "#         idx_s = skushopee[~skushopee['SKU'].astype(str).str.replace('(S)','', regex = False).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "#         idx_s = list(dict.fromkeys(idx_s))\n",
    "#         idx_hd = skuhd[~skuhd['SKU'].astype(str).str.replace('hd','',case = False).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "#         idx_hd = list(dict.fromkeys(idx_hd))\n",
    "\n",
    "#         to_excel = data_magento.to_excel(r'magento_new.xls', index = False)\n",
    "#         print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#         if len(idx) != 0 or len(idx_s) != 0 or len(idx_hd) != 0:\n",
    "#             print('SKU is missing')\n",
    "#             alert = data_magento.iloc[idx, ][['SKU', 'Product Name']].drop_duplicates()\n",
    "#             alert = alert.append(skushopee.iloc[idx_s][['SKU', 'Product Name']].drop_duplicates(), ignore_index = True, sort = False)\n",
    "#             alert['SKU Valid'] = np.nan\n",
    "#             to_excel = alert.to_excel('ALERT_MAGENTO_SKU_MISSING.xlsx')\n",
    "#             print(\"Some SKU Missing Please Complete It ====== 5/10\")\n",
    "#             print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#             s = smtplib.SMTP('smtp.gmail.com', 587) \n",
    "\n",
    "#             # start TLS for security \n",
    "#             s.starttls() \n",
    "\n",
    "#             # Authentication \n",
    "#             s.login(\"automationnfi@gmail.com\", \"nutrifood2020\") \n",
    "\n",
    "#             msg = MIMEMultipart()\n",
    "#             msg['Subject'] = \"ALERT SKU MAGENTO MISSING\"\n",
    "\n",
    "\n",
    "#             html = \"\"\"\\\n",
    "#             <html>\n",
    "#             <head></head>\n",
    "#             <body>\n",
    "#                 {0}\n",
    "#             </body>\n",
    "#             </html>\n",
    "#             \"\"\".format(alert.to_html())\n",
    "\n",
    "#             part1 = MIMEText(html, 'html')\n",
    "#             msg.attach(part1)\n",
    "\n",
    "#             # sending the mail \n",
    "#             s.sendmail(\"automationnfi@gmail.com\", \"andra.miftah@nutrifood.co.id\", msg.as_string()) \n",
    "\n",
    "#             # terminating the session \n",
    "#             s.quit()\n",
    "#         else :\n",
    "#             print(\"Preparing Appending Magento to Masterdata\")\n",
    "#             print(\"Filling Brand ====== 5/10\")  \n",
    "#             data_magento = data_magento.append(skushopee, ignore_index = True, sort = False)\n",
    "#             data_magento = data_magento.reset_index(drop = True)\n",
    "\n",
    "#             data_magento['SKU'] = data_magento['SKU'].astype(str)\n",
    "#             data_magento['Product Name'] = data_magento['Product Name'].astype(str)\n",
    "#             data_SKU['Real SKU'] = data_SKU['SKU'].astype(str)\n",
    "#             data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "\n",
    "#             data_magento = data_magento.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "#             temp = data_magento[data_magento['Real SKU'].isnull()].copy()\n",
    "#             temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "#             temp = temp.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "#             temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "#             temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "#             temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "#             temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "#             indeks = data_magento[data_magento['Real SKU'].isnull()].index.to_list()\n",
    "#             data_magento['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "#             data_magento['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "#             temp = data_magento[data_magento['Real SKU'].isnull()].copy()\n",
    "#             temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "#             temp = temp.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "#             temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "#             temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "#             temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "#             temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "#             indeks = data_magento[data_magento['Real SKU'].isnull()].index.to_list()\n",
    "#             data_magento['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "#             data_magento['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "#             data_magento['Real SKU'] = data_magento['Real SKU'].astype(str)\n",
    "#             data_magento = data_magento.merge(data_SKU[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "#             data_magento = data_magento.drop(['SKU_y'], axis = 1)\n",
    "#             data_magento = data_magento.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "#             print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#             print(\"Unbundling ====== 6/10\")\n",
    "#             list_col = ['SKU'] + data_SKU.columns[data_SKU.columns.get_loc('Produk 1'):data_SKU.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "#             data_magento = data_magento.merge(data_SKU[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "#             data_magento = data_magento.drop(['SKU_y'], axis = 1)\n",
    "#             data_magento = data_magento.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "#             indeks = data_magento[data_magento['Brand'] == 'Bundle'].index.to_list()\n",
    "#             data_magento['Bundle Flag'] = np.nan\n",
    "#             data_magento['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "#             print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#             print(\"Filling Date ====== 7/10\")\n",
    "#             data_magento['Date'] = np.nan\n",
    "#             data_magento['Month'] = np.nan\n",
    "#             data_magento['Year'] = np.nan\n",
    "\n",
    "#             for i in range(data_magento.shape[0]):\n",
    "#                 if int(data_magento['Order date'][i].strftime('%d')) <= 12:\n",
    "#                     data_magento['Date'][i] = pd.to_datetime(data_magento['Order date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "#                     data_magento['Month'][i] = pd.to_datetime(data_magento['Order date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "#                     data_magento['Year'][i] = pd.to_datetime(data_magento['Order date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "#                 else :\n",
    "#                     data_magento['Date'][i] = pd.to_datetime(data_magento['Order date'][i]).day\n",
    "#                     data_magento['Month'][i] = pd.to_datetime(data_magento['Order date'][i]).month_name()\n",
    "#                     data_magento['Year'][i] = pd.to_datetime(data_magento['Order date'][i]).year\n",
    "\n",
    "\n",
    "#             quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "#                     ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "#             data_magento = data_magento.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "#             data_magento = data_magento.drop(['Bulan'], axis = 1)\n",
    "#             data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "#                     {'Bulan' : 'January' , 'Number': 1},\n",
    "#                     {'Bulan' : 'February' , 'Number': 2},\n",
    "#                     {'Bulan' : 'March' , 'Number': 3},\n",
    "#                     {'Bulan' : 'April' , 'Number': 4},\n",
    "#                     {'Bulan' : 'May' , 'Number': 5},\n",
    "#                     {'Bulan' : 'June', 'Number': 6},\n",
    "#                     {'Bulan' : 'July' , 'Number': 7},\n",
    "#                     {'Bulan' : 'August', 'Number' : 8},\n",
    "#                     {'Bulan' : 'September', 'Number' : 9},\n",
    "#                     {'Bulan' : 'October' , 'Number': 10},\n",
    "#                     {'Bulan' : 'November' , 'Number': 11}])\n",
    "#             temp = data_magento.copy()\n",
    "#             temp['Day'] = temp['Date']\n",
    "#             temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "#             temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "#             data_magento['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "#             data_magento['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day']])\n",
    "#             data_magento['Channel'] = 'Nutrimart'\n",
    "#             data_magento['Store'] = 'Nutrimart'\n",
    "#             data_magento['Selling Price'] = data_magento['Item Price']\n",
    "#             print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#             print(\"Pricing\")\n",
    "#             data_magento = data_magento.merge(data_SKU[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(data_magento.index)\n",
    "#             data_magento = data_magento.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "#             data_magento['Price List NFI'] = pd.to_numeric(data_magento['Price List NFI']).astype(int)\n",
    "#             data_magento['Harga Cost'] = pd.to_numeric(data_magento['Harga Cost'], errors = 'coerce').fillna(0).astype(int)\n",
    "#             data_magento['Qty. Invoiced'] = pd.to_numeric(data_magento['Qty. Invoiced']).astype(int)\n",
    "#             data_magento['Total Net'] = data_magento['Price List NFI'] * data_magento['Qty. Invoiced']\n",
    "#             data_magento['Total Harga Cost'] = data_magento['Harga Cost'] * data_magento['Qty. Invoiced']\n",
    "\n",
    "#             data_magento = data_magento.drop('SKU_y', axis = 1)\n",
    "#             data_magento = data_magento.reset_index(drop = True)\n",
    "#             data_magento['Order #'] = data_magento['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "#             list_bundle = data_magento[data_magento['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "#             list_nobundle = data_magento[data_magento['Bundle Name'].notnull()]\n",
    "#             list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "#             list_nobundle\n",
    "\n",
    "#             data_magento['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "#             data_magento['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "#             temp = data_magento[data_magento['Bundle Name'].notnull()]\n",
    "#             temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "#             temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "#             temp['Selling Price'] = temp['Subtotal'] / temp['Qty. Invoiced']\n",
    "\n",
    "#             data_magento['Total'][temp.index] = temp['Total'].fillna(0).astype(int)\n",
    "#             data_magento['Subtotal'][temp.index] = temp['Subtotal'].fillna(0).astype(int)\n",
    "#             data_magento['Selling Price'][temp.index] = temp['Selling Price'].fillna(0).astype(int)\n",
    "\n",
    "#             print(\"Filling Location\")\n",
    "#             data_magento['Kecamatan'] = np.nan\n",
    "#             data_magento['Kelurahan'] = np.nan\n",
    "# #             data_magento = data_magento.rename(columns = {'Shipping City' : 'City', 'Shipping Province' : 'Region'})\n",
    "\n",
    "#             indeks = data_magento[data_magento['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "#             if len(indeks)>0:\n",
    "#                 data_magento['Kecamatan'][indeks] = data_magento['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "#                 data_magento['City'][indeks] = data_magento['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "#             indeks = data_magento[data_magento['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "#             if len(indeks)>0:\n",
    "#                 data_magento['Kelurahan'][indeks] = data_magento['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "#                 data_magento['Kecamatan'][indeks] = data_magento['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "#             indeks = data_magento[data_magento['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "#             if len(indeks)>0:\n",
    "#                 data_magento['Kecamatan'][indeks] = data_magento['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "#                 data_magento['City'][indeks] = data_magento['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "#             indeks = data_magento[data_magento['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "#             if len(indeks)>0:\n",
    "#                 data_magento['Kelurahan'][indeks] = data_magento['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "#                 data_magento['Kecamatan'][indeks] = data_magento['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "#             city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "#             temp = data_magento.copy()\n",
    "#             temp['City'] = temp['City'].astype(str).str.lower()\n",
    "#             city['All City'] = city['All City'].astype(str).str.lower()\n",
    "#             temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "#             indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "#             data_magento['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "#             province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "#             temp = data_magento.copy()\n",
    "#             temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "#             province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "#             temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "#             indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "#             data_magento['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "#             temp = data_magento.copy()\n",
    "#             temp = temp[temp['Region'].isnull()]\n",
    "#             temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "#             data_magento['Region'][temp.index] = temp['Region']\n",
    "\n",
    "#             district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "#             temp = data_magento.copy()\n",
    "#             temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "#             district['All District'] = district['All District'].astype(str).str.lower()\n",
    "#             temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "#             indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "#             data_magento['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "#             temp = data_magento.copy()\n",
    "#             temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "#             indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "#             data_magento['City'][indeks] = np.nan\n",
    "            \n",
    "#             indeks = data_magento[data_magento['Shipping City'].astype(str).str.contains('/')]['Shipping City'].index.to_list()\n",
    "#             if len(indeks)>0:\n",
    "#                 data_magento['Shipping City'][indeks] = data_magento['Shipping City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "#             indeks = data_magento[data_magento['Shipping City'].astype(str).str.contains(',')]['Shipping City'].index.to_list()\n",
    "#             if len(indeks)>0:\n",
    "#                 data_magento['Shipping City'][indeks] = data_magento['Shipping City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "#             city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "#             temp = data_magento.copy()\n",
    "#             temp['Shipping City'] = temp['Shipping City'].astype(str).str.lower()\n",
    "#             city['All City'] = city['All City'].astype(str).str.lower()\n",
    "#             temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'Shipping City', right_on = 'All City').set_index(temp.index)\n",
    "#             indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "#             data_magento['Shipping City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "#             province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "#             temp = data_magento.copy()\n",
    "#             temp['Shipping Province'] = temp['Shipping Province'].astype(str).str.lower()\n",
    "#             province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "#             temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Shipping Province', right_on = 'All Province').set_index(temp.index)\n",
    "#             indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "#             data_magento['Shipping Province'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "#             temp = data_magento.copy()\n",
    "#             temp = temp[temp['Shipping Province'].isnull()]\n",
    "#             temp['Shipping Province'] = temp.merge(master_map, how = 'left', left_on = 'Shipping City', right_on = 'City').set_index(temp.index)['Shipping Province']\n",
    "#             data_magento['Shipping Province'][temp.index] = temp['Shipping Province']\n",
    "\n",
    "#             temp = data_magento.copy()\n",
    "#             temp2 = temp[['Shipping Province', 'Shipping City']].merge(master_map, how = 'left', left_on = 'Shipping City', right_on = 'City')\n",
    "#             indeks = temp2[temp2['Shipping Province'] != temp2['Province']][temp2[temp2['Shipping Province'] != temp2['Province']]['Shipping City'].notnull()].index.to_list()\n",
    "#             data_magento['Shipping City'][indeks] = np.nan\n",
    "#             data_magento['Warehouse Name'] = 'Primary Warehouse'\n",
    "\n",
    "#             import os\n",
    "#             import glob\n",
    "\n",
    "#             list_of_files = glob.glob('Clean Data/*.csv')\n",
    "#             latest_file = max(list_of_files, key=os.path.getctime)\n",
    "\n",
    "#             data_all = pd.read_csv(latest_file, sep = ';',converters = {'Phone' : str, 'Order #' : str, 'AWB' : str})\n",
    "#             data_all = data_all[data_all['Store Type'] != 'Retail Online']\n",
    "            \n",
    "#             data_all['Phone'] = data_all['Phone'].astype(str).str.replace('=\"', '', regex = False)\n",
    "#             data_all['Phone'] = data_all['Phone'].astype(str).str.replace('\"', '', regex = False)\n",
    "\n",
    "#             lmen_store = forstok_all[forstok_all['Channel'] == 'L-Men Store Blibli']\n",
    "#             forstok_all = forstok_all[forstok_all['Channel'] != 'L-Men Store Blibli']\n",
    "\n",
    "#             lmen_store = lmen_store[~lmen_store['Order #'].astype(str).isin(data_all['Order #'].astype(str))]\n",
    "#             lmen_store['Sales Order ID'] = lmen_store['Sales Order ID'].fillna(lmen_store['No. Order Item L-Men Blibli'])\n",
    "#             ornum = lmen_store[['Order #', 'Sales Order ID']].drop_duplicates('Order #')\n",
    "\n",
    "#             options = Options()\n",
    "#             options.add_experimental_option(\"prefs\", {\n",
    "#                     \"download.default_directory\": str(os.getcwd())  + '/Input Data',\n",
    "#                     \"download.directory_upgrade\": True,\n",
    "#                     \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "#                     \"safebrowsing.enabled\": False\n",
    "#             })\n",
    "\n",
    "#             driver = webdriver.Chrome(options=options)\n",
    "#             driver.get(\"https://seller.blibli.com/sign-in\")\n",
    "\n",
    "\n",
    "#             username = driver.find_element_by_id(\"email\")\n",
    "#             username.clear()\n",
    "#             username.send_keys(\"novita.vidianti@nutrifood.co.id\")\n",
    "\n",
    "#             password = driver.find_element_by_id(\"password\")\n",
    "#             password.send_keys(\"EsPodeeng2021\")\n",
    "\n",
    "#             driver.find_element_by_id(\"sign-in\").click()\n",
    "#             time.sleep(5)\n",
    "# #             WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'close-announcement-button'))).click()\n",
    "# #             WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, 'remind-me-later-button'))).click()\n",
    "#             #     WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, 'nav-wrapper-ORDER'))).click()\n",
    "#             #     driver.find_element_by_id(\"sub-nav-item-0\").click()\n",
    "#             driver.get(\"https://seller.blibli.com/MTA/order/summary\")\n",
    "#             WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'btn-primary-mta'))).click()\n",
    "#             driver.find_element_by_id(\"semuaFilter\").click()\n",
    "\n",
    "#             ornum['Phone'] = np.nan\n",
    "#             ornum['Email'] = np.nan\n",
    "#             ornum['Address'] = np.nan\n",
    "\n",
    "#             for i in ornum.index:\n",
    "#                 orderNo = ornum['Order #'][i]\n",
    "#                 orderItemNo = int(pd.to_numeric(ornum['Sales Order ID'][i]))\n",
    "#                 link = \"https://merchant.blibli.com/MTA/neo/order/order-detail/\" + \"?orderNo=\" + str(orderNo) + \"&orderItemNo=\" + str(orderItemNo)\n",
    "#                 driver.get(link)\n",
    "#                 WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"customer-phone\"]/span')))\n",
    "#                 hp = driver.find_elements_by_xpath('//*[@id=\"customer-phone\"]/span')[0].text\n",
    "#                 if len(driver.find_elements_by_xpath('//*[@id=\"customer-email\"]/span')) != 0:\n",
    "#                     email = driver.find_elements_by_xpath('//*[@id=\"customer-email\"]/span')[0].text\n",
    "#                     ornum['Email'][i] = email\n",
    "#                 address = driver.find_elements_by_xpath('//*[@id=\"alamat-pengiriman\"]//div//p')[0].text\n",
    "#                 ornum['Phone'][i] = hp\n",
    "#                 ornum['Address'][i] = address\n",
    "\n",
    "#             driver.quit()\n",
    "#             if len(ornum) != 0:\n",
    "#                 tes = ornum.copy()\n",
    "#                 tes['Real Address'] = tes['Address'].str.split('\\n', expand = True)[1].str.strip()\n",
    "#                 tes['Kelurahan'] = tes['Address'].str.split('\\n', expand = True)[3].str.split('-', expand = True)[0].str.strip()\n",
    "#                 tes['Kecamatan'] = tes['Address'].str.split('\\n', expand = True)[3].str.split('-', expand = True)[1].str.strip()\n",
    "#                 tes['City'] = tes['Address'].str.split('\\n', expand = True)[4].str.split(',', expand = True)[0].str.strip()\n",
    "#                 tes['Region'] = tes['Address'].str.split('\\n', expand = True)[4].str.split(',', expand = True)[1].str.strip()\n",
    "#                 tes['Zip Code'] = tes['Address'].str.split('\\n', expand = True)[5].str.strip()\n",
    "\n",
    "#                 lmen_store['Order #'] = lmen_store['Order #'].astype(str)\n",
    "#                 tes['Order #'] = tes['Order #'].astype(str)\n",
    "#                 lmen_store = lmen_store.merge(tes[['Order #', 'Phone', 'Email', 'Real Address', 'Kelurahan', 'Kecamatan', 'City', 'Region', 'Zip Code']].drop_duplicates('Order #'), how = 'left', on = 'Order #')\n",
    "\n",
    "#                 indeks = lmen_store[lmen_store['Phone_y'].notnull()].index.to_list()\n",
    "#                 lmen_store['Phone_x'][indeks] = lmen_store['Phone_y'][indeks]\n",
    "#                 lmen_store['Customer Email'][indeks] = lmen_store['Email'][indeks]\n",
    "#                 lmen_store['Phone_x'][indeks] = lmen_store['Phone_y'][indeks]\n",
    "#                 lmen_store['Region_x'][indeks] = lmen_store['Region_y'][indeks]\n",
    "#                 lmen_store['City_x'][indeks] = lmen_store['City_y'][indeks]\n",
    "#                 lmen_store['Kecamatan_x'][indeks] = lmen_store['Kecamatan_y'][indeks]\n",
    "#                 lmen_store['Kelurahan_x'][indeks] = lmen_store['Kelurahan_y'][indeks]\n",
    "#                 lmen_store['Zip Code_x'][indeks] = lmen_store['Zip Code_y'][indeks]\n",
    "#                 lmen_store['Address'][indeks] = lmen_store['Real Address'][indeks]\n",
    "\n",
    "#                 lmen_store = lmen_store.drop(['Phone_y', 'Email', 'Region_y', 'City_y', 'Kecamatan_y', 'Kelurahan_y', 'Real Address', 'Zip Code_y'], axis = 1)\n",
    "#                 lmen_store = lmen_store.rename(columns = {'Phone_x' : 'Phone', 'Region_x' : 'Region', 'City_x' : 'City', 'Kecamatan_x' : 'Kecamatan', 'Kelurahan_x' : 'Kelurahan', 'Zip Code_x' : 'Zip Code'})\n",
    "\n",
    "#             forstok_all = forstok_all.append(lmen_store, ignore_index = True, sort = False)\n",
    "\n",
    "#             indeks = data_all[data_all['Channel'] == 'L-Men Store Blibli'].index.to_list()\n",
    "#             data_all['Store'][indeks] = 'Blibli'\n",
    "\n",
    "#             data_all = data_all[~data_all['Order #'].astype(str).isin(forstok_all['Order #'].astype(str))]\n",
    "#             data_all = data_all[~data_all['Order #'].astype(str).isin(data_magento['Order #'].astype(str))]\n",
    "#             data_all = data_all.append(forstok_all, ignore_index = True, sort = False)\n",
    "#             data_all = data_all.append(data_magento, ignore_index = True, sort = False)\n",
    "#             data_all['Brand'] = data_all['Brand'].astype(str).str.replace('Tropicana Slim', 'TS')\n",
    "\n",
    "#             indeks = data_all[data_all['Qty. Invoiced'] == 0].index.to_list()\n",
    "#             data_all['Qty. Invoiced'][indeks] = data_all['Qty. Shipped'][indeks]\n",
    "#             data_all['Total Net'][indeks] = data_all['Price List NFI'][indeks] * data_all['Qty. Invoiced'][indeks]\n",
    "#             indeks = data_all[data_all['Qty. Invoiced'] == 0].index.to_list()\n",
    "#             data_all['Qty. Invoiced'][indeks] = data_all['Qty. Ordered'][indeks]\n",
    "#             data_all['Total Net'][indeks] = data_all['Price List NFI'][indeks] * data_all['Qty. Invoiced'][indeks]\n",
    "\n",
    "# #             data_SKU['Brand Temp'] = np.nan\n",
    "# #             for i in range(len(data_SKU)):\n",
    "# #                 if data_SKU['Brand'][i] == 'Bonus Produk':\n",
    "# #                     if 'hilo' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                         brand = 'HiLo'\n",
    "# #                     elif 'tropicana' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                         brand = 'TS'\n",
    "# #                     elif 'l-men' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                         brand = 'L-Men'\n",
    "# #                     elif \"w'dank\" in data_SKU['Nama Produk'][i].lower():\n",
    "# #                         brand = \"W'dank\"\n",
    "# #                     elif 'nutrisari' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                         brand = 'NS'\n",
    "# #                     elif 'ts ' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                         brand = 'TS'\n",
    "# #                     data_SKU['Brand Temp'][i] = brand\n",
    "# #             data_SKU['Brand Temp'] = data_SKU['Brand Temp'].fillna(data_SKU['Brand'])\n",
    "\n",
    "# #             data_SKU['List Brand'] = np.nan\n",
    "# #             for i in range(len(data_SKU)):\n",
    "# #                 list_brand = []\n",
    "# #                 if data_SKU['Brand'][i] == 'Bundle':\n",
    "# #                     col_SKU = [x for x in data_SKU.columns if 'SKU Produk' in x]\n",
    "# #                     for j in col_SKU:\n",
    "# #                         if str(data_SKU[j][i]) != 'nan' and str(data_SKU[j][i]) != '0':\n",
    "# #                             brand = data_SKU[data_SKU['SKU'].astype(str) == str(data_SKU[j][i]).replace('(S)', '').replace('.0', '')]['Brand Temp'].values[0]\n",
    "# #                             if brand == 'Gimmick' : \n",
    "# #                                 if 'voucher' in data_SKU['Nama Produk'][i].lower() or 'saldo' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                     brand = 'Voucher'\n",
    "# #                                 elif 'pouch' in data_SKU['Nama Produk'][i].lower() or 'bag ' in data_SKU['Nama Produk'][i].lower() or 'tas ' in data_SKU['Nama Produk'][i].lower() or 'totebag' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                     brand = 'Bag'\n",
    "# #                                 elif 'bottle' in data_SKU['Nama Produk'][i].lower() or 'gelas ' in data_SKU['Nama Produk'][i].lower() or 'shaker' in data_SKU['Nama Produk'][i].lower() or 'tumblr' in data_SKU['Nama Produk'][i].lower() or 'tumbler' in data_SKU['Nama Produk'][i].lower() or 'botol' in data_SKU['Nama Produk'][i].lower() or 'thumbler' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                     brand = 'Tumblr'\n",
    "# #                                 elif 'lunch' in data_SKU['Nama Produk'][i].lower() or 'tupper' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                     brand = 'Lunch Box'\n",
    "# #                                 elif 'emoney' in data_SKU['Nama Produk'][i].lower() or 'e-money' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                     brand = 'E-Money'\n",
    "# #                                 elif 'magnet' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                     brand = 'Magnet'\n",
    "# #                                 elif 'masker' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                     brand = 'Masker'\n",
    "# #                                 elif 'spatula' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                     brand = 'Spatula'\n",
    "# #                                 elif 'nivea' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                     brand = 'Nivea'\n",
    "# #                                 elif 'card ' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                     brand = 'Card'\n",
    "# #                                 elif 'mug' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                     brand = 'Mug'\n",
    "# #                             list_brand.append(brand)\n",
    "# #                 data_SKU['List Brand'][i] = list_brand\n",
    "\n",
    "# #             for i in range(len(data_SKU)):\n",
    "# #                 if data_SKU['Brand'][i] == 'Bundle':\n",
    "# #                     list_brand = list(dict.fromkeys(data_SKU['List Brand'][i]))\n",
    "# #                     sum_brand = sum([1 for x in list_brand if x in ['NS', 'TS', 'HiLo', 'L-Men', \"W'dank\"]])\n",
    "# #                     if sum_brand == 1:\n",
    "# #                         list_brand = ' + '.join(list_brand)\n",
    "# #                     else :\n",
    "# #                         not_brand = [x for x in list_brand if x not in ['NS', 'TS', 'HiLo', 'L-Men', \"W'dank\"]]\n",
    "# #                         if len(not_brand) == 0:\n",
    "# #                             list_brand = 'Cross Brand'\n",
    "# #                         else :\n",
    "# #                             list_brand = 'Cross Brand + ' + ' + '.join(not_brand)\n",
    "# #                     data_SKU['Sub Brand'][i] = list_brand\n",
    "# #             temp = data_all[data_all['Brand'] == 'Bundle']\n",
    "# #             temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','',regex = False).str.replace('.0','',regex = False)\n",
    "# #             data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('(S)','',regex = False).str.replace('.0','',regex = False)\n",
    "# #             data_all['Sub Brand'][temp.index] = temp.merge(data_SKU[['SKU', 'Sub Brand']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(temp.index)['Sub Brand_y']\n",
    "        \n",
    "            \n",
    "#             import re \n",
    "#             data_all['Phone'] = data_all['Phone'].astype(str).str.split(';', expand = True)[0]\n",
    "#             data_all['Phone'] = data_all['Phone'].astype(str).str.replace('.0','', regex = False)\n",
    "#             non_phone = data_all[~data_all['Phone'].astype(str).str.isnumeric()]['Phone'].unique()\n",
    "#             for i in non_phone:\n",
    "#                 index = data_all[data_all['Phone'].astype(str) == str(i)].index.to_list()\n",
    "#                 if str(i) != 'nan' and str(i) != '':\n",
    "#                     phone = re.sub(\"[^0-9]\", \"\", i)\n",
    "#                     if phone[0] == '8':\n",
    "#                         phone = '0' + phone\n",
    "#                     data_all['Phone'][index] = phone\n",
    "#             data_all['Phone'] = data_all['Phone'].astype(str).str.replace('^628', '08', regex = True)\n",
    "#             data_all['Phone'] = data_all['Phone'].apply('=\"{}\"'.format)\n",
    "#             data_all['Shipping Phone'] = data_all['Shipping Phone'].apply('=\"{}\"'.format)\n",
    "#             indeks = data_all[data_all['City'] == 'nan'].index.to_list()\n",
    "#             data_all['City'][indeks] = np.nan\n",
    "\n",
    "#             indeks = data_all[data_all['Region'] == 'nan'].index.to_list()\n",
    "#             data_all['Region'][indeks] = np.nan\n",
    "\n",
    "#             indeks = data_all[data_all['Channel'] == 'FBL'].index.to_list()\n",
    "#             data_all['Warehouse Name'][indeks] = 'Lazada Warehouse'\n",
    "\n",
    "#             indeks = data_all[data_all['Warehouse Name'] == 'Lazada Warehouse'].index.to_list()\n",
    "#             data_all['Channel'][indeks] = 'FBL'\n",
    "\n",
    "#             print(\"Read Data Settlement\")\n",
    "#             data_set = pd.read_csv(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Settlement\\test.csv')\n",
    "#             data_all['Order #'] = data_all['Order #'].astype(str)\n",
    "#             data_set['channelorderid'] = data_set['channelorderid'].astype(str)\n",
    "\n",
    "#             temp_set = data_all.merge(data_set[['channelorderid', 'nominal', 'btlcost', 'gs', 'commfee', 'fullfee']].drop_duplicates('channelorderid'), how = 'left', left_on = 'Order #', right_on = 'channelorderid').set_index(data_all.index)\n",
    "#             if 'nominal' not in data_all.columns:\n",
    "#                 data_all['nominal'] = np.nan\n",
    "#                 data_all['btlcost'] = np.nan\n",
    "#                 data_all['gs'] = np.nan\n",
    "#                 data_all['commfee'] = np.nan\n",
    "#                 data_all['fullfee'] = np.nan\n",
    "#                 temp_set = temp_set[temp_set['Bundle Flag'] == 'nan']\n",
    "#                 temp_set['nominal'] = temp_set['nominal'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#                 temp_set['btlcost'] = temp_set['btlcost'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#                 temp_set['gs'] = temp_set['gs'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#                 temp_set['commfee'] = temp_set['commfee'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#                 temp_set['fullfee'] = temp_set['fullfee'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#                 temp_set = temp_set[temp_set['nominal'].notnull()]\n",
    "#                 data_all['nominal'][temp_set.index] = temp_set['nominal']\n",
    "#                 data_all['btlcost'][temp_set.index] = temp_set['btlcost']\n",
    "#                 data_all['gs'][temp_set.index] = temp_set['gs']\n",
    "#                 data_all['commfee'][temp_set.index] = temp_set['commfee']\n",
    "#                 data_all['fullfee'][temp_set.index] = temp_set['fullfee']\n",
    "#             else :\n",
    "#                 temp_set = temp_set[temp_set['Bundle Flag'].isnull()]\n",
    "#                 temp_set['nominal_y'] = temp_set['nominal_y'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#                 temp_set['btlcost_y'] = temp_set['btlcost_y'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#                 temp_set['gs_y'] = temp_set['gs_y'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#                 temp_set['commfee_y'] = temp_set['commfee_y'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#                 temp_set['fullfee_y'] = temp_set['fullfee_y'] * temp_set['Total Harga Cost']/temp_set.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "#                 temp_set = temp_set[temp_set['nominal_y'].notnull()]\n",
    "#                 data_all['nominal'][temp_set.index] = temp_set['nominal_y']\n",
    "#                 data_all['btlcost'][temp_set.index] = temp_set['btlcost_y']\n",
    "#                 data_all['gs'][temp_set.index] = temp_set['gs_y']\n",
    "#                 data_all['commfee'][temp_set.index] = temp_set['commfee_y']\n",
    "#                 data_all['fullfee'][temp_set.index] = temp_set['fullfee_y']\n",
    "\n",
    "#             print(\"Export Data All\")\n",
    "#             for i in data_all.columns[data_all.columns.get_loc('nominal'):]:\n",
    "#                 data_all[i] = pd.to_numeric(data_all[i], errors = 'coerce').fillna(0).astype(int)\n",
    "                \n",
    "#             temp = data_all.copy()\n",
    "#             temp = temp.rename(columns = {'Date' : 'Day'})\n",
    "#             temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "#             temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "#             temp['Hour'] = pd.to_datetime(data_all['Order date'],  errors='coerce').dt.hour\n",
    "#             temp['Minute'] = pd.to_datetime(data_all['Order date'],  errors='coerce').dt.minute\n",
    "#             temp['Second'] = pd.to_datetime(data_all['Order date'],  errors='coerce').dt.second\n",
    "#             data_all['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "#             data_all['Hour'] = temp['Hour']\n",
    "\n",
    "#             from datetime import datetime\n",
    "\n",
    "#             print('Input Forstok Date')\n",
    "#             start_date = datetime.today() - timedelta(days=(diff_date+14))\n",
    "#             end_date = datetime.today()\n",
    "#             date = start_date.strftime('%Y-%m-%d') + '-' + end_date.strftime('%Y-%m-%d')\n",
    "#             print(date)\n",
    "\n",
    "\n",
    "#             print('Opening Chrome')\n",
    "#             driver = webdriver.Chrome()\n",
    "#             driver.fullscreen_window()\n",
    "#             driver.get(\"https://www.forstok.com/dashboard/users/login\")\n",
    "#             print('Login Forstok')\n",
    "#             username = driver.find_element_by_id(\"dashboard_user_email\")\n",
    "#             username.clear()\n",
    "#             username.send_keys(\"andra.miftah@nutrifood.co.id\")\n",
    "\n",
    "#             password = driver.find_element_by_id(\"dashboard_user_password\")\n",
    "#             password.send_keys(\"nutrimart1234\")\n",
    "\n",
    "#             driver.find_element_by_name(\"commit\").click()\n",
    "\n",
    "#             datefield = WebDriverWait(driver, 300).until(EC.element_to_be_clickable((By.ID, 'history_date')))\n",
    "#             datefield.click()\n",
    "\n",
    "#             driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "#             if start_date.month == end_date.month:\n",
    "#                 text = \"//div[@class='drp-calendar right']//td[@class = 'available' or @class='weekend available' or @class='in-range available' or @class = 'weekend in-range available'][text() = \" + str(start_date.day) + \"]\"\n",
    "#             else :\n",
    "#                 text = \"//div[@class='drp-calendar left']//td[@class = 'available' or @class='weekend available' or @class='in-range available' or @class = 'weekend in-range available'][text() = \" + str(start_date.day) + \"]\"\n",
    "#             driver.find_element_by_xpath(text).click()\n",
    "#             text = \"//div[@class='drp-calendar right']//td[contains(@class, 'today')][text() = \" + str(end_date.day) + \"]\"\n",
    "#             driver.find_element_by_xpath(text).click()\n",
    "#             time.sleep(2)\n",
    "#             driver.find_element_by_class_name('applyBtn').click()\n",
    "#             driver.find_element_by_tag_name('body').send_keys(Keys.CONTROL + Keys.HOME)\n",
    "#             time.sleep(15)\n",
    "#             WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, 'export-button'))).click()\n",
    "#             driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "#             time.sleep(2)\n",
    "#             WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, 'group_by_'))).click()\n",
    "#             driver.find_element(By.NAME, 'button').click()\n",
    "#             time.sleep(5)\n",
    "#             driver.quit()\n",
    "# #             driver = webdriver.Chrome()\n",
    "# #             driver.get(\"https://www.forstok.com/dashboard/users/login\")\n",
    "# #             username = driver.find_element_by_id(\"dashboard_user_email\")\n",
    "# #             username.clear()\n",
    "# #             username.send_keys(\"andra.miftah@nutrifood.co.id\")\n",
    "\n",
    "# #             password = driver.find_element_by_id(\"dashboard_user_password\")\n",
    "# #             password.send_keys(\"nutrimart1234\")\n",
    "\n",
    "# #             driver.find_element_by_name(\"commit\").click()\n",
    "\n",
    "# #             datefield = WebDriverWait(driver, 300).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[2]/section/div')))\n",
    "# #             datefield.click()\n",
    "\n",
    "# #             driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "# #             if start_date.month != end_date.month:\n",
    "# #                 text = \"//*[normalize-space(text()) = '\" + str(start_date.strftime('%B')) + \"']\"\n",
    "# #                 driver.find_element_by_xpath(text).click()\n",
    "# #             text = \"//*[normalize-space(text()) = '\" + str(start_date.strftime('%B')) + \"']\" + \"/../..//*[normalize-space(text()) = '\" + str(start_date.day) + \"']\"\n",
    "# #             driver.find_element_by_xpath(text).click()\n",
    "# #             text = \"//*[normalize-space(text()) = '\" + str(end_date.strftime('%B')) + \"']/../..//td[not(contains(@class, 'otherMonth'))]//*[normalize-space(text()) = '\" + str(end_date.day) + \"']\"\n",
    "# #             driver.find_element_by_xpath(text).click()\n",
    "\n",
    "# #             driver.find_element_by_xpath('//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[2]/section/section/aside/div/button[2]').click()\n",
    "# #             driver.find_element_by_tag_name('body').send_keys(Keys.CONTROL + Keys.HOME)\n",
    "# #             time.sleep(15)\n",
    "# #             WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[3]/section/section[1]/button'))).click()\n",
    "# #             driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "# #             time.sleep(2)\n",
    "# #             driver.find_element(By.XPATH, '//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[3]/section/section[2]/section[1]/div/div[1]/label').click()\n",
    "# #             driver.find_element(By.XPATH, '//*[@id=\"root\"]/section/section[2]/article/section[4]/section/section[1]/section[3]/section/section[2]/section[2]/button').click()\n",
    "# #             time.sleep(15)\n",
    "# #             driver.quit()\n",
    "\n",
    "#             print('Forstok Downloaded')\n",
    "\n",
    "#             print('Download Data SKU')\n",
    "#             # Import library\n",
    "\n",
    "#             import time\n",
    "#             import pandas as pd\n",
    "#             import numpy as np\n",
    "#             import math\n",
    "\n",
    "#             import smtplib \n",
    "#             from email.mime.text import MIMEText\n",
    "#             from email.mime.application import MIMEApplication\n",
    "#             from email.mime.multipart import MIMEMultipart\n",
    "#             from smtplib import SMTP\n",
    "#             import smtplib\n",
    "#             import sys\n",
    "#             import requests\n",
    "#             import os\n",
    "\n",
    "#             print('Waiting to Download Forstok')\n",
    "#             s = requests.Session()\n",
    "#             r = s.get(\"https://www.forstok.com/dashboard/users/login\")\n",
    "#             data = {'dashboard_user_email' : 'andra.miftah@nutrifood.co.id', \"dashboard_user_password\" : 'nutrimart1234'}\n",
    "#             r = s.post(\"https://www.forstok.com/dashboard/users/login\", data = data)\n",
    "\n",
    "#             text = 'https://forstok-staging-storage.s3.ap-southeast-1.amazonaws.com/items_import/nutrifood--forstok-sales_orders-version_1-' + date + '.xls'\n",
    "#             print(text)\n",
    "#             while True:\n",
    "#                 r = s.get(text)\n",
    "#                 print('Waiting to Download Forstok')\n",
    "\n",
    "#                 if r.status_code == requests.codes.ok:\n",
    "#                     print(r.status_code)\n",
    "#                     with open('Input Data/Forstok_new_input.xls', 'wb') as output:\n",
    "#                         output.write(r.content)\n",
    "#                     break\n",
    "#                 else :\n",
    "#                     time.sleep(60)\n",
    "\n",
    "#             with open('Input Data/nutrifood--forstok-sales_orders-' + date + '.xls', 'wb') as output:\n",
    "#                 output.write(r.content)\n",
    "\n",
    "#             orstat_forstok = pd.read_excel(r'Input Data/Forstok_new_input.xls')\n",
    "#             orstat_forstok['Date'] = np.nan\n",
    "#             orstat_forstok['Month'] = np.nan\n",
    "#             orstat_forstok['Year'] = np.nan\n",
    "\n",
    "#             orstat_forstok['Order Date'] = pd.to_datetime(orstat_forstok['Order Date'])\n",
    "#             for i in range(orstat_forstok.shape[0]):\n",
    "#                 if int(orstat_forstok['Order Date'][i].strftime('%d')) <= 12:\n",
    "#                     orstat_forstok['Date'][i] = pd.to_datetime(orstat_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "#                     orstat_forstok['Month'][i] = pd.to_datetime(orstat_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "#                     orstat_forstok['Year'][i] = pd.to_datetime(orstat_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "#                 else :\n",
    "#                     orstat_forstok['Date'][i] = pd.to_datetime(orstat_forstok['Order Date'][i]).day\n",
    "#                     orstat_forstok['Month'][i] = pd.to_datetime(orstat_forstok['Order Date'][i]).month_name()\n",
    "#                     orstat_forstok['Year'][i] = pd.to_datetime(orstat_forstok['Order Date'][i]).year\n",
    "\n",
    "#             temp = orstat_forstok.copy()\n",
    "#             temp['Day'] = temp['Date']\n",
    "#             temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "#             temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "#             orstat_forstok['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "#             temp['Hour'] = pd.to_datetime(orstat_forstok['Order Date']).dt.hour\n",
    "#             temp['Minute'] = pd.to_datetime(orstat_forstok['Order Date']).dt.minute\n",
    "#             temp['Second'] = pd.to_datetime(orstat_forstok['Order Date']).dt.second\n",
    "#             orstat_forstok['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "            \n",
    "#             print(\"Update Order Status\")\n",
    "#             date_min  = orstat_forstok['True datetime'].min()\n",
    "#             orstat_forstok = orstat_forstok[['Sales Order ID','Status']].drop_duplicates('Sales Order ID')\n",
    "#             shopee_bp = data_all[data_all['Customer Name'] == 'Shopee Brand Portal']\n",
    "#             data_all = data_all[data_all['Customer Name'] != 'Shopee Brand Portal']\n",
    "#             temp_all = data_all[data_all['True datetime'] >= pd.to_datetime(date_min)][~data_all[data_all['True datetime'] >= pd.to_datetime(date_min)]['Channel'].isin(['Nutrimart', 'L-Men Store Blibli', 'Order Online', 'Order Online Jakarta', 'Order Online Surabaya'])]\n",
    "#             orstat_forstok['Sales Order ID'] = orstat_forstok['Sales Order ID'].astype(str)\n",
    "#             temp_all['Sales Order ID'] = temp_all['Sales Order ID'].astype(str)\n",
    "#             temp_all = temp_all.merge(orstat_forstok, how = 'left', on = 'Sales Order ID')\n",
    "#             temp_all['Status'] = temp_all['Status'].fillna('Canceled')\n",
    "#             temp_all['Order Status'] = temp_all['Status']\n",
    "#             temp_all = temp_all.drop('Status', axis = 1)\n",
    "#             data_all['Order #'] = data_all['Order #'].astype(str)\n",
    "#             temp_all['Order #'] = temp_all['Order #'].astype(str)\n",
    "#             data_all = data_all[~data_all['Order #'].isin(temp_all['Order #'])]\n",
    "#             data_all = data_all.append(temp_all, ignore_index = True, sort = False)\n",
    "#             data_all = data_all.append(shopee_bp, ignore_index = True, sort = False)\n",
    "#             print(\"Export Master Data\")\n",
    "            \n",
    "#             SKU = pd.read_excel(r'SKU_File/data_SKU.xlsx')\n",
    "#             SKU_baru = pd.read_excel(r'Subbrand Baru.xlsx')\n",
    "\n",
    "#             SKU_final = SKU.copy()\n",
    "#             SKU_baru['Item Group Code'] = SKU_baru['Item Group Code'].astype(str).str.replace('.0','', regex = False)\n",
    "#             SKU_final['SKU Clean'] = SKU_final['SKU'].astype(str).str.replace('(S)', '', regex = False).str.replace('(R)', '', regex = False).str.replace('(B)', '', regex = False).str.replace('(50%)', '', regex = False).str.replace('(E)', '', regex = False)\n",
    "#             SKU_final = SKU_final.merge(SKU_baru.drop_duplicates('Item Group Code'), how = 'left', left_on = 'SKU Clean', right_on = 'Item Group Code')\n",
    "\n",
    "#             no_pair = SKU[SKU['SKU'].astype(str).isin(SKU_final[SKU_final['Category Baru'].isnull()]['SKU'].astype(str))]\n",
    "#             SKU_final = SKU_final[~SKU_final['SKU'].astype(str).isin(no_pair['SKU'].astype(str))]\n",
    "\n",
    "#             no_pair['SKU Clean'] = no_pair['SKU'].astype(str).str.replace('(S)', '', regex = False).str.replace('(R)', '', regex = False).str.replace('(B)', '', regex = False).str.replace('(50%)', '', regex = False).str.replace('(E)', '', regex = False).str.replace('E', '', regex = False)\n",
    "#             SKU_baru['Item Group Code'] = SKU_baru['Product Code'].astype(str).str.replace('.0','', regex = False)\n",
    "\n",
    "#             index = no_pair[no_pair['SKU'].astype(str) == '1101984451'].index[0]\n",
    "#             no_pair['SKU Clean'][index] = '1101984453'\n",
    "\n",
    "#             index = no_pair[no_pair['SKU'].astype(str) == '2104393210'].index[0]\n",
    "#             no_pair['SKU Clean'][index] = '2104392210'\n",
    "\n",
    "#             no_pair = no_pair.merge(SKU_baru.drop_duplicates('Product Code'), how = 'left', left_on = 'SKU Clean', right_on = 'Product Code')\n",
    "\n",
    "#             SKU_final = SKU_final.append(no_pair, ignore_index = True, sort = False)\n",
    "\n",
    "#             index = SKU_final[SKU_final['SKU'].astype(str) == '1101569360'].index[0]\n",
    "#             SKU_final['Category Baru'][index] = 'NS MODERN'\n",
    "#             SKU_final['Unnamed: 3'][index] = \"NS JERUK PERAS REF 12DX500G\"\n",
    "\n",
    "#             index = SKU_final[SKU_final['SKU'].astype(str) == '1101686036'].index[0]\n",
    "#             SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "#             SKU_final['Unnamed: 3'][index] = \"W'DANK LKLT KOPI KAWISTA PLS 12RX10SX15G\"\n",
    "\n",
    "#             index = SKU_final[SKU_final['SKU'].astype(str) == '2104407'].index[0]\n",
    "#             SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "#             SKU_final['Unnamed: 3'][index] = 'TS EXTRA VIRGIN OLIVE OIL 12BTLX500ML'\n",
    "            \n",
    "#             index = SKU_final[SKU_final['SKU'].astype(str) == '2305551106'].index[0]\n",
    "#             SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "#             SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM CHOCO LATTE 6DX6SX33.5G'\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "#             SKU = SKU.merge(SKU_final[['SKU', 'Category Baru', 'Unnamed: 3']].drop_duplicates('SKU'), how = 'left', on = 'SKU')\n",
    "#             SKU = SKU.rename(columns = {'Unnamed: 3' : 'Exported Parent Item'})\n",
    "\n",
    "#             index = data_all[data_all['Real SKU'] == '2101492P24'].index.to_list()\n",
    "#             data_all['Brand'][index] = 'Bundle'\n",
    "#             index = data_all[data_all['SKU'].isin(['71210111', '71210112'])].index.to_list()\n",
    "#             data_all['Brand'][index] = 'Bundle'\n",
    "#             indeks = data_all[data_all['Brand'] == 'TS'][data_all[data_all['Brand'] == 'TS']['Real SKU'].astype(str) == '2101453180'].index.to_list()\n",
    "#             data_all['Real SKU'][indeks] = data_all['SKU'][indeks]\n",
    "#             data_all['Parent Item'][indeks] = 'Tropicana Slim Milk Low Fat Vanilla 500gr'\n",
    "#             index = data_all[data_all['Brand'] == \"W'dank\"].index.to_list()\n",
    "#             data_all['Brand'][index] = 'NS'\n",
    "\n",
    "#             data_all['Real SKU'] = data_all['Real SKU'].astype(str)\n",
    "#             data_all = data_all.drop(['Category Baru', 'Exported Parent Item'], axis = 1)\n",
    "#             data_all.rename(columns = {'SKU_x' : 'SKU'}, inplace = True)\n",
    "#             data_all = data_all.merge(SKU[['SKU', 'Category Baru', 'Exported Parent Item']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "\n",
    "#             data_SKU = SKU.copy()\n",
    "#             data_SKU['Category Baru'] = data_SKU['Category Baru'].fillna(data_SKU['Sub Brand'])\n",
    "#             data_SKU['Category Baru'] = data_SKU['Category Baru'].fillna(data_SKU['Brand'])\n",
    "#             data_SKU['Sub Brand'] = data_SKU['Category Baru']\n",
    "#             data_all['Sub Brand'] = data_all['Category Baru']\n",
    "#             data_all = data_all.drop('SKU_y', axis = 1)\n",
    "#             data_all.rename(columns = {'SKU_x' : 'SKU'}, inplace = True)\n",
    "\n",
    "#             data_SKU['List Brand'] = np.nan\n",
    "#             for i in range(len(data_SKU)):\n",
    "#                 list_brand = []\n",
    "#                 if data_SKU['Brand'][i] == 'Bundle':\n",
    "#                     col_SKU = [x for x in data_SKU.columns if 'SKU Produk' in x]\n",
    "#                     for j in col_SKU:\n",
    "#                         if str(data_SKU[j][i]) != 'nan' and str(data_SKU[j][i]) != '0':\n",
    "#                             subbrand = data_SKU[data_SKU['SKU'].astype(str) == str(data_SKU[j][i]).replace('(S)', '').replace('.0', '')]['Sub Brand'].values[0]\n",
    "#                             brand = data_SKU[data_SKU['SKU'].astype(str) == str(data_SKU[j][i]).replace('(S)', '').replace('.0', '')]['Brand'].values[0]\n",
    "#                             if brand == 'Gimmick' : \n",
    "#                                 if str(data_SKU['Nama Produk'][i]).lower() != 'nan' :\n",
    "#                                     if 'voucher' in data_SKU['Nama Produk'][i].lower() or 'saldo' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                         brand = 'Voucher'\n",
    "#                                     elif 'pouch' in data_SKU['Nama Produk'][i].lower() or 'bag ' in data_SKU['Nama Produk'][i].lower() or 'tas ' in data_SKU['Nama Produk'][i].lower() or 'totebag' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                         brand = 'Bag'\n",
    "#                                     elif 'bottle' in data_SKU['Nama Produk'][i].lower() or 'gelas ' in data_SKU['Nama Produk'][i].lower() or 'shaker' in data_SKU['Nama Produk'][i].lower() or 'tumblr' in data_SKU['Nama Produk'][i].lower() or 'tumbler' in data_SKU['Nama Produk'][i].lower() or 'botol' in data_SKU['Nama Produk'][i].lower() or 'thumbler' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                         brand = 'Tumblr'\n",
    "#                                     elif 'lunch' in data_SKU['Nama Produk'][i].lower() or 'tupper' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                         brand = 'Lunch Box'\n",
    "#                                     elif 'emoney' in data_SKU['Nama Produk'][i].lower() or 'e-money' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                         brand = 'E-Money'\n",
    "#                                     elif 'magnet' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                         brand = 'Magnet'\n",
    "#                                     elif 'masker' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                         brand = 'Masker'\n",
    "#                                     elif 'spatula' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                         brand = 'Spatula'\n",
    "#                                     elif 'nivea' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                         brand = 'Nivea'\n",
    "#                                     elif 'card ' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                         brand = 'Card'\n",
    "#                                     elif 'mug' in data_SKU['Nama Produk'][i].lower():\n",
    "#                                         brand = 'Mug'\n",
    "#                                     list_brand.append(brand)\n",
    "#                                     data_SKU['Sub Brand'][i] = brand\n",
    "#                                 else :\n",
    "#                                     list_brand.append(subbrand)\n",
    "#                 data_SKU['List Brand'][i] = str(list_brand)\n",
    "\n",
    "#             for i in range(len(data_SKU)):\n",
    "#                 if data_SKU['Brand'][i] == 'Bundle':\n",
    "#                     list_brand = list(dict.fromkeys(data_SKU['List Brand'][i]))\n",
    "#             #         sum_brand = sum([1 for x in list_brand if x in ['NS', 'TS', 'HiLo', 'L-Men', \"W'dank\"]])\n",
    "#             #         if sum_brand == 1:\n",
    "#                     list_brand = ' + '.join(list_brand)\n",
    "#             #         else :\n",
    "#             #             not_brand = [x for x in list_brand if x not in ['NS', 'TS', 'HiLo', 'L-Men', \"W'dank\"]]\n",
    "#             #             if len(not_brand) == 0:\n",
    "#             #                 list_brand = 'Cross Brand'\n",
    "#             #             else :\n",
    "#             #                 list_brand = 'Cross Brand + ' + ' + '.join(not_brand)\n",
    "#                     data_SKU['Sub Brand'][i] = list_brand\n",
    "\n",
    "\n",
    "#             temp = data_all.copy()\n",
    "#             temp['Real SKU'] = temp['Real SKU'].astype(str).str.replace('(S)','',regex = False).str.replace('.0','',regex = False)\n",
    "#             data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('(S)','',regex = False).str.replace('.0','',regex = False)\n",
    "#             data_all['Sub Brand'][temp.index] = temp.merge(data_SKU[['SKU', 'Sub Brand']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(temp.index)['Sub Brand_y']\n",
    "#             data_all.to_csv(r'Clean Data/data_all_' + data_now + '.csv', sep = ';', index = False)\n",
    "#             print(\"Clean Data Finish\")\n",
    "#             data_all[['Order #','Order Status','Date', 'Month','Year',\n",
    "#              'Hour',\n",
    "#              'Channel', 'Store',\n",
    "#              'SKU',\n",
    "#              'Brand',\n",
    "#              'Product Name',\n",
    "#              'Bundle Name',\n",
    "#              'Price List NFI',\n",
    "#              'Qty. Invoiced',\n",
    "#              'Total Net',\n",
    "#              'Sub Brand',\n",
    "#              'Real SKU',\n",
    "#              'Real Nama Produk',\n",
    "#              'Parent Item',\n",
    "#              'Parent SKU',\n",
    "#              'Bundle Flag',\n",
    "#              'Customer Email',\n",
    "#              'Customer Name',\n",
    "#              'Customer Group',\n",
    "#              'Phone',\n",
    "#              'Country',\n",
    "#              'Region',\n",
    "#              'City',\n",
    "#              'Kecamatan',\n",
    "#              'Kelurahan',\n",
    "#              'Address',\n",
    "#              'Zip Code','Shipping Courier',\n",
    "#              'Total',\n",
    "#              'Coupon Code','Subtotal',\n",
    "#              'Discounts','Cart Name Rule','Voucher Amount','Warehouse Name',\n",
    "#              'Regular Price',\n",
    "#              'Selling Price','Shipping',\n",
    "#              'Actual Shipping',\n",
    "#              'Seller Discount','True datetime',\n",
    "#              'Promo',\n",
    "#              'Discount MC',\n",
    "#              'Harga Cost',\n",
    "#              'Total Harga Cost','nominal',\n",
    "#              'btlcost',\n",
    "#              'gs',\n",
    "#              'commfee',\n",
    "#              'fullfee','Shipping Province',\n",
    "#              'Shipping City',\n",
    "#              'Shipping Address1',\n",
    "#              'Shipping Phone']].to_csv(r'Export Data/data_all_' + data_now + '.csv', sep = ';', index = False)\n",
    "#             print(\"Export Data Finish\")\n",
    "           \n",
    "#             data_all[data_all['Year'] == 2020][['Order #','Order Status','Date', 'Month','Year',\n",
    "#                  'Hour',\n",
    "#                  'Channel', 'Store',\n",
    "#                  'SKU',\n",
    "#                  'Brand',\n",
    "#                  'Product Name',\n",
    "#                  'Bundle Name',\n",
    "#                  'Price List NFI',\n",
    "#                  'Qty. Invoiced',\n",
    "#                  'Total Net',\n",
    "#                  'Sub Brand',\n",
    "#                  'Real SKU',\n",
    "#                  'Real Nama Produk',\n",
    "#                  'Parent Item',\n",
    "#                  'Parent SKU',\n",
    "#                  'Bundle Flag',\n",
    "#                  'Customer Email',\n",
    "#                  'Customer Name',\n",
    "#                  'Customer Group',\n",
    "#                  'Phone',\n",
    "#                  'Country',\n",
    "#                  'Region',\n",
    "#                  'City',\n",
    "#                  'Kecamatan',\n",
    "#                  'Kelurahan',\n",
    "#                  'Address',\n",
    "#                  'Zip Code','Shipping Courier',\n",
    "#                  'Total',\n",
    "#                  'Coupon Code','Subtotal',\n",
    "#                  'Discounts','Cart Name Rule','Voucher Amount','Warehouse Name',\n",
    "#                  'Regular Price',\n",
    "#                  'Selling Price','Shipping',\n",
    "#                  'Actual Shipping',\n",
    "#                  'Seller Discount','True datetime',\n",
    "#                  'Promo',\n",
    "#                  'Discount MC',\n",
    "#                  'Harga Cost',\n",
    "#                  'Total Harga Cost','nominal',\n",
    "#                  'btlcost',\n",
    "#                  'gs',\n",
    "#                  'commfee',\n",
    "#                  'fullfee','Shipping Province',\n",
    "#                  'Shipping City',\n",
    "#                  'Shipping Address1',\n",
    "#                  'Shipping Phone']].to_csv(r'Export Data/data_all_2020_' + data_now + '.csv', sep = ';', index = False)\n",
    "#             print(\"Export Data 2020 Finish\")\n",
    "            \n",
    "#             data_success = data_all[~data_all['Order Status'].isin(['\"Cancelled, Open\"', '\"Cancelled, Delivered\"', '\"Cancelled\"','\"Delivered, Cancelled\"','\"Cancelled, Delivered, Open\"','\"Cancelled, Delivered, Ready to Ship\"',\n",
    "#                                                     '\"Shipped, Cancelled\"','Order Batal', 'Pengiriman Gagal','canceled','\"Cancelled, Shipped\"','\"Cancelled, Ready to Ship\"', '\"Ready to Ship, Cancelled\"',\n",
    "#                                                     '\"Printed, Cancelled\"','\"Printed, Delivered, Cancelled\"','\"Shipped, Cancelled, Open\"','gosend_rejected','Canceled', 'CANCEL', 'CANCEL-REORDER'])]\n",
    "#             all_single = data_success[data_success['Brand'].isin(['NS', 'TS', 'L-Men', 'HiLo'])]\n",
    "\n",
    "#             print(\"Prepare E-mailing\")\n",
    "#             table_brand = all_single[['Brand', 'Sub Brand']].drop_duplicates().reset_index(drop = True)\n",
    "#             all_single['True datetime'] = pd.to_datetime(all_single['True datetime'])\n",
    "#             from datetime import datetime, timedelta\n",
    "\n",
    "#             today = datetime.today()\n",
    "#             yesterday = datetime.today() - timedelta(days=1)\n",
    "\n",
    "#             today = pd.to_datetime(today.strftime('%Y-%m-%d'))\n",
    "#             yesterday = pd.to_datetime(yesterday.strftime('%Y-%m-%d'))\n",
    "\n",
    "#             yesterday_sales = all_single[all_single['True datetime'] >= yesterday][all_single[all_single['True datetime'] >= yesterday]['True datetime']<today]\n",
    "#             yesterday_sales = yesterday_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "#             yesterday_sales = yesterday_sales.rename(columns = {'Total Net' : 'Yesterday Sales'})\n",
    "#             table_brand = table_brand.merge(yesterday_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "#             mtd_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)\n",
    "#             mtd_date = pd.to_datetime(mtd_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "#             mtd_sales = all_single[all_single['True datetime'] >= mtd_date][all_single[all_single['True datetime'] >= mtd_date]['True datetime']<today]\n",
    "#             mtd_sales = mtd_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "#             mtd_sales = mtd_sales.rename(columns = {'Total Net' : 'Local Sales'})\n",
    "#             table_brand = table_brand.merge(mtd_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "#             table_brand['Average This Month'] = table_brand['Local Sales']/(int(today.strftime('%d'))-1)\n",
    "\n",
    "#             from calendar import monthrange\n",
    "#             number_of_days = monthrange(today.year, today.month)[1]\n",
    "\n",
    "#             table_brand['Projected'] = table_brand['Average This Month'] * number_of_days\n",
    "\n",
    "#             from dateutil import rrule\n",
    "#             from dateutil.relativedelta import relativedelta\n",
    "\n",
    "#             start_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)-relativedelta(months=3)\n",
    "#             start_date = pd.to_datetime(start_date.strftime('%Y-%m-%d'))\n",
    "#             end_date = datetime.today()-timedelta(days=int(today.strftime('%d')))\n",
    "#             for dt in rrule.rrule(rrule.MONTHLY, dtstart=start_date, until=end_date):\n",
    "#                 first_date = pd.to_datetime(dt)\n",
    "#                 print(\"First Date \" + str(first_date))\n",
    "#                 last_date = first_date + relativedelta(months=1)\n",
    "#                 print(\"Last Date \" + str(last_date))\n",
    "#                 temp_sales = all_single[all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n",
    "#                 temp_sales = temp_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "#                 colname = str(first_date.month_name()) + ' ' + str(first_date.year)\n",
    "#                 temp_sales = temp_sales.rename(columns = {'Total Net' : colname})\n",
    "#                 table_brand = table_brand.merge(temp_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "#             table_brand = table_brand.reset_index(drop = True)\n",
    "#             table_brand = table_brand.drop('Average This Month', axis = 1)\n",
    "\n",
    "#             def highlight_max(x):\n",
    "#                 return ['font-weight: bold' if v == x.loc[x.index.max()] else ''\n",
    "#                             for v in x]\n",
    "\n",
    "#             table_brand = table_brand[table_brand['Local Sales'].notnull()]\n",
    "#             table_brand['Yesterday Sales'] = table_brand['Yesterday Sales'].astype(int)\n",
    "#             table_brand['Local Sales'] = table_brand['Local Sales'].astype(int)\n",
    "#             table_brand = table_brand.sort_values(['Brand','Local Sales'], ascending = [True, False])\n",
    "#             table_ecom = table_brand.copy()\n",
    "\n",
    "#             for i in table_ecom.columns[2:]:\n",
    "#                 table_ecom[i] = table_ecom[i].astype(int)\n",
    "\n",
    "#             table_ecom = table_ecom.append(table_ecom.sum(numeric_only=True), ignore_index=True)\n",
    "#             for i in table_ecom.columns[2:]:\n",
    "#                 table_ecom[i] = table_ecom[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "#                 table_ecom[i][table_ecom.index.max()] = \"<b> {} </b>\".format(table_ecom[i][table_ecom.index.max()])\n",
    "\n",
    "#             table_ecom = table_ecom.drop('Brand', axis = 1)\n",
    "#             table_ecom['Sub Brand'][table_ecom.index.max()] = '<b>Total E-Commerce Sales<b>'\n",
    "#             table_ecom = table_ecom.rename(columns = {'Sub Brand' : ''})\n",
    "\n",
    "#             table_ecom = table_ecom.iloc[[-1]].reset_index(drop = True)\n",
    "\n",
    "#             for i in table_brand.columns[2:]:\n",
    "#                 table_brand[i] = table_brand[i].astype(int)\n",
    "\n",
    "#             table_brand_hilo = table_brand[table_brand['Brand'] == 'HiLo'].reset_index(drop = True)\n",
    "#             table_brand_hilo = table_brand_hilo.append(table_brand_hilo.sum(numeric_only=True), ignore_index=True)\n",
    "#             table_brand_hilo['Sub Brand'][table_brand_hilo.index.max()] = '<b>TOTAL<b>'\n",
    "#             table_brand_hilo['Brand'][table_brand_hilo.index.max()] = ''\n",
    "\n",
    "\n",
    "#             table_brand_ns= table_brand[table_brand['Brand'] == 'NS'].reset_index(drop = True)\n",
    "#             table_brand_ns = table_brand_ns.append(table_brand_ns.sum(numeric_only=True), ignore_index=True)\n",
    "#             table_brand_ns['Sub Brand'][table_brand_ns.index.max()] = '<b>TOTAL<b>'\n",
    "#             table_brand_ns['Brand'][table_brand_ns.index.max()] = ''\n",
    "\n",
    "\n",
    "#             table_brand_lmen = table_brand[table_brand['Brand'] == 'L-Men'].reset_index(drop = True)\n",
    "#             table_brand_lmen = table_brand_lmen.append(table_brand_lmen.sum(numeric_only=True), ignore_index=True)\n",
    "#             table_brand_lmen['Sub Brand'][table_brand_lmen.index.max()] = '<b>TOTAL<b>'\n",
    "#             table_brand_lmen['Brand'][table_brand_lmen.index.max()] = ''\n",
    "\n",
    "\n",
    "#             table_brand_ts = table_brand[table_brand['Brand'] == 'TS'].reset_index(drop = True)\n",
    "#             table_brand_ts = table_brand_ts.append(table_brand_ts.sum(numeric_only=True), ignore_index=True)\n",
    "#             table_brand_ts['Sub Brand'][table_brand_ts.index.max()] = '<b>TOTAL<b>'\n",
    "#             table_brand_ts['Brand'][table_brand_ts.index.max()] = ''\n",
    "\n",
    "\n",
    "#             for i in table_brand_hilo.columns[2:]:\n",
    "#                 table_brand_hilo[i] = table_brand_hilo[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "#                 table_brand_hilo[i][table_brand_hilo.index.max()] = \"<b> {} </b>\".format(table_brand_hilo[i][table_brand_hilo.index.max()])\n",
    "\n",
    "#             for i in table_brand_lmen.columns[2:]:\n",
    "#                 table_brand_lmen[i] = table_brand_lmen[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "#                 table_brand_lmen[i][table_brand_lmen.index.max()] = \"<b> {} </b>\".format(table_brand_lmen[i][table_brand_lmen.index.max()])\n",
    "\n",
    "#             for i in table_brand_ns.columns[2:]:\n",
    "#                 table_brand_ns[i] = table_brand_ns[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "#                 table_brand_ns[i][table_brand_ns.index.max()] = \"<b> {} </b>\".format(table_brand_ns[i][table_brand_ns.index.max()])\n",
    "\n",
    "#             for i in table_brand_ts.columns[2:]:\n",
    "#                 table_brand_ts[i] = table_brand_ts[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "#                 table_brand_ts[i][table_brand_ts.index.max()] = \"<b> {} </b>\".format(table_brand_ts[i][table_brand_ts.index.max()])\n",
    "\n",
    "#             table_brand = table_brand_hilo.append(pd.Series(), ignore_index = True, sort = False)\n",
    "#             table_brand = table_brand.append(table_brand_lmen, ignore_index = True, sort = False)\n",
    "#             table_brand = table_brand.append(pd.Series(), ignore_index = True, sort = False)\n",
    "#             table_brand = table_brand.append(table_brand_ns, ignore_index = True, sort = False)\n",
    "#             table_brand = table_brand.append(pd.Series(), ignore_index = True, sort = False)\n",
    "#             table_brand = table_brand.append(table_brand_ts, ignore_index = True, sort = False)\n",
    "#             for i in table_brand.columns:\n",
    "#                 table_brand[i] = table_brand[i].fillna('')\n",
    "\n",
    "#             # table_brand_hilo.style.apply(highlight_max)\n",
    "#             # table_brand_ns.style.apply(highlight_max)\n",
    "#             # table_brand_lmen.style.apply(highlight_max)\n",
    "#             # table_brand_ts.style.apply(highlight_max)\n",
    "\n",
    "#             table_item = all_single[['Brand', 'Sub Brand', 'Exported Parent Item']].drop_duplicates().reset_index(drop = True)\n",
    "#             all_single['True datetime'] = pd.to_datetime(all_single['True datetime'])\n",
    "#             from datetime import datetime, timedelta\n",
    "\n",
    "#             today = datetime.today()\n",
    "#             yesterday = datetime.today() - timedelta(days=1)\n",
    "\n",
    "#             today = pd.to_datetime(today.strftime('%Y-%m-%d'))\n",
    "#             yesterday = pd.to_datetime(yesterday.strftime('%Y-%m-%d'))\n",
    "\n",
    "#             yesterday_sales = all_single[all_single['True datetime'] >= yesterday][all_single[all_single['True datetime'] >= yesterday]['True datetime']<today]\n",
    "#             yesterday_sales = yesterday_sales.groupby(['Brand', 'Sub Brand', 'Exported Parent Item'])['Total Net'].sum().reset_index()\n",
    "#             yesterday_sales = yesterday_sales.rename(columns = {'Total Net' : 'Yesterday Sales'})\n",
    "#             table_item = table_item.merge(yesterday_sales, how = 'left', on = ['Brand', 'Sub Brand', 'Exported Parent Item'])\n",
    "\n",
    "#             mtd_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)\n",
    "#             mtd_date = pd.to_datetime(mtd_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "#             mtd_sales = all_single[all_single['True datetime'] >= mtd_date][all_single[all_single['True datetime'] >= mtd_date]['True datetime']<today]\n",
    "#             mtd_sales = mtd_sales.groupby(['Brand', 'Sub Brand', 'Exported Parent Item'])['Total Net'].sum().reset_index()\n",
    "#             mtd_sales = mtd_sales.rename(columns = {'Total Net' : 'Local Sales'})\n",
    "#             table_item = table_item.merge(mtd_sales, how = 'left', on = ['Brand', 'Sub Brand', 'Exported Parent Item'])\n",
    "\n",
    "#             table_item['Average This Month'] = table_item['Local Sales']/(int(today.strftime('%d'))-1)\n",
    "\n",
    "#             from calendar import monthrange\n",
    "#             number_of_days = monthrange(today.year, today.month)[1]\n",
    "\n",
    "#             table_item['Projected'] = table_item['Average This Month'] * number_of_days\n",
    "\n",
    "#             from dateutil import rrule\n",
    "#             from dateutil.relativedelta import relativedelta\n",
    "\n",
    "#             start_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)-relativedelta(months=3)\n",
    "#             start_date = pd.to_datetime(start_date.strftime('%Y-%m-%d'))\n",
    "#             end_date = datetime.today()-timedelta(days=int(today.strftime('%d')))\n",
    "#             for dt in rrule.rrule(rrule.MONTHLY, dtstart=start_date, until=end_date):\n",
    "#                 first_date = pd.to_datetime(dt)\n",
    "#                 last_date = first_date + relativedelta(months=1)\n",
    "#                 temp_sales = all_single[all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n",
    "#                 temp_sales = temp_sales.groupby(['Brand', 'Sub Brand', 'Exported Parent Item'])['Total Net'].sum().reset_index()\n",
    "#                 colname = str(first_date.month_name()) + ' ' + str(first_date.year)\n",
    "#                 temp_sales = temp_sales.rename(columns = {'Total Net' : colname})\n",
    "#                 table_item = table_item.merge(temp_sales, how = 'left', on = ['Brand', 'Sub Brand', 'Exported Parent Item'])\n",
    "\n",
    "#             table_item = table_item[table_item['Local Sales'].notnull()]\n",
    "#             table_item['Yesterday Sales'] = pd.to_numeric(table_item['Yesterday Sales'], errors = 'coerce').fillna(0).astype(int)\n",
    "#             table_item['Local Sales'] = pd.to_numeric(table_item['Local Sales'], errors = 'coerce').fillna(0).astype(int)\n",
    "#             table_item = table_item.sort_values(['Brand','Local Sales'], ascending = [True, False])\n",
    "\n",
    "#             for i in table_item.columns[3:]:\n",
    "#                 table_item[i] = table_item[i].fillna(0).apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "\n",
    "#             table_item = table_item.reset_index(drop = True)\n",
    "#             table_item = table_item.drop('Average This Month', axis = 1)\n",
    "\n",
    "#             table_hilo = table_item[table_item['Brand'] == 'HiLo'].reset_index(drop = True)\n",
    "#             table_ns= table_item[table_item['Brand'] == 'NS'].reset_index(drop = True)\n",
    "#             table_lmen = table_item[table_item['Brand'] == 'L-Men'].reset_index(drop = True)\n",
    "#             table_ts = table_item[table_item['Brand'] == 'TS'].reset_index(drop = True)\n",
    "\n",
    "#             print(\"Prepare Emailing\")\n",
    "#             s = smtplib.SMTP('smtp.gmail.com', 587) \n",
    "\n",
    "#             # start TLS for security \n",
    "#             s.starttls() \n",
    "\n",
    "#             # Authentication \n",
    "#             s.login(\"automationnfi@gmail.com\", \"nutrifood2020\") \n",
    "\n",
    "#             me = \"automationnfi@gmail.com\"\n",
    "#             to = \"andra.miftah@nutrifood.co.id\"\n",
    "\n",
    "#             # text = \"\"\"\n",
    "#             # Dear all,\n",
    "\n",
    "#             # Berikut data jualan E-Com tanggal {tanggal} per Brand :\n",
    "#             # {table_brand}\n",
    "\n",
    "#             # Dan Berikut data jualan E-Com tanggal {tanggal} per Item :\n",
    "\n",
    "#             # {table_hilo}\n",
    "\n",
    "#             # {table_ns}\n",
    "\n",
    "#             # {table_lmen}\n",
    "\n",
    "#             # {table_ts}\n",
    "\n",
    "#             # Best regards,\n",
    "\n",
    "#             # Andra Miftah Ar Rahman\n",
    "#             # E-Commerce Executive\n",
    "#             # \"\"\"\n",
    "\n",
    "#             print(\"Prepare Emailing\")\n",
    "#             s = smtplib.SMTP('smtp.gmail.com', 587) \n",
    "\n",
    "#             # start TLS for security \n",
    "#             s.starttls() \n",
    "\n",
    "#             # Authentication \n",
    "#             s.login(\"automationnfi@gmail.com\", \"nutrifood2020\") \n",
    "\n",
    "#             me = \"automationnfi@gmail.com\"\n",
    "#             to = \"andra.miftah@nutrifood.co.id\"\n",
    "\n",
    "#             html = '''\n",
    "#             <html>\n",
    "#             <head>\n",
    "#             <style>\n",
    "\n",
    "#                 h2 {\n",
    "#                     text-align: center;\n",
    "#                     font-family: Helvetica, Arial, sans-serif;\n",
    "#                 }\n",
    "#                 table { \n",
    "#                     margin-left: auto;\n",
    "#                     margin-right: auto;\n",
    "#                 }\n",
    "#                 table, th, td {\n",
    "#                     border: 1px solid black;\n",
    "#                     border-collapse: collapse;\n",
    "#                 }\n",
    "#                 th, td {\n",
    "#                     padding: 5px;\n",
    "#                     text-align: center;\n",
    "#                     font-family: Helvetica, Arial, sans-serif;\n",
    "#                     font-size: 90%;\n",
    "#                 }\n",
    "#                 table tbody tr:hover {\n",
    "#                     background-color: #dddddd;\n",
    "#                 }\n",
    "#                 .wide {\n",
    "#                     width: 90%; \n",
    "#                 }\n",
    "\n",
    "#             </style>\n",
    "#             </head>\n",
    "#             <body>\n",
    "#                 '''\n",
    "#             html = html + \"\"\"\n",
    "#                 <p> Dear all, </p>\n",
    "#                 <p> Berikut data penjualan E-Com (After PPN) tanggal <b> {tanggal} </b> : </p>\n",
    "#             \"\"\".format(tanggal = str(datetime.today().date().strftime('%B %d, %Y')))\n",
    "\n",
    "#             html = html + table_ecom.to_html(classes='wide', escape=False).replace('&lt;b&gt;', '<b>').replace('&lt;/b&gt;', '</b>')\n",
    "\n",
    "#             html = html + \"\"\"\n",
    "#                 <p> Dan Berikut data penjualan E-Com (After PPN) tanggal <b> {tanggal} </b> per Brand :</p>\n",
    "#             \"\"\".format(tanggal = str(datetime.today().date().strftime('%B %d, %Y'))) \n",
    "\n",
    "#             html = html + table_brand.to_html(classes='wide', escape=False).replace('&lt;b&gt;', '<b>').replace('&lt;/b&gt;', '</b>')\n",
    "\n",
    "#             html = html + \"\"\"\n",
    "#                 <p> Dan berikut data penjualan E-Com (After PPN) per Item :</p>\n",
    "#                 <p> HiLo : </p>\"\"\"\n",
    "\n",
    "#             html = html + table_hilo.to_html(classes='wide', escape=False)\n",
    "\n",
    "#             html = html + \"<p> L-Men : </p>\"    \n",
    "\n",
    "#             html = html + table_lmen.to_html(classes='wide', escape=False)\n",
    "\n",
    "#             html = html + \"<p> NutriSari : </p>\"    \n",
    "\n",
    "#             html = html + table_ns.to_html(classes='wide', escape=False)\n",
    "\n",
    "#             html = html + \"<p> Tropicana Slim : </p>\"    \n",
    "\n",
    "#             html = html + table_ts.to_html(classes='wide', escape=False)\n",
    "\n",
    "#             html = html + \"\"\"\n",
    "#                 <p></p>\n",
    "#                 <p> Best regards, </p>\n",
    "#                 <p> Andra Miftah Ar Rahman </p>\n",
    "#                 <p> E-Commerce Executive </p>\n",
    "#             <body>\n",
    "#             </html>\n",
    "#             \"\"\"\n",
    "\n",
    "#             # text = text.format(tanggal = str(datetime.today().date()), table_brand = table_brand.to_html(), table_hilo = table_hilo.to_html(), table_ns = table_ns.to_html(), table_lmen = table_lmen.to_html(), table_ts = table_ts.to_html())\n",
    "\n",
    "#             msg = MIMEMultipart(\"alternative\", None, [MIMEText(html, 'html')])\n",
    "#             msg['Subject'] = \"Testing Report Ecom \" + str(datetime.today().date().strftime('%B %d, %Y'))\n",
    "\n",
    "#             # part1 = MIMEText(text)\n",
    "#             # msg.attach(part1)\n",
    "\n",
    "#             # sending the mail \n",
    "#             s.sendmail(\"automationnfi@gmail.com\", \"andra.miftah@nutrifood.co.id\", msg.as_string()) \n",
    "\n",
    "#             # terminating the session \n",
    "#             s.quit() \n",
    "#             print(\"E-mailing Finish\")\n",
    "#             # import pandas as pd\n",
    "#             # import numpy as np\n",
    "#             # import pypyodbc\n",
    "\n",
    "#             # conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#             #                 'Server=BAF-DB-01;'\n",
    "#             #                 'Database=e-commerce;'\n",
    "#             #                 )\n",
    "\n",
    "#             # cursor = conn.cursor()\n",
    "#             # ortrans = pd.read_sql(r'Select * from [Order Transaction]', conn)\n",
    "#             # orders = pd.read_sql(r'Select * from \"Order\"', conn)\n",
    "#             # or_ortrans = ortrans.merge(orders, how = 'left', left_on = 'order id', right_on = 'id')\n",
    "\n",
    "#             # print(\"Read Data All\")\n",
    "#             # # data_all = pd.read_csv(r'Clean Data/data_all_17 Juni.csv', sep = ';',converters = {'Phone' : str, 'Order #' : str, 'AWB' : str})\n",
    "#             # data_all['Brand'] = data_all['Brand'].astype(str).str.replace('Tropicana Slim', 'TS')\n",
    "#             # data_all['Phone'] = data_all['Phone'].astype(str).str.replace('=\"', '', regex = False)\n",
    "#             # data_all['Phone'] = data_all['Phone'].astype(str).str.replace('\"', '', regex = False)\n",
    "\n",
    "\n",
    "#             # # product = pd.read_sql(r'Select * from Product', conn)\n",
    "#             # # or_ortrans = or_ortrans.merge(product, how = 'left', left_on = 'product id', right_on = 'id')\n",
    "#             # # or_april = or_ortrans[or_ortrans['year'] == 2020][or_ortrans[or_ortrans['year'] == 2020]['month'] == 'May'].copy()\n",
    "#             # # list_id = or_april['id_x'].to_list()\n",
    "#             # # for i in list_id:\n",
    "#             # #     print(i)\n",
    "#             # #     cursor.execute('Delete from [Order Transaction] Where id = ?', [i])\n",
    "#             # #     conn.commit()\n",
    "\n",
    "#             # temp = data_all[data_all['Month'] == 'February'][data_all[data_all['Month'] == 'February']['Year'] == 2020].copy()\n",
    "#             # or_april = or_ortrans[or_ortrans['order #'].astype(str).isin(temp['Order #'].astype(str))]\n",
    "#             # list_id = or_april['id_x'].to_list()\n",
    "\n",
    "#             # print('Delete from Order Transaction')\n",
    "#             # for i in list_id:\n",
    "#             # #     print(i)\n",
    "#             #     cursor.execute('Delete from [Order Transaction] Where id = ?', [i])\n",
    "#             #     conn.commit()\n",
    "\n",
    "#             # print('Delete from Order')\n",
    "#             # list_id = or_april['order id'].to_list()\n",
    "#             # for i in list_id:\n",
    "#             # #     print(i)\n",
    "#             #     cursor.execute('Delete from [Order] Where id = ?', [i])\n",
    "#             #     conn.commit()\n",
    "\n",
    "#             # print('Delete Finish')\n",
    "\n",
    "#             # list_id = or_april['id'].to_list()\n",
    "#             # conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#             #                 'Server=BAF-DB-01;'\n",
    "#             #                 'Database=e-commerce;'\n",
    "#             #                 )\n",
    "\n",
    "#             # cursor = conn.cursor()\n",
    "#             # print('Delete from Order Transaction')\n",
    "#             # for i in list_id:\n",
    "#             # #     print(i)\n",
    "#             #     cursor.execute('Delete from [Order Transaction] Where  [order id]= ?', [i])\n",
    "#             #     conn.commit()\n",
    "\n",
    "#             # print('Delete from Order')\n",
    "#             # for i in list_id:\n",
    "#             # #     print(i)\n",
    "#             #     cursor.execute('Delete from [Order] Where id = ?', [i])\n",
    "#             #     conn.commit()\n",
    "\n",
    "#             # print('Delete Finish')\n",
    "                \n",
    "#             import requests\n",
    "#             import time\n",
    "\n",
    "#             import pandas as pd\n",
    "#             import numpy as np\n",
    "#             import datetime\n",
    "#             import math\n",
    "\n",
    "#             import smtplib \n",
    "#             from email.mime.text import MIMEText\n",
    "#             from email.mime.application import MIMEApplication\n",
    "#             from email.mime.multipart import MIMEMultipart\n",
    "#             from smtplib import SMTP\n",
    "#             import smtplib\n",
    "#             import sys\n",
    "#             import os\n",
    "\n",
    "#             data_SKU = pd.read_excel(r'SKU_File/data_SKU.xlsx')\n",
    "\n",
    "#             s = requests.Session()\n",
    "#             s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "#             s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "#             r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "#             with open('SKU_File/Master tatanama.xlsx', 'wb') as output:\n",
    "#                 output.write(r.content)\n",
    "\n",
    "#             if os.path.isfile('SKU_File/Master tatanama.xlsx') :    \n",
    "#                 SKU_append = pd.read_excel(r'SKU_File/Master tatanama.xlsx')\n",
    "#                 SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "#                 data_SKU = data_SKU[~data_SKU['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "#                 data_SKU = data_SKU.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "#             to_excel = data_SKU.to_excel(r'SKU_File/data_SKU.xlsx', index = False)\n",
    "\n",
    "#             print(\"Start insert to Database\")\n",
    "#             import pypyodbc\n",
    "\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "#             orders = pd.read_sql('select * from \"Order\"', conn)\n",
    "#             ortrans = pd.read_sql(r'Select * From [Order Transaction]', conn)\n",
    "#             or_ortrans = ortrans.merge(orders, how = 'left', left_on = 'order id', right_on = 'id')\n",
    "#             or_ortrans['order #'] = orders['order #'].astype(str)\n",
    "#             data_all['Order #'] = data_all['Order #'].astype(str)\n",
    "\n",
    "#             data_insert = data_all[~data_all['Order #'].astype(str).isin(or_ortrans['order #'].astype(str))]\n",
    "#             cust = pd.read_sql('Select * From Customers', conn)\n",
    "#             indeks = data_insert[~data_insert['Phone'].astype(str).isin(cust['phone'].astype(str))].drop_duplicates('Phone')['Phone'].index.to_list()\n",
    "#             lmen_phone = data_insert[data_insert['Phone'].isnull()].copy()\n",
    "#             indeks = indeks + lmen_phone[lmen_phone['Customer Name'].isin(cust['customer name'])].drop_duplicates('Customer Name').index.to_list()\n",
    "#             customers = data_insert[['Phone', 'Customer Email', 'Customer Name', 'Customer Group', 'Zip Code', 'Address', 'Shipping Address2', 'Country', 'Region', 'City', 'Kecamatan']].loc[indeks]\n",
    "\n",
    "#             customers['Zip Code'] = pd.to_numeric(customers['Zip Code'], errors = 'coerce').fillna(0)\n",
    "\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "#             print(\"Customer Database\")\n",
    "#             for index,row in customers.iterrows():\n",
    "#                 # print(index)\n",
    "#                 cursor.execute('Insert into Customers([phone], [customer email], [customer name], [customer group], [zip code], [address], [shipping address2], [country], [region], [city], [kecamatan]) Values (?, ?, ?, ?, ?,?, ?, ?, ?, ?, ?)', [str(row['Phone']), str(row['Customer Email']), str(row['Customer Name']), str(row['Customer Group']), int(row['Zip Code']), str(row['Address']), str(row['Shipping Address2']), str(row['Country']), str(row['Region']), str(row['City']), str(row['Kecamatan'])])\n",
    "#                 conn.commit()\n",
    "\n",
    "                \n",
    "#             product = pd.read_sql('Select * from Product', conn)\n",
    "#             all_product = data_insert[~data_insert['Real SKU'].astype(str).isin(product['real sku'].astype(str))].drop_duplicates('Real SKU')\n",
    "#             all_product = all_product[['Brand', 'Price List NFI', 'Sub Brand', 'Real SKU', 'Real Nama Produk', 'Parent Item', 'Parent SKU','Bundle Flag']]\n",
    "#             sql_arg = ''\n",
    "#             values_arg = ''\n",
    "#             for i in product.columns:\n",
    "#                 if i != 'id':\n",
    "#                     sql_arg = sql_arg + '[' + i + '], '\n",
    "#                     values_arg = values_arg + '?,'\n",
    "\n",
    "#             sql_arg = sql_arg[:-2]\n",
    "#             print(sql_arg)\n",
    "#             values_arg = values_arg[:-1]\n",
    "#             print(values_arg)\n",
    "\n",
    "#             sql_arg = 'Insert into Product(' + sql_arg + ') Values (' + values_arg + ')'\n",
    "\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "#             print(\"Product Database\")\n",
    "#             for index,row in all_product.iterrows():\n",
    "#                 # print(index)\n",
    "#                 cursor.execute('Insert into Product([brand], [price list nfi], [sub brand], [real sku], [real nama produk], [parent item], [parent sku], [bundle flag]) Values (?,?,?,?,?,?,?,?)',[str(row['Brand']), int(row['Price List NFI']), str(row['Sub Brand']), str(row['Real SKU']), str(row['Real Nama Produk']), str(row['Parent Item']), str(row['Parent SKU']), str(row['Bundle Flag'])])\n",
    "#                 conn.commit()\n",
    "                \n",
    "#             product = pd.read_sql('Select * from Product', conn)\n",
    "#             product['id'] = product['id'].astype(int)\n",
    "#             product['real sku'] = product['real sku'].astype(str)\n",
    "#             data_insert['Real SKU'] = data_insert['Real SKU'].astype(str)\n",
    "#             data_insert = data_insert.merge(product[['id', 'real sku']].drop_duplicates('real sku'), how = 'left', left_on = 'Real SKU', right_on = 'real sku')\n",
    "#             data_insert = data_insert.rename(columns = {'id' : 'Product Id'})\n",
    "#             data_insert = data_insert.drop('real sku', axis = 1)\n",
    "\n",
    "#             sql_bundle = pd.read_sql('Select * From [Bundle Details]', conn)\n",
    "#             bundle = product[product['bundle flag'] == 'Bundle'][~product[product['bundle flag'] == 'Bundle']['id'].isin(sql_bundle['product id'])]\n",
    "#             bundle_details = data_insert[data_insert['Real SKU'].isin(bundle['real sku'])].drop_duplicates('Real SKU')\n",
    "#             bundle_details = bundle_details[['Product Id'] + bundle_details.columns[bundle_details.columns.get_loc('Produk 1') : bundle_details.columns.get_loc('Harga Cost 7') + 1].to_list()]\n",
    "\n",
    "#             sql_arg = ''\n",
    "#             values_arg = ''\n",
    "#             for i in sql_bundle.columns:\n",
    "#                 if i != 'id':\n",
    "#                     sql_arg = sql_arg + '[' + i + '], '\n",
    "#                     values_arg = values_arg + '?,'\n",
    "\n",
    "#             sql_arg = sql_arg[:-2]\n",
    "#             print(sql_arg)\n",
    "#             values_arg = values_arg[:-1]\n",
    "#             print(values_arg)\n",
    "\n",
    "#             sql_arg = 'Insert into [Bundle Details](' + sql_arg + ') Values (' + values_arg + ')'\n",
    "\n",
    "#             for i in bundle_details.columns:\n",
    "#                 if 'PCS' in i or 'Subtotal' in i or 'Harga' in i or 'Price' in i:\n",
    "#                     bundle_details[i] = bundle_details[i].fillna(0)\n",
    "\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                     'Server=BAF-DB-01;'\n",
    "#                     'Database=e-commerce;'\n",
    "#                     )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "#             print(\"Bundle Database\")\n",
    "#             for index,row in bundle_details.iterrows():\n",
    "#                 # print(index)\n",
    "#                 cursor.execute(sql_arg, [int(row['Product Id']), str(row['Produk 1']), str(row['SKU Produk 1']), int(row['PCS Produk 1']), int(row['Price List NFI 1']), int(row['Subtotal Produk 1']), int(row['Harga Display 1']), int(row['Harga Cost 1']), str(row['Produk 2']), str(row['SKU Produk 2']), int(row['PCS Produk 2']), int(row['Price List NFI 2']), int(row['Subtotal Produk 2']), int(row['Harga Display 2']), int(row['Harga Cost 2']), str(row['Produk 3']), str(row['SKU Produk 3']), int(row['PCS Produk 3']), int(row['Price List NFI 3']), int(row['Subtotal Produk 3']), int(row['Harga Display 3']), int(row['Harga Cost 3']), str(row['Produk 4']), str(row['SKU Produk 4']), int(row['PCS Produk 4']), int(row['Price List NFI 4']), int(row['Subtotal Produk 4']), int(row['Harga Display 4']), int(row['Harga Cost 4']), str(row['Produk 5']), str(row['SKU Produk 5']), int(row['PCS Produk 5']), int(row['Price List NFI 5']), int(row['Subtotal Produk 5']), int(row['Harga Display 5']), int(row['Harga Cost 5']), str(row['Produk 6']), str(row['SKU Produk 6']), int(row['PCS Produk 6']), int(row['Price List NFI 6']), int(row['Subtotal Produk 6']), int(row['Harga Display 6']), int(row['Harga Cost 6']), str(row['Produk 7']), str(row['SKU Produk 7']), int(row['PCS Produk 7']), int(row['Price List NFI 7']), int(row['Subtotal Produk 7']), int(row['Harga Display 7']), int(row['Harga Cost 7'])])\n",
    "#                 conn.commit()\n",
    "\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "\n",
    "#             cust = pd.read_sql('Select * From Customers', conn)\n",
    "#             data_insert['Phone'] = data_insert['Phone'].astype(str)\n",
    "#             cust['phone'] = cust['phone'].astype(str)\n",
    "#             data_insert = data_insert.merge(cust[['id', 'phone']].drop_duplicates('phone'), how = 'left', left_on = 'Phone', right_on = 'phone')\n",
    "#             data_insert = data_insert.rename(columns = {'id' : 'Customer Id'})\n",
    "#             data_insert = data_insert.drop('phone', axis = 1)\n",
    "\n",
    "#             # lmen_phone = data_insert[data_insert['Phone'].isnull()].copy()\n",
    "#             # lmen_phone = lmen_phone.merge(cust[cust['phone'] == 'nan'][['id', 'customer name']].drop_duplicates('customer name'), how = 'left', left_on = 'Customer Name', right_on = 'customer name').set_index(lmen_phone.index)\n",
    "#             # data_insert['Customer Id'][lmen_phone.index] = lmen_phone['id'] \n",
    "\n",
    "#             orders = pd.read_sql('select * from \"Order\"', conn)\n",
    "#             orders['order #'] = orders['order #'].astype(str)\n",
    "#             data_insert['Order #'] = data_insert['Order #'].astype(str)\n",
    "\n",
    "#             all_order = data_insert[['Order #', 'Sales Order ID', 'AWB', 'Order date', 'Paid Date', 'Order Status', 'Channel', 'Customer Id', 'Coupon Code', 'Cart Name Rule', 'Ship Date', 'Payment Channel', 'Cancelled Date', 'Currency Code', 'Loc ID', 'Barcode ID', 'Warehouse Name', 'Store', 'Notes', 'Week', 'Date', 'Month', 'Quarter', 'Year', 'Shipping Name', 'Shipping Courier', 'True datetime']].drop_duplicates(['Order #'])\n",
    "\n",
    "#             temp = all_order.copy()\n",
    "#             temp.columns = [str(x).lower() for x in temp.columns]\n",
    "\n",
    "#             temp2 = orders.append(temp, ignore_index = True, sort = False)\n",
    "#             temp2['true datetime'] = pd.to_datetime(temp2['true datetime'])\n",
    "#             temp2 = temp2.sort_values('true datetime')\n",
    "#             temp2 = temp2.assign(count = temp2.groupby(['customer id']).cumcount())\n",
    "#             all_order = all_order.merge(temp2[['order #', 'count']].drop_duplicates('order #'), how = 'left', left_on = 'Order #', right_on = 'order #')\n",
    "#             all_order = all_order.rename(columns = {'count' : 'Pembelian Ke'})\n",
    "#             all_order = all_order.drop('order #', axis = 1)\n",
    "#             all_order['Pembelian Ke'] = all_order['Pembelian Ke']+1\n",
    "\n",
    "#             indeks = all_order[all_order['Pembelian Ke'] == 1].index.to_list()\n",
    "#             all_order['Repeat Return'] = np.nan\n",
    "#             all_order['Repeat Return'][indeks] = 'New'\n",
    "#             indeks = all_order[all_order['Pembelian Ke'] > 1].index.to_list()\n",
    "#             all_order['Repeat Return'][indeks] = 'Repeat'\n",
    "\n",
    "#             all_order['Order date'] = pd.to_datetime(all_order['Order date'], errors = 'coerce')\n",
    "#             all_order['Paid Date'] = pd.to_datetime(all_order['Paid Date'].fillna(pd.NaT), errors = 'coerce')\n",
    "#             all_order['Cancelled Date'] = pd.to_datetime(all_order['Cancelled Date'].fillna(pd.NaT), errors = 'coerce')\n",
    "#             all_order['Ship Date'] = pd.to_datetime(all_order['Ship Date'], errors = 'coerce')\n",
    "\n",
    "#             sql_arg = ''\n",
    "#             values_arg = ''\n",
    "#             for i in orders.columns:\n",
    "#                 if i != 'id':\n",
    "#                     sql_arg = sql_arg + '[' + i + '], '\n",
    "#                     values_arg = values_arg + '?,'\n",
    "\n",
    "#             sql_arg = sql_arg[:-2]\n",
    "#             print(sql_arg)\n",
    "#             values_arg = values_arg[:-1]\n",
    "#             print(values_arg)\n",
    "\n",
    "#             sql_arg = 'Insert into \"Order\"(' + sql_arg + ') Values (' + values_arg + ')'\n",
    "\n",
    "#             order_ada = all_order[all_order['Order #'].astype(str).isin(orders['order #'].astype(str))]\n",
    "#             order_gaada = all_order[~all_order['Order #'].astype(str).isin(orders['order #'].astype(str))]\n",
    "\n",
    "\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "#             print(\"Order ada Database\")\n",
    "#             for index,row in order_ada.iterrows():\n",
    "#                 # print(index)\n",
    "#                 cursor.execute('Update \"Order\" set [order status] = ? where CONVERT(VARCHAR, [order #]) = ?',[str(row['Order Status']), str(row['Order #'])])\n",
    "#                 conn.commit()\n",
    "                \n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "#             print(\"Order Baru Database\")\n",
    "#             for index,row in order_gaada.iterrows():\n",
    "#                 # print(index)\n",
    "#                 cursor = conn.cursor()\n",
    "#                 o_date = row['Order date']\n",
    "#                 p_date = row['Paid Date']\n",
    "#                 c_date = row['Cancelled Date']\n",
    "#                 s_date = row['Ship Date']\n",
    "#                 if str(o_date) == 'NaT':\n",
    "#                     o_date = None\n",
    "#                 if str(p_date) == 'NaT':\n",
    "#                     p_date = None\n",
    "#                 if str(c_date) == 'NaT':\n",
    "#                     c_date = None\n",
    "#                 if str(s_date) == 'NaT':\n",
    "#                     s_date = None\n",
    "#                 cursor.execute(sql_arg,[str(row['Order #']),str(row['Sales Order ID']),str(row['AWB']),o_date,p_date,str(row['Order Status']),str(row['Channel']),str(row['Customer Id']),str(row['Coupon Code']),str(row['Cart Name Rule']),s_date,str(row['Payment Channel']),c_date,str(row['Currency Code']),str(row['Loc ID']),str(row['Barcode ID']),str(row['Warehouse Name']),str(row['Store']),str(row['Notes']),int(row['Week']),int(row['Date']),str(row['Month']),str(row['Quarter']),int(row['Year']),str(row['Shipping Name']),str(row['Shipping Courier']), pd.to_datetime(row['True datetime']), row['Pembelian Ke'], row['Repeat Return']])\n",
    "#                 conn.commit()\n",
    "                    \n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "\n",
    "#             temp = data_insert.copy()\n",
    "#             orders = pd.read_sql('select * from \"Order\"', conn)\n",
    "#             temp = temp.merge(orders[['id', 'order #']].drop_duplicates('order #'), how = 'left', left_on = 'Order #', right_on = 'order #')\n",
    "#             temp = temp.rename(columns = {'id' : 'Order Id'})\n",
    "#             temp = temp.drop('order #', axis = 1)\n",
    "\n",
    "#             ortrans = pd.read_sql('select * from [Order Transaction]', conn)\n",
    "\n",
    "#             order_trans = temp[['Order Id','Product Id', 'SKU', 'Product Name', 'Bundle Name', 'Qty. Invoiced', 'Total Net', 'Total',\n",
    "#                     'Qty. Ordered', 'Qty. Shipped', 'Qty. Refunded', 'Item Price',\n",
    "#                     'Subtotal', 'Discounts', 'Tax', 'Total incl. Tax', 'Invoiced',\n",
    "#                     'Tax Invoiced', 'Invoiced incl. Tax', 'Refunded', 'Refunded incl. Tax',\n",
    "#                     'Voucher Amount', 'Discount Poin Reward', 'Discount Product', 'Bundle',\n",
    "#                     'Regular Price', 'Selling Price', 'VAT', 'Shipping', 'Actual Shipping',\n",
    "#                     'Seller Discount', 'Seller Rebate', 'Gross Sales', 'Discount MC', 'Promo', 'Harga Cost', 'Total Harga Cost', 'btlcost', 'fullfee', 'commfee', 'nominal']]\n",
    "\n",
    "\n",
    "#             sql_arg = ''\n",
    "#             values_arg = ''\n",
    "#             for i in ortrans.columns:\n",
    "#                 if i != 'id' and i != 'marketing cost':\n",
    "#                     sql_arg = sql_arg + '[' + i + '], '\n",
    "#                     values_arg = values_arg + '?,'\n",
    "\n",
    "#             sql_arg = sql_arg[:-2]\n",
    "#             print(sql_arg)\n",
    "#             values_arg = values_arg[:-1]\n",
    "#             print(values_arg)\n",
    "\n",
    "#             sql_arg = 'Insert into [Order Transaction](' + sql_arg + ') Values (' + values_arg + ')'\n",
    "#             sql_arg\n",
    "\n",
    "#             for i in order_trans.columns:\n",
    "#                 if i in order_trans.columns[:5].to_list() + ['Bundle Name', 'Bundle', 'Promo']:\n",
    "#                     pass\n",
    "#                 else:\n",
    "#                     order_trans[i] = order_trans[i].fillna(0)\n",
    "\n",
    "#             print(\"Order Transaction Database\")\n",
    "#             for index,row in order_trans.iterrows():\n",
    "#                 # print(index)\n",
    "#                 cursor.execute(sql_arg,[int(row['Order Id']), int(row['Product Id']), str(row['SKU']), str(row['Product Name']),str(row['Bundle Name']), int(row['Qty. Invoiced']), int(row['Total Net']), int(row['Total']), int(row['Qty. Ordered']), int(row['Qty. Shipped']), int(row['Qty. Refunded']), int(row['Item Price']), int(row['Subtotal']), int(row['Discounts']), int(row['Tax']), int(row['Total incl. Tax']), int(row['Invoiced']), int(row['Tax Invoiced']), int(row['Invoiced incl. Tax']), int(row['Refunded']), int(row['Refunded incl. Tax']), int(row['Voucher Amount']), int(row['Discount Poin Reward']), int(row['Discount Product']), str(row['Bundle']), int(row['Regular Price']), int(row['Selling Price']), int(row['VAT']), int(row['Shipping']), int(row['Actual Shipping']), int(row['Seller Discount']), int(row['Seller Rebate']), int(row['Gross Sales']), float(row['Discount MC']), str(row['Promo']), int(row['Harga Cost']), int(row['Total Harga Cost']), int(row['btlcost']), int(row['fullfee']), int(row['commfee']), int(row['nominal'])])\n",
    "#                 conn.commit()    \n",
    "\n",
    "#             print(\"Data Dashboard Customers\")\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "\n",
    "#             print(\"Pull data from database\")\n",
    "#             orders = pd.read_sql(r'Select * From \"Order\"', conn)\n",
    "\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "#             ortrans = pd.read_sql(r'Select * From [Order Transaction]', conn)\n",
    "\n",
    "#             or_ortrans = ortrans.merge(orders, how = 'left', left_on = 'order id', right_on = 'id')\n",
    "\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "#             cust = pd.read_sql('Select * from Customers', conn)\n",
    "#             customers = cust.copy()\n",
    "#             or_ortrans = or_ortrans.merge(cust, how = 'left', left_on = 'customer id', right_on = 'id')\n",
    "\n",
    "\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "#             products = pd.read_sql(r'Select * From Product', conn)\n",
    "#             or_ortrans = or_ortrans.merge(products, how = 'left', left_on = 'product id', right_on = 'id')\n",
    "\n",
    "#             from datetime import datetime\n",
    "#             from datetime import timedelta\n",
    "\n",
    "#             print(\"RFM\")\n",
    "#             cust = data_all[['Phone', 'Customer Email', 'Customer Name', 'Customer Group', 'Zip Code', 'Address', 'Shipping Address2', 'Country', 'Region', 'City', 'Kecamatan']].drop_duplicates('Phone')\n",
    "#             cust['Phone'] = cust['Phone'].astype(str)\n",
    "#             cust = cust.rename(columns = {'Phone' : 'phone'})\n",
    "#             cust = cust.merge(customers[['id', 'phone']], how = 'left', on = 'phone')\n",
    "\n",
    "#             max_purchase = or_ortrans.groupby('customer id')['true datetime'].max().reset_index()\n",
    "#             max_purchase.columns = ['id', 'MaxPurchaseDate']\n",
    "#             max_purchase['Recency'] = (datetime.today()- max_purchase['MaxPurchaseDate']).dt.days\n",
    "\n",
    "#             cust['recency'] = cust.merge(max_purchase[['id', 'Recency']], how = 'left', on = 'id')['Recency']\n",
    "\n",
    "#             data_freq = or_ortrans[or_ortrans['true datetime'] > datetime.today() - timedelta(days=365)]\n",
    "#             frequency = data_freq.groupby('customer id').agg({'order #' : pd.Series.nunique}).reset_index()\n",
    "\n",
    "#             frequency.columns = ['id', 'Frequency']\n",
    "#             cust['frequency']= cust.merge(frequency[['id', 'Frequency']], how = 'left', on = 'id')['Frequency']\n",
    "\n",
    "#             monetary = data_freq.groupby('customer id')['total net'].sum().reset_index()\n",
    "#             monetary.columns = ['id', 'Monetary']\n",
    "#             cust['monetary']= cust.merge(monetary[['id', 'Monetary']], how = 'left', on = 'id')['Monetary']\n",
    "\n",
    "#             cust['recency month'] = round(cust['recency']/30)\n",
    "\n",
    "#             indeks = cust[cust['recency'] >= 365].index.to_list()\n",
    "#             cust['status lf'] = np.nan\n",
    "#             cust['status bs'] = np.nan\n",
    "#             cust['status freq'] = np.nan\n",
    "\n",
    "#             cust['status lf'][indeks] = 'lost'\n",
    "#             cust['status freq'][indeks] = 'false'\n",
    "#             cust['status bs'][indeks] = 'dormain'\n",
    "\n",
    "#             indeks = cust[cust['recency month'] <= 3].index.to_list()\n",
    "#             cust['status lf'][indeks] = 'active'\n",
    "\n",
    "#             indeks = cust[cust['recency month'] > 3][cust[cust['recency month'] >= 3]['recency month']<=6].index.to_list()\n",
    "#             cust['status lf'][indeks] = 'at risk'\n",
    "\n",
    "#             indeks = cust[cust['recency month'] > 3][cust[cust['recency month'] >= 3]['recency month']<=6].index.to_list()\n",
    "#             cust['status lf'][indeks] = 'at risk'\n",
    "\n",
    "#             indeks = cust[cust['recency month'] > 6][cust[cust['recency month'] > 6]['recency month']<=12].index.to_list()\n",
    "#             cust['status lf'][indeks] = 'almost lost'\n",
    "\n",
    "#             indeks = cust[cust['frequency'] == 1].index.to_list()\n",
    "#             cust['status freq'][indeks] = 'one timer'\n",
    "\n",
    "#             indeks = cust[cust['frequency'] > 1][cust[cust['frequency'] > 1]['frequency']<=3].index.to_list()\n",
    "#             cust['status freq'][indeks] = 'repeat'\n",
    "\n",
    "#             indeks = cust[cust['frequency'] > 3].index.to_list()\n",
    "#             cust['status freq'][indeks] = 'loyal'\n",
    "\n",
    "#             indeks = cust[cust['monetary'] <= 500000].index.to_list()\n",
    "#             cust['status bs'][indeks] = 'silver'\n",
    "\n",
    "#             indeks = cust[cust['monetary'] > 500000][cust[cust['monetary'] > 500000]['monetary'] < 2000000].index.to_list()\n",
    "#             cust['status bs'][indeks] = 'gold'\n",
    "\n",
    "#             indeks = cust[cust['monetary'] > 2000000][cust[cust['monetary'] > 2000000]['monetary'] < 5000000].index.to_list()\n",
    "#             cust['status bs'][indeks] = 'platinum'\n",
    "\n",
    "#             indeks = cust[cust['monetary'] > 5000000].index.to_list()\n",
    "#             cust['status bs'][indeks] = 'diamond'\n",
    "\n",
    "#             indeks = cust[cust['recency'] >= 365].index.to_list()\n",
    "#             cust['status lf'][indeks] = 'lost'\n",
    "#             cust['status freq'][indeks] = 'false'\n",
    "#             cust['status bs'][indeks] = 'dormain'\n",
    "\n",
    "#             cust['frequency'] = cust['frequency'].fillna(0)\n",
    "#             cust['monetary'] = cust['monetary'].fillna(0)\n",
    "\n",
    "#             print(\"Affinity Scores\")\n",
    "#             brand_aff = or_ortrans[or_ortrans['bundle flag'] != 'Bundle']\n",
    "#             brand_aff = brand_aff[brand_aff['brand'].isin(['TS', 'NS', 'L-Men', 'HiLo', \"W'dank\", 'WRP'])]\n",
    "#             brand_aff = brand_aff.groupby(['customer id', 'brand'])['order #'].nunique().reset_index()\n",
    "#             brand_aff['percentage'] = brand_aff['order #']/brand_aff.groupby('customer id')['order #'].transform('sum')\n",
    "#             brand_aff = brand_aff.sort_values(['customer id', 'percentage'], ascending = [True, False])\n",
    "#             brand_aff = brand_aff.assign(count = brand_aff.groupby(['customer id']).cumcount())\n",
    "\n",
    "#             brand_aff1 = brand_aff[brand_aff['count'] == 0]\n",
    "#             brand_aff2 = brand_aff[brand_aff['count'] == 1]\n",
    "#             brand_aff = brand_aff1[['customer id', 'brand', 'percentage']].merge(brand_aff2[['customer id', 'brand', 'percentage']], how = 'left', on = 'customer id')\n",
    "#             brand_aff = brand_aff.rename(columns = {'customer id' : 'id','brand_x' : 'brand affinity', 'percentage_x' : 'brand affinity score','brand_y' : 'brand affinity 2', 'percentage_y' : 'brand affinity 2 score'})\n",
    "\n",
    "#             cust = cust.merge(brand_aff, how = 'left', on = 'id')\n",
    "\n",
    "#             store_aff = or_ortrans[or_ortrans['bundle flag'] != 'Bundle']\n",
    "#             store_aff = store_aff.groupby(['customer id', 'store'])['order #'].nunique().reset_index()\n",
    "#             store_aff['percentage'] = store_aff['order #']/store_aff.groupby('customer id')['order #'].transform('sum')\n",
    "#             store_aff = store_aff.sort_values(['customer id', 'percentage'], ascending = [True, False])\n",
    "#             store_aff = store_aff.assign(count = store_aff.groupby(['customer id']).cumcount())\n",
    "\n",
    "#             store_aff1 = store_aff[store_aff['count'] == 0]\n",
    "#             store_aff2 = store_aff[store_aff['count'] == 1]\n",
    "#             store_aff = store_aff1[['customer id', 'store', 'percentage']].merge(store_aff2[['customer id', 'store', 'percentage']], how = 'left', on = 'customer id')\n",
    "#             store_aff = store_aff.rename(columns = {'customer id' : 'id','store_x' : 'store affinity', 'percentage_x' : 'store affinity score','store_y' : 'store affinity 2', 'percentage_y' : 'store affinity 2 score'})\n",
    "\n",
    "#             cust = cust.merge(store_aff, how = 'left', on = 'id')\n",
    "\n",
    "#             first = or_ortrans.groupby('customer id')['true datetime'].min().reset_index().rename(columns = {'true datetime' : 'first date'})\n",
    "#             last = or_ortrans.groupby('customer id')['true datetime'].max().reset_index().rename(columns = {'true datetime' : 'last date'})\n",
    "\n",
    "#             cust = cust.merge(first, how = 'left', left_on = 'id', right_on = 'customer id').drop('customer id', axis = 1)\n",
    "#             cust = cust.merge(last, how = 'left', left_on = 'id', right_on = 'customer id').drop('customer id', axis = 1)\n",
    "\n",
    "#             store_num = or_ortrans.groupby('customer id')['store'].nunique().reset_index().rename(columns = {'store' : 'number of store'})\n",
    "#             cust = cust.merge(store_num, how = 'left', left_on = 'id', right_on = 'customer id').drop('customer id', axis = 1)\n",
    "#             cust['Jabodetabek'] = np.nan\n",
    "\n",
    "#             indeks = cust[cust['City'].astype(str).str.contains('Jakarta|Bekasi|Bogor|Depok|Tangerang', regex = True)].index.to_list()\n",
    "#             cust['Jabodetabek'][indeks] = 'Yes'\n",
    "\n",
    "#             for i in cust.columns:\n",
    "#                 if i in ['Zip Code', 'brand affinity score', 'brand affinity 2 score','store affinity score','store affinity 2 score']:\n",
    "#                     cust[i] = cust[i].fillna(0)\n",
    "\n",
    "#             cust = cust.rename(columns = {'store' : 'number of store'})\n",
    "#             cust['Zip Code'] = pd.to_numeric(cust['Zip Code'], errors = 'coerce').fillna(0)\n",
    "#             cust['number of store'] = pd.to_numeric(cust['number of store'], errors = 'coerce').fillna(0)\n",
    "\n",
    "#             command = 'Update Customers set '\n",
    "#             for i in cust.columns:\n",
    "#                 if i not in ['phone', 'id']:\n",
    "#                     command = command + '[' + i + '] = ?,'\n",
    "#             command = command[:-1]\n",
    "#             command = command + ' Where id = ?'\n",
    "\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "\n",
    "#             cust_not = cust[~cust['phone'].isin(data_insert['Phone'])]\n",
    "#             cust = cust[cust['phone'].isin(data_insert['Phone'])]\n",
    "\n",
    "#             for index, row in cust.iterrows():\n",
    "#                 if row['phone'] != 'nan' and str(row['id']) != 'nan':\n",
    "#                     f_date = row['first date']\n",
    "#                     l_date = row['last date']\n",
    "#                     if str(f_date) == 'NaT':\n",
    "#                         f_date = None\n",
    "#                     if str(l_date) == 'NaT':\n",
    "#                         l_date = None\n",
    "#                     # print(index)\n",
    "#                     cursor.execute(command, [str(row['Customer Email']), str(row['Customer Name']), str(row['Customer Group']), int(row['Zip Code']), str(row['Address']), str(row['Shipping Address2']), str(row['Country']), str(row['Region']), str(row['City']), str(row['Kecamatan']), str(row['recency']), str(row['frequency']), str(row['monetary']), str(row['recency month']), str(row['status lf']), str(row['status bs']), str(row['status freq']), str(row['brand affinity']), int(row['brand affinity score']), str(row['brand affinity 2']), int(row['brand affinity 2 score']), str(row['store affinity']), int(row['store affinity score']), str(row['store affinity 2']), int(row['store affinity 2 score']), pd.to_datetime(f_date), pd.to_datetime(l_date), int(row['number of store']), str(row['Jabodetabek']), row['id']])\n",
    "#                     conn.commit()\n",
    "\n",
    "#             for index, row in cust_not.iterrows():\n",
    "#                 if row['phone'] != 'nan' and str(row['id']) != 'nan':\n",
    "#                     f_date = row['first date']\n",
    "#                     l_date = row['last date']\n",
    "#                     if str(f_date) == 'NaT':\n",
    "#                         f_date = None\n",
    "#                     if str(l_date) == 'NaT':\n",
    "#                         l_date = None\n",
    "#                     # print(index)\n",
    "#                     cursor.execute('Update Customers set recency = ? where id = ?', [str(row['recency']), row['id']])\n",
    "#                     conn.commit()\n",
    "\n",
    "#             print(\"Move to Organic Data\")\n",
    "#             cumcount = or_ortrans.sort_values('true datetime', ascending = True).drop_duplicates('order #')\n",
    "#             cumcount = cumcount.assign(count = cumcount.groupby(['customer id']).cumcount())\n",
    "#             prev_store = cumcount[['customer id', 'count', 'true datetime', 'store']][cumcount[['customer id', 'count', 'true datetime', 'store']]['store'] == 'Nutrimart'][cumcount[['customer id', 'count', 'true datetime', 'store']][cumcount[['customer id', 'count', 'true datetime', 'store']]['store'] == 'Nutrimart']['count'] > 0].groupby('customer id')['count', 'true datetime'].first().reset_index()\n",
    "#             prev_store['count-1'] = prev_store['count']-1\n",
    "#             prev_store = prev_store.merge(cumcount[['customer id', 'count', 'store']], how = 'left', left_on = ['customer id', 'count-1'], right_on = ['customer id', 'count'])\n",
    "#             to_organic = prev_store[prev_store['store'] != 'Nutrimart']\n",
    "#             to_organic = to_organic[['customer id', 'store']].rename(columns = {'store' : 'previous store'})\n",
    "\n",
    "#             print(\"Insert into Customers Database\")\n",
    "#             conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                             'Server=BAF-DB-01;'\n",
    "#                             'Database=e-commerce;'\n",
    "#                             )\n",
    "\n",
    "#             cursor = conn.cursor()\n",
    "#             for index,row in to_organic.iterrows():\n",
    "#                 # print(index)\n",
    "#                 cursor.execute('Update Customers set [move to organic] = ?, [previous store] = ? where id = ?', ['Yes', row['previous store'], row['customer id']])\n",
    "#                 conn.commit()\n",
    "\n",
    "#             print('All Finish\n",
    "\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4e21dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b63b533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2580, 2618]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fafa0653",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3948359156.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [16]\u001b[1;36m\u001b[0m\n\u001b[1;33m    end = 11:20:00\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8daf1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63014d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79282c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c2c1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e316e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65341831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a73b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffcea87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d63bd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 2), dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skushopee[['Item Name', 'SKU']].drop_duplicates().values\n",
    "### ini harus null juga, jgn ada item masuk pake sku shopee (S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f444a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9742320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 3), dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### opsional , if errror\n",
    "### cek sku missing (belum ada di tatanama)\n",
    "### to do: regist single/bundle/alias \n",
    "\n",
    "data_forstok[data_forstok['SKU'].isnull()]['Item Name'].unique()\n",
    "data_forstok[~data_forstok['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))][['Store','Item Name','SKU']].drop_duplicates().values#.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99e4d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb2bb6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Magento\n",
      "Opening Chrome\n",
      "Login Magento\n",
      "Go To Sales Form\n",
      "Input Date\n",
      "Download Magento\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'file_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 228>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(change) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    251\u001b[0m     magentouser_name \u001b[38;5;241m=\u001b[39m change\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m--> 252\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mfile_name\u001b[49m)\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMore than one file or no file downloaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'file_name' is not defined"
     ]
    }
   ],
   "source": [
    "## Run-4\n",
    "## scrap magento detail order blibli update order status\n",
    "## kadang auto logout di blibli -> solusi: run partial / add code\n",
    "\n",
    "\n",
    "magento_scrape = False\n",
    "magentoUser_scrape = False\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Marketing Calendar Lazada\")\n",
    "# iterator = pd.ExcelFile(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Lazada 26 July.xlsx')\n",
    "\n",
    "# MC_Lazada = pd.DataFrame()\n",
    "\n",
    "\n",
    "# for i in iterator.sheet_names:\n",
    "#     temp = pd.read_excel(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Lazada 26 July.xlsx', sheet_name = i)\n",
    "#     temp = temp.drop(0)\n",
    "#     MC_Lazada = MC_Lazada.append(temp, ignore_index = True, sort = False)\n",
    "\n",
    "# MC_Lazada['Start Date'] = pd.to_datetime(MC_Lazada['Start Date'])\n",
    "# MC_Lazada['End Date'] = pd.to_datetime(MC_Lazada['End Date'])\n",
    "\n",
    "# MC_Lazada = MC_Lazada.dropna(subset = ['Promo'])\n",
    "# MC_Lazada = MC_Lazada.reset_index(drop = True)\n",
    "\n",
    "# Lazada = forstok_all[forstok_all['Channel'] == 'Lazada']\n",
    "\n",
    "# for i in range(MC_Lazada.shape[0]):\n",
    "#     promo = MC_Lazada['Promo'][i]\n",
    "#     start = MC_Lazada['Start Date'][i]\n",
    "#     end = MC_Lazada['End Date'][i]+ timedelta(days=1)\n",
    "#     SKU = MC_Lazada['SKU'][i]\n",
    "#     diskon = MC_Lazada['Diskon'][i]\n",
    "#     if '(S)' in str(SKU):\n",
    "#         temp = Lazada[Lazada['SKU'].astype(str) == str(SKU)]\n",
    "#     else :\n",
    "#         temp = Lazada[Lazada['Real SKU'].astype(str) == str(SKU)]\n",
    "#     temp = temp[temp['True datetime'] >= start]\n",
    "#     temp = temp[temp['True datetime'] < end]\n",
    "#     temp['Promo'] = promo\n",
    "#     temp['Discount MC'] = diskon\n",
    "#     forstok_all['Promo'][temp.index] = promo\n",
    "#     forstok_all['Discount MC'][temp.index] = diskon\n",
    "\n",
    "# print(\"Marketing Calendar Tokopedia\")\n",
    "# iterator = pd.ExcelFile(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Tokopedia.xlsx')\n",
    "\n",
    "# MC_Tokopedia = pd.DataFrame()\n",
    "\n",
    "# for i in iterator.sheet_names[:2]:\n",
    "#     print(i)\n",
    "#     temp = pd.read_excel(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Tokopedia.xlsx', sheet_name = i)\n",
    "#     temp = temp.drop(0)\n",
    "#     MC_Tokopedia = MC_Tokopedia.append(temp, ignore_index = True, sort = False)\n",
    "\n",
    "# MC_Tokopedia['Start Date'] = pd.to_datetime(MC_Tokopedia['Start Date'])\n",
    "# MC_Tokopedia['End Date'] = pd.to_datetime(MC_Tokopedia['End Date'])\n",
    "\n",
    "# MC_Tokopedia['Promo'] = MC_Tokopedia['Promo'].fillna('Promo Februari 2020')\n",
    "# MC_Tokopedia = MC_Tokopedia.reset_index(drop = True)\n",
    "\n",
    "# Tokopedia = forstok_all[forstok_all['Channel'] == 'Tokopedia']\n",
    "\n",
    "# for i in range(MC_Tokopedia.shape[0]):\n",
    "#     promo = MC_Tokopedia['Promo'][i]\n",
    "#     start = MC_Tokopedia['Start Date'][i]\n",
    "#     end = MC_Tokopedia['End Date'][i]+ timedelta(days=1)\n",
    "#     SKU = MC_Tokopedia['SKU'][i]\n",
    "#     diskon = MC_Tokopedia['Diskon'][i]\n",
    "#     if '(S)' in str(SKU):\n",
    "#         temp = Tokopedia[Tokopedia['SKU'].astype(str) == str(SKU)]\n",
    "#     else :\n",
    "#         temp = Tokopedia[Tokopedia['Real SKU'].astype(str) == str(SKU)]\n",
    "#     temp = temp[temp['True datetime'] >= start]\n",
    "#     temp = temp[temp['True datetime'] < end]\n",
    "#     temp['Promo'] = promo\n",
    "#     temp['Discount MC'] = diskon\n",
    "#     forstok_all['Promo'][temp.index] = promo\n",
    "#     forstok_all['Discount MC'][temp.index] = diskon\n",
    "\n",
    "# print(\"Marketing Calendar Bukalapak\")\n",
    "# iterator = pd.ExcelFile(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Bukalapak.xlsx')\n",
    "\n",
    "# MC_Bukalapak = pd.DataFrame()\n",
    "\n",
    "# for i in iterator.sheet_names:\n",
    "#     temp = pd.read_excel(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Bukalapak.xlsx', sheet_name = i)\n",
    "#     temp = temp.drop(0)\n",
    "#     MC_Bukalapak = MC_Bukalapak.append(temp, ignore_index = True, sort = False)\n",
    "\n",
    "# MC_Bukalapak['Start Date'] = pd.to_datetime(MC_Bukalapak['Start Date'])\n",
    "# MC_Bukalapak['End Date'] = pd.to_datetime(MC_Bukalapak['End Date'])\n",
    "\n",
    "# MC_Bukalapak = MC_Bukalapak.dropna(subset = ['Promo'])\n",
    "# MC_Bukalapak = MC_Bukalapak.reset_index(drop = True)\n",
    "\n",
    "# Bukalapak = forstok_all[forstok_all['Channel'] == 'Bukalapak']\n",
    "\n",
    "# for i in range(MC_Bukalapak.shape[0]):\n",
    "#     promo = MC_Bukalapak['Promo'][i]\n",
    "#     start = MC_Bukalapak['Start Date'][i]\n",
    "#     end = MC_Bukalapak['End Date'][i]+ timedelta(days=1)\n",
    "#     SKU = MC_Bukalapak['SKU'][i]\n",
    "#     diskon = MC_Bukalapak['Diskon'][i]\n",
    "#     if '(S)' in str(SKU):\n",
    "#         temp = Bukalapak[Bukalapak['SKU'].astype(str) == str(SKU)]\n",
    "#     else :\n",
    "#         temp = Bukalapak[Bukalapak['Real SKU'].astype(str) == str(SKU)]\n",
    "#     temp = temp[temp['True datetime'] >= start]\n",
    "#     temp = temp[temp['True datetime'] < end]\n",
    "#     temp['Promo'] = promo\n",
    "#     temp['Discount MC'] = diskon\n",
    "#     forstok_all['Promo'][temp.index] = promo\n",
    "#     forstok_all['Discount MC'][temp.index] = diskon\n",
    "\n",
    "# print(\"Marketing Calendar FBL\")\n",
    "# iterator = pd.ExcelFile(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Lazada 26 July.xlsx')\n",
    "\n",
    "# MC_Lazada = pd.DataFrame()\n",
    "\n",
    "# for i in iterator.sheet_names:\n",
    "#     temp = pd.read_excel(r'\\\\nfi-data-01\\QEA-QEB$\\06. Report\\Marketing Calendar\\Promo Plan per Marketplace/Lazada 26 July.xlsx', sheet_name = i)\n",
    "#     temp = temp.drop(0)\n",
    "#     MC_Lazada = MC_Lazada.append(temp, ignore_index = True, sort = False)\n",
    "\n",
    "# MC_Lazada['Start Date'] = pd.to_datetime(MC_Lazada['Start Date'])\n",
    "# MC_Lazada['End Date'] = pd.to_datetime(MC_Lazada['End Date'])\n",
    "\n",
    "# MC_Lazada = MC_Lazada.dropna(subset = ['Promo'])\n",
    "# MC_Lazada = MC_Lazada.reset_index(drop = True)\n",
    "\n",
    "# Lazada = forstok_all[forstok_all['Channel'] == 'FBL']\n",
    "\n",
    "# for i in range(MC_Lazada.shape[0]):\n",
    "#     promo = MC_Lazada['Promo'][i]\n",
    "#     start = MC_Lazada['Start Date'][i]\n",
    "#     end = MC_Lazada['End Date'][i]+ timedelta(days=1)\n",
    "#     SKU = MC_Lazada['SKU'][i]\n",
    "#     diskon = MC_Lazada['Diskon'][i]\n",
    "#     if '(S)' in str(SKU):\n",
    "#         temp = Lazada[Lazada['SKU'].astype(str) == str(SKU)]\n",
    "#     else :\n",
    "#         temp = Lazada[Lazada['Real SKU'].astype(str) == str(SKU)]\n",
    "#     temp = temp[temp['True datetime'] >= start]\n",
    "#     temp = temp[temp['True datetime'] < end]\n",
    "#     temp['Promo'] = promo\n",
    "#     temp['Discount MC'] = diskon\n",
    "#     forstok_all['Promo'][temp.index] = promo\n",
    "#     forstok_all['Discount MC'][temp.index] = diskon\n",
    "\n",
    "# forstok_all_final = forstok_all.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "if not magento_scrape: \n",
    "    print(\"Starting Magento\")\n",
    "\n",
    "    # Download the file using Selenium here\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    print('Opening Chrome')\n",
    "    driver = webdriver.Chrome(\"chromedriver.exe\",options=options)\n",
    "    driver.get(\"https://nutrimart.co.id/backoffice\")\n",
    "    print('Login Magento')\n",
    "    username = driver.find_element_by_id(\"username\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"andra\")\n",
    "    password = driver.find_element_by_id(\"login\")\n",
    "    password.send_keys(\"andra123\")\n",
    "\n",
    "    print('Go To Sales Form')\n",
    "    time.sleep(5)\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "    driver.find_element_by_xpath(\"//button[@class = 'action-login action-primary']\").click()\n",
    "    time.sleep(5)\n",
    "    WebDriverWait(driver, 300).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"menu-magento-sales-sales\"]'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"menu-magento-sales-sales\"]/div/ul/li[2]/ul/li[2]/div/ul/li[1]/a').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"profile_id\"]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"profile_id\"]/optgroup[2]/option[2]').click()\n",
    "#     driver.find_element_by_xpath('//*[@id=\"profile_id\"]/optgroup[2]/option').click()\n",
    "    \n",
    "\n",
    "    start_date = datetime.today() - timedelta(days=14)\n",
    "    end_date = datetime.today()\n",
    "    date = start_date.strftime('%d %b %Y') + '-' + end_date.strftime('%d %b %Y')\n",
    "\n",
    "    print('Input Date')\n",
    "    date_from = driver.find_element_by_name('daterange_from')\n",
    "    date_from.clear()\n",
    "    date_from.send_keys(start_date.strftime('%m/%d/%Y'))\n",
    "\n",
    "    date_to = driver.find_element_by_name('daterange_to')\n",
    "    date_to.clear()\n",
    "    date_to.send_keys(end_date.strftime('%m/%d/%Y'))\n",
    "    print('Download Magento')\n",
    "    driver.find_element_by_xpath('//*[@id=\"export_button\"]').click()\n",
    "\n",
    "    time.sleep(120)\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        magento_name = change.pop()\n",
    "    else:\n",
    "        print(\"More than one file or no file downloaded\")\n",
    "    \n",
    "    \n",
    "    # data_magento = pd.read_csv(r\"D:\\Masterdata\\Input Data\\export_sales_detailed_report_318150.csv\", sep = ',', index_col = False)\n",
    "    # data_magento = pd.read_csv(r\"D:\\Masterdata\\magentosementara6(2).csv\")\n",
    "    data_magento = pd.read_csv('Input Data/' + magento_name, sep = ',', index_col = False)\n",
    "    magento_scrape = True\n",
    "else :\n",
    "    data_magento = pd.read_csv('Input Data/' + magento_name, sep = ',', index_col = False)\n",
    "    \n",
    "if not magentoUser_scrape:\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    driver.find_element_by_xpath('//*[@id=\"profile_id\"]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"profile_id\"]/optgroup[2]/option[1]').click()\n",
    "\n",
    "    start_date = datetime.today() - timedelta(days=17)\n",
    "    end_date = datetime.today()\n",
    "    date = start_date.strftime('%d %b %Y') + '-' + end_date.strftime('%d %b %Y')\n",
    "\n",
    "    date_from = driver.find_element_by_name('daterange_from')\n",
    "    date_from.clear()\n",
    "    date_from.send_keys(start_date.strftime('%m/%d/%Y'))\n",
    "\n",
    "    date_to = driver.find_element_by_name('daterange_to')\n",
    "    date_to.clear()\n",
    "    date_to.send_keys(end_date.strftime('%m/%d/%Y'))\n",
    "\n",
    "    driver.find_element_by_xpath('//*[@id=\"export_button\"]').click()\n",
    "    time.sleep(60)\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        magentouser_name = change.pop()\n",
    "        print(file_name)\n",
    "    else:\n",
    "        print(\"More than one file or no file downloaded\")\n",
    "        print(change)\n",
    "    driver.quit()\n",
    "    #\n",
    "    \n",
    "    # data_magentoUser2 = pd.read_csv(r\"D:\\Masterdata\\Input Data\\export_318137.csv\", sep = ',', index_col = False)\n",
    "    data_magentoUser2 = pd.read_csv('Input Data/' + magentouser_name, sep = ',', index_col = False)\n",
    "    for i in range(data_magentoUser2.shape[1]):\n",
    "        data_magentoUser2 = data_magentoUser2.rename(columns={ data_magentoUser2.columns[i] : data_magentoUser2.columns[i].replace(\"    \",\" \")})\n",
    "    magentoUser_scrape = True\n",
    "else :\n",
    "    data_magentoUser2 = pd.read_csv('Input Data/' + magentouser_name, sep = ',', index_col = False)\n",
    "    for i in range(data_magentoUser2.shape[1]):\n",
    "        data_magentoUser2 = data_magentoUser2.rename(columns={ data_magentoUser2.columns[i] : data_magentoUser2.columns[i].replace(\"    \",\" \")})\n",
    "\n",
    "data_SKU = pd.read_excel(r\"SKU_File\\data_SKU.xlsx\")\n",
    "\n",
    "s = requests.Session()\n",
    "s.get(\"https://tatanama.pythonanywhere.com\")\n",
    "s.post(\"https://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "r = s.get(\"https://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "with open(r\"SKU_File\\Master tatanama.xlsx\", 'wb') as output:\n",
    "    output.write(r.content)\n",
    "\n",
    "if os.path.isfile(r\"SKU_File\\Master tatanama.xlsx\") :    \n",
    "    SKU_append = pd.read_excel(r\"SKU_File\\Master tatanama.xlsx\")\n",
    "    SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "    data_SKU = data_SKU[~data_SKU['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "    data_SKU = data_SKU.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "to_excel = data_SKU.to_excel(r\"SKU_File\\data_SKU.xlsx\", index = False)\n",
    "\n",
    "\n",
    "# Import library\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Import data\n",
    "start_time = time.time()\n",
    "print(\"Import Data ====== 1/10\")\n",
    "# data_magento = pd.read_excel(r'magento_new.xls')\n",
    "data_magentoUser = pd.read_excel('All Data\\data_magentoUser_2020.xlsx', index_col = False)\n",
    "data_magentoUser = data_magentoUser[~data_magentoUser['Sales Order Id'].astype(str).isin(data_magentoUser2['Sales Order Id'].astype(str))]\n",
    "data_magentoUser = data_magentoUser.append(data_magentoUser2, ignore_index = True, sort = False)\n",
    "magento_pure = data_magento.copy()\n",
    "\n",
    "list_skumiss = []\n",
    "\n",
    "# Formatting Magento\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Formatting Data ====== 2/10\")\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "if set(['Qty. Ordered\"', 'Qty. Shipped\"']).issubset(data_magento.columns):\n",
    "    data_magento = data_magento.rename(columns={'Qty. Ordered\"' : 'Qty. Ordered', \n",
    "                                            'Qty. Shipped\"' : 'Qty. Shipped'})\n",
    "if \"Manufacturer\" in data_magento.columns:\n",
    "    data_magento= data_magento.drop([\"Manufacturer\"], axis=1)\n",
    "if \"Item Cost\" in data_magento.columns:\n",
    "    data_magento= data_magento.drop([\"Item Cost\"], axis=1)\n",
    "if \"Package Name\" in data_magento.columns:\n",
    "    data_magento= data_magento.drop([\"Package Name\"], axis=1)\n",
    "if \"Tax Refunded\" in data_magento.columns:\n",
    "    data_magento= data_magento.drop([\"Tax Refunded\"], axis=1)\n",
    "if \"Catalog Name Rule\" in data_magento.columns:\n",
    "    data_magento= data_magento.drop([\"Catalog Name Rule\"], axis=1)\n",
    "if \"Order date\" in data_magento.columns:\n",
    "    data_magento[\"Order date\"] = pd.to_datetime(data_magento[\"Order date\"], errors = 'coerce')\n",
    "if \"Customer Email\" in data_magento.columns:\n",
    "    data_magento[\"Customer Email\"] = data_magento[\"Customer Email\"].replace(regex = r'\"', value=\"\")\n",
    "if \"Qty. Ordered\" in data_magento.columns:\n",
    "    data_magento['Qty. Ordered'] = data_magento['Qty. Ordered'].fillna(0)\n",
    "    if \"Qty. Invoiced\" in data_magento.columns:\n",
    "        data_magento['Qty. Invoiced'] = data_magento['Qty. Invoiced'].fillna(0)\n",
    "    if \"Qty. Shipped\" in data_magento.columns:\n",
    "        data_magento['Qty. Shipped'] = data_magento['Qty. Shipped'].fillna(0)\n",
    "    if \"Qty. Refunded\" in data_magento.columns:\n",
    "        data_magento['Qty. Refunded'] = data_magento['Qty. Refunded'].fillna(0)\n",
    "    if \"Item Price\" in data_magento.columns:\n",
    "        data_magento['Item Price'] = data_magento['Item Price'].fillna(0)\n",
    "    if \"Subtotal\" in data_magento.columns:\n",
    "        data_magento['Subtotal'] = data_magento['Subtotal'].fillna(0)\n",
    "    if \"Discounts\" in data_magento.columns:\n",
    "        data_magento['Discounts'] = data_magento['Discounts'].fillna(0)\n",
    "    if \"Invoiced\" in data_magento.columns:\n",
    "        data_magento['Invoiced'] = data_magento['Invoiced'].fillna(0)\n",
    "    if \"Tax Invoiced\" in data_magento.columns:\n",
    "        data_magento['Tax Invoiced'] = data_magento['Tax Invoiced'].fillna(0)\n",
    "    if \"Voucher Amount\" in data_magento.columns:\n",
    "        data_magento[data_magento['Voucher Amount'].astype(str).str.isdigit()]['Voucher Amount'] = data_magento[data_magento['Voucher Amount'].fillna(0).astype(str).str.isdigit()]['Voucher Amount'].astype(float).div(10000)\n",
    "    if \"Discount Poin Reward\" in data_magento.columns:\n",
    "        data_magento['Discount Poin Reward'] = data_magento['Discount Poin Reward'].fillna(0)\n",
    "    if \"Discount Product\" in data_magento.columns:\n",
    "        data_magento['Discount Product'] = data_magento['Discount Product'].fillna(0)\n",
    "if \"Tax\" in data_magento.columns:\n",
    "    data_magento['Tax'] = data_magento['Tax'].astype(np.float32)\n",
    "if \"Total\" in data_magento.columns:\n",
    "    data_magento['Total'] = data_magento['Total'].astype(np.float32)\n",
    "if \"Total incl. Tax\" in data_magento.columns:\n",
    "    data_magento['Total incl. Tax'] = pd.to_numeric(data_magento['Total incl. Tax'], errors = 'coerce').astype(np.float32)\n",
    "if \"Invoiced incl. Tax\" in data_magento.columns:\n",
    "    data_magento['Invoiced incl. Tax'] = data_magento['Invoiced incl. Tax'].astype(np.float32)\n",
    "if \"Refunded\" in data_magento.columns:\n",
    "    data_magento['Refunded'] = data_magento['Refunded'].astype(np.float32)\n",
    "if \"Refunded incl. Tax\" in data_magento.columns:\n",
    "    data_magento['Refunded incl. Tax'] = data_magento['Refunded incl. Tax'].astype(np.float32)\n",
    "if \"Ship Date\" in data_magento.columns:\n",
    "    data_magento['Ship Date'] = data_magento['Ship Date'].astype(str).str.replace('false', '')\n",
    "\n",
    "# Customer Information Filling  \n",
    "for i in range(data_magentoUser.shape[1]):\n",
    "    data_magentoUser = data_magentoUser.rename(columns={ data_magentoUser.columns[i] : data_magentoUser.columns[i].replace(\"    \",\" \")})\n",
    "\n",
    "for i in range(data_magento.shape[0]):\n",
    "    if str(data_magento[\"Customer Group\"][i]) == 'nan':\n",
    "        if data_magento[\"Order #\"][i] in data_magentoUser[\"Sales Order Id\"].values:\n",
    "            data_magento[\"Customer Name\"][i] = data_magentoUser[\"Shipping Name\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "            data_magento[\"Customer Group\"][i] = \"Not Logged In\"\n",
    "            data_magento[\"Country\"][i] = data_magentoUser[\"Shipping Country\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "            data_magento[\"Region\"][i] = data_magentoUser[\"Shipping Province\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "            data_magento[\"City\"][i] = data_magentoUser[\"Shipping City\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "            data_magento[\"Zip Code\"][i] = data_magentoUser[\"Shipping Zip\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "            data_magento[\"Address\"][i] = data_magentoUser[\"Shipping Address1\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "            data_magento[\"Phone\"][i] = data_magentoUser[\"Shipping Phone\"].loc[data_magento[\"Order #\"][i]==data_magentoUser[\"Sales Order Id\"]].values[0]\n",
    "\n",
    "indeks = data_magento[data_magento['Phone'].isnull()].index.to_list()\n",
    "data_magento['Phone Condition'] = np.nan\n",
    "data_magento['Phone Condition'][indeks] = 'X'\n",
    "\n",
    "data_magentoUser['Sales Order Id'] = data_magentoUser['Sales Order Id'].astype(str)\n",
    "data_magento['Order #'] = data_magento['Order #'].astype(str)\n",
    "\n",
    "temp2 = data_magento.merge(data_magentoUser[['Sales Order Id', 'AWB', 'Shipping Cost', 'Shipping Address1', 'Shipping City', 'Shipping Province', 'Shipping Phone', 'Shipping Courier']].drop_duplicates('Sales Order Id'), how = 'left', left_on = 'Order #', right_on = 'Sales Order Id').set_index(data_magento.index)\n",
    "\n",
    "data_magento['Shipping'] = np.nan\n",
    "data_magento['AWB'] = np.nan\n",
    "data_magento['Shipping Courier'] = np.nan\n",
    "\n",
    "data_magento['Shipping'][temp2.index] = temp2['Shipping Cost']\n",
    "data_magento['AWB'][temp2.index] = temp2['AWB']\n",
    "data_magento['Shipping Courier'][temp2.index] = temp2['Shipping Courier']\n",
    "\n",
    "\n",
    "# Phone formatting\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].fillna(0.0)\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\" \",\"\")\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"-\",\"\")\n",
    "temp = data_magento[\"Phone\"].astype(str).str.split(\",\", expand = True)\n",
    "data_magento[\"Phone\"] = temp[0]\n",
    "temp = data_magento[\"Phone\"].astype(str).str.split(\"/\", expand = True)\n",
    "data_magento[\"Phone\"] = temp[0]\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^\\+620\", \"0\", regex = True)\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^\\+62\", \"0\")\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^620\", \"0\", regex = True)\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^62\", \"0\", regex = True)\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^8\", \"08\", regex = True)\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^62\", \"0\", regex = True)\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"(021)\", \"021\")\n",
    "data_magento[\"Phone\"] = data_magento[\"Phone\"].astype(str).str.replace(\"^21\", \"021\", regex = True)\n",
    "\n",
    "\n",
    "data_magento['Shipping Address1'] = np.nan\n",
    "data_magento['Shipping City'] = np.nan\n",
    "data_magento['Shipping Province'] = np.nan\n",
    "data_magento['Shipping Phone'] = np.nan\n",
    "\n",
    "# data_magento['Shipping Address1'][temp2.index] = temp2['Shipping Address1']\n",
    "# data_magento['Shipping City'][temp2.index] = temp2['Shipping City']\n",
    "# data_magento['Shipping Province'][temp2.index] = temp2['Shipping Province']\n",
    "# data_magento['Shipping Phone'][temp2.index] = temp2['Shipping Phone']\n",
    "\n",
    "\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].fillna(0.0)\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\" \",\"\")\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"-\",\"\")\n",
    "temp = data_magento[\"Shipping Phone\"].astype(str).str.split(\",\", expand = True)\n",
    "data_magento[\"Shipping Phone\"] = temp[0]\n",
    "temp = data_magento[\"Shipping Phone\"].astype(str).str.split(\"/\", expand = True)\n",
    "data_magento[\"Shipping Phone\"] = temp[0]\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^\\+620\", \"0\", regex = True)\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^\\+62\", \"0\")\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^620\", \"0\", regex = True)\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^62\", \"0\", regex = True)\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^8\", \"08\", regex = True)\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^62\", \"0\", regex = True)\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"(021)\", \"021\")\n",
    "data_magento[\"Shipping Phone\"] = data_magento[\"Shipping Phone\"].astype(str).str.replace(\"^21\", \"021\", regex = True)\n",
    "\n",
    "# Master tatanama\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Fulfilling SKU ====== 3/10\")\n",
    "\n",
    "data_magento['SKU'] = data_magento['SKU'].astype(str).str.split('-').str[0]\n",
    "indeks = data_magento[~data_magento['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))]['SKU'].index.to_list()\n",
    "\n",
    "skuhd = data_magento[data_magento['SKU'].astype(str).str.contains('hd', case = False)]\n",
    "skushopee = data_magento[data_magento['SKU'].astype(str).str.contains('(S)',regex = False)]\n",
    "data_magento = data_magento[~data_magento['SKU'].astype(str).isin(skushopee['SKU'].astype(str))]\n",
    "data_magento = data_magento[~data_magento['SKU'].astype(str).isin(skuhd['SKU'].astype(str))]\n",
    "\n",
    "skuhd = skuhd.reset_index(drop = True)\n",
    "skushopee = skushopee.reset_index(drop = True)\n",
    "data_magento = data_magento.reset_index(drop = True)\n",
    "\n",
    "indeks = data_magento[~data_magento['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))]['SKU'].index.to_list()\n",
    "for i in indeks:\n",
    "    if data_magento['Product Name'][i].lower() in data_SKU['Nama Produk'].str.lower().values:\n",
    "        data_magento['SKU'][i] = data_SKU['SKU'].loc[data_SKU['Nama Produk'].str.lower() == str(data_magento['Product Name'][i]).lower()].values[0]\n",
    "\n",
    "list_alias = []\n",
    "list_alias_name = []\n",
    "for colname in data_SKU.columns:\n",
    "    if 'Alias SKU' in colname:\n",
    "        list_alias.append(colname)\n",
    "    if 'Alias Nama' in colname:\n",
    "        list_alias_name.append(colname)\n",
    "\n",
    "for i in indeks:\n",
    "    for j in list_alias:\n",
    "        if str(data_magento['SKU'][i]) in data_SKU[j].astype(str).values:\n",
    "            idx = data_SKU[str(data_magento['SKU'][i]) == data_SKU[j].astype(str)].index.to_list()\n",
    "            for k in idx:\n",
    "                if str(data_magento['SKU'][i]) == data_SKU[j.replace('SKU', 'Nama')][k]:\n",
    "                    data_magento['SKU'][i] = data_SKU['SKU'][k]\n",
    "\n",
    "indeks = data_magento[~data_magento['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))]['SKU'].index.to_list()\n",
    "\n",
    "for i in indeks:\n",
    "    for j in list_alias_name:\n",
    "        if str(data_magento['Product Name'][i]).lower() in data_SKU[j].astype(str).str.lower().values:\n",
    "            data_magento['SKU'][i] = data_SKU['SKU'].loc[str(data_magento['Product Name'][i]).lower() == data_SKU[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'WRP Everyday Low Fat Milk Coklat 4 Pillow Bag']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Kitchen Vietnamese Coffee Latte (12 Sch)']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Blush Yo Raspberry Pumpkin (24 pcs)']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Blush Yo Raspberry Pumpkin (1 pc)']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Kitchen Thai Tea Latte (12 Sch)']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Blush Greek Yogurt Blueberry (24 Pcs)']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Blush Greek Yogurt Blueberry']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Blush Yo Lychee Spinach (24 Pcs)']\n",
    "data_magento = data_magento[data_magento['Product Name'].astype(str) != 'Heavenly Blush Yo Lychee Spinach (1 pc)']\n",
    "\n",
    "\n",
    "\n",
    "data_magento['SKU'] = data_magento['SKU'].astype(str).str.replace('7300281P24', '7300281')\n",
    "\n",
    "data_magento = data_magento[~data_magento['Product Name'].astype(str).str.contains('JANGAN DIORDER INI TESTING')]\n",
    "data_magento = data_magento[~data_magento['SKU'].astype(str).str.contains('7300851')]\n",
    "data_magento = data_magento[~data_magento['SKU'].astype(str).str.contains('F0301002006')]\n",
    "data_magento = data_magento[~data_magento['SKU'].astype(str).str.contains('F0302004002')]\n",
    "data_magento = data_magento[~data_magento['SKU'].astype(str).str.contains('F0301002005P24')]\n",
    "data_magento = data_magento[~data_magento['SKU'].astype(str).str.contains('F0301002005')]\n",
    "\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Listing SKU Missing ====== 4/10\")   \n",
    "idx = data_magento[['SKU']][data_magento['SKU'].isnull()].drop_duplicates().index.to_list()\n",
    "idx = idx + data_magento[['SKU', 'Product Name']][~data_magento['SKU'].astype(str).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "idx = list(dict.fromkeys(idx))\n",
    "idx_s = skushopee[~skushopee['SKU'].astype(str).str.replace('(S)','', regex = False).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "idx_s = list(dict.fromkeys(idx_s))\n",
    "idx_hd = skuhd[~skuhd['SKU'].astype(str).str.replace('hd','',case = False).isin(data_SKU['SKU'].astype(str))].index.to_list()\n",
    "idx_hd = list(dict.fromkeys(idx_hd))\n",
    "\n",
    "to_excel = data_magento.to_excel(r'magento_new.xls', index = False)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "if len(idx) != 0 or len(idx_s) != 0 or len(idx_hd) != 0:\n",
    "    print('SKU is missing')\n",
    "    alert = data_magento.iloc[idx, ][['SKU', 'Product Name']].drop_duplicates()\n",
    "    alert = alert.append(skushopee.iloc[idx_s][['SKU', 'Product Name']].drop_duplicates(), ignore_index = True, sort = False)\n",
    "    alert['SKU Valid'] = np.nan\n",
    "    to_excel = alert.to_excel('ALERT_MAGENTO_SKU_MISSING.xlsx')\n",
    "    print(\"Some SKU Missing Please Complete It ====== 5/10\")\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    s = smtplib.SMTP('smtp.gmail.com', 587) \n",
    "\n",
    "    # start TLS for security \n",
    "    s.starttls() \n",
    "\n",
    "    # Authentication \n",
    "    s.login(\"automationnfi@gmail.com\", \"nutrifood2020\") \n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['Subject'] = \"ALERT SKU MAGENTO MISSING\"\n",
    "\n",
    "\n",
    "    html = \"\"\"\\\n",
    "    <html>\n",
    "    <head></head>\n",
    "    <body>\n",
    "        {0}\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\".format(alert.to_html())\n",
    "\n",
    "    part1 = MIMEText(html, 'html')\n",
    "    msg.attach(part1)\n",
    "\n",
    "    # sending the mail \n",
    "    s.sendmail(\"automationnfi@gmail.com\", \"andra.miftah@nutrifood.co.id\", msg.as_string()) \n",
    "\n",
    "    # terminating the session \n",
    "    s.quit()\n",
    "else :\n",
    "    print(\"Preparing Appending Magento to Masterdata\")\n",
    "    print(\"Filling Brand ====== 5/10\")  \n",
    "    data_magento = data_magento.append(skushopee, ignore_index = True, sort = False)\n",
    "    data_magento = data_magento.reset_index(drop = True)\n",
    "\n",
    "    data_magento['SKU'] = data_magento['SKU'].astype(str)\n",
    "    data_magento['Product Name'] = data_magento['Product Name'].astype(str)\n",
    "    data_SKU['Real SKU'] = data_SKU['SKU'].astype(str)\n",
    "    data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "\n",
    "    data_magento = data_magento.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "    temp = data_magento[data_magento['Real SKU'].isnull()].copy()\n",
    "    temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "    temp = temp.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "    temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "    temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "    temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "    temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "    indeks = data_magento[data_magento['Real SKU'].isnull()].index.to_list()\n",
    "    data_magento['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "    data_magento['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "    temp = data_magento[data_magento['Real SKU'].isnull()].copy()\n",
    "    temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "    temp = temp.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "    temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "    temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "    temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "    temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "    indeks = data_magento[data_magento['Real SKU'].isnull()].index.to_list()\n",
    "    data_magento['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "    data_magento['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "    data_magento['Real SKU'] = data_magento['Real SKU'].astype(str)\n",
    "    data_magento = data_magento.merge(data_SKU[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "    data_magento = data_magento.drop(['SKU_y'], axis = 1)\n",
    "    data_magento = data_magento.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"Unbundling ====== 6/10\")\n",
    "    list_col = ['SKU'] + data_SKU.columns[data_SKU.columns.get_loc('Produk 1'):data_SKU.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "    data_magento = data_magento.merge(data_SKU[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "    data_magento = data_magento.drop(['SKU_y'], axis = 1)\n",
    "    data_magento = data_magento.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "    indeks = data_magento[data_magento['Brand'] == 'Bundle'].index.to_list()\n",
    "    data_magento['Bundle Flag'] = np.nan\n",
    "    data_magento['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"Filling Date ====== 7/10\")\n",
    "    data_magento['Date'] = np.nan\n",
    "    data_magento['Month'] = np.nan\n",
    "    data_magento['Year'] = np.nan\n",
    "\n",
    "    for i in range(data_magento.shape[0]):\n",
    "        if int(data_magento['Order date'][i].strftime('%d')) <= 12:\n",
    "            data_magento['Date'][i] = pd.to_datetime(data_magento['Order date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "            data_magento['Month'][i] = pd.to_datetime(data_magento['Order date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "            data_magento['Year'][i] = pd.to_datetime(data_magento['Order date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "        else :\n",
    "            data_magento['Date'][i] = pd.to_datetime(data_magento['Order date'][i]).day\n",
    "            data_magento['Month'][i] = pd.to_datetime(data_magento['Order date'][i]).month_name()\n",
    "            data_magento['Year'][i] = pd.to_datetime(data_magento['Order date'][i]).year\n",
    "\n",
    "\n",
    "    quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "            ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "    data_magento = data_magento.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "    data_magento = data_magento.drop(['Bulan'], axis = 1)\n",
    "    data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "            {'Bulan' : 'January' , 'Number': 1},\n",
    "            {'Bulan' : 'February' , 'Number': 2},\n",
    "            {'Bulan' : 'March' , 'Number': 3},\n",
    "            {'Bulan' : 'April' , 'Number': 4},\n",
    "            {'Bulan' : 'May' , 'Number': 5},\n",
    "            {'Bulan' : 'June', 'Number': 6},\n",
    "            {'Bulan' : 'July' , 'Number': 7},\n",
    "            {'Bulan' : 'August', 'Number' : 8},\n",
    "            {'Bulan' : 'September', 'Number' : 9},\n",
    "            {'Bulan' : 'October' , 'Number': 10},\n",
    "            {'Bulan' : 'November' , 'Number': 11}])\n",
    "    temp = data_magento.copy()\n",
    "    temp['Day'] = temp['Date']\n",
    "    temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "    temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "    data_magento['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "    data_magento['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day']])\n",
    "    data_magento['Channel'] = 'Nutrimart'\n",
    "    data_magento['Store'] = 'Nutrimart'\n",
    "    data_magento['Selling Price'] = data_magento['Item Price']\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"Pricing\")\n",
    "    data_magento = data_magento.merge(data_SKU[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(data_magento.index)\n",
    "    data_magento = data_magento.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "    data_magento['Price List NFI'] = pd.to_numeric(data_magento['Price List NFI']).astype(int)\n",
    "    data_magento['Harga Cost'] = pd.to_numeric(data_magento['Harga Cost'], errors = 'coerce').fillna(0).astype(int)\n",
    "    data_magento['Qty. Invoiced'] = pd.to_numeric(data_magento['Qty. Invoiced']).astype(int)\n",
    "    data_magento['Total Net'] = data_magento['Price List NFI'] * data_magento['Qty. Invoiced']\n",
    "    data_magento['Total Harga Cost'] = data_magento['Harga Cost'] * data_magento['Qty. Invoiced']\n",
    "\n",
    "    data_magento = data_magento.drop('SKU_y', axis = 1)\n",
    "    data_magento = data_magento.reset_index(drop = True)\n",
    "    data_magento['Order #'] = data_magento['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "    list_bundle = data_magento[data_magento['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "    list_nobundle = data_magento[data_magento['Bundle Name'].notnull()]\n",
    "    list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "    list_nobundle\n",
    "\n",
    "    data_magento['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "    data_magento['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "    temp = data_magento[data_magento['Bundle Name'].notnull()]\n",
    "    temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "    temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "    temp['Selling Price'] = temp['Subtotal'] / temp['Qty. Invoiced']\n",
    "\n",
    "    data_magento['Total'][temp.index] = temp['Total'].fillna(0).astype(int)\n",
    "    data_magento['Subtotal'][temp.index] = temp['Subtotal'].fillna(0).astype(int)\n",
    "    data_magento['Selling Price'][temp.index] = temp['Selling Price'].fillna(0).astype(int)\n",
    "\n",
    "    print(\"Filling Location\")\n",
    "    data_magento['Kecamatan'] = np.nan\n",
    "    data_magento['Kelurahan'] = np.nan\n",
    "#             data_magento = data_magento.rename(columns = {'Shipping City' : 'City', 'Shipping Province' : 'Region'})\n",
    "\n",
    "    indeks = data_magento[data_magento['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        data_magento['Kecamatan'][indeks] = data_magento['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "        data_magento['City'][indeks] = data_magento['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "    indeks = data_magento[data_magento['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        data_magento['Kelurahan'][indeks] = data_magento['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "        data_magento['Kecamatan'][indeks] = data_magento['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "    indeks = data_magento[data_magento['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        data_magento['Kecamatan'][indeks] = data_magento['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "        data_magento['City'][indeks] = data_magento['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "    indeks = data_magento[data_magento['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        data_magento['Kelurahan'][indeks] = data_magento['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "        data_magento['Kecamatan'][indeks] = data_magento['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "    city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "    temp = data_magento.copy()\n",
    "    temp['City'] = temp['City'].astype(str).str.lower()\n",
    "    city['All City'] = city['All City'].astype(str).str.lower()\n",
    "    temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "    indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "    data_magento['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "    province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "    temp = data_magento.copy()\n",
    "    temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "    province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "    temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "    indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "    data_magento['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "    temp = data_magento.copy()\n",
    "    temp = temp[temp['Region'].isnull()]\n",
    "    temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "    data_magento['Region'][temp.index] = temp['Region']\n",
    "\n",
    "    district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "    temp = data_magento.copy()\n",
    "    temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "    district['All District'] = district['All District'].astype(str).str.lower()\n",
    "    temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "    indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "    data_magento['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "    temp = data_magento.copy()\n",
    "    temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "    indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "    data_magento['City'][indeks] = np.nan\n",
    "\n",
    "    indeks = data_magento[data_magento['Shipping City'].astype(str).str.contains('/')]['Shipping City'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        data_magento['Shipping City'][indeks] = data_magento['Shipping City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "    indeks = data_magento[data_magento['Shipping City'].astype(str).str.contains(',')]['Shipping City'].index.to_list()\n",
    "    if len(indeks)>0:\n",
    "        data_magento['Shipping City'][indeks] = data_magento['Shipping City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "    city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "    temp = data_magento.copy()\n",
    "    temp['Shipping City'] = temp['Shipping City'].astype(str).str.lower()\n",
    "    city['All City'] = city['All City'].astype(str).str.lower()\n",
    "    temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'Shipping City', right_on = 'All City').set_index(temp.index)\n",
    "    indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "    data_magento['Shipping City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "    province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "    temp = data_magento.copy()\n",
    "    temp['Shipping Province'] = temp['Shipping Province'].astype(str).str.lower()\n",
    "    province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "    temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Shipping Province', right_on = 'All Province').set_index(temp.index)\n",
    "    indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "    data_magento['Shipping Province'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "    temp = data_magento.copy()\n",
    "    temp = temp[temp['Shipping Province'].isnull()]\n",
    "    temp['Shipping Province'] = temp.merge(master_map, how = 'left', left_on = 'Shipping City', right_on = 'City').set_index(temp.index)['Shipping Province']\n",
    "    data_magento['Shipping Province'][temp.index] = temp['Shipping Province']\n",
    "\n",
    "    temp = data_magento.copy()\n",
    "    temp2 = temp[['Shipping Province', 'Shipping City']].merge(master_map, how = 'left', left_on = 'Shipping City', right_on = 'City')\n",
    "    indeks = temp2[temp2['Shipping Province'] != temp2['Province']][temp2[temp2['Shipping Province'] != temp2['Province']]['Shipping City'].notnull()].index.to_list()\n",
    "    data_magento['Shipping City'][indeks] = np.nan\n",
    "    data_magento['Warehouse Name'] = 'Primary Warehouse'\n",
    "\n",
    "    import os\n",
    "    import glob\n",
    "\n",
    "    list_of_files = glob.glob('D:\\Masterdata\\Clean Data\\*.csv')\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "\n",
    "    data_all = pd.read_csv(latest_file, sep = ';',converters = {'Phone' : str, 'Order #' : str, 'AWB' : str})\n",
    "    data_all = data_all[data_all['Store Type'] != 'Retail Online']\n",
    "\n",
    "    data_all['Phone'] = data_all['Phone'].astype(str).str.replace('=\"', '', regex = False)\n",
    "    data_all['Phone'] = data_all['Phone'].astype(str).str.replace('\"', '', regex = False)\n",
    "\n",
    "    lmen_store = forstok_all[forstok_all['Channel'] == 'L-Men Store Blibli']\n",
    "    forstok_all = forstok_all[forstok_all['Channel'] != 'L-Men Store Blibli']\n",
    "\n",
    "    lmen_store = lmen_store[~lmen_store['Order #'].astype(str).isin(data_all['Order #'].astype(str))]\n",
    "    lmen_store['Sales Order ID'] = lmen_store['Sales Order ID'].fillna(lmen_store['No. Order Item L-Men Blibli'])\n",
    "    ornum = lmen_store[['Order #', 'Sales Order ID']].drop_duplicates('Order #')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": str(os.getcwd())  + '/Input Data',\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.maximize_window()\n",
    "    driver.get(\"https://seller.blibli.com/sign-in\")\n",
    "    time.sleep(30)\n",
    "\n",
    "\n",
    "    username = driver.find_element_by_id(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customer1@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_id(\"password\")\n",
    "    password.send_keys(\"Nutrimart12345\")\n",
    "\n",
    "    driver.find_element_by_id(\"sign-in\").click()\n",
    "    time.sleep(25)\n",
    "    #             WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'close-announcement-button'))).click()\n",
    "    #             WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, 'remind-me-later-button'))).click()\n",
    "    #     WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, 'nav-wrapper-ORDER'))).click()\n",
    "    #     driver.find_element_by_id(\"sub-nav-item-0\").click()\n",
    "    driver.get(\"https://seller.blibli.com/MTA/order/summary\")\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'btn-primary-mta'))).click()\n",
    "    driver.find_element_by_id(\"semuaFilter\").click()\n",
    "\n",
    "    ornum['Phone'] = np.nan\n",
    "    ornum['Email'] = np.nan\n",
    "    ornum['Address'] = np.nan\n",
    "\n",
    "    for i in ornum.index:\n",
    "        orderNo = ornum['Order #'][i]\n",
    "        orderItemNo = int(pd.to_numeric(ornum['Sales Order ID'][i]))\n",
    "        link = \"https://merchant.blibli.com/MTA/neo/order/order-detail/\" + \"?orderNo=\" + str(orderNo) + \"&orderItemNo=\" + str(orderItemNo)\n",
    "        driver.get(link)\n",
    "        WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"customer-phone\"]/div/span')))\n",
    "        hp = driver.find_elements_by_xpath('//*[@id=\"customer-phone\"]/div/span')[0].text\n",
    "        if len(driver.find_elements_by_xpath('//*[@id=\"customer-email\"]/span')) != 0:\n",
    "            email = driver.find_elements_by_xpath('//*[@id=\"customer-email\"]/span')[0].text\n",
    "            ornum['Email'][i] = email\n",
    "        address = driver.find_elements_by_xpath('//*[@id=\"alamat-pengiriman\"]//div//p')[0].text\n",
    "        ornum['Phone'][i] = hp\n",
    "        ornum['Address'][i] = address\n",
    "\n",
    "    driver.quit()\n",
    "    if len(ornum) != 0:\n",
    "        tes = ornum.copy()\n",
    "        tes['Real Address'] = tes['Address'].str.split('\\n', expand = True)[1].str.strip()\n",
    "        tes['Kelurahan'] = tes['Address'].str.split('\\n', expand = True)[3].str.split('-', expand = True)[0].str.strip()\n",
    "        tes['Kecamatan'] = tes['Address'].str.split('\\n', expand = True)[3].str.split('-', expand = True)[1].str.strip()\n",
    "        tes['City'] = tes['Address'].str.split('\\n', expand = True)[4].str.split(',', expand = True)[0].str.strip()\n",
    "        tes['Region'] = tes['Address'].str.split('\\n', expand = True)[4].str.split(',', expand = True)[1].str.strip()\n",
    "        tes['Zip Code'] = tes['Address'].str.split('\\n', expand = True)[5].str.strip()\n",
    "\n",
    "        lmen_store['Order #'] = lmen_store['Order #'].astype(str)\n",
    "        tes['Order #'] = tes['Order #'].astype(str)\n",
    "        lmen_store = lmen_store.merge(tes[['Order #', 'Phone', 'Email', 'Real Address', 'Kelurahan', 'Kecamatan', 'City', 'Region', 'Zip Code']].drop_duplicates('Order #'), how = 'left', on = 'Order #')\n",
    "\n",
    "        indeks = lmen_store[lmen_store['Phone_y'].notnull()].index.to_list()\n",
    "        lmen_store['Phone_x'][indeks] = lmen_store['Phone_y'][indeks]\n",
    "        lmen_store['Customer Email'][indeks] = lmen_store['Email'][indeks]\n",
    "        lmen_store['Phone_x'][indeks] = lmen_store['Phone_y'][indeks]\n",
    "        lmen_store['Region_x'][indeks] = lmen_store['Region_y'][indeks]\n",
    "        lmen_store['City_x'][indeks] = lmen_store['City_y'][indeks]\n",
    "        lmen_store['Kecamatan_x'][indeks] = lmen_store['Kecamatan_y'][indeks]\n",
    "        lmen_store['Kelurahan_x'][indeks] = lmen_store['Kelurahan_y'][indeks]\n",
    "        lmen_store['Zip Code_x'][indeks] = lmen_store['Zip Code_y'][indeks]\n",
    "        lmen_store['Address'][indeks] = lmen_store['Real Address'][indeks]\n",
    "\n",
    "        lmen_store = lmen_store.drop(['Phone_y', 'Email', 'Region_y', 'City_y', 'Kecamatan_y', 'Kelurahan_y', 'Real Address', 'Zip Code_y'], axis = 1)\n",
    "        lmen_store = lmen_store.rename(columns = {'Phone_x' : 'Phone', 'Region_x' : 'Region', 'City_x' : 'City', 'Kecamatan_x' : 'Kecamatan', 'Kelurahan_x' : 'Kelurahan', 'Zip Code_x' : 'Zip Code'})\n",
    "\n",
    "    forstok_all = forstok_all.append(lmen_store, ignore_index = True, sort = False)\n",
    "\n",
    "    indeks = data_all[data_all['Channel'] == 'L-Men Store Blibli'].index.to_list()\n",
    "    data_all['Store'][indeks] = 'Blibli'\n",
    "\n",
    "    print('Blibli Done')\n",
    "    \n",
    "    data_all = data_all[~data_all['Order #'].astype(str).isin(forstok_all['Order #'].astype(str))]\n",
    "    data_all = data_all[~data_all['Order #'].astype(str).isin(data_magento['Order #'].astype(str))]\n",
    "    data_all = data_all.append(forstok_all, ignore_index = True, sort = False)\n",
    "    data_all = data_all.append(data_magento, ignore_index = True, sort = False)\n",
    "    data_all['Brand'] = data_all['Brand'].astype(str).str.replace('Tropicana Slim', 'TS')\n",
    "\n",
    "    indeks = data_all[data_all['Qty. Invoiced'] == 0].index.to_list()\n",
    "    data_all['Qty. Invoiced'][indeks] = data_all['Qty. Shipped'][indeks]\n",
    "    data_all['Total Net'][indeks] = data_all['Price List NFI'][indeks] * data_all['Qty. Invoiced'][indeks]\n",
    "    indeks = data_all[data_all['Qty. Invoiced'] == 0].index.to_list()\n",
    "    data_all['Qty. Invoiced'][indeks] = data_all['Qty. Ordered'][indeks]\n",
    "    data_all['Total Net'][indeks] = data_all['Price List NFI'][indeks] * data_all['Qty. Invoiced'][indeks]\n",
    "\n",
    "#   Cleaning Phone Number\n",
    "    import re \n",
    "    from re import sub            \n",
    "    data_all['Phone'] = data_all['Phone'].astype(str).str.split(';', expand = True)[0]\n",
    "    data_all['Phone'] = data_all['Phone'].astype(str).str.replace('.0','', regex = False)\n",
    "    data_all['Phone'] = data_all['Phone'].astype(str).str.replace('+','', regex = False)\n",
    "    non_phone = data_all[(data_all['Phone'].astype(str).str.startswith('62'))]['Phone'].unique()\n",
    "    non_phone1 = data_all[(data_all['Phone'].astype(str).str.startswith('62'))][['Store','Phone']].drop_duplicates()\n",
    "    for i in non_phone:\n",
    "        index = data_all[data_all['Phone'].astype(str) == str(i)].index.to_list()\n",
    "        phone = str(i).replace('62','0', 1)\n",
    "        print(i, phone, sep='-')\n",
    "        data_all['Phone'][index] = phone\n",
    "            \n",
    "    print('done')\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    data_all['Phone'] = data_all['Phone'].apply('=\"{}\"'.format)\n",
    "    data_all['Shipping Phone'] = data_all['Shipping Phone'].apply('=\"{}\"'.format)\n",
    "    indeks = data_all[data_all['City'] == 'nan'].index.to_list()\n",
    "    data_all['City'][indeks] = np.nan\n",
    "\n",
    "    indeks = data_all[data_all['Region'] == 'nan'].index.to_list()\n",
    "    data_all['Region'][indeks] = np.nan\n",
    "\n",
    "    indeks = data_all[data_all['Channel'] == 'FBL'].index.to_list()\n",
    "    data_all['Warehouse Name'][indeks] = 'Lazada Warehouse'\n",
    "\n",
    "    indeks = data_all[data_all['Warehouse Name'] == 'Lazada Warehouse'].index.to_list()\n",
    "    data_all['Channel'][indeks] = 'FBL'\n",
    "\n",
    "    print(\"Read Data Settlement\")\n",
    "    \n",
    "    print('Opening Chrome')\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    actions = ActionChains(driver)\n",
    "    driver.get(\"https://www.forstok.com/dashboard/users/login\")\n",
    "    print('Login Forstok')\n",
    "    username = driver.find_element_by_id(\"dashboard_user_email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"timotius.giovandi@nutrifood.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_id(\"dashboard_user_password\")\n",
    "    password.send_keys(\"timo123\")\n",
    "    \n",
    "    driver.find_element_by_name(\"commit\").click()\n",
    "    \n",
    "    time.sleep(20)\n",
    "    datefield = WebDriverWait(driver, 100).until(EC.element_to_be_clickable((By.XPATH,'//*[@type=\"button\" and contains(text(),\"Last 30 days\")]')))\n",
    "    datef = WebDriverWait(driver, 200).until(EC.element_to_be_clickable((By.XPATH,'//*[@id=\"root\"]/section/section[2]/article/div/div/aside/div/div[1]/section[5]/section[1]/h2')))\n",
    "    driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datef)\n",
    "    time.sleep(30)\n",
    "    driver.execute_script(\"return arguments[0].scrollIntoView(true);\", datefield)\n",
    "    time.sleep(10)\n",
    "    datefield.click()\n",
    "    pilih=0\n",
    "    while pilih < 3:    \n",
    "            n_elem=0\n",
    "            for i in driver.find_elements_by_xpath('(//*[@class=\"DateRangePicker__MonthHeaderLabel DateRangePicker__MonthHeaderLabel--month\"])'):\n",
    "                val=(driver.find_elements_by_xpath('(//*[@class=\"DateRangePicker__MonthHeaderLabel DateRangePicker__MonthHeaderLabel--month\"])')[n_elem].text.split()[0])\n",
    "                if val==start_date.strftime('%B'):\n",
    "                    # print(n_elem)\n",
    "                    fin_n_elem=n_elem\n",
    "                n_elem=n_elem+1\n",
    "            if fin_n_elem==0:\n",
    "                text = '(//*[@class=\"DateRangePicker__Month\"])[1]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(start_date.day) + '\")]'\n",
    "                if len(driver.find_elements_by_xpath(text))==2:\n",
    "                    text = '('+text+')[2]'\n",
    "            else:\n",
    "                text = '(//*[@class=\"DateRangePicker__Month\"])[2]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(start_date.day) + '\")]'\n",
    "                if len(driver.find_elements_by_xpath(text))==2:\n",
    "                    text = '('+text+')[1]'\n",
    "            driver.find_element_by_xpath(text).click()\n",
    "            time.sleep(10)\n",
    "\n",
    "            n_elem=0\n",
    "            for i in driver.find_elements_by_xpath('(//*[@class=\"DateRangePicker__MonthHeaderLabel DateRangePicker__MonthHeaderLabel--month\"])'):\n",
    "                val=(driver.find_elements_by_xpath('(//*[@class=\"DateRangePicker__MonthHeaderLabel DateRangePicker__MonthHeaderLabel--month\"])')[n_elem].text.split()[0])\n",
    "                if val==end_date.strftime('%B'):\n",
    "                    fin_n_elem=n_elem\n",
    "                n_elem=n_elem+1\n",
    "            if fin_n_elem==0:\n",
    "                text = '(//*[@class=\"DateRangePicker__Month\"])[1]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(end_date.day) + '\")]'\n",
    "                if len(driver.find_elements_by_xpath(text))==2:\n",
    "                    text = '('+text+')[2]'\n",
    "            else:\n",
    "                text = '(//*[@class=\"DateRangePicker__Month\"])[2]//*[@class=\"DateRangePicker__DateLabel\" and (text()=\"' + str(end_date.day) + '\")]'\n",
    "                if end_date.strftime('%B')==start_date.strftime('%B'):\n",
    "                    text = '('+text+')[2]'\n",
    "                else :\n",
    "                    text = '('+text+')[1]'\n",
    "            driver.find_element_by_xpath(text).click()\n",
    "            time.sleep(10)\n",
    "            pilih=pilih+1\n",
    "    driver.find_element_by_xpath('//*[@type=\"button\" and contains(text(),\"Apply\")]').click()\n",
    "    time.sleep(100)\n",
    "    WebDriverWait(driver, 30).until(EC.element_to_be_clickable((By.XPATH, \"(//*[@type='button' and contains(text(),'Export')])[1]\"))).click()\n",
    "    driver.find_element_by_xpath('//span[text()=\"Sales Order\"]').click()\n",
    "    driver.find_element_by_xpath('//span[text()=\"Sales Order\"]').click()\n",
    "    WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"(//*[@type='button' and contains(text(),'Export')])[2]\"))).click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    print('Forstok Downloaded')\n",
    "\n",
    "    print('Download Data SKU')\n",
    "    # Import library\n",
    "\n",
    "    import time\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import math\n",
    "\n",
    "    import smtplib \n",
    "    from email.mime.text import MIMEText\n",
    "    from email.mime.application import MIMEApplication\n",
    "    from email.mime.multipart import MIMEMultipart\n",
    "    from smtplib import SMTP\n",
    "    import smtplib\n",
    "    import sys\n",
    "    import requests\n",
    "    import os\n",
    "\n",
    "    print('Waiting to Download Forstok 1')\n",
    "    s = requests.Session()\n",
    "    r = s.get(\"https://www.forstok.com/dashboard/users/login\")\n",
    "    data = {'dashboard_user_email' : 'timotius.giovandi@nutrifood.co.id', \"dashboard_user_password\" : 'timo123'}\n",
    "    r = s.post(\"https://www.forstok.com/dashboard/users/login\", data = data)\n",
    "\n",
    "    text = 'https://forstok-staging-storage.s3.ap-southeast-1.amazonaws.com/items_import/nutrifood--forstok-sales_orders-version_1-' + date + '.xls'\n",
    "    print(text)\n",
    "    while True:\n",
    "        r = s.get(text)\n",
    "        print('Waiting to Download Forstok 2')\n",
    "\n",
    "        if r.status_code == requests.codes.ok:\n",
    "            print(r.status_code)\n",
    "            with open('Input Data/Forstok_new_input.xls', 'wb') as output:\n",
    "                output.write(r.content)\n",
    "            print('output out')\n",
    "            break\n",
    "        else :\n",
    "            time.sleep(60)\n",
    "\n",
    "    with open('Input Data/nutrifood--forstok-sales_orders-' + date + '.xls', 'wb') as output:\n",
    "        output.write(r.content)\n",
    "\n",
    "    orstat_forstok = pd.read_excel(r'Input Data/Forstok_new_input.xls')\n",
    "    orstat_forstok['Date'] = np.nan\n",
    "    orstat_forstok['Month'] = np.nan\n",
    "    orstat_forstok['Year'] = np.nan\n",
    "\n",
    "    orstat_forstok['Order Date'] = pd.to_datetime(orstat_forstok['Order Date'])\n",
    "    for i in range(orstat_forstok.shape[0]):\n",
    "        if int(orstat_forstok['Order Date'][i].strftime('%d')) <= 12:\n",
    "            orstat_forstok['Date'][i] = pd.to_datetime(orstat_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "            orstat_forstok['Month'][i] = pd.to_datetime(orstat_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "            orstat_forstok['Year'][i] = pd.to_datetime(orstat_forstok['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "        else :\n",
    "            orstat_forstok['Date'][i] = pd.to_datetime(orstat_forstok['Order Date'][i]).day\n",
    "            orstat_forstok['Month'][i] = pd.to_datetime(orstat_forstok['Order Date'][i]).month_name()\n",
    "            orstat_forstok['Year'][i] = pd.to_datetime(orstat_forstok['Order Date'][i]).year\n",
    "\n",
    "    temp = orstat_forstok.copy()\n",
    "    temp['Day'] = temp['Date']\n",
    "    temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "    temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "    orstat_forstok['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "    temp['Hour'] = pd.to_datetime(orstat_forstok['Order Date']).dt.hour\n",
    "    temp['Minute'] = pd.to_datetime(orstat_forstok['Order Date']).dt.minute\n",
    "    temp['Second'] = pd.to_datetime(orstat_forstok['Order Date']).dt.second\n",
    "    orstat_forstok['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "    print(\"Update Order Status\")\n",
    "    date_min  = orstat_forstok['True datetime'].min()\n",
    "    orstat_forstok = orstat_forstok[['Sales Order ID','Status']].drop_duplicates('Sales Order ID')\n",
    "    shopee_bp = data_all[data_all['Customer Name'] == 'Shopee Brand Portal']\n",
    "    data_all = data_all[data_all['Customer Name'] != 'Shopee Brand Portal']\n",
    "    temp_all = data_all[data_all['True datetime'] >= pd.to_datetime(date_min)][~data_all[data_all['True datetime'] >= pd.to_datetime(date_min)]['Channel'].isin(['Nutrimart', 'L-Men Store Blibli', 'Order Online', 'Order Online Jakarta', 'Order Online Surabaya'])]\n",
    "    orstat_forstok['Sales Order ID'] = orstat_forstok['Sales Order ID'].astype(str)\n",
    "    temp_all['Sales Order ID'] = temp_all['Sales Order ID'].astype(str)\n",
    "    temp_all = temp_all.merge(orstat_forstok, how = 'left', on = 'Sales Order ID')\n",
    "    temp_all['Status'] = temp_all['Status'].fillna('Canceled')\n",
    "    temp_all['Order Status'] = temp_all['Status']\n",
    "    temp_all = temp_all.drop('Status', axis = 1)\n",
    "    data_all['Order #'] = data_all['Order #'].astype(str)\n",
    "    temp_all['Order #'] = temp_all['Order #'].astype(str)\n",
    "    data_all = data_all[~data_all['Order #'].isin(temp_all['Order #'])]\n",
    "    data_all = data_all.append(temp_all, ignore_index = True, sort = False)\n",
    "    data_all = data_all.append(shopee_bp, ignore_index = True, sort = False)\n",
    "    print(\"Export Master Data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08056513",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['62', '62293491451', '6218935183349', '6291239657995',\n",
       "       '6271233337458', '629812331232', '621239657995', '621241920815',\n",
       "       '6271239657995', '6292370388788', '620895356352333',\n",
       "       '62987688645333', '6271347626463', '62313723419', '620',\n",
       "       '6291347626463', '62721771322', '6277850341800', '622345989093',\n",
       "       '629', '6271271512942', '6290', '6211', '62283161782312',\n",
       "       '6278704608139', '6277336717123', '6275242637182', '6215', '6208',\n",
       "       '6239', '6234', '6260', '6248', '6217', '6235', '6254', '6249',\n",
       "       '6230', '6220', '6277', '6261', '6247', '6255', '6299', '6224',\n",
       "       '6292', '6204', '6201', '6214', '6266', '6233', '6227', '6232',\n",
       "       '6269', '6226', '6241', '6274', '6262', '6259', '6216', '6273',\n",
       "       '6210', '6223', '6298', '6229', '6245', '6243', '6228', '6275',\n",
       "       '6200', '6258', '6225', '6205', '6279', '6240', '6251', '6268',\n",
       "       '6202', '6218', '6207', '6270', '6236', '6213', '6263', '6272',\n",
       "       '6267', '6231', '6271', '6256', '6296', '6252', '6253', '6242',\n",
       "       '6212', '6221', '6237', '6206', '6238', '6276', '6203', '6219',\n",
       "       '6250', '6265', '6244', '6297', '6209', '6257', '6278', '6246',\n",
       "       '6294', '6285852035606', '6282335308993', '6287840037917',\n",
       "       '6282226868412', '6282139432399', '6285749999432', '628563292890',\n",
       "       '6281330424669', '6282244142841', '628563356327', '62881036596273',\n",
       "       '6281938777090', '6285791997097', '6281946220760', '6289525347371',\n",
       "       '6281914108302', '6289688256600', '6287851682778', '628973803650',\n",
       "       '6289685343071', '6285668971742', '6282232597557', '6281216138041',\n",
       "       '6287766696320', '6285204236213', '6285257216829', '6285334134474',\n",
       "       '6287758160169', '6285777235467', '6285852032000', '6289687358278',\n",
       "       '6282139013028', '6281359020693', '6282155022207', '6281344567621',\n",
       "       '6281334733348', '6281334557372', '62895710281000',\n",
       "       '6281335432632', '62895322354080', '6285645220987',\n",
       "       '6282248159910', '6282243182358', '6283141134855', '6285749015823',\n",
       "       '6281233174863', '6285735545655', '6285735373761',\n",
       "       '62854643452390', '6281217579807', '6285232587788',\n",
       "       '6281237456724', '628135765558', '62899199600', '6285731934865',\n",
       "       '6281336054945', '6281217498009', '6282147531661', '6281233355861',\n",
       "       '6282230678590', '6282333828579', '6285736946413', '6282113120664',\n",
       "       '6282141447646', '6282331750462', '6282302042728', '6282132482209',\n",
       "       '6281234842380', '6285700895692', '6287703379759', '6281803874471',\n",
       "       '6285235455325', '6285850309810', '6281330324742', '6281997796601',\n",
       "       '6281235407525', '6285755946583', '6285784722742', '6281334178920',\n",
       "       '628953038048', '628773301184', '6285704004677', '6283831111384',\n",
       "       '6282232000676', '6287861124103', '6289693292000', '6281249693155',\n",
       "       '6282132171212', '6285754635475', '628214072307', '6282285333325',\n",
       "       '6283146852889', '6281217602514', '6281334470047', '6281215909003',\n",
       "       '6285601067466', '6281331393200', '6282141648578', '6285736522843',\n",
       "       '6285778681114', '6285646526153', '62838311113840',\n",
       "       '6281331108819', '6285100594956', '6287777188444', '6289680634999',\n",
       "       '6285859777547', '6285755597567', '62881036596272', '628968533444',\n",
       "       '6283162941110', '62895392399977', '6282233640841',\n",
       "       '6282139592128', '6285331891635', '6287878615946', '6289955006148',\n",
       "       '6282331341608', '628174147421', '6283866358370', '6287758890030',\n",
       "       '6285737093803', '6282234321166', '6289525041697', '6281334564766',\n",
       "       '6287857697340', '6281345665754', '6285677456766', '6289677474623',\n",
       "       '6281335829550', '6285648687858', '6281334520675', '6285732482293',\n",
       "       '6285735001413', '6281336182649', '6281221321888', '6281233557441',\n",
       "       '6285102200622', '6285895186108', '6282331597258', '6285299069074',\n",
       "       '6281733652295', '628574688446', '6281334537655', '6281775482907',\n",
       "       '6285708314052', '6281233434766', '6281345665897', '6287665486756',\n",
       "       '6285745256942', '6281216625768', '6285606188669',\n",
       "       '62895336053396', '6285815180216', '6287886871055',\n",
       "       '6285850183515', '6285105139637', '6281212080881',\n",
       "       '62895421859561', '6285853406961', '6281344321176',\n",
       "       '6281358191292', '62895356352333', '6285656028812',\n",
       "       '6287758695307', '6289615141773', '6287878719508', '6281319749212',\n",
       "       '6283149936035', '6281330414123', '6281359982040', '6282146295552',\n",
       "       '6289621232088', '6285784433761', '6281335180039', '628123326558',\n",
       "       '6281333309016', '6281325172751', '6281216526626', '6282139240298',\n",
       "       '628193828634801', '6285692433861', '6285668394133',\n",
       "       '6285859865046', '6281249634433', '6285780581706', '6283854198732',\n",
       "       '6283835555517', '6281346789967', '6281252345075', '6289521503884',\n",
       "       '628123200660', '6285711364058', '6281805894598', '6281615459630',\n",
       "       '6282228366152', '6285338259600', '6289621839712', '6285230495707',\n",
       "       '6287888809706', '6282140636457', '6285645067188', '6285816789435',\n",
       "       '6285954714480', '628818469767', '6281322114582', '6285649925553',\n",
       "       '6281310777088', '6285259616297', '6285731986488', '6281359548387',\n",
       "       '628138312951', '628123116916', '62881036052209', '6285708510279',\n",
       "       '6282331600115', '628113031767', '6281334340888', '6289516113356',\n",
       "       '6289649088931', '6287759738939', '6281336183842', '628133044201',\n",
       "       '6285855648068', '6285708663312', '6282131696829', '6282244964944',\n",
       "       '6285856182856', '628175098299', '6282245154829', '6281235071108',\n",
       "       '6282246542335', '6281333163796', '6285733262093', '6282234326220',\n",
       "       '6282230714416', '6281216346022', '6285204926668', '6285648921000',\n",
       "       '6282334891290', '6285330558766', '628125847098', '628813318352',\n",
       "       '6282131028879', '6289544317546', '6281234516870', '6281333966060',\n",
       "       '6282398354350', '6285732512994', '6281235722236', '6285646242666',\n",
       "       '6287851940060', '6281344512411', '6281330720433', '6282175270941',\n",
       "       '6285225273499', '6287810677911', '6282122832503', '6282380847923',\n",
       "       '6282380213410', '6282387297538', '62811783769', '6282114462706',\n",
       "       '6282374041283', '6282278594731', '6281231718904', '6281373661504',\n",
       "       '6285896190802', '6287815537538', '6285267094835', '6285266868552',\n",
       "       '628973658731', '62895336121188', '6281809797952', '6285702074535',\n",
       "       '628985844725', '6289689973395', '6285866272006', '6285870000069',\n",
       "       '6283869766361', '6285725022721', '6285725459988', '6285742085970',\n",
       "       '6282290209709', '62882008771637', '6282133727302',\n",
       "       '6285171515230', '6281802466660', '6282335101057',\n",
       "       '62821255555415', '62895350942899', '6285559201182',\n",
       "       '6282135393563', '6289673904300', '6285729632411', '6289603552464',\n",
       "       '6282175107117', '62895415907111', '6285801147995',\n",
       "       '6285600637378', '6281227043289', '6285643686161', '6282135316135',\n",
       "       '6287830430483', '6285325484480', '62895636528128',\n",
       "       '6289636989335', '628122810296', '6282329147707', '6282220128479',\n",
       "       '6282243973456', '6281226312960', '6285877681151', '6281211913466',\n",
       "       '6283878671891', '6285943804260', '6282228228399', '6281388871934',\n",
       "       '6285641138170', '6285877247363', '6287830414242', '6282329147704',\n",
       "       '6281239657995', '6282146957614', '6287853683048', '6281353230582',\n",
       "       '6282116921227', '6281934381250', '6287762648820', '6282144020282',\n",
       "       '628814728614', '6287855083527', '6281805540464', '6281338720234',\n",
       "       '6281916303952', '6281238228266', '6281337732114', '6287815640796',\n",
       "       '6282141446689', '6281339620971', '624113612807', '6295765701012',\n",
       "       '6285753430049', '6281350034035', '6285250770123',\n",
       "       '62895700101871', '6285351315511', '6281351781556',\n",
       "       '6281224693205', '6281322251752', '6282284312183', '628125538239',\n",
       "       '6285246743559', '6285250630333', '628115000857', '6281295558876',\n",
       "       '6282154533540', '6283170683241', '628117213377', '62895613208000',\n",
       "       '6285664644461', '6281368121153', '6281363800307', '6282121391113',\n",
       "       '6281546255207', '6289510116538', '6281326738534', '6285382499024',\n",
       "       '6282379565006', '6281532274413', '628117211756', '6283184988694',\n",
       "       '6281367596460', '6285887819880', '6289637576042', '6285250055181',\n",
       "       '628127917821', '6281272059461', '6282280671423', '6288287684277',\n",
       "       '6289616007416', '6289602307553', '6282258774098', '6282186138545',\n",
       "       '6281273518880', '6288286888776', '6287899844432', '6281272790557',\n",
       "       '6282281010011', '6281278579980', '6285841245494', '628994683340',\n",
       "       '6282176010996', '6281272391009', '62895640519743',\n",
       "       '62895608037030', '6282181105034', '6282113371204',\n",
       "       '6282376187881', '6281369108646', '6285832651077', '6285669333511',\n",
       "       '6282179320622', '6281273437253', '628995742342', '6281367889106',\n",
       "       '6287806711085', '6281379115359', '6281268158963', '6285355261087',\n",
       "       '6285271622030', '6281378254878', '6281276553511', '6282387310107',\n",
       "       '6281276668479', '62811758850', '6285157730807', '6281267512690',\n",
       "       '6281276121223', '6285156781577', '6289525231062', '6282385546821',\n",
       "       '6285265588800', '628117681488', '628127537960', '628127677156',\n",
       "       '6282285064529', '6285210883939', '6287734775959', '6281917992332',\n",
       "       '6281374087969', '6288296243377', '6285240007228', '6281365609714',\n",
       "       '6281248831908', '628127555128', '6282170082245', '6288279225102',\n",
       "       '6281275409856', '6282255912202', '6282250724632', '6282353021433',\n",
       "       '6285849666339', '6282281552383', '6285750587210', '6281348199855',\n",
       "       '6281350086425', '6285218000060', '6281347544082', '6285389154190',\n",
       "       '6281348683005', '6281346500281', '628115144441', '6288809502807',\n",
       "       '62895358441870', '6281223016687', '6281283114652', '628994466965',\n",
       "       '6281220071052', '6281222230760', '6281312621293', '6289654505065',\n",
       "       '6285798483828', '6287780465710', '6287718857117', '6281322378580',\n",
       "       '6289655523801', '62895393580009', '6285694433860',\n",
       "       '6281315867733', '62895333728028', '6283824153875',\n",
       "       '6283107231314'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d730a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0c6a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555a1ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2608fe27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c991f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a17d3bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245a396a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6146dfcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78fd26f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a97853e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bfd049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68a7f043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### if sku missing di magento\n",
    "### to do : listing di tatanama rerun kode atas Run -4 \n",
    "data_magento[~data_magento['SKU'].isin(data_SKU['SKU'])]['Product Name'].unique()\n",
    "data_magento[~data_magento['SKU'].isin(data_SKU['SKU'])]['SKU'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee24331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17430c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6945a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb82c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run-5\n",
    "indeks = data_all[data_all['Qty. Invoiced'].isnull()].index.to_list()\n",
    "data_all['Qty. Invoiced'][indeks] = 0\n",
    "data_all['Total Net'][indeks] = data_all['Price List NFI'][indeks] * data_all['Qty. Invoiced'][indeks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73050790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed37837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c25268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8711fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##run-6\n",
    "order_online_cond = False\n",
    "shopee_scrap = False\n",
    "shopee_done = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceb243a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c822ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75c9338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##run-7\n",
    "order_online_jatim = False\n",
    "order_online_jkt = False\n",
    "order_online_jateng = False\n",
    "order_online_bali = False\n",
    "order_online_makasar = False\n",
    "order_online_samarinda = False\n",
    "order_online_medan = False\n",
    "order_online_lampung = False\n",
    "order_online_pekanbaru = False\n",
    "order_online_banjarmasin = False\n",
    "order_online_jabar = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c79c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9562ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757cdfe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6ca66f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_online_lampung\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6321: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6324: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6329: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6336: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6346: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6357: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6358: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6359: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6360: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6361: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6363: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6364: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6365: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6366: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6367: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6369: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6370: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6371: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6372: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6374: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6375: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6376: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6377: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6378: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6379: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6380: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6381: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6382: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6383: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6384: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6385: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6386: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6387: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6388: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6389: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6390: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6391: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6393: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo School Susu Coklat (10 sch) Gusset - Khusus Homdel', 45800, 22900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6450: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 126.93186640739441 seconds ---\n",
      "Unbundling ====== 6/10\n",
      "--- 127.01914882659912 seconds ---\n",
      "Filling Date ====== 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6625: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6685: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Location\n",
      "Unbundling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6798: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pricing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6816: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:6828: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7039: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_online_pekanbaru\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7130: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7133: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7138: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7145: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7155: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7166: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7167: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7168: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7169: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7170: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7172: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7173: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7174: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7175: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7176: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7178: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7179: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7180: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7181: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7183: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7184: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7185: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7186: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7187: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7188: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7189: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7190: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7191: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7192: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7193: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7194: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7195: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7196: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7197: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7198: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7199: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7200: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 233.55008816719055 seconds ---\n",
      "Unbundling ====== 6/10\n",
      "--- 233.6253800392151 seconds ---\n",
      "Filling Date ====== 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7432: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7494: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Location\n",
      "Unbundling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7607: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pricing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7625: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7637: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7848: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_online_banjarmasin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7936: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7939: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7944: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7951: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7961: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7972: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7973: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7974: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7975: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7976: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7978: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7979: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7980: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7981: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7982: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7984: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7985: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7986: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7987: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7989: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7990: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7991: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7992: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7993: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7994: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7995: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7996: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7997: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7998: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:7999: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8000: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8001: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8002: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8003: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8004: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8005: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8006: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 317.89954566955566 seconds ---\n",
      "Unbundling ====== 6/10\n",
      "--- 317.92915773391724 seconds ---\n",
      "Filling Date ====== 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8237: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8299: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Location\n",
      "Unbundling\n",
      "Pricing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8412: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8430: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8442: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8653: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_online_jabar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8741: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8744: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8749: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8756: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8766: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8777: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8778: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8779: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8780: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8781: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8783: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8784: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8785: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8786: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8787: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8789: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8790: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8791: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8792: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8794: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8795: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8796: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8797: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8798: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8799: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8800: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8801: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8802: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8803: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8804: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8805: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8806: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8807: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8808: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8809: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8810: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:8811: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 399.8916800022125 seconds ---\n",
      "Unbundling ====== 6/10\n",
      "--- 399.9267818927765 seconds ---\n",
      "Filling Date ====== 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:9042: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:9104: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Location\n",
      "Unbundling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:9217: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:9235: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:9247: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_order = data_order.append(temp , ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pricing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3124578757.py:9458: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "## run 8\n",
    "## until all region true\n",
    "## error : add missing prod to code line jatim jkt jateng, other to \"D:\\Masterdata\\Order Online\\SKU buat andra updated maret 2021.xlsx\"\n",
    "\n",
    "start_time = time.time()\n",
    "if not order_online_jatim:\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "    \n",
    "    print('order_online_jatim')\n",
    "    ##komen sementara\n",
    "\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "    \n",
    "    time.sleep(30)\n",
    "\n",
    "    username = driver.find_element_by_name(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customer@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_name(\"password\")\n",
    "    password.send_keys(\"jatimhomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element_by_class_name(\"btn-submit\").click()\n",
    "\n",
    "    WebDriverWait(driver, 60).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div').click()\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    time.sleep(10)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/button').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/div/button[1]').click()\n",
    "\n",
    "    time.sleep(60)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    \n",
    "    #komen sementara\n",
    "    # data_order=pd.read_csv(r\"D:\\Masterdata\\Input Data\\orderonline_orders_all_products_08-07-2022_MOoUrPq6Pzq0pu2y.csv\")\n",
    "    driver.close()\n",
    "#     data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Surabaya.csv')\n",
    "    product_order = pd.read_csv(r'Input Data/orderonline_products_Surabaya.csv')\n",
    "    \n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    \n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('L-Men Hi Protein 2 Go Chocolate (24 pcs) - 12gr Protein / Serving', 'L-Men Hi Protein 2 Go Chocolate (24 pcs)', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch (x2) ', 'Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch ', regex = False)\n",
    "\n",
    "    \n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch')\n",
    "#     indeks = data_order[data_order['product'].astype(str).str.contains('L-Men Hi Protein 2 Go Chocolate 24 pcs')].index.to_list()\n",
    "#     data_order['Quantity'][indeks] = 1\n",
    "                        \n",
    "    product_order['title'] = product_order['title'].str.strip().str.replace('  ', ' ')\n",
    "    product_order['title'] = product_order['title'].str.strip().str.replace('L-Men Gain Mass Chocolate 500 gr', 'L Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Mango Smoothie 200ml (6pcs)', 36300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (6pcs)', 48000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate (12sch)', 5500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey (50sch)', 39500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Orange 750ml', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 225gr', 57500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gainmass Taro 225gr', 69600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 139200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Mangga Gandaria (40 sch)', 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 750gr + Free Kertas Gambar', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Jeruk Peras (40sch x 2) + Nutrisari Mangga Gandaria (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Blewah (40sch x 2) + Nutrisari Jeruk Maroko (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Nutrisari American Sweet Orange (40sch x 2) + Nutrisari Milky Orange (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 500gr + Free Kertas Gambar', 117600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 750gr', 127100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 Sch)', 15000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Es Cincau 40 sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sunflower Oil 946 ml', 52800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Lose Weight Chocolate Cereal 300gr\", 118800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Platinum Choco Latte Dus 6 sch\", 80000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 pcs)\", 264000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 10500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Gain Mass Banana 225gr\", 61000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate 12 sch\", 105600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Hilo Chocolate Taro (10 sch)\", 14700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 1 GET 1 - W'Dank Empon Empon 10 Sachet Renceng\", 15000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 15000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(FREE) W'Dank Empon-Empon 10 sch\", 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Teen Chocolate 1000 gr\", 136400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-MEN Gain Mass Taro 225 gr\", 52800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Whey Daily Dark Chocolate 250gr\", 49500]], columns = ['title', 'price']), ignore_index = True, sort = False)                                        \n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 13200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Hilo Es Ketan Hitam 10 sch\", 13200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo School Honey 500gr\", 71500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Teen Vanilla 750gr\", 102300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 26400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 26400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "#     product_order = product_order.append(pd.DataFrame([[\"Hilo Es Ketan Hitam 10 sch\", 13200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)', 52000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim Sweetener Jahe 50 sch\", 38500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim Korean Garlic Butter Cookies 5 Sch\", 17500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sambal Terasi 200 gr', 29700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2', 107800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)', 67500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Protein Bar Chocolate 12 sch', 105600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Protein Crunch BBQ Beef (20gr)', 9900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Avocado Coffee 4 Sch x 2', 24200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Avocado Coffee 4 Sch', 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Taro 500gr', 71500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 28900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 20700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Cocopandan 40 sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Shirataki Noodles 71gr', 28100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Saus Tiram 200ml', 39600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Shirataki Noodles 71gr', 14200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Saus Tiram 200ml', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim White Coffee (4sch)', 17600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hampers Idul Fitri Tropicana Slim', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Takjil HiLo Dessert', 67500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Ramadhan NutriSari 2021', 60000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Kehangatan WDank - Ramadhan Edition', 60000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Platinum Kacang Hijau 800g', 275000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Topping Kental Manis 150ml - SUGAR FREE', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Whey Advanced Cappuccino 250gr', 79200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Minyak Kanola 946ml - 100% Pure Canola Oil - Free Korean Garlic Butter Cookies 1 sch', 59400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Minyak Kanola 946ml', 59400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(EACH)Tropicana Slim Korean Garlic Butter Cookies - Sampling', 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Platinum Ketan Hitam 800g (25g protein / serving) - Suplemen Tinggi Whey Protein Rendah Lemak', 302500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Whey Advanced Choco Vanilla 500gr', 148500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['FREE Cookies - Tropicana Slim Susu Skim Chocolate 500gr - Bantu Turunkan Kolesterol', 106700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['FREE Cookies - Tropicana Slim Cafe Latte 10 Sachet 14gr - Kopi Susu Nikmat Tanpa Gula Pasir', 27500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Platinum Choco Latte 800gr (25gr protein)', 302500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['FREE Cookies - Tropicana Slim Susu Skim Plain 1000gr - Bantu Turunkan Kolesterol', 180400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['FREE Cookies - Tropicana Slim Susu Skim Coffee 500gr - Bantu Turunkan Kolesterol', 106700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack - HiLo Active Es Teler 175gr', 38000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Es Teler 175gr', 19000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Apel Jeruk 40 Sachet', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo Teen Popcorn Caramel 500 gram x 2', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Avocado Coffee 4 Sch', 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch', 57800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Rose Vanilla 50 sch', 28900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Milk Skim Chocolate 500gr', 106700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Milk Skim Coffee 500gr', 106700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Extra Virgin Olive Oil 500 ml - [Free] Tropicana Slim Shirataki Noodles 71gr', 83500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Chocolate 750g Susu Tinggi Kalsium Lebih Rendah Lemak - [FREE] HiLo Active Ketan Hitam 175g', 111000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim DIABTX (100 sch) - [FREE] Tropicana Slim Avocado Coffee 4 Sch', 76000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Milk Skim Original 1kg', 187700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Oat Drink 190 ml (RTD) x 4 pcs', 22600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Es Rujak Jeruk Bali 40 Sachet', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Oat Drink 190 ml (RTD)', 5650]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Mayonnaise 200 g x 2', 34800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Mayonnaise 200 g - Bantu Dukung Hidup Sehat', 17400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Chocolate 1000 gr', 115500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: L-Men Daily Popcorn Caramel 250gr x 2', 78200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Extra Virgin Olive Oil 500 ml', 83500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Daily Popcorn Caramel 250gr', 39100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 - HiLo Gold Sweet Potato 500 gram', 73200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NuTrilogi Seri Jeje Si Jeli', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Asin 200 ml', 24600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Sweet Potato 500 gram', 73200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(FREE) HiLo Gold Sweet Potato 500 gram', 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 FREE HiLo Joint Plus 140gr', 38300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Joint Plus Orange 140 gram', 38300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(FREE) HiLo Joint Plus Orange 140 gram', 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Korean Goguma Cookies (5 Sch) x 2', 32200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Goguma Cookies (5 Sch)', 16100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NuTrilogi Seri Mba Nana Si Penuh Pesona', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Popcorn Caramel 500gr', 68600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Chocolate 1000 gr', 141900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Lokalate Kopi Andaliman 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Lokalate Kopi Tape Ketan 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Special Bundle - Tropicana Slim Sweetener Rose Vanilla & Tropicana Slim Korean Goguma Cookies', 55000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Andaliman 10 Sachet', 6850]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Tape Ketan 10 Sachet', 6850]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Rose Vanilla 50 sch', 40000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(FREE) Lokalate Kopi Andaliman 10 Sachet', 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(FREE) Lokalate Kopi Tape Ketan 10 Sachet', 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Goguma Cookies (5 Sch)', 16100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Plain 1000 gr', 128200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NuTrilogi Seri Mas Kaka yang Banyak Akal', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo School Strawberry Cheesecake 500 gram x 2', 110600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Strawberry Cheesecake 500 gram', 55300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo Joint Plus Orange 140 gram x 2', 55300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Vanilla Vegiberi 750gr', 76600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Madu Kurma Pack (4R)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Jeruk Jeju [40 Sachet]', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Es Rujak (4R)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Jeruk Nipis (40 sch)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Madu Lemon (40 Sch)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Thai Tea (10 sch)', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Chocolate Taro RTD 200ml (4pcs)', 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Swiss Chocolate (10 sch) Renceng', 17200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo Teen Coffee Tiramisu Ready To Drink Susu UHT [4 pcs]', 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo Teen Chocolate Ready To Drink Susu [4 pcs]', 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Vanilla Vegiberi Ready To Drink Susu [200ml/4 pcs]', 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Lychee Tea 40 sch', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Yuzu Orange 40 sch', 46200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Jeruk Manis 500gr', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo Gold Sweet Potato 500 gram x 2', 105600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin pack - Lokalate Kopi Andaliman 10 Sachet', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Sweet Potato 500 gram', 52800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Andaliman 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin pack - Lokalate Kopi Tape Ketan 10 Sachet', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Tape Ketan 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim DIABTX (100 sch)', 76100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Nutty Chocolate Cookies 200gr', 40000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Markisa (40 Sch)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Madu Jeruk (40sch)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari NUTRI C1000 Jeruk 40 Sachet', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Chocolate 500gr', 61800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"W'Dank Bajigur (10 sch)\", 17200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener I Sweet', 21700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Kacang Hijau 200gr', 40000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack - Lokalate Kopi Tape Ketan 10 Sachet', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Tape Ketan 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Classic Refill 500gr', 98400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Milk Skim Fiber Pro Plain 500gr', 111000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Vanilla Caramel 500gr', 76600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim High Fiber High Calcium Milk Chocolate 500gr', 112100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack - Lokalate Kopi Andaliman 10 Sachet', 35000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Andaliman 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo Almond Milk Coconut 200gr x 2', 70000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Almond Milk Coconut 200gr', 35000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Yoghurt Smoothie Bowl Strawberry (8 sch)', 62900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"W'Dank Bandrek 10 sachet Renceng\", 17200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo School Chocolate Candy (10 sch)\", 18300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"2102500320 (CI160)\", 72160]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"2102500336 (CS)\", 45100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Jeruk Maroko (40 Sch) FREE Lokalate Andaliman (10 Sch)\", 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Jeruk Peras Refill 500 gr\", 34300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Nutrisari Jeruk Maroko (40 sch)\", 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(FREE) Lokalate Kopi Andaliman 10 Sachet\", 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twin Pack:HiLo Teen Strawberry Milkshake 500g x 2\", 100000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Teen Strawberry Milkshake 500g\", 50000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo School Chocolate Ready To Drink (4 tetrapack)\", 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo School RTD Coklat 200ml\", 6525]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim Sirup Leci 750ml\", 30900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Mango Smoothie 200ml (4 Pcs)\", 27500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari RTD Jeruk Madu 200 ml (4 tetrapack)\", 22900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari RTD Mango Smoothie 200 ml\", 6900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari RTD Jeruk Madu 200 ml\", 5750]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Active Chocolate 750gr\", 89200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate x 4 pcs\", 38400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate\", 9600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey 50 sachet', 40000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Triple Pack - Tropicana Slim Klepon Cookies (5 Sch) - Snack Bebas Gula, 100 Kalori', 50000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Klepon Cookies (5 Sch)', 16700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Platinum Swiss Chocolate 420gr', 91500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Chocolate 250g (Health & Green Science Competition)', 38300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Shirataki Rice 72 g', 50000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Shirataki Rice 72 g', 25000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Jeruk Nipis Jahe 40 Sachet', 35000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Vanilla 500gr', 65200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Yoghurt Banana 250gr', 38400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['TS SHIRATAKI RICE RASA NASI UDUK 24PX72G', 29700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Cotton Candy 500g', 62500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Es Kuwud Nipis', 37500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Lychee Tea Refill 500 gram', 34300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Thai Tea Ready to Drink 200ml x 4pcs', 23600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo RTD Thai Tea 200ml', 5900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 Free - HiLo School Bubble Gum 500g', 92400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED) HiLo School RTD Coklat 200ML', 6270]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Brownies Instant Powder Cake Mix 230 g - Bantu Dukung Hidup Sehat', 59400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Klepon Latte Refill 500g - Powder Drink Tinggi Kalsium', 49500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim BROWNIES  Instant Powder Cake Mix 230 g', 29700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Caramel Latte 500g', 50500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Avocado Chocolate (10 Sch)', 127160]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Bundle - HiLo Teen Taro 500gr & HiLo Teen Strawberry Milkshake 500g', 11400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Taro 500gr', 63600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Strawberry Milkshake 500g', 63600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED)Bundle L-Men Platinum Ketan Hitam 800g & L-Men Platinum Kacang Hijau 800g', 314600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED)L-Men Platinum Ketan Hitam 800g ', 157300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED)L-Men Platinum Kacang Hijau 800g', 157300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED)Twinpack: L-Men Platinum Kacang Hijau 800g', 314600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED)L-Men Platinum Kacang Hijau 800g', 157300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Es Ketan Hitam 500g - Powder Drink Tinggi Kalsium', 44000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Biscuit Caramel 500gr', 65000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Plain (Original) 500gr', 77800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Lemon Tea 500 gram', 34300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Lokalate Kopi Pisang Bakar 10 sch', 17500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Pisang Bakar Epe 10 sch', 8750]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Bubble Gum 500g', 80100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack/B1G1 HiLo Multigrain Original 500g', 176000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Multigrain Original 500g', 88000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Lemon-C (25 sch)', 25200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Belgian Chocolate (10 sch)', 49200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Chocolate Polos 10's\", 12000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo White Chocolate (10 Sch)', 12000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Cookies Paket Hampers Idul Fitri Parcel Lebaran', 131600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Chocolate Banana 10 sch', 12000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese Cookies', 22300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Nutty Chocolate Cookies 200gr', 40000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Garlic Butter Cookies 5 Sch', 22300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Goguma Cookies (5 Sch)', 22300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Klepon Cookies (5 Sch)', 21500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Gift - Paper Bag Ramadhan Tropicana Slim', 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Es Pisang Ijo 10 Sch x 2 pcs', 17500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Mangga 500gr', 132700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 - Tropicana Slim Mint Cocoa - Minuman Cokelat Mint Nikmat Tanpa Gula Pasir', 20000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 FREE L-Men Lose Weight Mango Sticky Rice 300gr', 145200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 FREE Tropicana Slim Susu Low Fat Macchiato Coffee 500gr', 143000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Diabetamil Milk Vanilla 150 gram', 29700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Susu Low Fat Macchiato Coffee 500 gram', 71500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Brownies Instant Powder Cake Mix 230 g - Bantu Dukung Hidup Sehat', 30900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-MEN PLANTPROTEIN OGURA 6Dx216G', 103900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr - Near ED', 16150]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Choco Series Paket Hampers Idul Fitri Parcel Lebaran', 139600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 1000g - Susu Tinggi Kalsium Lebih Rendah Lemak', 104800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Vanilla 1000g - Susu Tinggi Kalsium Lebih Rendah Lemak', 115500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Vanilla 1000g - Susu Tinggi Kalsium Lebih Rendah Lemak', 86650]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Es Pisang Ijo 10 Sch', 14300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Soy Latte - Kopi Plant Based Rendah Gula', 36900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Mint Cocoa 4 Sachet', 20000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Taro 500g x 2 pcs', 133900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 Free - HiLo Gold Biscuit Cereal 500g', 80800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Alpukat 500 gram - Tinggi Vitamin A Lebih Rendah Gula', 44400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Thai Tea Refill 500g', 48000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Soy Latte - Kopi Susu Kacang Bebas Gula', 36900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Berondong 500 gram - Tinggi Vitamin A Lebih Rendah Gula', 44400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['2102900319 (D)', 90400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Biscuit Cereal 500g', 80800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Anggur Hijau 40 Sachet', 43300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Gula Asem 40 Sachet', 43300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack - Tropicana Slim Low Fat Milk Korean Strawberry 500g', 159900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Low Fat Milk Korean Strawberry 500g', 79900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese Cookies 100gr', 22500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Wdank Madu Temulawak 10 Sachet', 16600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Es Ketan Hitam Refill 500g - Powder Drink Tinggi Kalsium', 59400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) Lokalate Kopi Tape Ketan 10's\", 7500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED) HiLo Joint Plus Orange 140 gram', 19150]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED) BUY 1 GET 1 L-Men Gain Mass Mangga 500gr', 132700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED) HiLo Teen Taro 500gr', 43300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Bundle - Lokalate Kopi Alpukat Refill 500 gram & Kopi Berondong Refill 500 gram', 92400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Thai Tea RTD 200ml x 4pcs', 24000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 1 GET 1 - W'Dank Temulawak Madu\", 33300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['TRIPLE HEMAT - HiLo Thai Tea Refill 500g', 100900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['TRIPLE HEMAT - NutriSari Lemon Tea 500 gram', 72700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"W'dank Sarabba Extra 10 Sachet\", 18870]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"W'dank Madu Temulawak 10 Sachet\", 16650]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Blewah 40 sch', 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Mangga Gandaria 40 sch', 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Nutrisari Jeruk Nipis 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Nutrisari American Sweet Orange 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Jeruk Peras 40 sch', 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Milky Orange 40 sch', 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Chocolate Polos 10 sch\", 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Madu Lemon 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"Nutrisari Florida Orange 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Anggur Hijau 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari NUTRI C1000 Jeruk 40 sch', 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Markisa 40 sch', 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Es Kuwud Nipis 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"TRIPLE HEMAT - NutriSari Lychee Tea Refill 500 gram\", 72700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"Nutrisari Jeruk Maroko 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Apel Jeruk 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo Chocolate Taro 10 sch', 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Avocado Chocolate 10 sch', 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 1 GET 1 - HiLo Platinum Original 360 gram\", 111000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"TRIPLE DEALS - NutriSari Lychee Tea & Lemon Tea 500 gram Refill\", 72700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Gula Asem 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Nutrisari Madu Jeruk 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Lemon Tea Refill 500 gram\", 34600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"TRIPLE HEMAT - HiLo Klepon Latte Refill 500g\", 109100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twinpack Tropicana Slim Bumbu Saus Telur Asin 3 Sachet - Lebih Rendah Lemak dan Garam\", 29000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Madu Kurma Pack 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo White Chocolate 10 sch\", 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Taro Latte Refill 500g\", 32700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Es Rujak 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Es Rujak Jeruk Bali 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"TRIPLE DEALS - HiLo Thai Tea , Klepon Latte , Taro Latte Refill 500g\", 103900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"Buy 3 Get 3 - HiLo Milky Vanilla Cookies Ready to Drink 200ml\", 60000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twinpack Lokalate Kopi Alpukat Refill 500 gram\", 92400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twinpack Lokalate Kopi Berondong Refill 500 gram\", 92400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Nutrisari Jeruk Jeju 40 sch\", 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "     \n",
    "    price = product_order[product_order['title'] == 'Tropicana Slim Goldenmil Vanilla (6sch)']['price'].values[0]\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    price = product_order[product_order['title'] == 'Lokalate Kopi Kawista (10sch)']['price'].values[0]\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Lokalate Kopi Kawista (10sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    price = product_order[product_order['title'] == 'Tropicana Slim Kecap Manis 200ml']['price'].values[0]\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200m', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    data_SKU = pd.read_excel(r'Order Online\\SKU buat andra.xlsx')\n",
    "    data_SKU = data_SKU.rename(columns = {'Unnamed: 0' : 'SKU', 'ref.1' : 'product', 'Pricelist Nutrimart' : 'Price List NFI', 'Harga jua Homdel' : 'Harga Display'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip()\n",
    "\n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "    product_order['title'] = product_order['title'].astype(str)\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "    # data_order = data_order[data_order['SKU'].notnull()]\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    s = requests.Session()\n",
    "    s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    with open(r'SKU_File\\Master tatanama.xlsx', 'wb') as output:\n",
    "        output.write(r.content)\n",
    "\n",
    "    if os.path.isfile(r'SKU_File\\Master tatanama.xlsx') :    \n",
    "        SKU_append = pd.read_excel(r'SKU_File\\Master tatanama.xlsx')\n",
    "        SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "        data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "        data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    to_excel = data_SKU2.to_excel(r'SKU_File\\data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "#     data_order = data_order[~data_order['product'].astype(str).isin(['2102500336 (CS)'])]\n",
    "#     data_order = data_order.reset_index(drop = True)\n",
    "    \n",
    "#     data_order = data_order[~data_order['product'].astype(str).isin(['2102500320 (CI160)'])]\n",
    "#     data_order = data_order.reset_index(drop = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    \n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Surabaya'\n",
    "\n",
    "    #     list_drop = []\n",
    "    #     indeks = data_order[data_order['SKU'].isin(data_SKU2[data_SKU2['Brand'] == 'Bundle']['SKU'])].index.to_list()\n",
    "    #     for i in indeks:\n",
    "    #         if str(data_order['SKU'][i]) in data_SKU2['SKU'].astype(str).values:\n",
    "    #             idx = data_SKU2[str(data_order['SKU'][i] ) == data_SKU2['SKU'].astype(str)].index[0]\n",
    "    #             for j in range(1,8):\n",
    "    #                 colname = 'Produk ' + str(j)\n",
    "    #                 if str(data_SKU2[colname][idx]) != 'nan':\n",
    "    #                     new_data = data_order.iloc[i,]\n",
    "    #                     new_data['Item Name'] = data_SKU2[colname][idx]\n",
    "    #                     new_data['Selling Price'] = data_SKU2['Subtotal ' + colname][idx] * new_data['Quantity']\n",
    "    #                     new_data['Quantity'] = new_data['Quantity'] * data_SKU2['PCS ' + colname][idx]\n",
    "    #                     new_data['SKU'] = str(data_SKU2['SKU ' + colname][idx]).replace('.0','')\n",
    "    #                     new_data['Quantity'] = str(new_data['Quantity']).replace('.0','')\n",
    "    #                     new_data['Selling Price'] = str(new_data['Selling Price']).replace('.0','')\n",
    "    #                     data_order = data_order.append(new_data, ignore_index = True)\n",
    "    #                     list_drop.append(i)\n",
    "    #     data_order = data_order.drop(list_drop, axis = 0)\n",
    "    #     data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "    #     for i in range(data_order.shape[0]):\n",
    "    #         if int(data_order['Order date'][i].strftime('%d')) < 12:\n",
    "    #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i].strftime('%Y-%d-%m %H:%M'))\n",
    "    #         else :\n",
    "    #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i])\n",
    "        indeks = data_order[data_order['Item Name'].astype(str).str.contains('pcs')].index.to_list()\n",
    "        temp = data_order.iloc[indeks].copy()\n",
    "        product = temp['Item Name'].str.split(\"\\(\",1, expand = True)\n",
    "#         if len(product) != 0:\n",
    "#             temp['Quantity Inside'] = product[1].astype(str).str.replace('pcs)', '', regex = False).astype(int)\n",
    "#             data_order['Quantity'][indeks] = data_order['Quantity'][indeks] * temp['Quantity Inside']\n",
    "\n",
    "    #     data_order_1 = data_order[data_order['payment_method'] == 'cod']\n",
    "    #     data_order_2 = data_order[data_order['payment_method'] != 'cod'][data_order[data_order['payment_method'] != 'cod']['payment_status'] == 'paid']\n",
    "    #     data_WMS = data_order_1.append(data_order_2, ignore_index = True, sort = False)\n",
    "    #     data_WMS = data_WMS[['Order date', 'Channel', 'Sales Order ID', 'Channel Order ID', 'Invoice Number', 'Customer Name', 'Item Name', 'SKU', 'Quantity', 'Price', 'Shipping Cost', 'Shipping Name', 'Shipping Address1', 'Shipping Address2', 'Shipping City', 'Shipping Zip', 'Shipping Province', 'Shipping Country', 'Shipping Phone', 'Shipping Courier', 'AWB']]\n",
    "    #     data_WMS.to_excel(r'data_WMS_OrderOnline.xlsx', index = False)\n",
    "    #     print('Finished')\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        index = order_all[order_all['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        order_all['SKU'][index] = '2306592173'\n",
    "        order_all['Real SKU'][index] = '2306592173'\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Price' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "        \n",
    "        \n",
    "        \n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500320 (CI160)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "        \n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        \n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "        \n",
    "        order_all['Selling Price'] = order_all['Regular Price'].astype(int)\n",
    "        \n",
    "        data_SKU3 = pd.read_excel(r'Order Online\\SKU buat andra updated maret 2021.xlsx')\n",
    "        data_SKU3 = data_SKU3.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "        data_SKU3['SKU'] = data_SKU3['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "        data_SKU3 = data_SKU3[data_SKU3['SKU'] != 'nan'][data_SKU3[data_SKU3['SKU'] != 'nan']['SKU'] != '0'][data_SKU3[data_SKU3['SKU'] != 'nan'][data_SKU3[data_SKU3['SKU'] != 'nan']['SKU'] != '0']['Harga Coret'].notnull()]\n",
    "        data_SKU3['product'] = data_SKU3['product'].str.strip()\n",
    "        data_SKU3 = data_SKU3.reset_index(drop = True)\n",
    "        \n",
    "        for i in range(data_SKU3.shape[0]):\n",
    "            if data_SKU3['SKU'][i] in order_all['SKU'].values:\n",
    "                indeks = order_all[order_all['SKU'].astype(str) == i].index.to_list()\n",
    "                order_all['Regular Price'][indeks] = data_SKU3['Harga Display'][i]\n",
    "                order_all['Selling Price'][indeks] = data_SKU3['Harga Coret'][i]\n",
    "        \n",
    "        \n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Order Online Surabaya Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "         'Product Name',\n",
    "         'Customer Name',\n",
    "         'Phone',\n",
    "         'Address',\n",
    "         'Region',\n",
    "         'City',\n",
    "         'Zip Code',\n",
    "         'payment_status',\n",
    "         'Regular Price',\n",
    "         'Shipping Courier',\n",
    "         'Shipping Cost',\n",
    "         'Subtotal',\n",
    "         'Qty. Invoiced',\n",
    "         'SKU',\n",
    "         'Order #',\n",
    "         'Invoice Number',\n",
    "         'Shipping Name',\n",
    "         'Shipping Address2',\n",
    "         'Country',\n",
    "         'AWB',\n",
    "         'Channel',\n",
    "         'Order date',\n",
    "         'Real SKU',\n",
    "         'Real Nama Produk',\n",
    "         'Brand',\n",
    "         'Sub Brand',\n",
    "         'Parent Item',\n",
    "         'Parent SKU',\n",
    "         'Produk 1',\n",
    "         'SKU Produk 1',\n",
    "         'PCS Produk 1',\n",
    "         'Price List NFI 1',\n",
    "         'Subtotal Produk 1',\n",
    "         'Harga Display 1',\n",
    "         'Harga Cost 1',\n",
    "         'Harga Organik 1',\n",
    "         'Produk 2',\n",
    "         'SKU Produk 2',\n",
    "         'PCS Produk 2',\n",
    "         'Price List NFI 2',\n",
    "         'Subtotal Produk 2',\n",
    "         'Harga Display 2',\n",
    "         'Harga Cost 2',\n",
    "         'Harga Organik 2',\n",
    "         'Produk 3',\n",
    "         'SKU Produk 3',\n",
    "         'PCS Produk 3',\n",
    "         'Price List NFI 3',\n",
    "         'Subtotal Produk 3',\n",
    "         'Harga Display 3',\n",
    "         'Harga Cost 3',\n",
    "         'Harga Organik 3',\n",
    "         'Produk 4',\n",
    "         'SKU Produk 4',\n",
    "         'PCS Produk 4',\n",
    "         'Price List NFI 4',\n",
    "         'Subtotal Produk 4',\n",
    "         'Harga Display 4',\n",
    "         'Harga Cost 4',\n",
    "         'Harga Organik 4',\n",
    "         'Produk 5',\n",
    "         'SKU Produk 5',\n",
    "         'PCS Produk 5',\n",
    "         'Price List NFI 5',\n",
    "         'Subtotal Produk 5',\n",
    "         'Harga Display 5',\n",
    "         'Harga Cost 5',\n",
    "         'Harga Organik 5',\n",
    "         'Produk 6',\n",
    "         'SKU Produk 6',\n",
    "         'PCS Produk 6',\n",
    "         'Price List NFI 6',\n",
    "         'Subtotal Produk 6',\n",
    "         'Harga Display 6',\n",
    "         'Harga Cost 6',\n",
    "         'Harga Organik 6',\n",
    "         'Produk 7',\n",
    "         'SKU Produk 7',\n",
    "         'PCS Produk 7',\n",
    "         'Price List NFI 7',\n",
    "         'Subtotal Produk 7',\n",
    "         'Harga Display 7',\n",
    "         'Harga Cost 7',\n",
    "         'Harga Organik 7',\n",
    "         'Bundle Flag',\n",
    "         'Date',\n",
    "         'Month',\n",
    "         'Year',\n",
    "         'Quarter',\n",
    "         'Week',\n",
    "         'True datetime',\n",
    "         'Total',\n",
    "         'Price List NFI',\n",
    "         'Total Net',\n",
    "         'Selling Price',\n",
    "         'Kecamatan',\n",
    "         'Kelurahan',\n",
    "         'Bundle Name',\n",
    "         'Harga Cost',\n",
    "         'Total Harga Cost',\n",
    "         'Seller Discount',\n",
    "         'Shipping',\n",
    "         'Promo',\n",
    "         'Discount MC',\n",
    "         'Warehouse Name',\n",
    "         'Customer Email',\n",
    "         'Order Status',\n",
    "         'Payment Channel',\n",
    "         'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "\n",
    "        order_online_jatim = True\n",
    "        del file_name\n",
    "\n",
    "if not order_online_jkt:\n",
    "    import pandas as pd \n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "    \n",
    "    print('order_online_jkt')\n",
    "    #komen sementara\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element_by_name(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"nutrimart.nfi@gmail.com\")\n",
    "\n",
    "    password = driver.find_element_by_name(\"password\")\n",
    "    password.send_keys(\"sumselhomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element_by_class_name(\"btn-submit\").click()\n",
    "\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div').click()\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/button').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/div/button[1]').click()\n",
    "\n",
    "    time.sleep(20)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "    #komen sementara\n",
    "    # data_order= pd.read_csv(r\"D:\\Masterdata\\Input Data\\orderonline_orders_all_products_08-07-2022_UdbAylEcFfXdjZIPk.csv\")\n",
    "#         data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Jakarta.csv')\n",
    "    product_order = pd.read_csv(r'Input Data/orderonline_products_Jakarta.csv')\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "\n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch')\n",
    "\n",
    "    data_SKU = pd.read_excel(r'Order Online\\SKU buat andra.xlsx')\n",
    "    data_SKU = data_SKU.rename(columns = {'Unnamed: 0' : 'SKU', 'ref.1' : 'product', 'Pricelist Nutrimart' : 'Price List NFI', 'Harga jua Homdel' : 'Harga Display'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip()\n",
    "    product_order['title'] = product_order['title'].str.strip().str.replace('  ', ' ')\n",
    "    product_order['title'] = product_order['title'].str.strip().str.replace('L-Men Gain Mass Chocolate 500 gr', 'L Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Mango Smoothie 200ml (6pcs)', 36300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (6pcs)', 48000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)', 264000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate (12sch)', 5500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey (50sch)', 39500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Orange 750ml', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 225gr', 57500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gainmass Taro 225gr', 69600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo Milk Brown Sugar RTD 200ml (6pcs)', 33000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Lose Weight Chocolate Cereal (12sch)', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 139200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Strawberry Jam 375gr', 72600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Mangga Gandaria (40 sch)', 45000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Cegah Diabetes (+Kaos)', 116100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 250gr + Free Kertas Gambar', 40500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 750gr + Free Kertas Gambar', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Jeruk Peras (40sch x 2) + Nutrisari Mangga Gandaria (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Blewah (40sch x 2) + Nutrisari Jeruk Maroko (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Nutrisari American Sweet Orange (40sch x 2) + Nutrisari Milky Orange (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 500gr + Free Kertas Gambar', 117600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Ngopi Lokalate', 136000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 750gr', 127100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Florida Orange (40sch x 2) + Nutrisari Markisa (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Extra Virgin Olive Oil 500 ml', 82000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)', 94000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 Sch)', 15000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Platinum Choco Latte Dus 6 sch\", 80000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 104000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 75000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 42500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Es Cincau 40 sch\", 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 180400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 13200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 26400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 26400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Hilo Es Ketan Hitam 10 sch\", 13200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Jeruk Nipis (40 sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Madu Lemon (40 Sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Sweet Mango (40 sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Protein Bar Chocolate 12 sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Protein Crunch BBQ Beef (20gr)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo Chocolate Taro (10 sch)', 11000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Markisa (40 Sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)', 67500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Avocado Coffee 4 Sch x 2', 18200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Avocado Coffee 4 Sch', 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Cocopandan 40 sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sambal Terasi 200 gr', 22300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Lemon Tea 40 sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    product_order = product_order.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 13200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Vanilla 750gr', 102300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo RTD Kacang Hijau 200ml (6pcs)', 29700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Chocolate 250gr', 29150]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Milky Orange (40sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 28900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)', 52000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Vanilla 500gr', 66000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Jahe 50 sch', 38500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 13200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo Gold Plain (Original) 750gr\", 92400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Vanilla Vegiberi 500gr', 71500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Lose Weight Chocolate Cereal 300gr', 104500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Honey 500gr', 71500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Garlic Butter Cookies 5 Sch', 20400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Taro 500gr', 71500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 pcs) - 12gr Protein / Serving', 211200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-MEN Gain Mass Taro 225 gr', 52800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School RTD Chocolate 200ml (6pcs)', 36300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sunflower Oil 946 ml', 57200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"L-Men Whey Daily Dark Chocolate 250gr\", 49500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Vanilla 200gr', 59400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Chocolate 1000 gr', 136400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 1 GET 1 - W'Dank Empon Empon 10 Sachet Renceng\", 26400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Banana 225gr', 60500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Mangga Gandaria', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo RTD Kacang Hijau 200 ml', 4950]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate', 8800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(FREE) W'Dank Empon-Empon 10 sch\", 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Khusus Homdel - HiLo Chocolate Banana 10 sch', 11000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Lychee Tea 40 sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Strawberry 40 Sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School RTD Vanila Vegiberi 200ml (6pcs)', 36300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Saus Tiram 200ml', 39600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Shirataki Noodles 71gr', 28100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School RTD Vanila Vegiberi 200ml', 6100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Saus Tiram 200ml', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Shirataki Noodles 71gr', 14100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari American Sweet Orange (40 Sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Madu Kurma Pack (4R)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Milky Orange (40 sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo Chocolate (10 sch)', 11000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Swiss Chocolate (10 sch) Renceng', 16500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Leci 40 sch', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Sweet Guava (40 sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Hilo - Lebaran Edition', 56100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Ramadhan NutriSari 7 Rasa (7 x 10 sch)', 294000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Jeruk Peras (40 Sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Lebaran Tropicana Slim', 96300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Lokalate untuk Sobatku - Idul Fitri Edition', 54120]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Topping Kental Manis 150ml - SUGAR FREE', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Florida Orange (40 Sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo RTD Milky Brown Sugar 200 ml', 4950]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Belgian Chocolate (10 sch)', 41800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Mangga Gandaria (40 sch)', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Asin 200 ml', 23650]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Apel Jeruk 40 Sachet', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Minyak Jagung 1lt', 69300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Coffee Tiramisu 200ml (6pcs) - Ready to Drink', 36300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Nutrisari Jeruk Madu Jeruk 40'sachet (4 Renceng)\", 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen RTD Coffee Tiramisu 200ml', 6050]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Milk Skim Chocolate 500gr', 111000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Mayonnaise 200 g x 2', 34800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Oat Drink 190 ml (RTD) x 4 pcs', 22600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Mayonnaise 200 g - Bantu Dukung Hidup Sehat', 17400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Oat Drink 190 ml (RTD)', 5650]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Baru! NutriSari NUTRI C1000 Jeruk 40 Sachet', 35000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: L-Men Daily Popcorn Caramel 250gr x 2', 78300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Daily Popcorn Caramel 250gr', 39150]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 FREE HiLo Joint Plus 140gr', 38300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Es Rujak Jeruk Bali 40 Sachet', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Lokalate Kopi Tape Ketan 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Tape Ketan 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False) \n",
    "    product_order = product_order.append(pd.DataFrame([['(FREE) Lokalate Kopi Tape Ketan 10 Sachet', 0]], columns = ['title', 'price']), ignore_index = True, sort = False) \n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: Tropicana Slim Korean Goguma Cookies (5 Sch) x 2', 32200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Goguma Cookies (5 Sch)', 16100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Lokalate Kopi Andaliman 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Andaliman 10 Sachet', 6850]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(FREE) Lokalate Kopi Andaliman 10 Sachet', 0]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Goguma Cookies (5 Sch)', 16100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Gold Plain 1000 gr', 128200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NuTrilogi Seri Mas Kaka yang Banyak Akal', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Vanilla Vegiberi 500gr', 76600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Vanilla Caramel 500gr', 76600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari NUTRI C1000 Jeruk 40 Sachet', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo Joint Plus Orange 140 gram x 2', 55300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Tape Ketan 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Popcorn Caramel 500 gram - Susu Tinggi Kalsium Lebih Rendah Lemak', 68600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo School Strawberry Cheesecake 500 gram x 2', 110600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Yuzu Orange 40 sch', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Jeruk Jeju [40 Sachet]', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Strawberry Cheesecake 500 gram', 55300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin pack - Lokalate Kopi Andaliman 10 Sachet', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Masak Sehat', 125000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Extra Virgin Olive Oil 500 ml', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200ml', 27500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Santan 5 sachet', 15400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Twin pack - Lokalate Kopi Tape Ketan 10 Sachet', 19800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Tape Ketan 10 Sachet', 13700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Chocolate Taro RTD 200ml (4pcs)', 22900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Chocolate Taro RTD 200ml', 5750]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['Paket Ngemil Sehat', 125000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Korean Goguma Cookies (5 Sch)', 21200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Oat Drink 190 ml (RTD)', 7500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Topping Kental Manis 150ml - SUGAR FREE', 29700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese Cookies', 21200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Avocado Coffee 4 Sch', 12600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['2102900319 (D)', 82500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['2102500336 (classic stick)', 46900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Jeruk Maroko (40 Sch) FREE Lokalate Andaliman (10 Sch)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Nutty Chocolate Cookies 200gr', 40000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Es Rujak (4R)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Nutrisari Jeruk Maroko (40 sch)', 42600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(FREE) Lokalate Kopi Andaliman 10 Sachet', 13600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Chocolate 750gr', 111000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Yoghurt Smoothie Bowl Strawberry (8 sch)', 62900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Chocolate Ready To Drink (4 tetrapack)', 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo Teen Chocolate Ready To Drink Susu [4 pcs]', 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School RTD Coklat 200ml', 6525]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen RTD Coklat 200ml', 6525]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['Twin Pack: HiLo Almond Milk Coconut 200gr x 2', 70000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate x 4 pcs', 38400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Almond Milk Coconut 200gr', 35000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate', 9600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Thai Tea Ready to Drink 200ml x 4pcs', 22900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo RTD Thai Tea 200ml', 5750]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"W'Dank Bajigur (10 sch)\", 17200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"W'Dank Bandrek 10 sachet Renceng\", 17200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo Milky Brown Sugar Ready To Drink 200ml (4 Tetrapack)', 22900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Hilo School Vanilla Vegiberi Ready To Drink Susu [200ml/4 pcs]', 26100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Hilo RTD Milky Brown Sugar 200 ml\", 5725]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo School RTD Vanila Vegiberi 200ml\", 6525]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"HiLo School Chocolate Candy (10 sch)\", 18300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"2102500320 (CI160)\", 72160]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Chocolate 1000 gr', 141900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Triple Pack: Tropicana Slim Klepon Cookies (5 Sch)', 50000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Klepon Cookies (5 Sch)', 16700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Jeruk Nipis Jahe 40 Sachet', 35000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Shirataki Rice 72 g', 50000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Shirataki Rice 72 g', 25000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Leci 750ml', 30900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Mango Smoothie 200ml (4 Pcs)', 27500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari RTD Mango Smoothie 200 ml', 6900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Active Es Teler 175gr', 26300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Platinum Swiss Chocolate 420gr', 91500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Es Kuwud Nipis', 37500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Classic Refill 500gr', 104100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Brownies Instant Powder Cake Mix 230 g - Bantu Dukung Hidup Sehat', 59400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Bundle - HiLo Teen Taro 500gr & HiLo Teen Strawberry Milkshake 500g', 127200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 Free - HiLo School Bubble Gum 500g', 92400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HILO ALMOND MILK COCONUT 12DX200G', 51500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Taro 500gr', 80100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['(Near ED) HiLo School RTD Coklat 200ML', 6900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Teen Strawberry Milkshake 500g', 75500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener I Sweet', 25200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 - Lokalate Kopi Pisang Bakar 10 sch', 17500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Pisang Bakar Epe 10 sch', 8750]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo School Vanilla Vegiberi 750gr', 116700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['HiLo Coffee Milk Pillow Bag (2 sch)', 10300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Lychee Tea Refill 500 gram', 34300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Cookies Paket Hampers Idul Fitri Parcel Lebaran', 131600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Lemon-C (25 sch)', 25200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim High Fiber High Calcium Milk Chocolate 500gr', 116700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Lemon Tea 500 gram', 42000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['NutriSari Jeruk Peras Refill 500 gr', 37800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['LOKALATE KOPI PISANG BAKAR EPE', 15000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Buy 1 Get 1 - Tropicana Slim Mint Cocoa - Minuman Cokelat Mint Nikmat Tanpa Gula Pasir', 20000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Es Pisang Ijo 10 Sch x 2 pcs', 17500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ '(Near ED)L-Men Platinum Kacang Hijau 800g', 158750]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'L-Men Platinum Choco Latte 800 gr - Near ED', 164500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'NutriSari RTD Jeruk Madu 200 ml', 6000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'NutriSari Jeruk Manis 500gr', 38100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'L-Men Gain Mass Mangga 500gr', 133900]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Avocado Chocolate (10 Sch)', 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo White Chocolate (10 Sch)', 12100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'Diabetamil Milk Vanilla 150 gram', 35000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'Buy 1 Get 1 FREE Tropicana Slim Susu Low Fat Macchiato Coffee 500gr', 143000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Active Chocolate 1000 gr', 121200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Joint Plus Orange 140 gram', 38700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'Tropicana Slim Susu Low Fat Macchiato Coffee 500 gram', 71500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Teen Biscuit Caramel 500gr', 65000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Active Caramel Latte 500g', 65800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'Buy 1 Get 1 Free - HiLo Gold Biscuit Cereal 500g', 80800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HILO TEEN STRAWBERRY MILKSHAKE\\xa0 12DX500G', 76200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo School Bubble Gum 500g', 80800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ '2102500336 (CS)', 49200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Thai Tea Refill 500g', 48000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'Hilo Teen Coffee Tiramisu Ready To Drink Susu UHT [4 pcs]', 27600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ '(Near ED)L-Men Platinum Ketan Hitam 800g', 157300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Klepon Latte Refill 500g - Powder Drink Tinggi Kalsium', 46800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'NutriSari Gula Asem 40 Sachet', 43300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'NutriSari Anggur Hijau 40 Sachet', 43300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'HiLo Es Pisang Ijo 10 Sch', 14300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'Buy 1 Get 1 FREE L-Men Lose Weight Mango Sticky Rice 300gr', 145200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[ 'TRIPLE DEALS - NutriSari Lychee Tea & Lemon Tea 500 gram Refill', 72700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'TRIPLE HEMAT - NutriSari Lemon Tea 500 gram', 72700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'TRIPLE HEMAT - HiLo Thai Tea Refill 500g', 72700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'TRIPLE HEMAT - HiLo Klepon Latte Refill 500g', 109100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'Bundle - Lokalate Kopi Alpukat Refill 500 gram & Kopi Berondong Refill 500 gram', 46200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'TRIPLE HEMAT - NutriSari Lychee Tea Refill 500 gram', 72700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ '(Near ED)L-Men Gain Mass Mangga 500gr', 66350]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'Lokalate Kopi Berondong 500 gram - Tinggi Vitamin A Lebih Rendah Gula', 44400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[ 'Lokalate Kopi Alpukat 500 gram - Tinggi Vitamin A Lebih Rendah Gula', 44400]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    product_order = product_order.append(pd.DataFrame([[\"Buy 1 Get 1 - Tropicana Slim Bumbu Kaldu Ayam dan Jamur 100 gram\", 48500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"BUY 1 GET 1 - HiLo Platinum Original 360 gram\", 255000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) HiLo School Chocolate 1000 gr\", 148700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"Near ED - HiLo Teen Chocolate 1000 gr\", 148700]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([[\"(Near ED) HiLo Joint Plus Orange 140 gram\", 19150]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    price = product_order[product_order['title'] == 'Tropicana Slim Goldenmil Vanilla (6sch)']['price'].values[0]\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    price = product_order[product_order['title'] == 'Lokalate Kopi Kawista (10sch)']['price'].values[0]\n",
    "    product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Lokalate Kopi Kawista (10sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Kawista', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    price = product_order[product_order['title'] == 'Tropicana Slim Kecap Manis 200ml']['price'].values[0]\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200m', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    price = product_order[product_order['title'] == 'Tropicana Slim Diabtx 50 sch']['price'].values[0]\n",
    "    product_order = product_order.append(pd.DataFrame([['Tropicana Slim Diabtx (50 sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "    product_order['title'] = product_order['title'].astype(str)\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "    # data_order = data_order[data_order['SKU'].notnull()]\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    # display(data_order[data_order['SKU'].isnull()])\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    # display(data_order[data_order['SKU'].isnull()])\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    s = requests.Session()\n",
    "    s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    with open(r'SKU_File\\Master tatanama.xlsx', 'wb') as output:\n",
    "        output.write(r.content)\n",
    "\n",
    "    if os.path.isfile(r'SKU_File\\Master tatanama.xlsx') :    \n",
    "        SKU_append = pd.read_excel(r'SKU_File\\Master tatanama.xlsx')\n",
    "        SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "        data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "        data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    to_excel = data_SKU2.to_excel(r'SKU_File\\data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    indeks\n",
    "    # display(data_order[data_order['SKU'].isnull()])\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Jakarta'\n",
    "\n",
    "    #     list_drop = []\n",
    "    #     indeks = data_order[data_order['SKU'].isin(data_SKU2[data_SKU2['Brand'] == 'Bundle']['SKU'])].index.to_list()\n",
    "    #     for i in indeks:\n",
    "    #         if str(data_order['SKU'][i]) in data_SKU2['SKU'].astype(str).values:\n",
    "    #             idx = data_SKU2[str(data_order['SKU'][i] ) == data_SKU2['SKU'].astype(str)].index[0]\n",
    "    #             for j in range(1,8):\n",
    "    #                 colname = 'Produk ' + str(j)\n",
    "    #                 if str(data_SKU2[colname][idx]) != 'nan':\n",
    "    #                     new_data = data_order.iloc[i,]\n",
    "    #                     new_data['Item Name'] = data_SKU2[colname][idx]\n",
    "    #                     new_data['Selling Price'] = data_SKU2['Subtotal ' + colname][idx] * new_data['Quantity']\n",
    "    #                     new_data['Quantity'] = new_data['Quantity'] * data_SKU2['PCS ' + colname][idx]\n",
    "    #                     new_data['SKU'] = str(data_SKU2['SKU ' + colname][idx]).replace('.0','')\n",
    "    #                     new_data['Quantity'] = str(new_data['Quantity']).replace('.0','')\n",
    "    #                     new_data['Selling Price'] = str(new_data['Selling Price']).replace('.0','')\n",
    "    #                     data_order = data_order.append(new_data, ignore_index = True)\n",
    "    #                     list_drop.append(i)\n",
    "    #     data_order = data_order.drop(list_drop, axis = 0)\n",
    "    #     data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "    #     for i in range(data_order.shape[0]):\n",
    "    #         if int(data_order['Order date'][i].strftime('%d')) < 12:\n",
    "    #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i].strftime('%Y-%d-%m %H:%M'))\n",
    "    #         else :\n",
    "    #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i])\n",
    "        indeks = data_order[data_order['Item Name'].astype(str).str.contains('pcs')].index.to_list()\n",
    "        temp = data_order.iloc[indeks].copy()\n",
    "        product = temp['Item Name'].str.split(\"\\(\",1, expand = True)\n",
    "#             if len(product) != 0:\n",
    "#                 temp['Quantity Inside'] = product[1].astype(str).str.replace('pcs)', '', regex = False).astype(int)\n",
    "#                 data_order['Quantity'][indeks] = data_order['Quantity'][indeks] * temp['Quantity Inside']\n",
    "\n",
    "    #     data_order_1 = data_order[data_order['payment_method'] == 'cod']\n",
    "    #     data_order_2 = data_order[data_order['payment_method'] != 'cod'][data_order[data_order['payment_method'] != 'cod']['payment_status'] == 'paid']\n",
    "    #     data_WMS = data_order_1.append(data_order_2, ignore_index = True, sort = False)\n",
    "    #     data_WMS = data_WMS[['Order date', 'Channel', 'Sales Order ID', 'Channel Order ID', 'Invoice Number', 'Customer Name', 'Item Name', 'SKU', 'Quantity', 'Price', 'Shipping Cost', 'Shipping Name', 'Shipping Address1', 'Shipping Address2', 'Shipping City', 'Shipping Zip', 'Shipping Province', 'Shipping Country', 'Shipping Phone', 'Shipping Courier', 'AWB']]\n",
    "    #     data_WMS.to_excel(r'data_WMS_OrderOnline.xlsx', index = False)\n",
    "    #     print('Finished')\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        index = order_all[order_all['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        order_all['SKU'][index] = '2306592173'\n",
    "        order_all['Real SKU'][index] = '2306592173'\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Price' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "        \n",
    "#         indeks = order_all[order_all['Product Name'].isin([\n",
    "#             '2102500336 (classic stick)', '2102500336 (CS)', '2102900319 (D)'\n",
    "#         ])].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "        order_all = order_all.reset_index()\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        #order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost'], errors = 'coerce').fillna(0).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        \n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        order_all['Selling Price'] = order_all['Regular Price'].astype(int)\n",
    "\n",
    "        data_SKU3 = pd.read_excel(r'Order Online\\SKU buat andra updated maret 2021.xlsx')\n",
    "        data_SKU3 = data_SKU3.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "        data_SKU3['SKU'] = data_SKU3['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "        data_SKU3 = data_SKU3[data_SKU3['SKU'] != 'nan'][data_SKU3[data_SKU3['SKU'] != 'nan']['SKU'] != '0'][data_SKU3[data_SKU3['SKU'] != 'nan'][data_SKU3[data_SKU3['SKU'] != 'nan']['SKU'] != '0']['Harga Coret'].notnull()]\n",
    "        data_SKU3['product'] = data_SKU3['product'].str.strip()\n",
    "        data_SKU3 = data_SKU3.reset_index(drop = True)\n",
    "\n",
    "        for i in range(data_SKU3.shape[0]):\n",
    "            if data_SKU3['SKU'][i] in order_all['SKU'].values:\n",
    "                indeks = order_all[order_all['SKU'].astype(str) == i].index.to_list()\n",
    "                order_all['Regular Price'][indeks] = data_SKU3['Harga Display'][i]\n",
    "                order_all['Selling Price'][indeks] = data_SKU3['Harga Coret'][i]\n",
    "\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "        \n",
    "        order_all_append['True datetime'] = pd.to_datetime(order_all_append['True datetime'])\n",
    "\n",
    "        indeks = order_all_append[\n",
    "            (order_all_append['True datetime'] > pd.to_datetime('2021-02-28')) &\n",
    "            (order_all_append['Channel'] == 'Order Online Jakarta')\n",
    "        ].index.to_list()\n",
    "\n",
    "        order_all_append['Channel'][indeks] = 'Order Online Sumsel'\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "\n",
    "        order_online_jkt = True\n",
    "        del file_name\n",
    "\n",
    "if not order_online_jateng:\n",
    "            \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "    \n",
    "    print('order_online_jateng')\n",
    "\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element_by_name(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customer1@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_name(\"password\")\n",
    "    password.send_keys(\"jatenghomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element_by_class_name(\"btn-submit\").click()\n",
    "\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div').click()\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/button').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/div/button[1]').click()\n",
    "\n",
    "    time.sleep(15)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name), error_bad_lines=False, engine=\"python\")\n",
    "    \n",
    "    driver.close()\n",
    "#         data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Jakarta.csv')\n",
    "#             product_order = pd.read_csv(r'Input Data/orderonline_products_Jakarta.csv')\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "#     data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch (x2) ', 'Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Tropicana Slim Oat Drink 190 ml \\(RTD\\) x 4 pcs$', 'Tropicana Slim Oat Drink 190 ml (RTD) x 4 pcs (x1)')\n",
    "    data_order=data_order[data_order['product']!=\"2102500336 (CS)\"]\n",
    "    data_order=data_order.reset_index(drop=True)\n",
    "    \n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    product = product[product[0] != 'nan']\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"Rtd\", \"RTD\").str.replace('Turmeric 180gr', 'Turmeric (6 sch)').str.replace('L-Men Gainmass Taro 225gr', 'L-Men Gain Mass Taro 225 gr').str.replace('L-Men Lose Weight Chocolate Cereal (12sch)', 'L-Men Lose Weight Chocolate Cereal 300gr').str.replace(' (+kaos)', ' (+Kaos)', regex = False).str.replace('40 sch', '40sch', regex = False).str.replace('Coklat', 'Chocolate', regex = False)\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "\n",
    "    data_SKU = pd.read_excel(r'Order Online\\SKU buat andra updated maret 2021.xlsx')\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"Rtd\", \"RTD\").str.replace('Turmeric 180gr', 'Turmeric (6 sch)').str.replace('L-Men Gainmass Taro 225gr', 'L-Men Gain Mass Taro 225 gr').str.replace('L-Men Lose Weight Chocolate Cereal (12sch)', 'L-Men Lose Weight Chocolate Cereal 300gr').str.replace(' (+kaos)', ' (+Kaos)', regex = False).str.replace('40 sch', '40sch', regex = False).str.replace('Coklat', 'Chocolate', regex = False)\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('  ', ' ')\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('L-Men Gain Mass Chocolate 500 gr', 'L Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Nutrisari Mango Smoothie 200ml (6pcs)', 6050]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (6pcs)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey (50sch)', 39500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Orange 750ml', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 225gr', 57500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gainmass Taro 225gr', 69600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo Milk Brown Sugar RTD 200ml (6pcs)', 5500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Lose Weight Chocolate Cereal (12sch)', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 139200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Strawberry Jam 375gr', 72600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 19800, 19800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Cegah Diabetes (+Kaos)', 116100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 250gr + Free Kertas Gambar', 40500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 750gr + Free Kertas Gambar', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Jeruk Peras (40sch x 2) + Nutrisari Mangga Gandaria (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Blewah (40sch x 2) + Nutrisari Jeruk Maroko (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari American Sweet Orange (40sch x 2) + Nutrisari Milky Orange (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 500gr + Free Kertas Gambar', 117600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Ngopi Lokalate', 136000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 750gr', 127100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Florida Orange (40sch x 2) + Nutrisari Markisa (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Platinum Swiss Chocolate 420gr', 91500, 91500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim White Coffee (4 sch)', 21200, 18400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-MEN Gain Mass Taro 225 gr', 58300, 58300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Extra Virgin Olive Oil 500ml', 85800, 85800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Jeruk Peras Refill 500gr', 34300, 34300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500gr', 125800, 125800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Jeruk Manis Refill 500gr', 37800, 37800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Roasted Sesame Mayonnaise 200g - Bantu Dukung Hidup Sehat', 22900, 22900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Shirataki Rice 72 g', 50000, 50000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Jeruk Nipis Jahe 40 Sachet', 62500, 35000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo school Chocolate 250g (Health & green Science Competition)', 38300, 38300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Kacang Hijau Ready to Drink 200ml (4 tetrapack)', 22900, 22900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Shirataki Noodles 71gr', 9700, 9700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo RTD Kacang Hijau 200 ml', 2850, 2850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo RTD Milky Brown Sugar 200 ml', 2550, 2550]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HILO TEEN STRAWBERRY MILKSHAKEÂ\\xa0 12Dx500G', 66800, 66800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) NutriSari Cocopandan 40sch', 21300, 21300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Lemon Tea (40sch)', 42600, 42600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Mayonnaise 200 g', 11450, 11450]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Caramel Latte 500g', 95000, 50500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo school Cotton Candy 500g', 88400, 62500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Oat Drink 190ml (RTD)', 9999, 7500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 Free - HiLo school Bubble Gum 500g', 154000, 92400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Brownies Instant Powder Cake Mix 230 g - Bantu Dukung Hidup Sehat', 59400, 59400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 pcs) - 12gr Protein / Serving', 237600, 199000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Klepon Latte Refill 500g - Powder Drink Tinggi Kalsium', 59400, 49500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Brownies Instant Powder Cake Mix 230g - Bantu Dukung Hidup Sehat', 59400, 59400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HILO ALMOND MILK COCONUT 12Dx200G', 51500, 51500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo school Bubble Gum 500g', 80100, 80100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Lemon Tea 500 gram', 42000, 34300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Teen Biscuit Caramel 500gr', 92400, 65000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE L-Men Lose Weight Mango Sticky Rice 300gr', 290400, 145200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 - Tropicana Slim Mint Cocoa - Minuman Cokelat Mint Nikmat Tanpa Gula Pasir', 40000, 20000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Es Pisang Ijo 10 sch x 2 pcs', 35000, 17500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NuTrilogi Seri Mas Kaka yang Banyak Akal', 70000, 42600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE Tropicana Slim Susu Low Fat Macchiato Coffee 500gr', 257400, 143000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Lokalate Kopi Pisang Bakar 10 sch', 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Choco Series Paket Hampers Idul Fitri Parcel Lebaran', 185300, 139600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Brownies Instant Powder Cake Mix 230g - Bantu Dukung Hidup Sehat', 31200, 31200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['BUY 1 GET 1 - Tropicana Slim Soy Latte - Kopi Plant Based Rendah Gula', 81800, 36900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Susu Low Fat Macchiato Coffee 500 gram', 75000, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo Teen Taro 500gr - Khusus Homdel', 80800, 40400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari RTD Jeruk Madu 200 ml (4 tetrapack)', 24000, 24000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) W'dank Bandrek 10 sachet Renceng - Khusus Homdel\", 17300, 8650]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) W'dank Empon-Empon 10 sch - Khusus Homdel\", 15000, 7500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 1 Get 1 Free - HiLo Gold Biscuit Cereal 500g\", 161600, 80800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 500 gram - Tinggi Vitamin A Lebih Rendah Gula\", 59400, 44400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) HiLo Joint Plus Orange 140 gram\", 38300, 19150]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) HiLo Active Es Teler 175gr\", 29700, 14850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"(Near ED) Lokalate Kopi Tape Ketan 10's\", 14900, 7450]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sweetener Jahe (50 sch)\", 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Anggur Hijau 40 Sachet\", 62000, 43290]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Gula Asem 40 Sachet\", 62000, 43290]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack - Tropicana Slim Low Fat Milk Korean Strawberry 500g\", 257400, 159900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Temulawak Madu\", 42000, 33300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack - Tropicana Slim Low Fat Milk Korean Strawberry 500g\", 257400, 159900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Temulawak Madu\", 42000, 33300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"TRIPLE HEMAT - HiLo Taro Latte Refill 500g\", 145500, 101800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"TRIPLE HEMAT - HiLo Thai Tea Refill 500g\", 144000, 100900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"TRIPLE DEALS - NutriSari Lychee Tea & Lemon Tea 500 gram Refill\", 103900, 72700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twinpack Tropicana Slim Bumbu Saus Telur Asin 3 Sachet - Lebih Rendah Lemak dan Garam\", 58000, 29000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Near ED - Lokalate Kopi Andaliman 10 Sachet\", 15000, 7500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo RTD Chocolate Avocado 200ml (4pcs)\", 25400, 25400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 1 Get 1 - L-Men Gain Mass Klepon Latte\", 277100, 138500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    # data_SKU = data_SKU.append(pd.DataFrame([[\"TRIPLE DEALS - NutriSari Lychee Tea & Lemon Tea 500 gram Refill\", 103800, 72700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    # data_SKU = data_SKU.append(pd.DataFrame([[\"TRIPLE HEMAT - NutriSari Lemon Tea 500 gram\", 103800, 100900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    # data_SKU = data_SKU.append(pd.DataFrame([[\"TRIPLE HEMAT - HiLo Thai Tea Refill 500g\", 103900, 72700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "#     product_order = product_order.append(pd.DataFrame([['HiLo school Chocolate 250g (Health & green Science Competition)', 38300]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    \n",
    "\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Goldenmil Vanilla (6sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Lokalate Kopi Kawista (10sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Lokalate Kopi Kawista (10sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Kawista', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Kecap Manis 200ml']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200m', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Diabtx 50 sch']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Diabtx (50 sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    #             data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "    # data_order = data_order[data_order['SKU'].notnull()]\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    s = requests.Session()\n",
    "    s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    with open(r'SKU_File\\Master tatanama.xlsx', 'wb') as output:\n",
    "        output.write(r.content)\n",
    "\n",
    "    if os.path.isfile(r'SKU_File\\Master tatanama.xlsx') :    \n",
    "        SKU_append = pd.read_excel(r'SKU_File\\Master tatanama.xlsx')\n",
    "        SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "        data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "        data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    to_excel = data_SKU2.to_excel(r'SKU_File\\data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Jateng'\n",
    "\n",
    "    #     list_drop = []\n",
    "    #     indeks = data_order[data_order['SKU'].isin(data_SKU2[data_SKU2['Brand'] == 'Bundle']['SKU'])].index.to_list()\n",
    "    #     for i in indeks:\n",
    "    #         if str(data_order['SKU'][i]) in data_SKU2['SKU'].astype(str).values:\n",
    "    #             idx = data_SKU2[str(data_order['SKU'][i] ) == data_SKU2['SKU'].astype(str)].index[0]\n",
    "    #             for j in range(1,8):\n",
    "    #                 colname = 'Produk ' + str(j)\n",
    "    #                 if str(data_SKU2[colname][idx]) != 'nan':\n",
    "    #                     new_data = data_order.iloc[i,]\n",
    "    #                     new_data['Item Name'] = data_SKU2[colname][idx]\n",
    "    #                     new_data['Selling Price'] = data_SKU2['Subtotal ' + colname][idx] * new_data['Quantity']\n",
    "    #                     new_data['Quantity'] = new_data['Quantity'] * data_SKU2['PCS ' + colname][idx]\n",
    "    #                     new_data['SKU'] = str(data_SKU2['SKU ' + colname][idx]).replace('.0','')\n",
    "    #                     new_data['Quantity'] = str(new_data['Quantity']).replace('.0','')\n",
    "    #                     new_data['Selling Price'] = str(new_data['Selling Price']).replace('.0','')\n",
    "    #                     data_order = data_order.append(new_data, ignore_index = True)\n",
    "    #                     list_drop.append(i)\n",
    "    #     data_order = data_order.drop(list_drop, axis = 0)\n",
    "    #     data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "    # #     for i in range(data_order.shape[0]):\n",
    "    # #         if int(data_order['Order date'][i].strftime('%d')) < 12:\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i].strftime('%Y-%d-%m %H:%M'))\n",
    "    # #         else :\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i])\n",
    "    #     indeks = data_order[data_order['Item Name'].astype(str).str.contains('pcs')].index.to_list()\n",
    "    #     temp = data_order.iloc[indeks].copy()\n",
    "    #     product = temp['Item Name'].str.split(\"\\(\",1, expand = True)\n",
    "    #     if len(product) != 0:\n",
    "    #         temp['Quantity Inside'] = product[1].astype(str).str.replace('pcs)', '', regex = False).astype(int)\n",
    "    #         data_order['Quantity'][indeks] = data_order['Quantity'][indeks] * temp['Quantity Inside']\n",
    "\n",
    "    # #     data_order_1 = data_order[data_order['payment_method'] == 'cod']\n",
    "    # #     data_order_2 = data_order[data_order['payment_method'] != 'cod'][data_order[data_order['payment_method'] != 'cod']['payment_status'] == 'paid']\n",
    "    # #     data_WMS = data_order_1.append(data_order_2, ignore_index = True, sort = False)\n",
    "    # #     data_WMS = data_WMS[['Order date', 'Channel', 'Sales Order ID', 'Channel Order ID', 'Invoice Number', 'Customer Name', 'Item Name', 'SKU', 'Quantity', 'Price', 'Shipping Cost', 'Shipping Name', 'Shipping Address1', 'Shipping Address2', 'Shipping City', 'Shipping Zip', 'Shipping Province', 'Shipping Country', 'Shipping Phone', 'Shipping Courier', 'AWB']]\n",
    "    # #     data_WMS.to_excel(r'data_WMS_OrderOnline.xlsx', index = False)\n",
    "    # #     print('Finished')\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (classic stick)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "        \n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (CS)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "        \n",
    "#         indeks = order_all[order_all['Product Name'] == '2102900319 (D)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "        \n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500320 (CI160)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "        \n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "        \n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        #order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost'], errors = 'coerce').fillna(0).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "        \n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "        \n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "\n",
    "        order_online_jateng = True\n",
    "        del file_name\n",
    "\n",
    "if not order_online_bali:\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "    \n",
    "    print('order_online_bali')\n",
    "\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element_by_name(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customerbali@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_name(\"password\")\n",
    "    password.send_keys(\"balihomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element_by_class_name(\"btn-submit\").click()\n",
    "    time.sleep(15)\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div').click()\n",
    "    time.sleep(5)\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/button').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/div/button[1]').click()\n",
    "\n",
    "    time.sleep(15)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "#         data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Jakarta.csv')\n",
    "#             product_order = pd.read_csv(r'Input Data/orderonline_products_Jakarta.csv')\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch (x2) ', 'Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch ', regex = False)\n",
    "\n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\")\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "\n",
    "    data_SKU = pd.read_excel(r'Order Online\\SKU buat andra updated maret 2021.xlsx')\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\")\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('  ', ' ')\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('L-Men Gain Mass Chocolate 500 gr', 'L Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Nutrisari Mango Smoothie 200ml (6pcs)', 6050]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (6pcs)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey (50sch)', 39500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Orange 750ml', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 225gr', 57500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gainmass Taro 225gr', 69600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo Milk Brown Sugar RTD 200ml (6pcs)', 5500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Lose Weight Chocolate Cereal (12sch)', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 139200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Strawberry Jam 375gr', 72600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 19800, 19800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Cegah Diabetes (+Kaos)', 116100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 250gr + Free Kertas Gambar', 40500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 750gr + Free Kertas Gambar', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Jeruk Peras (40sch x 2) + Nutrisari Mangga Gandaria (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Blewah (40sch x 2) + Nutrisari Jeruk Maroko (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari American Sweet Orange (40sch x 2) + Nutrisari Milky Orange (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 500gr + Free Kertas Gambar', 117600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Ngopi Lokalate', 136000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 750gr', 127100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Florida Orange (40sch x 2) + Nutrisari Markisa (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo School Chocolate 500gr', 38300, 38300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)Tropicana Slim Extra Virgin Olive Oil 500 ml', 42900, 42900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo Active Vanilla 500gr', 32600, 32600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo Gold Plain (Original) 500gr', 36600, 36600]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo Teen Chocolate 750gr', 55500, 55500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo School Chocolate 750gr', 55500, 55500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)L-Men Gain Mass Chocolate 500gr', 62900, 62900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Platinum Choco 800 gr - Near ED', 157300, 157300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED)HiLo Teen Chocolate 500gr', 38300, 38300]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo RTD Milky Brown Sugar 200 ml', 2574, 2574]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo RTD Thai Tea 200ml - Near ED', 2860, 2860]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 - L-Men Gain Mass Klepon Latte', 277100, 138500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 12 Get 12 - HiLo Chocolate Avocado Ready to Drink 200ml - Minuman Siap Minum Tinggi Kalsium', 152400, 84000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Goldenmil Vanilla (6sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Lokalate Kopi Kawista (10sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Lokalate Kopi Kawista (10sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Kawista', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Kecap Manis 200ml']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200m', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Diabtx 50 sch']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Diabtx (50 sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    #             data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "    # data_order = data_order[data_order['SKU'].notnull()]\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "#     s = requests.Session()\n",
    "#     s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "#     s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "#     r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "#     with open(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx', 'wb') as output:\n",
    "#         output.write(r.content)\n",
    "\n",
    "#     if os.path.isfile(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx') :    \n",
    "#         SKU_append = pd.read_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx')\n",
    "#         SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "#         data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "#         data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "#     to_excel = data_SKU2.to_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Bali'\n",
    "\n",
    "    #     list_drop = []\n",
    "    #     indeks = data_order[data_order['SKU'].isin(data_SKU2[data_SKU2['Brand'] == 'Bundle']['SKU'])].index.to_list()\n",
    "    #     for i in indeks:\n",
    "    #         if str(data_order['SKU'][i]) in data_SKU2['SKU'].astype(str).values:\n",
    "    #             idx = data_SKU2[str(data_order['SKU'][i] ) == data_SKU2['SKU'].astype(str)].index[0]\n",
    "    #             for j in range(1,8):\n",
    "    #                 colname = 'Produk ' + str(j)\n",
    "    #                 if str(data_SKU2[colname][idx]) != 'nan':\n",
    "    #                     new_data = data_order.iloc[i,]\n",
    "    #                     new_data['Item Name'] = data_SKU2[colname][idx]\n",
    "    #                     new_data['Selling Price'] = data_SKU2['Subtotal ' + colname][idx] * new_data['Quantity']\n",
    "    #                     new_data['Quantity'] = new_data['Quantity'] * data_SKU2['PCS ' + colname][idx]\n",
    "    #                     new_data['SKU'] = str(data_SKU2['SKU ' + colname][idx]).replace('.0','')\n",
    "    #                     new_data['Quantity'] = str(new_data['Quantity']).replace('.0','')\n",
    "    #                     new_data['Selling Price'] = str(new_data['Selling Price']).replace('.0','')\n",
    "    #                     data_order = data_order.append(new_data, ignore_index = True)\n",
    "    #                     list_drop.append(i)\n",
    "    #     data_order = data_order.drop(list_drop, axis = 0)\n",
    "    #     data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "    # #     for i in range(data_order.shape[0]):\n",
    "    # #         if int(data_order['Order date'][i].strftime('%d')) < 12:\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i].strftime('%Y-%d-%m %H:%M'))\n",
    "    # #         else :\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i])\n",
    "    #     indeks = data_order[data_order['Item Name'].astype(str).str.contains('pcs')].index.to_list()\n",
    "    #     temp = data_order.iloc[indeks].copy()\n",
    "    #     product = temp['Item Name'].str.split(\"\\(\",1, expand = True)\n",
    "    #     if len(product) != 0:\n",
    "    #         temp['Quantity Inside'] = product[1].astype(str).str.replace('pcs)', '', regex = False).astype(int)\n",
    "    #         data_order['Quantity'][indeks] = data_order['Quantity'][indeks] * temp['Quantity Inside']\n",
    "\n",
    "    # #     data_order_1 = data_order[data_order['payment_method'] == 'cod']\n",
    "    # #     data_order_2 = data_order[data_order['payment_method'] != 'cod'][data_order[data_order['payment_method'] != 'cod']['payment_status'] == 'paid']\n",
    "    # #     data_WMS = data_order_1.append(data_order_2, ignore_index = True, sort = False)\n",
    "    # #     data_WMS = data_WMS[['Order date', 'Channel', 'Sales Order ID', 'Channel Order ID', 'Invoice Number', 'Customer Name', 'Item Name', 'SKU', 'Quantity', 'Price', 'Shipping Cost', 'Shipping Name', 'Shipping Address1', 'Shipping Address2', 'Shipping City', 'Shipping Zip', 'Shipping Province', 'Shipping Country', 'Shipping Phone', 'Shipping Courier', 'AWB']]\n",
    "    # #     data_WMS.to_excel(r'data_WMS_OrderOnline.xlsx', index = False)\n",
    "    # #     print('Finished')\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (classic stick)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (CS)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "\n",
    "        order_online_bali = True\n",
    "        del file_name\n",
    "\n",
    "if not order_online_makasar :\n",
    "                    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "\n",
    "    print('order_online_makasar')\n",
    "    \n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element_by_name(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customermakassar@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_name(\"password\")\n",
    "    password.send_keys(\"makassarhomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element_by_class_name(\"btn-submit\").click()\n",
    "\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div').click()\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/button').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/div/button[1]').click()\n",
    "\n",
    "    time.sleep(20)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "#         data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Jakarta.csv')\n",
    "#             product_order = pd.read_csv(r'Input Data/orderonline_products_Jakarta.csv')\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch (x2) ', 'Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch ', regex = False)\n",
    "\n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace(\"tetra\", \"Tetra\").str.replace(\"[6pcs]\", \"(6pcs)\", regex = False)\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "    data_order['product'] = data_order['product'].str.replace(\"Tropicana Slim Goldenmil Vanilla Turmeric 180gr\", 'Tropicana Slim Goldenmil Vanilla Turmeric (6 sch)')\n",
    "    data_order['product'] = data_order['product'].str.replace(\"NutriSari Mango Smoothie Ready to Drink Jus 200ml (6pcs)\", 'NutriSari Mango Smoothie 200ml (6pcs)', regex = False)\n",
    "    \n",
    "    data_SKU = pd.read_excel(r'Order Online\\SKU buat andra updated maret 2021.xlsx')\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace(\"tetra\", \"Tetra\").str.replace(\"[6pcs]\", \"(6pcs)\", regex = False)\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('  ', ' ')\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('L-Men Gain Mass Chocolate 500 gr', 'L Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Nutrisari Mango Smoothie 200ml (6pcs)', 6050]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (6pcs)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey (50sch)', 39500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Orange 750ml', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 225gr', 57500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gainmass Taro 225gr', 69600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo Milk Brown Sugar RTD 200ml (6pcs)', 5500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Lose Weight Chocolate Cereal (12sch)', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 139200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Strawberry Jam 375gr', 72600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 19800, 19800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Cegah Diabetes (+Kaos)', 116100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 250gr + Free Kertas Gambar', 40500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 750gr + Free Kertas Gambar', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Jeruk Peras (40sch x 2) + Nutrisari Mangga Gandaria (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Blewah (40sch x 2) + Nutrisari Jeruk Maroko (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari American Sweet Orange (40sch x 2) + Nutrisari Milky Orange (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 500gr + Free Kertas Gambar', 117600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Ngopi Lokalate', 136000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 750gr', 127100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Florida Orange (40sch x 2) + Nutrisari Markisa (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    # data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    \n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Goldenmil Vanilla (6sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Lokalate Kopi Kawista (10sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Lokalate Kopi Kawista (10sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Kawista', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Kecap Manis 200ml']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200m', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Diabtx 50 sch']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Diabtx (50 sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    #             data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "    # data_order = data_order[data_order['SKU'].notnull()]\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    #         s = requests.Session()\n",
    "    #         s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    #         s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    #         r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    #         with open(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx', 'wb') as output:\n",
    "    #             output.write(r.content)\n",
    "\n",
    "    #         if os.path.isfile(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx') :    \n",
    "    #             SKU_append = pd.read_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx')\n",
    "    #             SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "    #             data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "    #             data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    # to_excel = data_SKU.to_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    \n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Makassar'\n",
    "\n",
    "    #     list_drop = []\n",
    "    #     indeks = data_order[data_order['SKU'].isin(data_SKU2[data_SKU2['Brand'] == 'Bundle']['SKU'])].index.to_list()\n",
    "    #     for i in indeks:\n",
    "    #         if str(data_order['SKU'][i]) in data_SKU2['SKU'].astype(str).values:\n",
    "    #             idx = data_SKU2[str(data_order['SKU'][i] ) == data_SKU2['SKU'].astype(str)].index[0]\n",
    "    #             for j in range(1,8):\n",
    "    #                 colname = 'Produk ' + str(j)\n",
    "    #                 if str(data_SKU2[colname][idx]) != 'nan':\n",
    "    #                     new_data = data_order.iloc[i,]\n",
    "    #                     new_data['Item Name'] = data_SKU2[colname][idx]\n",
    "    #                     new_data['Selling Price'] = data_SKU2['Subtotal ' + colname][idx] * new_data['Quantity']\n",
    "    #                     new_data['Quantity'] = new_data['Quantity'] * data_SKU2['PCS ' + colname][idx]\n",
    "    #                     new_data['SKU'] = str(data_SKU2['SKU ' + colname][idx]).replace('.0','')\n",
    "    #                     new_data['Quantity'] = str(new_data['Quantity']).replace('.0','')\n",
    "    #                     new_data['Selling Price'] = str(new_data['Selling Price']).replace('.0','')\n",
    "    #                     data_order = data_order.append(new_data, ignore_index = True)\n",
    "    #                     list_drop.append(i)\n",
    "    #     data_order = data_order.drop(list_drop, axis = 0)\n",
    "    #     data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "    # #     for i in range(data_order.shape[0]):\n",
    "    # #         if int(data_order['Order date'][i].strftime('%d')) < 12:\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i].strftime('%Y-%d-%m %H:%M'))\n",
    "    # #         else :\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i])\n",
    "    #     indeks = data_order[data_order['Item Name'].astype(str).str.contains('pcs')].index.to_list()\n",
    "    #     temp = data_order.iloc[indeks].copy()\n",
    "    #     product = temp['Item Name'].str.split(\"\\(\",1, expand = True)\n",
    "    #     if len(product) != 0:\n",
    "    #         temp['Quantity Inside'] = product[1].astype(str).str.replace('pcs)', '', regex = False).astype(int)\n",
    "    #         data_order['Quantity'][indeks] = data_order['Quantity'][indeks] * temp['Quantity Inside']\n",
    "\n",
    "    # #     data_order_1 = data_order[data_order['payment_method'] == 'cod']\n",
    "    # #     data_order_2 = data_order[data_order['payment_method'] != 'cod'][data_order[data_order['payment_method'] != 'cod']['payment_status'] == 'paid']\n",
    "    # #     data_WMS = data_order_1.append(data_order_2, ignore_index = True, sort = False)\n",
    "    # #     data_WMS = data_WMS[['Order date', 'Channel', 'Sales Order ID', 'Channel Order ID', 'Invoice Number', 'Customer Name', 'Item Name', 'SKU', 'Quantity', 'Price', 'Shipping Cost', 'Shipping Name', 'Shipping Address1', 'Shipping Address2', 'Shipping City', 'Shipping Zip', 'Shipping Province', 'Shipping Country', 'Shipping Phone', 'Shipping Courier', 'AWB']]\n",
    "    # #     data_WMS.to_excel(r'data_WMS_OrderOnline.xlsx', index = False)\n",
    "    # #     print('Finished')\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (classic stick)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (CS)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "        \n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500318 (CI)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "        \n",
    "        \n",
    "\n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost'], errors = 'coerce').fillna(0).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "\n",
    "        order_online_makasar = True\n",
    "        del file_name\n",
    "\n",
    "if not order_online_medan:\n",
    "                        \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "    \n",
    "    print('order_online_medan')\n",
    "\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element_by_name(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customermedan@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_name(\"password\")\n",
    "    password.send_keys(\"medanhomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element_by_class_name(\"btn-submit\").click()\n",
    "\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div').click()\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/button').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/div/button[1]').click()\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "#         data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Jakarta.csv')\n",
    "#             product_order = pd.read_csv(r'Input Data/orderonline_products_Jakarta.csv')\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch (x2) ', 'Twin Pack: Tropicana Slim Sweetener Rose Vanilla 50 sch ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Tropicana Slim Oat Drink 190 ml \\(RTD\\) x 4 pcs$', 'Tropicana Slim Oat Drink 190 ml (RTD) x 4 pcs (x1)')\n",
    "    \n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men', case = False).str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace(\"tetra\", \"Tetra\").str.replace(\"[6pcs]\", \"(6pcs)\", regex = False)\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "    data_order['product'] = data_order['product'].str.replace(\"NutriSari Jeruk Nipis 40'sachet (4 Renceng)\", 'NutriSari Jeruk Nipis (40 sch)', regex = False)\n",
    "    data_order['product'] = data_order['product'].str.replace(\"Tropicana Slim Sweetener Honey 50 sachet\", 'Tropicana Slim Sweetener Honey (50sch)', regex = False)\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Teen Coklat 250gr\", 'HiLo Teen Chocolate 250gr', regex = False)\n",
    "    data_order.loc[data_order['product']=='HILO TEEN STRAWBERRY MILKSHAKE\\xa0 12Dx500G','product']=\"HiLo Teen Strawberry Milkshake 500gr\"\n",
    "    \n",
    "\n",
    "\n",
    "    data_SKU = pd.read_excel(r'Order Online\\SKU buat andra updated maret 2021.xlsx')\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men', case = False).str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace(\"tetra\", \"Tetra\").str.replace(\"[6pcs]\", \"(6pcs)\", regex = False)\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('  ', ' ')\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('L-Men Gain Mass Chocolate 500 gr', 'L Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Nutrisari Mango Smoothie 200ml (6pcs)', 6050]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (6pcs)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey (50sch)', 39500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Orange 750ml', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 225gr', 57500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gainmass Taro 225gr', 69600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo Milk Brown Sugar RTD 200ml (6pcs)', 5500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Lose Weight Chocolate Cereal (12sch)', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 139200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Strawberry Jam 375gr', 72600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 19800, 19800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Cegah Diabetes (+Kaos)', 116100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 250gr + Free Kertas Gambar', 40500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 750gr + Free Kertas Gambar', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Jeruk Peras (40sch x 2) + Nutrisari Mangga Gandaria (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Blewah (40sch x 2) + Nutrisari Jeruk Maroko (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari American Sweet Orange (40sch x 2) + Nutrisari Milky Orange (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 500gr + Free Kertas Gambar', 117600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Ngopi Lokalate', 136000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 750gr', 127100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Florida Orange (40sch x 2) + Nutrisari Markisa (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) Tropicana Slim Korean Garlic Butter Cookies 5 sch - Khusus Homdel', 11500, 11500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Goldenmil Vanilla (6sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Lokalate Kopi Kawista (10sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Lokalate Kopi Kawista (10sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Kawista', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Kecap Manis 200ml']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200m', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Diabtx 50 sch']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Diabtx (50 sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    #             data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "    # data_order = data_order[data_order['SKU'].notnull()]\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    #         s = requests.Session()\n",
    "    #         s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    #         s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    #         r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    #         with open(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx', 'wb') as output:\n",
    "    #             output.write(r.content)\n",
    "\n",
    "    #         if os.path.isfile(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx') :    \n",
    "    #             SKU_append = pd.read_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx')\n",
    "    #             SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "    #             data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "    #             data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    # to_excel = data_SKU.to_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Medan'\n",
    "\n",
    "    #     list_drop = []\n",
    "    #     indeks = data_order[data_order['SKU'].isin(data_SKU2[data_SKU2['Brand'] == 'Bundle']['SKU'])].index.to_list()\n",
    "    #     for i in indeks:\n",
    "    #         if str(data_order['SKU'][i]) in data_SKU2['SKU'].astype(str).values:\n",
    "    #             idx = data_SKU2[str(data_order['SKU'][i] ) == data_SKU2['SKU'].astype(str)].index[0]\n",
    "    #             for j in range(1,8):\n",
    "    #                 colname = 'Produk ' + str(j)\n",
    "    #                 if str(data_SKU2[colname][idx]) != 'nan':\n",
    "    #                     new_data = data_order.iloc[i,]\n",
    "    #                     new_data['Item Name'] = data_SKU2[colname][idx]\n",
    "    #                     new_data['Selling Price'] = data_SKU2['Subtotal ' + colname][idx] * new_data['Quantity']\n",
    "    #                     new_data['Quantity'] = new_data['Quantity'] * data_SKU2['PCS ' + colname][idx]\n",
    "    #                     new_data['SKU'] = str(data_SKU2['SKU ' + colname][idx]).replace('.0','')\n",
    "    #                     new_data['Quantity'] = str(new_data['Quantity']).replace('.0','')\n",
    "    #                     new_data['Selling Price'] = str(new_data['Selling Price']).replace('.0','')\n",
    "    #                     data_order = data_order.append(new_data, ignore_index = True)\n",
    "    #                     list_drop.append(i)\n",
    "    #     data_order = data_order.drop(list_drop, axis = 0)\n",
    "    #     data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "    # #     for i in range(data_order.shape[0]):\n",
    "    # #         if int(data_order['Order date'][i].strftime('%d')) < 12:\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i].strftime('%Y-%d-%m %H:%M'))\n",
    "    # #         else :\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i])\n",
    "    #     indeks = data_order[data_order['Item Name'].astype(str).str.contains('pcs')].index.to_list()\n",
    "    #     temp = data_order.iloc[indeks].copy()\n",
    "    #     product = temp['Item Name'].str.split(\"\\(\",1, expand = True)\n",
    "    #     if len(product) != 0:\n",
    "    #         temp['Quantity Inside'] = product[1].astype(str).str.replace('pcs)', '', regex = False).astype(int)\n",
    "    #         data_order['Quantity'][indeks] = data_order['Quantity'][indeks] * temp['Quantity Inside']\n",
    "\n",
    "    # #     data_order_1 = data_order[data_order['payment_method'] == 'cod']\n",
    "    # #     data_order_2 = data_order[data_order['payment_method'] != 'cod'][data_order[data_order['payment_method'] != 'cod']['payment_status'] == 'paid']\n",
    "    # #     data_WMS = data_order_1.append(data_order_2, ignore_index = True, sort = False)\n",
    "    # #     data_WMS = data_WMS[['Order date', 'Channel', 'Sales Order ID', 'Channel Order ID', 'Invoice Number', 'Customer Name', 'Item Name', 'SKU', 'Quantity', 'Price', 'Shipping Cost', 'Shipping Name', 'Shipping Address1', 'Shipping Address2', 'Shipping City', 'Shipping Zip', 'Shipping Province', 'Shipping Country', 'Shipping Phone', 'Shipping Courier', 'AWB']]\n",
    "    # #     data_WMS.to_excel(r'data_WMS_OrderOnline.xlsx', index = False)\n",
    "    # #     print('Finished')\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (classic stick)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (CS)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "        \n",
    "#         indeks = order_all[order_all['Product Name'] == '2102900319 (D)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "        \n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500320 (CI160)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "       \n",
    "        \n",
    "        \n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        #order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost'], errors = 'coerce').fillna(0).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "\n",
    "        order_online_medan = True\n",
    "        del file_name\n",
    "\n",
    "if not order_online_samarinda:\n",
    "                            \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "\n",
    "    print('order_online_samarinda')\n",
    "    \n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element_by_name(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customersamarinda@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_name(\"password\")\n",
    "    password.send_keys(\"samarindahomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element_by_class_name(\"btn-submit\").click()\n",
    "\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div').click()\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/button').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/div/button[1]').click()\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "#         data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Jakarta.csv')\n",
    "#             product_order = pd.read_csv(r'Input Data/orderonline_products_Jakarta.csv')\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "\n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate')\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "\n",
    "    data_SKU = pd.read_excel(r'Order Online\\SKU buat andra updated maret 2021.xlsx')\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate')\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('  ', ' ')\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('L-Men Gain Mass Chocolate 500 gr', 'L Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Nutrisari Mango Smoothie 200ml (6pcs)', 6050]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (6pcs)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey (50sch)', 39500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Orange 750ml', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 225gr', 57500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gainmass Taro 225gr', 69600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo Milk Brown Sugar RTD 200ml (6pcs)', 5500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Lose Weight Chocolate Cereal (12sch)', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 139200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Strawberry Jam 375gr', 72600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 19800, 19800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Cegah Diabetes (+Kaos)', 116100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 250gr + Free Kertas Gambar', 40500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 750gr + Free Kertas Gambar', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Jeruk Peras (40sch x 2) + Nutrisari Mangga Gandaria (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Blewah (40sch x 2) + Nutrisari Jeruk Maroko (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari American Sweet Orange (40sch x 2) + Nutrisari Milky Orange (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 500gr + Free Kertas Gambar', 117600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Ngopi Lokalate', 136000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 750gr', 127100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Florida Orange (40sch x 2) + Nutrisari Markisa (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Goldenmil Vanilla (6sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Lokalate Kopi Kawista (10sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Lokalate Kopi Kawista (10sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Kawista', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Kecap Manis 200ml']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200m', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Diabtx 50 sch']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Diabtx (50 sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    #             data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "    # data_order = data_order[data_order['SKU'].notnull()]\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    #         s = requests.Session()\n",
    "    #         s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    #         s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    #         r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    #         with open(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx', 'wb') as output:\n",
    "    #             output.write(r.content)\n",
    "\n",
    "    #         if os.path.isfile(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx') :    \n",
    "    #             SKU_append = pd.read_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx')\n",
    "    #             SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "    #             data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "    #             data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    # to_excel = data_SKU.to_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Samarinda'\n",
    "\n",
    "    #     list_drop = []\n",
    "    #     indeks = data_order[data_order['SKU'].isin(data_SKU2[data_SKU2['Brand'] == 'Bundle']['SKU'])].index.to_list()\n",
    "    #     for i in indeks:\n",
    "    #         if str(data_order['SKU'][i]) in data_SKU2['SKU'].astype(str).values:\n",
    "    #             idx = data_SKU2[str(data_order['SKU'][i] ) == data_SKU2['SKU'].astype(str)].index[0]\n",
    "    #             for j in range(1,8):\n",
    "    #                 colname = 'Produk ' + str(j)\n",
    "    #                 if str(data_SKU2[colname][idx]) != 'nan':\n",
    "    #                     new_data = data_order.iloc[i,]\n",
    "    #                     new_data['Item Name'] = data_SKU2[colname][idx]\n",
    "    #                     new_data['Selling Price'] = data_SKU2['Subtotal ' + colname][idx] * new_data['Quantity']\n",
    "    #                     new_data['Quantity'] = new_data['Quantity'] * data_SKU2['PCS ' + colname][idx]\n",
    "    #                     new_data['SKU'] = str(data_SKU2['SKU ' + colname][idx]).replace('.0','')\n",
    "    #                     new_data['Quantity'] = str(new_data['Quantity']).replace('.0','')\n",
    "    #                     new_data['Selling Price'] = str(new_data['Selling Price']).replace('.0','')\n",
    "    #                     data_order = data_order.append(new_data, ignore_index = True)\n",
    "    #                     list_drop.append(i)\n",
    "    #     data_order = data_order.drop(list_drop, axis = 0)\n",
    "    #     data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "    # #     for i in range(data_order.shape[0]):\n",
    "    # #         if int(data_order['Order date'][i].strftime('%d')) < 12:\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i].strftime('%Y-%d-%m %H:%M'))\n",
    "    # #         else :\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i])\n",
    "    #     indeks = data_order[data_order['Item Name'].astype(str).str.contains('pcs')].index.to_list()\n",
    "    #     temp = data_order.iloc[indeks].copy()\n",
    "    #     product = temp['Item Name'].str.split(\"\\(\",1, expand = True)\n",
    "    #     if len(product) != 0:\n",
    "    #         temp['Quantity Inside'] = product[1].astype(str).str.replace('pcs)', '', regex = False).astype(int)\n",
    "    #         data_order['Quantity'][indeks] = data_order['Quantity'][indeks] * temp['Quantity Inside']\n",
    "\n",
    "    # #     data_order_1 = data_order[data_order['payment_method'] == 'cod']\n",
    "    # #     data_order_2 = data_order[data_order['payment_method'] != 'cod'][data_order[data_order['payment_method'] != 'cod']['payment_status'] == 'paid']\n",
    "    # #     data_WMS = data_order_1.append(data_order_2, ignore_index = True, sort = False)\n",
    "    # #     data_WMS = data_WMS[['Order date', 'Channel', 'Sales Order ID', 'Channel Order ID', 'Invoice Number', 'Customer Name', 'Item Name', 'SKU', 'Quantity', 'Price', 'Shipping Cost', 'Shipping Name', 'Shipping Address1', 'Shipping Address2', 'Shipping City', 'Shipping Zip', 'Shipping Province', 'Shipping Country', 'Shipping Phone', 'Shipping Courier', 'AWB']]\n",
    "    # #     data_WMS.to_excel(r'data_WMS_OrderOnline.xlsx', index = False)\n",
    "    # #     print('Finished')\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (classic stick)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (CS)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "        data_all_aft_order = data_all.copy()\n",
    "        del file_name\n",
    "        order_online_samarinda = True\n",
    "        \n",
    "if not order_online_lampung:\n",
    "                            \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "\n",
    "    print('order_online_lampung')\n",
    "    \n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element_by_name(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customerlampung@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_name(\"password\")\n",
    "    password.send_keys(\"lampunghomdel\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element_by_class_name(\"btn-submit\").click()\n",
    "    time.sleep(15)\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div').click()\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/button').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/div/button[1]').click()\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "#         data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Jakarta.csv')\n",
    "#             product_order = pd.read_csv(r'Input Data/orderonline_products_Jakarta.csv')\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "\n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate').str.replace('40 sch', '40sch').str.replace('6 tetrapack', '6 Tetrapack').str.replace(\"Diabetx 100s\", \"Diabtx (100 sch)\").str.replace(\"Alpukat 10's\", \"Alpukat (10sch)\").str.replace(\"Kawista 10 sch\", \"Kawista (10sch)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "\n",
    "    data_SKU = pd.read_excel(r'Order Online\\SKU buat andra updated maret 2021.xlsx')\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate').str.replace('40 sch', '40sch').str.replace('6 tetrapack', '6 Tetrapack').str.replace(\"Diabetx 100s\", \"Diabtx (100 sch)\").str.replace(\"Alpukat 10's\", \"Alpukat (10sch)\").str.replace(\"Kawista 10 sch\", \"Kawista (10sch)\")\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('  ', ' ')\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('L-Men Gain Mass Chocolate 500 gr', 'L Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Nutrisari Mango Smoothie 200ml (6pcs)', 6050]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (6pcs)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey (50sch)', 39500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Orange 750ml', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 225gr', 57500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gainmass Taro 225gr', 69600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo Milk Brown Sugar RTD 200ml (6pcs)', 5500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Lose Weight Chocolate Cereal (12sch)', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 139200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Strawberry Jam 375gr', 72600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 19800, 19800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Cegah Diabetes (+Kaos)', 116100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 250gr + Free Kertas Gambar', 40500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 750gr + Free Kertas Gambar', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Jeruk Peras (40sch x 2) + Nutrisari Mangga Gandaria (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Blewah (40sch x 2) + Nutrisari Jeruk Maroko (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari American Sweet Orange (40sch x 2) + Nutrisari Milky Orange (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 500gr + Free Kertas Gambar', 117600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Ngopi Lokalate', 136000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 750gr', 127100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Florida Orange (40sch x 2) + Nutrisari Markisa (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['(Near ED) HiLo School Susu Coklat (10 sch) Gusset - Khusus Homdel', 45800, 22900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    \n",
    "    #data_SKU = data_SKU.append(pd.DataFrame([['HiLo Thai Tea (10Sch) - Near ED', 14900, 7450]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Goldenmil Vanilla (6sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Lokalate Kopi Kawista (10sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Lokalate Kopi Kawista (10sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Kawista', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Kecap Manis 200ml']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200m', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Diabtx 50 sch']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Diabtx (50 sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    #             data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "    # data_order = data_order[data_order['SKU'].notnull()]\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    s = requests.Session()\n",
    "    s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    with open(r'SKU_File\\Master tatanama.xlsx', 'wb') as output:\n",
    "        output.write(r.content)\n",
    "\n",
    "    if os.path.isfile(r'SKU_File\\Master tatanama.xlsx') :    \n",
    "        SKU_append = pd.read_excel(r'SKU_File\\Master tatanama.xlsx')\n",
    "        SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "        data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "        data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    to_excel = data_SKU2.to_excel(r'SKU_File\\data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Lampung'\n",
    "\n",
    "    #     list_drop = []\n",
    "    #     indeks = data_order[data_order['SKU'].isin(data_SKU2[data_SKU2['Brand'] == 'Bundle']['SKU'])].index.to_list()\n",
    "    #     for i in indeks:\n",
    "    #         if str(data_order['SKU'][i]) in data_SKU2['SKU'].astype(str).values:\n",
    "    #             idx = data_SKU2[str(data_order['SKU'][i] ) == data_SKU2['SKU'].astype(str)].index[0]\n",
    "    #             for j in range(1,8):\n",
    "    #                 colname = 'Produk ' + str(j)\n",
    "    #                 if str(data_SKU2[colname][idx]) != 'nan':\n",
    "    #                     new_data = data_order.iloc[i,]\n",
    "    #                     new_data['Item Name'] = data_SKU2[colname][idx]\n",
    "    #                     new_data['Selling Price'] = data_SKU2['Subtotal ' + colname][idx] * new_data['Quantity']\n",
    "    #                     new_data['Quantity'] = new_data['Quantity'] * data_SKU2['PCS ' + colname][idx]\n",
    "    #                     new_data['SKU'] = str(data_SKU2['SKU ' + colname][idx]).replace('.0','')\n",
    "    #                     new_data['Quantity'] = str(new_data['Quantity']).replace('.0','')\n",
    "    #                     new_data['Selling Price'] = str(new_data['Selling Price']).replace('.0','')\n",
    "    #                     data_order = data_order.append(new_data, ignore_index = True)\n",
    "    #                     list_drop.append(i)\n",
    "    #     data_order = data_order.drop(list_drop, axis = 0)\n",
    "    #     data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "    # #     for i in range(data_order.shape[0]):\n",
    "    # #         if int(data_order['Order date'][i].strftime('%d')) < 12:\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i].strftime('%Y-%d-%m %H:%M'))\n",
    "    # #         else :\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i])\n",
    "    #     indeks = data_order[data_order['Item Name'].astype(str).str.contains('pcs')].index.to_list()\n",
    "    #     temp = data_order.iloc[indeks].copy()\n",
    "    #     product = temp['Item Name'].str.split(\"\\(\",1, expand = True)\n",
    "    #     if len(product) != 0:\n",
    "    #         temp['Quantity Inside'] = product[1].astype(str).str.replace('pcs)', '', regex = False).astype(int)\n",
    "    #         data_order['Quantity'][indeks] = data_order['Quantity'][indeks] * temp['Quantity Inside']\n",
    "\n",
    "    # #     data_order_1 = data_order[data_order['payment_method'] == 'cod']\n",
    "    # #     data_order_2 = data_order[data_order['payment_method'] != 'cod'][data_order[data_order['payment_method'] != 'cod']['payment_status'] == 'paid']\n",
    "    # #     data_WMS = data_order_1.append(data_order_2, ignore_index = True, sort = False)\n",
    "    # #     data_WMS = data_WMS[['Order date', 'Channel', 'Sales Order ID', 'Channel Order ID', 'Invoice Number', 'Customer Name', 'Item Name', 'SKU', 'Quantity', 'Price', 'Shipping Cost', 'Shipping Name', 'Shipping Address1', 'Shipping Address2', 'Shipping City', 'Shipping Zip', 'Shipping Province', 'Shipping Country', 'Shipping Phone', 'Shipping Courier', 'AWB']]\n",
    "    # #     data_WMS.to_excel(r'data_WMS_OrderOnline.xlsx', index = False)\n",
    "    # #     print('Finished')\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (classic stick)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (CS)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "#         data_all_aft_order = data_all.copy()\n",
    "        del file_name\n",
    "        order_online_lampung = True\n",
    "        \n",
    "\n",
    "        \n",
    "if not order_online_pekanbaru:\n",
    "                            \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "\n",
    "    print('order_online_pekanbaru')\n",
    "    \n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element_by_name(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"customerpekanbaru@nutrimart.co.id\")\n",
    "\n",
    "    password = driver.find_element_by_name(\"password\")\n",
    "    password.send_keys(\"pekanbaruhomdel1\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element_by_class_name(\"btn-submit\").click()\n",
    "    time.sleep(15)\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div').click()\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/button').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/div/button[1]').click()\n",
    "\n",
    "    time.sleep(25)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "#         data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Jakarta.csv')\n",
    "#             product_order = pd.read_csv(r'Input Data/orderonline_products_Jakarta.csv')\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "    data_order.loc[data_order['product']=='HILO TEEN STRAWBERRY MILKSHAKE\\xa0 12Dx500G','product']=\"HiLo Teen Strawberry Milkshake 500gr\"\n",
    "    \n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "#     product.loc[product[1].isnull(),1]=\"1)\"\n",
    "    product.loc[product[0]==\"HiLo Teen Taro 500gr\",1]=\"1)\"\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate').str.replace('40 sch', '40sch')\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "\n",
    "    data_SKU = pd.read_excel(r'Order Online\\SKU buat andra updated maret 2021.xlsx')\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate').str.replace('40 sch', '40sch')\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('  ', ' ')\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('L-Men Gain Mass Chocolate 500 gr', 'L Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Nutrisari Mango Smoothie 200ml (6pcs)', 6050]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (6pcs)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey (50sch)', 39500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Orange 750ml', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 225gr', 57500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gainmass Taro 225gr', 69600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo Milk Brown Sugar RTD 200ml (6pcs)', 5500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Lose Weight Chocolate Cereal (12sch)', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 139200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Strawberry Jam 375gr', 72600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 19800, 19800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Cegah Diabetes (+Kaos)', 116100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 250gr + Free Kertas Gambar', 40500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 750gr + Free Kertas Gambar', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Jeruk Peras (40sch x 2) + Nutrisari Mangga Gandaria (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Blewah (40sch x 2) + Nutrisari Jeruk Maroko (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari American Sweet Orange (40sch x 2) + Nutrisari Milky Orange (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 500gr + Free Kertas Gambar', 117600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Ngopi Lokalate', 136000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 750gr', 127100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Florida Orange (40sch x 2) + Nutrisari Markisa (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Goldenmil Vanilla (6sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Lokalate Kopi Kawista (10sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Lokalate Kopi Kawista (10sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Kawista', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Kecap Manis 200ml']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200m', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Diabtx 50 sch']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Diabtx (50 sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "    data_order.loc[data_order['product']=='HILO TEEN STRAWBERRY MILKSHAKE\\xa0 12Dx500G','product']=\"HiLo Teen Strawberry Milkshake 500gr\"\n",
    "\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    #             data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "    # data_order = data_order[data_order['SKU'].notnull()]\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    #         s = requests.Session()\n",
    "    #         s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    #         s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    #         r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    #         with open(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx', 'wb') as output:\n",
    "    #             output.write(r.content)\n",
    "\n",
    "    #         if os.path.isfile(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx') :    \n",
    "    #             SKU_append = pd.read_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx')\n",
    "    #             SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "    #             data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "    #             data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    # to_excel = data_SKU.to_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Pekanbaru'\n",
    "\n",
    "    #     list_drop = []\n",
    "    #     indeks = data_order[data_order['SKU'].isin(data_SKU2[data_SKU2['Brand'] == 'Bundle']['SKU'])].index.to_list()\n",
    "    #     for i in indeks:\n",
    "    #         if str(data_order['SKU'][i]) in data_SKU2['SKU'].astype(str).values:\n",
    "    #             idx = data_SKU2[str(data_order['SKU'][i] ) == data_SKU2['SKU'].astype(str)].index[0]\n",
    "    #             for j in range(1,8):\n",
    "    #                 colname = 'Produk ' + str(j)\n",
    "    #                 if str(data_SKU2[colname][idx]) != 'nan':\n",
    "    #                     new_data = data_order.iloc[i,]\n",
    "    #                     new_data['Item Name'] = data_SKU2[colname][idx]\n",
    "    #                     new_data['Selling Price'] = data_SKU2['Subtotal ' + colname][idx] * new_data['Quantity']\n",
    "    #                     new_data['Quantity'] = new_data['Quantity'] * data_SKU2['PCS ' + colname][idx]\n",
    "    #                     new_data['SKU'] = str(data_SKU2['SKU ' + colname][idx]).replace('.0','')\n",
    "    #                     new_data['Quantity'] = str(new_data['Quantity']).replace('.0','')\n",
    "    #                     new_data['Selling Price'] = str(new_data['Selling Price']).replace('.0','')\n",
    "    #                     data_order = data_order.append(new_data, ignore_index = True)\n",
    "    #                     list_drop.append(i)\n",
    "    #     data_order = data_order.drop(list_drop, axis = 0)\n",
    "    #     data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "    # #     for i in range(data_order.shape[0]):\n",
    "    # #         if int(data_order['Order date'][i].strftime('%d')) < 12:\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i].strftime('%Y-%d-%m %H:%M'))\n",
    "    # #         else :\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i])\n",
    "    #     indeks = data_order[data_order['Item Name'].astype(str).str.contains('pcs')].index.to_list()\n",
    "    #     temp = data_order.iloc[indeks].copy()\n",
    "    #     product = temp['Item Name'].str.split(\"\\(\",1, expand = True)\n",
    "    #     if len(product) != 0:\n",
    "    #         temp['Quantity Inside'] = product[1].astype(str).str.replace('pcs)', '', regex = False).astype(int)\n",
    "    #         data_order['Quantity'][indeks] = data_order['Quantity'][indeks] * temp['Quantity Inside']\n",
    "\n",
    "    # #     data_order_1 = data_order[data_order['payment_method'] == 'cod']\n",
    "    # #     data_order_2 = data_order[data_order['payment_method'] != 'cod'][data_order[data_order['payment_method'] != 'cod']['payment_status'] == 'paid']\n",
    "    # #     data_WMS = data_order_1.append(data_order_2, ignore_index = True, sort = False)\n",
    "    # #     data_WMS = data_WMS[['Order date', 'Channel', 'Sales Order ID', 'Channel Order ID', 'Invoice Number', 'Customer Name', 'Item Name', 'SKU', 'Quantity', 'Price', 'Shipping Cost', 'Shipping Name', 'Shipping Address1', 'Shipping Address2', 'Shipping City', 'Shipping Zip', 'Shipping Province', 'Shipping Country', 'Shipping Phone', 'Shipping Courier', 'AWB']]\n",
    "    # #     data_WMS.to_excel(r'data_WMS_OrderOnline.xlsx', index = False)\n",
    "    # #     print('Finished')\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (classic stick)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "#         indeks = order_all[order_all['Product Name'] == '2102500336 (CS)'].index.to_list()\n",
    "#         order_all = order_all.drop(indeks, axis = 0)\n",
    "        \n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "\n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "#         data_all_aft_order = data_all.copy()\n",
    "        del file_name\n",
    "        order_online_pekanbaru = True\n",
    "        # order_online_cond = True\n",
    "if not order_online_banjarmasin:\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "\n",
    "    print('order_online_banjarmasin')\n",
    "\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(\"Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element_by_name(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"banjarmasinpromosi.nhd2022@gmail.com\")\n",
    "\n",
    "    password = driver.find_element_by_name(\"password\")\n",
    "    password.send_keys(\"nhdcuan\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element_by_class_name(\"btn-submit\").click()\n",
    "    time.sleep(15)\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div').click()\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/button').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/div/button[1]').click()\n",
    "\n",
    "    time.sleep(25)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "    #         data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Jakarta.csv')\n",
    "    #             product_order = pd.read_csv(r'Input Data/orderonline_products_Jakarta.csv')\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "\n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    #     product.loc[product[1].isnull(),1]=\"1)\"\n",
    "    product.loc[product[0]==\"HiLo Teen Taro 500gr\",1]=\"1)\"\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate').str.replace('40 sch', '40sch')\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "\n",
    "    data_SKU = pd.read_excel(r'Order Online\\SKU buat andra updated maret 2021.xlsx')\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate').str.replace('40 sch', '40sch')\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('  ', ' ')\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('L-Men Gain Mass Chocolate 500 gr', 'L Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Nutrisari Mango Smoothie 200ml (6pcs)', 6050]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (6pcs)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey (50sch)', 39500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Orange 750ml', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 225gr', 57500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gainmass Taro 225gr', 69600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo Milk Brown Sugar RTD 200ml (6pcs)', 5500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Lose Weight Chocolate Cereal (12sch)', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 139200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Strawberry Jam 375gr', 72600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 19800, 19800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Cegah Diabetes (+Kaos)', 116100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 250gr + Free Kertas Gambar', 40500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 750gr + Free Kertas Gambar', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Jeruk Peras (40sch x 2) + Nutrisari Mangga Gandaria (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Blewah (40sch x 2) + Nutrisari Jeruk Maroko (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari American Sweet Orange (40sch x 2) + Nutrisari Milky Orange (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 500gr + Free Kertas Gambar', 117600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Ngopi Lokalate', 136000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 750gr', 127100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Florida Orange (40sch x 2) + Nutrisari Markisa (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Goldenmil Vanilla (6sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Lokalate Kopi Kawista (10sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Lokalate Kopi Kawista (10sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Kawista', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Kecap Manis 200ml']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200m', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Diabtx 50 sch']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Diabtx (50 sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    #             data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "    # data_order = data_order[data_order['SKU'].notnull()]\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    #         s = requests.Session()\n",
    "    #         s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    #         s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    #         r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    #         with open(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx', 'wb') as output:\n",
    "    #             output.write(r.content)\n",
    "\n",
    "    #         if os.path.isfile(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx') :    \n",
    "    #             SKU_append = pd.read_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx')\n",
    "    #             SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "    #             data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "    #             data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    # to_excel = data_SKU.to_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Banjarmasin'\n",
    "\n",
    "    #     list_drop = []\n",
    "    #     indeks = data_order[data_order['SKU'].isin(data_SKU2[data_SKU2['Brand'] == 'Bundle']['SKU'])].index.to_list()\n",
    "    #     for i in indeks:\n",
    "    #         if str(data_order['SKU'][i]) in data_SKU2['SKU'].astype(str).values:\n",
    "    #             idx = data_SKU2[str(data_order['SKU'][i] ) == data_SKU2['SKU'].astype(str)].index[0]\n",
    "    #             for j in range(1,8):\n",
    "    #                 colname = 'Produk ' + str(j)\n",
    "    #                 if str(data_SKU2[colname][idx]) != 'nan':\n",
    "    #                     new_data = data_order.iloc[i,]\n",
    "    #                     new_data['Item Name'] = data_SKU2[colname][idx]\n",
    "    #                     new_data['Selling Price'] = data_SKU2['Subtotal ' + colname][idx] * new_data['Quantity']\n",
    "    #                     new_data['Quantity'] = new_data['Quantity'] * data_SKU2['PCS ' + colname][idx]\n",
    "    #                     new_data['SKU'] = str(data_SKU2['SKU ' + colname][idx]).replace('.0','')\n",
    "    #                     new_data['Quantity'] = str(new_data['Quantity']).replace('.0','')\n",
    "    #                     new_data['Selling Price'] = str(new_data['Selling Price']).replace('.0','')\n",
    "    #                     data_order = data_order.append(new_data, ignore_index = True)\n",
    "    #                     list_drop.append(i)\n",
    "    #     data_order = data_order.drop(list_drop, axis = 0)\n",
    "    #     data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "    # #     for i in range(data_order.shape[0]):\n",
    "    # #         if int(data_order['Order date'][i].strftime('%d')) < 12:\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i].strftime('%Y-%d-%m %H:%M'))\n",
    "    # #         else :\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i])\n",
    "    #     indeks = data_order[data_order['Item Name'].astype(str).str.contains('pcs')].index.to_list()\n",
    "    #     temp = data_order.iloc[indeks].copy()\n",
    "    #     product = temp['Item Name'].str.split(\"\\(\",1, expand = True)\n",
    "    #     if len(product) != 0:\n",
    "    #         temp['Quantity Inside'] = product[1].astype(str).str.replace('pcs)', '', regex = False).astype(int)\n",
    "    #         data_order['Quantity'][indeks] = data_order['Quantity'][indeks] * temp['Quantity Inside']\n",
    "\n",
    "    # #     data_order_1 = data_order[data_order['payment_method'] == 'cod']\n",
    "    # #     data_order_2 = data_order[data_order['payment_method'] != 'cod'][data_order[data_order['payment_method'] != 'cod']['payment_status'] == 'paid']\n",
    "    # #     data_WMS = data_order_1.append(data_order_2, ignore_index = True, sort = False)\n",
    "    # #     data_WMS = data_WMS[['Order date', 'Channel', 'Sales Order ID', 'Channel Order ID', 'Invoice Number', 'Customer Name', 'Item Name', 'SKU', 'Quantity', 'Price', 'Shipping Cost', 'Shipping Name', 'Shipping Address1', 'Shipping Address2', 'Shipping City', 'Shipping Zip', 'Shipping Province', 'Shipping Country', 'Shipping Phone', 'Shipping Courier', 'AWB']]\n",
    "    # #     data_WMS.to_excel(r'data_WMS_OrderOnline.xlsx', index = False)\n",
    "    # #     print('Finished')\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "    #         indeks = order_all[order_all['Product Name'] == '2102500336 (classic stick)'].index.to_list()\n",
    "    #         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "    #         indeks = order_all[order_all['Product Name'] == '2102500336 (CS)'].index.to_list()\n",
    "    #         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "\n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "    #         data_all_aft_order = data_all.copy()\n",
    "        del file_name\n",
    "        order_online_banjarmasin = True\n",
    "        # order_online_cond = True\n",
    "if not order_online_jabar:\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    import os\n",
    "\n",
    "    print('order_online_jabar')\n",
    "\n",
    "    before = os.listdir(os.getcwd() + '/Input Data')\n",
    "\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": os.path.abspath(r\"C:\\Users\\steven.nathanael\\OneDrive - PT Nutrifood Indonesia\\Documents\\Python\\Data\\Master Data\\MD min\\Input Data\"),\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.fullscreen_window()\n",
    "    driver.get(\"https://app.orderonline.id\")\n",
    "\n",
    "    username = driver.find_element_by_name(\"email\")\n",
    "    username.clear()\n",
    "    username.send_keys(\"nutrimartbandung1@gmail.com\")\n",
    "\n",
    "    password = driver.find_element_by_name(\"password\")\n",
    "    password.send_keys(\"nhdcuancuan\")\n",
    "    password.click()\n",
    "\n",
    "    driver.find_element_by_class_name(\"btn-submit\").click()\n",
    "    time.sleep(15)\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"main-nav-dropdown\"]/ul/li[3]/a'))).click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div').click()\n",
    "    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[1]/div[1]/ul/li[6]'))).click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[1]/div/div[2]/div/div/div[2]/div[2]/button[2]').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/button').click()\n",
    "    driver.find_element_by_xpath('//*[@id=\"app\"]/main/div/div[1]/div[3]/div/div/button[1]').click()\n",
    "\n",
    "    time.sleep(25)\n",
    "\n",
    "    after = os.listdir(os.getcwd() + '/Input Data')\n",
    "    change = set(after) - set(before)\n",
    "    if len(change) == 1:\n",
    "        file_name = change.pop()\n",
    "    elif len(change) == 0: \n",
    "        print(\"No file downloaded\")\n",
    "    else :\n",
    "        print(\"More than one file downloaded\")\n",
    "\n",
    "    data_order = pd.read_csv(r'Input Data/' + str(file_name))\n",
    "    driver.close()\n",
    "    #         data_order = pd.read_csv(r'Input Data/orderonline_orders_all_products_Jakarta.csv')\n",
    "    #             product_order = pd.read_csv(r'Input Data/orderonline_products_Jakarta.csv')\n",
    "\n",
    "    data_order['order_id'] = data_order['order_id'].fillna(method='ffill')\n",
    "    data_order = data_order.drop('quantity', axis = 1)\n",
    "    temp = data_order.drop_duplicates('order_id').drop('product', axis = 1)\n",
    "    data_order = data_order[['order_id', 'product']]\n",
    "    data_order = data_order.merge(temp, how = 'left', on = 'order_id')\n",
    "    data_order['order_id'] = data_order['order_id'].astype(int)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Shirataki Noodles 71gr (x2) ', 'Twin Pack: Tropicana Slim Shirataki Noodles 71gr ', regex = False)\n",
    "    data_order['product'] = data_order['product'].astype(str).str.replace('Twin Pack: Tropicana Slim Saus Tiram 200ml (x2) ', 'Twin Pack: Tropicana Slim Saus Tiram 200ml ', regex = False)\n",
    "\n",
    "    product = data_order['product'].str.split(\"\\(x\",1, expand = True)\n",
    "    #     product.loc[product[1].isnull(),1]=\"1)\"\n",
    "    product.loc[product[0]==\"HiLo Teen Taro 500gr\",1]=\"1)\"\n",
    "    data_order['Quantity'] = product[1].astype(str).str.replace(')', '', regex = False).astype(int)\n",
    "    data_order['product'] = product[0].str.strip().str.replace('  ', ' ').str.replace('6 SCH', '6sch').str.replace(\"W'Dank\", \"W'dank\").str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate').str.replace('40 sch', '40sch')\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace(\"HiLo Thai Tea \\(10sch\\)$\", 'HiLo Thai Tea (10 sch)', regex = True)\n",
    "\n",
    "    data_SKU = pd.read_excel(r'Order Online\\SKU buat andra updated maret 2021.xlsx')\n",
    "    data_SKU = data_SKU.rename(columns = {'Product' : 'product', 'PL NFI' : 'Price List NFI'})\n",
    "    data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "    data_SKU = data_SKU[data_SKU['SKU'] != 'nan'][data_SKU[data_SKU['SKU'] != 'nan']['SKU'] != '0']\n",
    "    data_SKU['product'] = data_SKU['product'].str.strip().str.replace('L-men', 'L-Men').str.replace(\"Hilo\", \"HiLo\").str.replace(\"Sch\", \"sch\").str.replace(\"Ml\", \"ml\").str.replace(\"Gr\", \"gr\").str.replace(\"DIABTX\", \"Diabtx\").str.replace(\"Empon-empon\", \"Empon-Empon\").str.replace(\"Nutrisari\", \"NutriSari\").str.replace(\"X\", \"x\").str.replace(\"original\", \"Original\").str.replace(\"hilo\", \"HiLo\").str.replace(\"Bbq\", \"BBQ\").str.replace(\"school\", \"School\").str.replace(\"Rtd\", \"RTD\").str.replace('Honey 50 sachet', 'Honey (50sch)').str.replace('Teen Coklat', 'Teen Chocolate').str.replace('40 sch', '40sch')\n",
    "\n",
    "\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Kecap Manis 200ml'].copy()\n",
    "    price['product'] = 'Tropicana Slim Kecap Manis 200m'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Diabtx (50 sch)'].copy()\n",
    "    price['product'] = 'Tropicana Slim Diabtx 50 sch'\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    price = data_SKU[data_SKU['product'] == 'Tropicana Slim Hokkaido Cheese 100gr'].copy()\n",
    "    price['product'] = 'Tropicana Slim Hokaido Cheese 100gr'\n",
    "\n",
    "\n",
    "    data_SKU = data_SKU.append(price, ignore_index = True, sort = False)\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('  ', ' ')\n",
    "    #             product_order['title'] = product_order['title'].str.strip().str.replace('L-Men Gain Mass Chocolate 500 gr', 'L Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Nutrisari Mango Smoothie 200ml (6pcs)', 6050]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (6pcs)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)', 8600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['L-Men Bar Crunchy Chocolate 12sch', 5500, 5500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sweetener Honey (50sch)', 39500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Sirup Orange 750ml', 28600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 225gr', 57500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gainmass Taro 225gr', 69600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo Milk Brown Sugar RTD 200ml (6pcs)', 5500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Lose Weight Chocolate Cereal (12sch)', 99000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['L-Men Gain Mass Chocolate 500 gr', 139200]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Strawberry Jam 375gr', 72600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Hokkaido Cheese 100gr', 19800, 19800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['NutriSari Mangga Gandaria', 45000, 45000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Cegah Diabetes (+Kaos)', 116100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 250gr + Free Kertas Gambar', 40500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 750gr + Free Kertas Gambar', 85800]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Jeruk Peras (40sch x 2) + Nutrisari Mangga Gandaria (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Blewah (40sch x 2) + Nutrisari Jeruk Maroko (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari American Sweet Orange (40sch x 2) + Nutrisari Milky Orange (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Hilo School Chocolate 500gr + Free Kertas Gambar', 117600]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Ngopi Lokalate', 136000]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['HiLo Gold Chocolate 750gr', 127100]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Paket Nutrisari Florida Orange (40sch x 2) + Nutrisari Markisa (40sch x 1)', 157500]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Teen Vanilla Caramel 500gr', 71500, 71500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Paket Bundle HiLo Renceng (Hilo Chocolate Banana (10 sch) + Hilo Chocolate Taro (10 sch) + HiLo Thai Tea (10sch))', 35200, 35200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Berondong 10's\", 15000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Kecap Asin 200 ml\", 28500, 26000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim DIABTX (100 sch)\", 87700, 75000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Teen Chocolate 750gr\", 117800, 104000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Ngopi Lokalate\", 136000, 109200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Hi Protein 2 Go Chocolate (24 TETRAPAK)\", 240000, 238000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)\", 39160, 31000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Lokalate Kopi Kawista\", 17500, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Paket Bundle HiLo (HiLo Active Chocolate 500gr + HiLo Teen Yoghurt Banana 250gr)\", 122900, 101850]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Strawberry Jam 375gr\", 72600, 58500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Crunch BBQ Beef (20gr)\", 13500, 10500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Cocopandan 40 sch\", 52500, 52500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"BUY 1 GET 1 - W'dank Empon Empon 10 Sachet Renceng\", 35000, 15000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Semangka 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"NutriSari Nanas 40 sch\", 62000, 42000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"W'Dank Empon-Empon 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Milk Skim Fiber Pro Plain 500gr\", 135000, 106700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"HiLo Es Teler 10 sch\", 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: HiLo Es Teler 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Hilo Es Ketan Hitam 10 sch x 2\", 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Triple Pack: Tropicana Slim Korean Garlic Butter Cookies (5 Sch)\", 73500, 52000]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Avocado Coffee 4 Sch\", 21200, 12100]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Tropicana Slim Sambal Terasi 200 gr\", 35600, 29700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Twin Pack: Tropicana Slim Avocado Coffee 4 sch x 2\", 42400, 24200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"L-Men Protein Bar Chocolate (12 Sch) + L-Men Protein Crunch BBQ Beef x 2\", 159000, 107800]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([[\"Buy 5 Get 5 L-Men Protein Crunch BBQ Beef (20gr)\", 130000, 67500]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['HiLo Active Ketan Hitam 175gr', 48500, 20700]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Hilo Es Ketan Hitam 10 sch', 17500, 13200]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Tropicana Slim Sweetener Lemongrass Pandan 50 sch', 44200, 28900]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "    data_SKU = data_SKU.append(pd.DataFrame([['Buy 1 Get 1 FREE: Lokalate Kopi Berondong (10 sch)', 35000, 26400]], columns = ['product', 'Harga Display', 'Harga Coret']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Goldenmil Vanilla (6sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Tropicana Slim Goldenmil Vanilla (6sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Lokalate Kopi Kawista (10sch)']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['BUY 1 GET 1 Lokalate Kopi Kawista (10sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Lokalate Kopi Kawista', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Kecap Manis 200ml']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Kecap Manis 200m', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "    #             price = product_order[product_order['title'] == 'Tropicana Slim Diabtx 50 sch']['price'].values[0]\n",
    "    #             product_order = product_order.append(pd.DataFrame([['Tropicana Slim Diabtx (50 sch)', price]], columns = ['title', 'price']), ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "    data_order['product'] = data_order['product'].astype(str)\n",
    "    data_SKU['product'] = data_SKU['product'].astype(str)\n",
    "\n",
    "    data_order['product'] = data_order['product'].str.replace('L Men Gain Mass Chocolate 500 gr', 'L-Men Gain Mass Chocolate 500 gr')\n",
    "\n",
    "\n",
    "\n",
    "    data_order = data_order.merge(data_SKU[['SKU', 'product', 'Harga Display', 'Harga Coret']].drop_duplicates('product'), how = 'left', on = 'product')\n",
    "    #             data_order = data_order.merge(product_order[['title', 'price']].drop_duplicates('title'), how = 'left', left_on = 'product', right_on = 'title').drop('title', axis = 1)\n",
    "    # data_order = data_order[data_order['SKU'].notnull()]\n",
    "    data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "    indeks = data_order[data_order['product'] == \"Lokalate Kopi Berondong 10's\"].index.to_list()\n",
    "    data_order['Harga Display'][indeks] = 15000\n",
    "    data_order['Harga Coret'][indeks] = 15000\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "    for i in indeks:\n",
    "        col = [x for x in data_SKU.columns if 'Alias Nama' in x]\n",
    "        for j in col:\n",
    "            if data_order['product'][i] in data_SKU[j].astype(str).values:\n",
    "                SKU = data_SKU[data_SKU[j].astype(str) == data_order['product'][i]]['SKU'].values[0]\n",
    "                data_order['SKU'][i] = SKU\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    data_SKU2 = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "    data_SKU2['Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "    #         s = requests.Session()\n",
    "    #         s.get(\"http://tatanama.pythonanywhere.com\")\n",
    "    #         s.post(\"http://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ecommerce'})\n",
    "    #         r = s.get(\"http://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "    #         with open(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx', 'wb') as output:\n",
    "    #             output.write(r.content)\n",
    "\n",
    "    #         if os.path.isfile(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx') :    \n",
    "    #             SKU_append = pd.read_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/Master tatanama.xlsx')\n",
    "    #             SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "    #             data_SKU2 = data_SKU2[~data_SKU2['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "    #             data_SKU2 = data_SKU2.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "    # to_excel = data_SKU.to_excel(r'C:\\Users\\andra.miftah\\Demo 9\\SKU_File/data_SKU.xlsx', index = False)\n",
    "\n",
    "    for i in indeks:\n",
    "        if str(data_order['product'][i]).lower() in data_SKU2['Nama Produk'].astype(str).str.lower().values:\n",
    "            data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2['Nama Produk'].astype(str).str.lower()].values[0]\n",
    "\n",
    "    list_alias_name = [x for x in data_SKU2.columns if 'Alias Nama' in x]\n",
    "\n",
    "    for i in indeks:\n",
    "        for j in list_alias_name:\n",
    "            if str(data_order['product'][i]).lower() in data_SKU2[j].astype(str).str.lower().values:\n",
    "                data_order['SKU'][i] = data_SKU2['SKU'].loc[str(data_order['product'][i]).lower() == data_SKU2[j].astype(str).str.lower()].values[0]\n",
    "\n",
    "    indeks = data_order[data_order['SKU'].isnull()].index.to_list()\n",
    "\n",
    "    if len(indeks) != 0:\n",
    "        print('Alert SKU Missing')\n",
    "        data_order['product'][indeks].drop_duplicates().to_excel('Alert SKU Missing.xlsx', index = False)\n",
    "    else :\n",
    "        data_order['phone'] = data_order['phone'].astype(str).str.replace('+628', '08', regex = False)\n",
    "\n",
    "        data_order['zip'] = data_order['zip'].replace('.0', '', regex = False)\n",
    "\n",
    "        data_order = data_order.rename(columns = {'order_id' : 'Sales Order ID', 'name' : 'Customer Name', 'product' : 'Item Name', 'price' : 'Price', 'shipping_cost' : 'Shipping Cost', 'address' : 'Shipping Address1', 'city' : 'Shipping City', 'zip' : 'Shipping Zip', 'province' : 'Shipping Province', 'phone' : 'Shipping Phone', 'courier' : 'Shipping Courier'})\n",
    "        data_order['Channel Order ID'] = data_order['Sales Order ID']\n",
    "        data_order['Invoice Number'] = data_order['Sales Order ID']\n",
    "        data_order['Shipping Name'] = data_order['Customer Name']\n",
    "        data_order['Shipping Address2'] = 0\n",
    "        data_order['Shipping Country'] = 'Indonesia'\n",
    "        data_order['AWB'] = 0\n",
    "        data_order['Channel'] = 'Order Online Jabar'\n",
    "\n",
    "    #     list_drop = []\n",
    "    #     indeks = data_order[data_order['SKU'].isin(data_SKU2[data_SKU2['Brand'] == 'Bundle']['SKU'])].index.to_list()\n",
    "    #     for i in indeks:\n",
    "    #         if str(data_order['SKU'][i]) in data_SKU2['SKU'].astype(str).values:\n",
    "    #             idx = data_SKU2[str(data_order['SKU'][i] ) == data_SKU2['SKU'].astype(str)].index[0]\n",
    "    #             for j in range(1,8):\n",
    "    #                 colname = 'Produk ' + str(j)\n",
    "    #                 if str(data_SKU2[colname][idx]) != 'nan':\n",
    "    #                     new_data = data_order.iloc[i,]\n",
    "    #                     new_data['Item Name'] = data_SKU2[colname][idx]\n",
    "    #                     new_data['Selling Price'] = data_SKU2['Subtotal ' + colname][idx] * new_data['Quantity']\n",
    "    #                     new_data['Quantity'] = new_data['Quantity'] * data_SKU2['PCS ' + colname][idx]\n",
    "    #                     new_data['SKU'] = str(data_SKU2['SKU ' + colname][idx]).replace('.0','')\n",
    "    #                     new_data['Quantity'] = str(new_data['Quantity']).replace('.0','')\n",
    "    #                     new_data['Selling Price'] = str(new_data['Selling Price']).replace('.0','')\n",
    "    #                     data_order = data_order.append(new_data, ignore_index = True)\n",
    "    #                     list_drop.append(i)\n",
    "    #     data_order = data_order.drop(list_drop, axis = 0)\n",
    "    #     data_order = data_order.reset_index(drop = True)\n",
    "\n",
    "        data_order['Order Date'] = pd.to_datetime(data_order['created_at'])\n",
    "\n",
    "    # #     for i in range(data_order.shape[0]):\n",
    "    # #         if int(data_order['Order date'][i].strftime('%d')) < 12:\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i].strftime('%Y-%d-%m %H:%M'))\n",
    "    # #         else :\n",
    "    # #             data_order['Order date'][i] = pd.to_datetime(data_order['Order date'][i])\n",
    "    #     indeks = data_order[data_order['Item Name'].astype(str).str.contains('pcs')].index.to_list()\n",
    "    #     temp = data_order.iloc[indeks].copy()\n",
    "    #     product = temp['Item Name'].str.split(\"\\(\",1, expand = True)\n",
    "    #     if len(product) != 0:\n",
    "    #         temp['Quantity Inside'] = product[1].astype(str).str.replace('pcs)', '', regex = False).astype(int)\n",
    "    #         data_order['Quantity'][indeks] = data_order['Quantity'][indeks] * temp['Quantity Inside']\n",
    "\n",
    "    # #     data_order_1 = data_order[data_order['payment_method'] == 'cod']\n",
    "    # #     data_order_2 = data_order[data_order['payment_method'] != 'cod'][data_order[data_order['payment_method'] != 'cod']['payment_status'] == 'paid']\n",
    "    # #     data_WMS = data_order_1.append(data_order_2, ignore_index = True, sort = False)\n",
    "    # #     data_WMS = data_WMS[['Order date', 'Channel', 'Sales Order ID', 'Channel Order ID', 'Invoice Number', 'Customer Name', 'Item Name', 'SKU', 'Quantity', 'Price', 'Shipping Cost', 'Shipping Name', 'Shipping Address1', 'Shipping Address2', 'Shipping City', 'Shipping Zip', 'Shipping Province', 'Shipping Country', 'Shipping Phone', 'Shipping Courier', 'AWB']]\n",
    "    # #     data_WMS.to_excel(r'data_WMS_OrderOnline.xlsx', index = False)\n",
    "    # #     print('Finished')\n",
    "\n",
    "        data_order['SKU'] = data_order['SKU'].astype(str)\n",
    "        data_order['Item Name'] = data_order['Item Name'].astype(str)\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        index = data_order[data_order['SKU'].astype(str) == '2306551174'].index.to_list()\n",
    "        data_order['SKU'][index] = '2306592173'\n",
    "\n",
    "        data_order = data_order.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        temp = data_order[data_order['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('hd','', regex = False)\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('HD','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "        temp['Real SKU_x'] = temp['Real SKU_x'].fillna(temp['Real SKU_y'])\n",
    "        temp['Real Nama Produk_x'] = temp['Real Nama Produk_x'].fillna(temp['Real Nama Produk_y'])\n",
    "        temp = temp.drop(['Real SKU_y', 'Real Nama Produk_y'], axis = 1)\n",
    "        temp = temp.rename(columns = {'Real SKU_x' : 'Real SKU', 'Real Nama Produk_x' : 'Real Nama Produk'})\n",
    "\n",
    "        indeks = data_order[data_order['Real SKU'].isnull()].index.to_list()\n",
    "        data_order['Real SKU'][indeks] = temp['Real SKU'][indeks]\n",
    "        data_order['Real Nama Produk'][indeks] = temp['Real Nama Produk'][indeks]\n",
    "\n",
    "        data_order['Real SKU'] = data_order['Real SKU'].astype(str)\n",
    "        data_order = data_order.merge(data_SKU2[['SKU', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Unbundling ====== 6/10\")        \n",
    "        # Forstok Unbundling    \n",
    "        list_col = ['SKU'] + data_SKU2.columns[data_SKU2.columns.get_loc('Produk 1'):data_SKU2.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "        data_order = data_order.merge(data_SKU2[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "        list_pcs = [x for x in data_order.columns if 'PCS' in x]\n",
    "        for i in list_pcs:\n",
    "            data_order[i] = data_order[i] * data_order['Quantity']\n",
    "        data_order = data_order.drop(['SKU_y'], axis = 1)\n",
    "        data_order = data_order.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'].index.to_list()\n",
    "        data_order['Bundle Flag'] = np.nan\n",
    "        data_order['Bundle Flag'][indeks] = 'Bundle'\n",
    "\n",
    "        indeks = data_order[data_order['Brand'] == 'Bundle'][data_order[data_order['Brand'] == 'Bundle']['SKU'].astype(str).str.contains('(S)', regex = False)].index.to_list()\n",
    "        data_order['SKU Produk 1'][indeks] = '(S)' + data_order['SKU Produk 1'][indeks].astype(str)\n",
    "        data_order['SKU Produk 2'][indeks] = '(S)' + data_order['SKU Produk 2'][indeks].astype(str)\n",
    "        data_order['SKU Produk 3'][indeks] = '(S)' + data_order['SKU Produk 3'][indeks].astype(str)\n",
    "        data_order['SKU Produk 4'][indeks] = '(S)' + data_order['SKU Produk 4'][indeks].astype(str)\n",
    "        data_order['SKU Produk 5'][indeks] = '(S)' + data_order['SKU Produk 5'][indeks].astype(str)\n",
    "        data_order['SKU Produk 6'][indeks] = '(S)' + data_order['SKU Produk 6'][indeks].astype(str)\n",
    "        data_order['SKU Produk 7'][indeks] = '(S)' + data_order['SKU Produk 7'][indeks].astype(str)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"Filling Date ====== 7/10\")\n",
    "        data_order['Date'] = np.nan\n",
    "        data_order['Month'] = np.nan\n",
    "        data_order['Year'] = np.nan\n",
    "\n",
    "        for i in range(data_order.shape[0]):\n",
    "            if int(data_order['Order Date'][i].strftime('%d')) <= 12:\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i].strftime('%Y-%d-%m %H:%M')).year\n",
    "            else :\n",
    "                data_order['Date'][i] = pd.to_datetime(data_order['Order Date'][i]).day\n",
    "                data_order['Month'][i] = pd.to_datetime(data_order['Order Date'][i]).month_name()\n",
    "                data_order['Year'][i] = pd.to_datetime(data_order['Order Date'][i]).year\n",
    "\n",
    "        quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "                ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "        data_order = data_order.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "        data_order = data_order.drop(['Bulan'], axis = 1)\n",
    "        data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "                {'Bulan' : 'January' , 'Number': 1},\n",
    "                {'Bulan' : 'February' , 'Number': 2},\n",
    "                {'Bulan' : 'March' , 'Number': 3},\n",
    "                {'Bulan' : 'April' , 'Number': 4},\n",
    "                {'Bulan' : 'May' , 'Number': 5},\n",
    "                {'Bulan' : 'June', 'Number': 6},\n",
    "                {'Bulan' : 'July' , 'Number': 7},\n",
    "                {'Bulan' : 'August', 'Number' : 8},\n",
    "                {'Bulan' : 'September', 'Number' : 9},\n",
    "                {'Bulan' : 'October' , 'Number': 10},\n",
    "                {'Bulan' : 'November' , 'Number': 11}])\n",
    "        temp = data_order.copy()\n",
    "        temp['Day'] = temp['Date']\n",
    "        temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "        temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "        data_order['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "        temp['Hour'] = pd.to_datetime(data_order['Order Date']).dt.hour\n",
    "        temp['Minute'] = pd.to_datetime(data_order['Order Date']).dt.minute\n",
    "        temp['Second'] = pd.to_datetime(data_order['Order Date']).dt.second\n",
    "        data_order['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])\n",
    "\n",
    "\n",
    "\n",
    "        order_all = data_order.copy()\n",
    "        order_all['Total'] = order_all['net_revenue']\n",
    "        order_all['Price List NFI'] = np.nan\n",
    "        order_all['Total Net'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        order_all = order_all.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                                'Status' : 'Order Status',\n",
    "                                                'Order Date' : 'Order date',\n",
    "                                                'Item Name' :'Product Name',\n",
    "                                                'Bundle Name' : 'Bundle',\n",
    "                                                'Shipping Country' : 'Country',\n",
    "                                                'Shipping Province' : 'Region',\n",
    "                                                'Shipping City' : 'City',\n",
    "                                                'Shipping Zip' : 'Zip Code',\n",
    "                                                'Shipping Address1' : 'Address',\n",
    "                                                'Shipping Phone' : 'Phone',\n",
    "                                                'Quantity' : 'Qty. Invoiced',\n",
    "                                                'Harga Display' : 'Regular Price',\n",
    "                                                'net_revenue' : 'Subtotal'})\n",
    "    #         indeks = order_all[order_all['Product Name'] == '2102500336 (classic stick)'].index.to_list()\n",
    "    #         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "    #         indeks = order_all[order_all['Product Name'] == '2102500336 (CS)'].index.to_list()\n",
    "    #         order_all = order_all.drop(indeks, axis = 0)\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "\n",
    "        order_all['Selling Price'] = order_all['Harga Coret'].astype(int)\n",
    "        order_all['Kecamatan'] = np.nan\n",
    "        order_all['Kelurahan'] = np.nan\n",
    "\n",
    "        print(\"Filling Location\")\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains('/')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split('/', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains('-')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split('-', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['City'].astype(str).str.contains(',')]['City'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kecamatan'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['City'][indeks] = order_all['City'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        indeks = order_all[order_all['Kecamatan'].astype(str).str.contains(',')]['Kecamatan'].index.to_list()\n",
    "        if len(indeks)>0:\n",
    "            order_all['Kelurahan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[1]\n",
    "            order_all['Kecamatan'][indeks] = order_all['Kecamatan'][indeks].str.split(',', n = 1,expand = True)[0]\n",
    "\n",
    "        order_all['City'] = order_all['City'].astype(str).str.replace('Kab\\.', 'Kabupaten' ,case = False)\n",
    "\n",
    "        master_map = pd.read_csv(r'All Data/Province.csv', names = ['Kode Prov', 'Province'], header= 0)\n",
    "        master_map2 = pd.read_csv(r'All Data/City.csv', names = ['Kode City', 'Kode Prov', 'City'], header = 0)\n",
    "        master_map = master_map.merge(master_map2, how = 'right', on = 'Kode Prov')\n",
    "        master_map['Kode Prov'][515] = 14\n",
    "        master_map['Province'][515] = 'Riau'\n",
    "        master_map['Kode Prov'] = master_map['Kode Prov'].astype(int)\n",
    "        master_map['Province'] = master_map['Province'].str.title()\n",
    "        master_map['City'] = master_map['City'].str.title()\n",
    "\n",
    "        city = pd.read_excel(r'All Data/list_city.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['City'] = temp['City'].astype(str).str.lower()\n",
    "        temp['City'] = temp['City'].astype(str).str.replace('kab. ', 'kabupaten ', regex = False, case = False)\n",
    "        city['All City'] = city['All City'].astype(str).str.lower()\n",
    "        temp = temp.merge(city.drop_duplicates('All City'), how = 'left', left_on = 'City', right_on = 'All City').set_index(temp.index)\n",
    "        indeks = temp[temp['Real City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = temp['Real City'][indeks]\n",
    "\n",
    "        province = pd.read_excel(r'All Data/list_province.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Region'] = temp['Region'].astype(str).str.lower()\n",
    "        province['All Province'] = province['All Province'].astype(str).str.lower()\n",
    "        temp = temp.merge(province.drop_duplicates('All Province'), how = 'left', left_on = 'Region', right_on = 'All Province').set_index(temp.index)\n",
    "        indeks = temp[temp['Real Province'].notnull()].index.to_list()\n",
    "        order_all['Region'][indeks] = temp['Real Province'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp = temp[temp['Region'].isnull()]\n",
    "        temp['Region'] = temp.merge(master_map, how = 'left', on = 'City').set_index(temp.index)['Province']\n",
    "        order_all['Region'][temp.index] = temp['Region']  \n",
    "\n",
    "        district = pd.read_excel(r'All Data/list_district.xlsx')\n",
    "        temp = order_all.copy()\n",
    "        temp['Kecamatan'] = temp['Kecamatan'].astype(str).str.lower()\n",
    "        district['All District'] = district['All District'].astype(str).str.lower()\n",
    "        temp = temp.merge(district.drop_duplicates('All District'), how = 'left', left_on = 'Kecamatan', right_on = 'All District').set_index(temp.index)\n",
    "        indeks = temp[temp['Real District'].notnull()].index.to_list()\n",
    "        order_all['Kecamatan'][indeks] = temp['Real District'][indeks]\n",
    "\n",
    "        temp = order_all.copy()\n",
    "        temp2 = temp[['Region', 'City', 'Kecamatan']].merge(master_map, how = 'left', on = 'City')\n",
    "        indeks = temp2[temp2['Region'] != temp2['Province']][temp2[temp2['Region'] != temp2['Province']]['City'].notnull()].index.to_list()\n",
    "        order_all['City'][indeks] = np.nan\n",
    "\n",
    "        data_SKU2['Real SKU'] = data_SKU2['SKU'].astype(str)\n",
    "        data_SKU2['Real Nama Produk'] = data_SKU2['Nama Produk'].astype(str)\n",
    "\n",
    "        print(\"Unbundling\")\n",
    "        data_bundle1 = order_all[~order_all['Produk 1'].isnull()]\n",
    "        data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "        data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "        data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "        data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "        data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "        data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle2 = order_all[~order_all['Produk 2'].isnull()]\n",
    "        data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "        data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "        data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "        data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "        data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "        data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "        data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle3 = order_all[~order_all['Produk 3'].isnull()]\n",
    "        data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "        data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "        data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "        data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "        data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "        data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "        data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle4 = order_all[~order_all['Produk 4'].isnull()]\n",
    "        data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "        data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "        data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "        data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "        data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "        data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "        data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle5 = order_all[~order_all['Produk 5'].isnull()]\n",
    "        data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "        data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "        data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "        data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "        data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "        data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle6 = order_all[~order_all['Produk 6'].isnull()]\n",
    "        data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "        data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "        data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "        data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "        data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "        data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle7 = order_all[~order_all['Produk 7'].isnull()]\n",
    "        data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "        data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "        data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "        data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "        data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "        data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "        data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "        data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "        data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "        temp = data_bundle[data_bundle['Real SKU'].isnull()].copy()\n",
    "        temp['SKU'] = temp['SKU'].astype(str).str.replace('(S)','', regex = False)\n",
    "        temp = temp.merge(data_SKU2[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp.index)\n",
    "\n",
    "        indeks = data_bundle[data_bundle['Real SKU'].isnull()].index.to_list()\n",
    "        data_bundle['Real SKU'][indeks] = temp['Real SKU_y'][indeks]\n",
    "        data_bundle['Real Nama Produk'][indeks] = temp['Nama Produk'][indeks]\n",
    "        data_bundle['Brand'][indeks] = temp['Brand_y'][indeks]\n",
    "        data_bundle['Sub Brand'][indeks] = temp['Sub Brand_y'][indeks]\n",
    "        data_bundle['Parent Item'][indeks] = temp['Parent Item_y'][indeks]\n",
    "        data_bundle['Parent SKU'][indeks] = temp['Parent SKU_y'][indeks]\n",
    "\n",
    "        print(\"Pricing\")\n",
    "        order_all = order_all.append(data_bundle, ignore_index = True, sort = False)\n",
    "\n",
    "        colname = temp.columns[temp.columns.get_loc('Produk 1') : temp.columns.get_loc('Harga Cost 7') + 1]\n",
    "        colname_str = [x for x in colname if 'Subtotal' not in x and 'Harga' not in x]\n",
    "        colname_int = [x for x in colname if x not in colname_str]\n",
    "\n",
    "        for i in colname_str:\n",
    "            temp[i] = np.nan\n",
    "\n",
    "        for i in colname_int:\n",
    "            temp[i] = 0\n",
    "\n",
    "        data_order = data_order.append(temp , ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "        order_all = order_all.merge(data_SKU2[['SKU', 'Price List NFI', 'Harga Cost']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(order_all.index)\n",
    "        order_all['Price List NFI_x'] = order_all['Price List NFI_x'].fillna(order_all['Price List NFI_y'])\n",
    "        order_all =  order_all.drop(['Price List NFI_y', 'SKU_y'], axis = 1)\n",
    "        order_all = order_all.rename(columns = {'SKU_x' : 'SKU', 'Price List NFI_x' : 'Price List NFI'})\n",
    "\n",
    "        indeks = order_all[order_all['Product Name'] == 'HiLo Teen Chocolate 250gr'].index.to_list()\n",
    "        order_all['Real Nama Produk'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Parent Item'][indeks] = 'HiLo Teen Chocolate 250gr'\n",
    "        order_all['Brand'][indeks] = 'HiLo'\n",
    "        order_all['Sub Brand'][indeks] = 'HILO TEEN'\n",
    "        order_all['Price List NFI'][indeks] = 36850\n",
    "        order_all['Harga Cost'][indeks] = 36850\n",
    "        order_all['Real SKU'][indeks] = '2101651155'\n",
    "        order_all['Parent SKU'][indeks] = '2101651155'\n",
    "\n",
    "\n",
    "        order_all['Price List NFI'] = pd.to_numeric(order_all['Price List NFI']).astype(int)\n",
    "        order_all['Harga Cost'] = pd.to_numeric(order_all['Harga Cost']).astype(int)\n",
    "        order_all['Qty. Invoiced'] = pd.to_numeric(order_all['Qty. Invoiced']).astype(int)\n",
    "\n",
    "        order_all['Total Net'] = order_all['Price List NFI'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total Harga Cost'] = order_all['Harga Cost'] * order_all['Qty. Invoiced']\n",
    "        order_all['Subtotal'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "        order_all['Total'] = order_all['Selling Price'] * order_all['Qty. Invoiced']\n",
    "\n",
    "        order_all = order_all.reset_index(drop = True)\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        order_all['Seller Discount'] = order_all['discount']\n",
    "        order_all['Shipping'] = order_all['Shipping Cost']\n",
    "\n",
    "        temp = order_all[order_all['Brand'] != 'Bundle']\n",
    "        temp['discount'] = temp['discount'] * temp['Total Harga Cost']/temp.groupby(['Order #'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['discount'][temp.index] = temp['discount']\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "        order_all['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "        temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Total'][temp.index] = temp['Total']\n",
    "        order_all['Subtotal'][temp.index] = temp['Subtotal']\n",
    "        order_all['Selling Price'][temp.index] = temp['Selling Price']\n",
    "\n",
    "\n",
    "        order_all['Order #'] = order_all['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "        temp = order_all[order_all['Bundle Name'].isnull()]\n",
    "        temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "        temp = order_all.merge(temp_group, how = 'left', on = 'Order #').set_index(order_all.index)\n",
    "        temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping_y']\n",
    "        list_bundle = order_all[order_all['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "        list_nobundle = order_all[order_all['Bundle Name'].notnull()]\n",
    "        list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "        list_nobundle\n",
    "\n",
    "        order_all['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "        temp = order_all[order_all['Bundle Name'].notnull()]\n",
    "        temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "        order_all['Shipping'][temp.index] = temp['Shipping']\n",
    "        order_all['True datetime'] = pd.to_datetime(order_all['True datetime'])\n",
    "        order_all['Promo'] = np.nan\n",
    "        order_all['Discount MC'] = np.nan\n",
    "\n",
    "\n",
    "        order_all['Warehouse Name'] = 'Primary Warehouse'\n",
    "        order_all['Store'] = 'Order Online'\n",
    "\n",
    "        order_all['Customer Email'] = order_all['email']\n",
    "        order_all['Order Status'] = order_all['status']\n",
    "        order_all['Payment Channel'] = order_all['payment_method']\n",
    "        order_all['Coupon Code'] = order_all['coupon']\n",
    "        order_all.columns.to_list()\n",
    "\n",
    "        order_all_append = order_all[['Sales Order ID', 'Store',\n",
    "            'Product Name',\n",
    "            'Customer Name',\n",
    "            'Phone',\n",
    "            'Address',\n",
    "            'Region',\n",
    "            'City',\n",
    "            'Zip Code',\n",
    "            'payment_status',\n",
    "            'Regular Price',\n",
    "            'Shipping Courier',\n",
    "            'Shipping Cost',\n",
    "            'Subtotal',\n",
    "            'Qty. Invoiced',\n",
    "            'SKU',\n",
    "            'Order #',\n",
    "            'Invoice Number',\n",
    "            'Shipping Name',\n",
    "            'Shipping Address2',\n",
    "            'Country',\n",
    "            'AWB',\n",
    "            'Channel',\n",
    "            'Order date',\n",
    "            'Real SKU',\n",
    "            'Real Nama Produk',\n",
    "            'Brand',\n",
    "            'Sub Brand',\n",
    "            'Parent Item',\n",
    "            'Parent SKU',\n",
    "            'Produk 1',\n",
    "            'SKU Produk 1',\n",
    "            'PCS Produk 1',\n",
    "            'Price List NFI 1',\n",
    "            'Subtotal Produk 1',\n",
    "            'Harga Display 1',\n",
    "            'Harga Cost 1',\n",
    "            'Harga Organik 1',\n",
    "            'Produk 2',\n",
    "            'SKU Produk 2',\n",
    "            'PCS Produk 2',\n",
    "            'Price List NFI 2',\n",
    "            'Subtotal Produk 2',\n",
    "            'Harga Display 2',\n",
    "            'Harga Cost 2',\n",
    "            'Harga Organik 2',\n",
    "            'Produk 3',\n",
    "            'SKU Produk 3',\n",
    "            'PCS Produk 3',\n",
    "            'Price List NFI 3',\n",
    "            'Subtotal Produk 3',\n",
    "            'Harga Display 3',\n",
    "            'Harga Cost 3',\n",
    "            'Harga Organik 3',\n",
    "            'Produk 4',\n",
    "            'SKU Produk 4',\n",
    "            'PCS Produk 4',\n",
    "            'Price List NFI 4',\n",
    "            'Subtotal Produk 4',\n",
    "            'Harga Display 4',\n",
    "            'Harga Cost 4',\n",
    "            'Harga Organik 4',\n",
    "            'Produk 5',\n",
    "            'SKU Produk 5',\n",
    "            'PCS Produk 5',\n",
    "            'Price List NFI 5',\n",
    "            'Subtotal Produk 5',\n",
    "            'Harga Display 5',\n",
    "            'Harga Cost 5',\n",
    "            'Harga Organik 5',\n",
    "            'Produk 6',\n",
    "            'SKU Produk 6',\n",
    "            'PCS Produk 6',\n",
    "            'Price List NFI 6',\n",
    "            'Subtotal Produk 6',\n",
    "            'Harga Display 6',\n",
    "            'Harga Cost 6',\n",
    "            'Harga Organik 6',\n",
    "            'Produk 7',\n",
    "            'SKU Produk 7',\n",
    "            'PCS Produk 7',\n",
    "            'Price List NFI 7',\n",
    "            'Subtotal Produk 7',\n",
    "            'Harga Display 7',\n",
    "            'Harga Cost 7',\n",
    "            'Harga Organik 7',\n",
    "            'Bundle Flag',\n",
    "            'Date',\n",
    "            'Month',\n",
    "            'Year',\n",
    "            'Quarter',\n",
    "            'Week',\n",
    "            'True datetime',\n",
    "            'Total',\n",
    "            'Price List NFI',\n",
    "            'Total Net',\n",
    "            'Selling Price',\n",
    "            'Kecamatan',\n",
    "            'Kelurahan',\n",
    "            'Bundle Name',\n",
    "            'Harga Cost',\n",
    "            'Total Harga Cost',\n",
    "            'Seller Discount',\n",
    "            'Shipping',\n",
    "            'Promo',\n",
    "            'Discount MC',\n",
    "            'Warehouse Name',\n",
    "            'Customer Email',\n",
    "            'Order Status',\n",
    "            'Payment Channel',\n",
    "            'Coupon Code']]\n",
    "\n",
    "        data_all = data_all[~data_all['Order #'].astype(str).isin(order_all_append['Order #'].astype(str))]\n",
    "        data_all = data_all.append(order_all_append, ignore_index = True, sort = False)\n",
    "    #         data_all_aft_order = data_all.copy()\n",
    "        del file_name\n",
    "        order_online_jabar = True\n",
    "        order_online_cond = True\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b6ded07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c97c595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 2), dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### optional cek item yang error\n",
    "### to do: add to code jatim jkt jateng\n",
    "### add to sheet sisanya\n",
    "order_all[order_all['Regular Price'].isnull()][['SKU','Product Name']].drop_duplicates().values#.to_excel('nhd ed.xlsx',index=False)#.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c24d25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "### optional cman utk cek ada kota homdel yang belum ke run atau tidak\n",
    "for n in [order_online_jatim,order_online_jkt,\n",
    "          order_online_jateng,order_online_bali,\n",
    "          order_online_makasar,order_online_samarinda,\n",
    "          order_online_medan,order_online_lampung,\n",
    "          order_online_pekanbaru,order_online_banjarmasin,order_online_jabar]:\n",
    "    print (n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7819fa45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4442986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e000a7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd26dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6e85c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17ab7d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2595306692.py:12: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_nubi = pd.read_csv(r\"C:\\Users\\steven.nathanael\\Downloads\\Main_Sheet_(timo)_(2)_Full_Data_data (1).csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Date ====== 7/10\n",
      "Filling Brand ====== 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2595306692.py:54: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  data_nubi['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales Order ID</th>\n",
       "      <th>Order #</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Order date</th>\n",
       "      <th>Paid Date</th>\n",
       "      <th>Order Status</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Store</th>\n",
       "      <th>Currency Code</th>\n",
       "      <th>Warehouse Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Category</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Real SKU</th>\n",
       "      <th>Real Nama Produk</th>\n",
       "      <th>Sub Brand</th>\n",
       "      <th>Parent Item</th>\n",
       "      <th>Parent SKU</th>\n",
       "      <th>Price List NFI</th>\n",
       "      <th>Total</th>\n",
       "      <th>Total Net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Sales Order ID, Order #, Customer Name, Order date, Paid Date, Order Status, Channel, Store, Currency Code, Warehouse Name, Regular Price, Selling Price, Subtotal, Gross Sales, SKU, Product Name, Qty. Invoiced, Date, Month, Year, True datetime, Week, Brand, Category, Quarter, Real SKU, Real Nama Produk, Sub Brand, Parent Item, Parent SKU, Price List NFI, Total, Total Net]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2595306692.py:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_nubi=data_nubi[data_nubi['Price List NFI'].notnull()].append(temp)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\2595306692.py:172: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_nubi = data_nubi.append(temp, ignore_index = True, sort = False)\n"
     ]
    }
   ],
   "source": [
    "### Run - 9\n",
    "### download file tabi di Main_Sheet_(timo)_(2)\n",
    "### replace file di var data_nubi\n",
    "### idea: use sql\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "data_all = data_all[data_all['Store Type'] != 'Retail Online']\n",
    "data_nubi = pd.read_csv(r\"C:\\Users\\steven.nathanael\\Downloads\\Main_Sheet_(timo)_(2)_Full_Data_data (1).csv\")\n",
    "# data_nubi = data_nubi[~data_nubi['Customer SO Group Area'].astype(str).str.contains('E-COM')]\n",
    "# data_nubi = data_nubi[~data_nubi['Customer SO Group Area'].astype(str).str.contains('ECOM')]\n",
    "# data_nubi.loc[data_nubi['Customer SO Desc'].isin(['SWIFT LOGISTICS SOLUTIONS - BEKASI, PT',\n",
    "#                                                   'SWIFT LOGISTICS SOLUTIONS - JKT UTARA,PT']),['Customer SO Group Area','Customer SO Parent Desc']]='ECOM RETAIL - SWIFT LOGISTICS SOLUTIONS'\n",
    "data_nubi.loc[data_nubi['Customer SO Desc']=='INDOPASIFIK FARMA MEDIKA INDONESIA, PT',['Customer SO Group Area','Customer SO Parent Desc']]='ECOM RETAIL - INDOPASIFIK FARMA MEDIKA INDONESIA'\n",
    "\n",
    "data_nubi = data_nubi[data_nubi['Customer SO Group Area'].astype(str).str.contains('ECOM RETAIL')]\n",
    "\n",
    "data_SKU = pd.read_excel(r'SKU_File\\data_SKU.xlsx')\n",
    "\n",
    "# miss = data_nubi[~data_nubi['Product Code'].astype(str).isin(data_SKU['SKU'].astype(str))]\n",
    "data_nubi['Sales Order ID'] = 'Nubi -' + data_nubi['Customer SO Parent Desc'].astype(str)\n",
    "data_nubi['Channel Order ID'] = 'Nubi -' + data_nubi['Customer SO Parent Desc'].astype(str)\n",
    "data_nubi['Customer Name'] = 'Nubi Retail Online'\n",
    "\n",
    "print(\"Filling Date ====== 7/10\")\n",
    "\n",
    "data_nubi['Date'] = data_nubi['Day of Invoice Date SO']\n",
    "data_nubi['Month'] = data_nubi['Month of Invoice Date SO']\n",
    "data_nubi['Year'] = data_nubi['Year of Invoice Date SO']\n",
    "\n",
    "quarter = pd.DataFrame([['January', 1], ['February', 1], ['March', 1], ['April', 2], ['May', 2], ['June', 2], \n",
    "        ['July', 3], ['August', 3], ['September', 3],['October', 4], ['November', 4], ['December', 4]], columns = ['Bulan', 'Quarter'])\n",
    "data_nubi = data_nubi.merge(quarter, how = 'left', left_on = 'Month', right_on = 'Bulan')\n",
    "data_nubi = data_nubi.drop(['Bulan'], axis = 1)\n",
    "data_bulan = pd.DataFrame([{'Bulan' : 'December', 'Number' : 12} ,\n",
    "        {'Bulan' : 'January' , 'Number': 1},\n",
    "        {'Bulan' : 'February' , 'Number': 2},\n",
    "        {'Bulan' : 'March' , 'Number': 3},\n",
    "        {'Bulan' : 'April' , 'Number': 4},\n",
    "        {'Bulan' : 'May' , 'Number': 5},\n",
    "        {'Bulan' : 'June', 'Number': 6},\n",
    "        {'Bulan' : 'July' , 'Number': 7},\n",
    "        {'Bulan' : 'August', 'Number' : 8},\n",
    "        {'Bulan' : 'September', 'Number' : 9},\n",
    "        {'Bulan' : 'October' , 'Number': 10},\n",
    "        {'Bulan' : 'November' , 'Number': 11}])\n",
    "temp = data_nubi.copy()\n",
    "temp['Day'] = temp['Date']\n",
    "temp = temp.merge(data_bulan, how = 'left', left_on = 'Month', right_on='Bulan')\n",
    "temp= temp.rename(columns = {'Month' : 'Bulan', 'Number' : 'Month'})\n",
    "data_nubi['Week'] = pd.to_datetime(temp[['Year', 'Month', 'Day']]).dt.week\n",
    "data_nubi['True datetime'] = pd.to_datetime(temp[['Year', 'Month', 'Day']])\n",
    "\n",
    "data_nubi['Order Date'] = data_nubi['Day of Invoice Date SO']\n",
    "data_nubi['Paid Date'] = data_nubi['Day of Invoice Date SO']\n",
    "data_nubi['Status'] = 'Delivered'\n",
    "data_nubi['Channel'] = data_nubi['Customer SO Parent Desc']\n",
    "data_nubi['Store'] = data_nubi['Customer SO Group Area']\n",
    "data_nubi['Currency Code'] = \"IDR\"\n",
    "data_nubi['Warehouse Name'] = data_nubi['Customer SO Desc']\n",
    "data_nubi['Regular Price'] = data_nubi['Sales Value Netto SO'] / data_nubi['Sales Qty SO']\n",
    "data_nubi['Store Type'] = 'Retail Online'\n",
    "\n",
    "indeks = data_nubi[data_nubi['Regular Price'].isnull()].index.to_list()\n",
    "data_nubi['Regular Price'][indeks] = 0\n",
    "\n",
    "data_nubi['Selling Price'] = data_nubi['Sales Value Netto SO'] / data_nubi['Sales Qty SO']\n",
    "indeks = data_nubi[data_nubi['Selling Price'].isnull()].index.to_list()\n",
    "data_nubi['Selling Price'][indeks] = 0\n",
    "\n",
    "indeks = data_nubi[data_nubi['Sales Qty SO'] == 0].index.to_list()\n",
    "data_nubi['Selling Price'][indeks] = 0\n",
    "data_nubi['Regular Price'][indeks] = 0\n",
    "\n",
    "indeks = data_nubi[data_nubi['Sales Value Netto SO'] == 0].index.to_list()\n",
    "data_nubi['Selling Price'][indeks] = 0\n",
    "data_nubi['Regular Price'][indeks] = 0\n",
    "\n",
    "data_nubi['Sub Total'] = data_nubi['Sales Value Netto SO']\n",
    "data_nubi['Gross Sales'] = data_nubi['Sales Value Netto SO']\n",
    "\n",
    "data_nubi = data_nubi.rename(columns = {'Item Group Code' : 'SKU', 'Item Group' : 'Item Name', 'Sales Qty SO' : 'Quantity'})\n",
    "\n",
    "data_nubi = data_nubi[['Sales Order ID', 'Channel Order ID', 'Customer Name', 'Order Date', 'Paid Date','Status','Channel', 'Store', 'Currency Code', 'Warehouse Name', 'Regular Price', 'Selling Price',\n",
    "              'Sub Total', 'Gross Sales', 'SKU', 'Item Name', 'Quantity', 'Date', 'Month', 'Year', 'True datetime', \"Week\", 'Brand', 'Category']]\n",
    "\n",
    "data_nubi['Order Date'] = data_nubi['True datetime']\n",
    "data_nubi['Quarter'] = pd.to_datetime(data_nubi['True datetime']).dt.quarter\n",
    "\n",
    "print(\"Filling Brand ====== 5/10\")\n",
    "data_nubi['SKU'] = data_nubi['SKU'].astype(str)\n",
    "data_nubi['Item Name'] = data_nubi['Item Name'].astype(str)\n",
    "data_SKU['Real SKU'] = data_SKU['SKU']\n",
    "data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "\n",
    "# data_SKU['Price List NFI']=data_SKU['Price List NFI']*1.1/1.11 ###masih 10 % yaaa\n",
    "\n",
    "data_nubi = data_nubi.merge(data_SKU[['Real SKU', 'Real Nama Produk']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')\n",
    "data_nubi['Real SKU'] = data_nubi['Real SKU'].astype(str)\n",
    "data_nubi = data_nubi.merge(data_SKU[['SKU', 'Sub Brand', 'Parent Item', 'Parent SKU','Price List NFI']].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU')\n",
    "data_nubi['Parent Item'] = data_nubi['Parent Item'].fillna(data_nubi['Item Name'])\n",
    "data_nubi = data_nubi.drop(['SKU_y'], axis = 1)\n",
    "data_nubi = data_nubi.rename(columns = {'SKU_x':'SKU'})\n",
    "\n",
    "indeks = data_nubi[data_nubi['Real SKU'].astype(str) == 'nan'].index.to_list()\n",
    "data_nubi['Real SKU'][indeks] = data_nubi['SKU'][indeks]\n",
    "\n",
    "indeks = data_nubi[data_nubi['Real Nama Produk'].astype(str) == 'nan'].index.to_list()\n",
    "data_nubi['Real Nama Produk'][indeks] = data_nubi['Item Name'][indeks]\n",
    "\n",
    "data_nubi['Sub Brand'] = data_nubi['Category']\n",
    "\n",
    "data_nubi['Total'] = data_nubi['Sub Total']\n",
    "data_nubi['Total Net'] = np.nan\n",
    "\n",
    "data_nubi = data_nubi.rename(columns={'Channel Order ID' : 'Order #',\n",
    "                                        'Status' : 'Order Status',\n",
    "                                        'Order Date' : 'Order date',\n",
    "                                        'Item Name' :'Product Name',\n",
    "                                        'Bundle Name' : 'Bundle',\n",
    "                                        'Shipping Country' : 'Country',\n",
    "                                        'Shipping Province' : 'Region',\n",
    "                                        'Shipping City' : 'City',\n",
    "                                        'Shipping Zip' : 'Zip Code',\n",
    "                                        'Shipping Address1' : 'Address',\n",
    "                                        'Shipping Phone' : 'Phone',\n",
    "                                        'Quantity' : 'Qty. Invoiced',\n",
    "                                        'Item Price' : 'Regular Price',\n",
    "                                        'Sub Total' : 'Subtotal'})\n",
    "\n",
    "\n",
    "\n",
    "# data_nubi['Price List NFI'] = data_nubi['Selling Price'] * 1.1\n",
    "temp = data_nubi[data_nubi['Price List NFI'].isnull()]\n",
    "skuoff=pd.read_excel('data_supp\\item gk tau harga.xlsx')\n",
    "skuoff=skuoff[['Real SKU','Price List NFI']]\n",
    "skuoff['Real SKU']=skuoff['Real SKU'].astype(str)#.info()\n",
    "display(temp[~temp['Real SKU'].isin(skuoff['Real SKU'].unique())])\n",
    "temp=temp.merge(skuoff,how='left',on='Real SKU').rename(columns=({'Price List NFI_y':'Price List NFI'}))\n",
    "data_nubi=data_nubi[data_nubi['Price List NFI'].notnull()].append(temp)\n",
    "\n",
    "\n",
    "data_nubi['Price List NFI'] = pd.to_numeric(data_nubi['Price List NFI']).astype(int)\n",
    "data_nubi['Qty. Invoiced'] = pd.to_numeric(data_nubi['Qty. Invoiced']).fillna(0).astype(int)\n",
    "\n",
    "data_nubi['Total Net'] = data_nubi['Price List NFI'] * data_nubi['Qty. Invoiced']\n",
    "\n",
    "data_nubi = data_nubi.reset_index(drop = True)\n",
    "\n",
    "data_nubi['True datetime'] = pd.to_datetime(data_nubi['True datetime'])\n",
    "data_nubi['Promo'] = np.nan\n",
    "data_nubi['Discount MC'] = np.nan\n",
    "data_nubi['Store Type'] = 'Retail Online'\n",
    "\n",
    "for i in data_nubi['Brand'].unique():\n",
    "    indeks = data_nubi[data_nubi['Brand'] == i].index.to_list()\n",
    "    if i == 'NUTRISARI':\n",
    "        data_nubi['Brand'][indeks] = 'NS'\n",
    "    elif i == 'HI LO':\n",
    "        data_nubi['Brand'][indeks] = 'HiLo'\n",
    "        \n",
    "temp = data_nubi[data_nubi['Store'] == 'WARUNG PINTAR DISTRIBUSI - BOGOR, PT'].copy()\n",
    "data_nubi = data_nubi[data_nubi['Store'] != 'WARUNG PINTAR DISTRIBUSI - BOGOR, PT']\n",
    "\n",
    "temp['Store'] = 'WARUNG PINTAR'\n",
    "temp['Channel'] = 'WARUNG PINTAR DISTRIBUSI, PT'\n",
    "temp['Warehouse Name'] = 'WARUNG PINTAR DISTRIBUSI - BOGOR, PT'\n",
    "\n",
    "data_nubi = data_nubi.append(temp, ignore_index = True, sort = False)\n",
    "\n",
    "indeks = data_nubi[data_nubi['Store'] == 'SHOPEE'].index.to_list()\n",
    "data_nubi['Store'][indeks] = 'Shopee Sell-In'\n",
    "\n",
    "# data_all = data_all.append(data_nubi, ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a37e07d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedbb487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f78035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ec7138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b30958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "701e6870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_nubi\\data_nubi_2022-11-02.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1406586828.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_nubi=data_nubi.append(data_nubinew)\n"
     ]
    }
   ],
   "source": [
    "### ini run\n",
    "from datetime import date\n",
    "import glob\n",
    "import os\n",
    "cutoff=str((date.today().replace(day=1)-timedelta(1)).replace(day=1))\n",
    "data_nubinew=data_nubi[data_nubi['True datetime']>=cutoff]\n",
    "\n",
    "list_of_files = glob.glob('data_nubi\\*.xlsx') # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "print(latest_file)\n",
    "\n",
    "data_nubi=pd.read_excel(latest_file)\n",
    "# data_nubi['Total Net Before ]\n",
    "data_nubi=data_nubi[data_nubi['True datetime']<cutoff]\n",
    "          \n",
    "data_nubi=data_nubi.append(data_nubinew)\n",
    "\n",
    "data_nubi.to_excel(f\"data_nubi\\data_nubi_{date.today()}.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a42baed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaec944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e848b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858b902b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "289ec5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Month</th>\n",
       "      <th>Store</th>\n",
       "      <th>April</th>\n",
       "      <th>August</th>\n",
       "      <th>February</th>\n",
       "      <th>January</th>\n",
       "      <th>July</th>\n",
       "      <th>June</th>\n",
       "      <th>March</th>\n",
       "      <th>May</th>\n",
       "      <th>October</th>\n",
       "      <th>September</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASTRO TECHNOLOGIES - TANGERANG, PT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50292000.0</td>\n",
       "      <td>6629040.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261485400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CIBINONG CENTER INDUSTRIAL ESTATE , PT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250607064.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECOM RETAIL - ASTRO</td>\n",
       "      <td>5004324.0</td>\n",
       "      <td>87549696.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75724200.0</td>\n",
       "      <td>31898736.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13320000.0</td>\n",
       "      <td>34133832.0</td>\n",
       "      <td>114376176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ECOM RETAIL - BAYI NINJA JAKARTA</td>\n",
       "      <td>21581100.0</td>\n",
       "      <td>12182148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9896760.0</td>\n",
       "      <td>10478520.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13598508.0</td>\n",
       "      <td>13274268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ECOM RETAIL - EMOS</td>\n",
       "      <td>668131200.0</td>\n",
       "      <td>273379680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272433960.0</td>\n",
       "      <td>471195000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216516600.0</td>\n",
       "      <td>338088240.0</td>\n",
       "      <td>290282760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ECOM RETAIL - INDOPASIFIK FARMA MEDIKA INDONESIA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58048560.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8764560.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14558760.0</td>\n",
       "      <td>27159480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ECOM RETAIL - JD ID</td>\n",
       "      <td>16596720.0</td>\n",
       "      <td>15158160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20095440.0</td>\n",
       "      <td>6726600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5069370.0</td>\n",
       "      <td>12227760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ECOM RETAIL - LIFEPACK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10389600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9597060.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ECOM RETAIL - SAYUR BOX JAKARTA</td>\n",
       "      <td>81112140.0</td>\n",
       "      <td>19793520.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4155840.0</td>\n",
       "      <td>207976260.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29856780.0</td>\n",
       "      <td>10722600.0</td>\n",
       "      <td>11055600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ECOM RETAIL - SAYUR BOX SURABAYA</td>\n",
       "      <td>28919940.0</td>\n",
       "      <td>41836344.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28147380.0</td>\n",
       "      <td>55053336.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>732600.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ECOM RETAIL - SWIFT BEKASI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33354168.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ECOM RETAIL - SWIFT JKT UTARA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7166160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55259352.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ECOM RETAIL - TOKO NOW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71507976.0</td>\n",
       "      <td>77858952.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EMOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>420274800.0</td>\n",
       "      <td>168636600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281344800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>INDOPASIFIK TEKNOLOGI MED INDONESIA, PT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65934000.0</td>\n",
       "      <td>112384800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15622176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>INOVASI DIGITAL NIAGA - KALIDERES, PT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61402440.0</td>\n",
       "      <td>31566480.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73890642.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>INOVASI DIGITAL NIAGA - SURABAYA, PT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14702160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KREASI NOSTRA MANDIRI - BOGOR, PT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68138400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89798040.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KREASI NOSTRA MANDIRI - SURABAYA, PT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21493956.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>KREASI TANI LAKSMI - SURABAYA, PT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4241600.0</td>\n",
       "      <td>8472200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RITEL BERSAMA NASIONAL; PT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13516800.0</td>\n",
       "      <td>8910000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5324000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SAYUR BOX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14031600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TANIHUB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5728800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Month                                             Store        April  \\\n",
       "0                    ASTRO TECHNOLOGIES - TANGERANG, PT          0.0   \n",
       "1                CIBINONG CENTER INDUSTRIAL ESTATE , PT          0.0   \n",
       "2                                   ECOM RETAIL - ASTRO    5004324.0   \n",
       "3                      ECOM RETAIL - BAYI NINJA JAKARTA   21581100.0   \n",
       "4                                    ECOM RETAIL - EMOS  668131200.0   \n",
       "5      ECOM RETAIL - INDOPASIFIK FARMA MEDIKA INDONESIA          0.0   \n",
       "6                                   ECOM RETAIL - JD ID   16596720.0   \n",
       "7                                ECOM RETAIL - LIFEPACK          0.0   \n",
       "8                       ECOM RETAIL - SAYUR BOX JAKARTA   81112140.0   \n",
       "9                      ECOM RETAIL - SAYUR BOX SURABAYA   28919940.0   \n",
       "10                           ECOM RETAIL - SWIFT BEKASI          0.0   \n",
       "11                        ECOM RETAIL - SWIFT JKT UTARA          0.0   \n",
       "12                               ECOM RETAIL - TOKO NOW          0.0   \n",
       "13                                                 EMOS          0.0   \n",
       "14              INDOPASIFIK TEKNOLOGI MED INDONESIA, PT          0.0   \n",
       "15                INOVASI DIGITAL NIAGA - KALIDERES, PT          0.0   \n",
       "16                 INOVASI DIGITAL NIAGA - SURABAYA, PT          0.0   \n",
       "17                    KREASI NOSTRA MANDIRI - BOGOR, PT          0.0   \n",
       "18                 KREASI NOSTRA MANDIRI - SURABAYA, PT          0.0   \n",
       "19                    KREASI TANI LAKSMI - SURABAYA, PT          0.0   \n",
       "20                           RITEL BERSAMA NASIONAL; PT          0.0   \n",
       "21                                            SAYUR BOX          0.0   \n",
       "22                                              TANIHUB          0.0   \n",
       "\n",
       "Month       August     February      January         July         June  \\\n",
       "0              0.0   50292000.0    6629040.0          0.0          0.0   \n",
       "1              0.0          0.0          0.0          0.0          0.0   \n",
       "2       87549696.0          0.0          0.0   75724200.0   31898736.0   \n",
       "3       12182148.0          0.0          0.0    9896760.0   10478520.0   \n",
       "4      273379680.0          0.0          0.0  272433960.0  471195000.0   \n",
       "5       58048560.0          0.0          0.0    8764560.0          0.0   \n",
       "6       15158160.0          0.0          0.0   20095440.0    6726600.0   \n",
       "7              0.0          0.0          0.0          0.0   10389600.0   \n",
       "8       19793520.0          0.0          0.0    4155840.0  207976260.0   \n",
       "9       41836344.0          0.0          0.0   28147380.0   55053336.0   \n",
       "10             0.0          0.0          0.0   33354168.0          0.0   \n",
       "11       7166160.0          0.0          0.0   55259352.0          0.0   \n",
       "12             0.0          0.0          0.0          0.0          0.0   \n",
       "13             0.0  420274800.0  168636600.0          0.0          0.0   \n",
       "14             0.0   65934000.0  112384800.0          0.0          0.0   \n",
       "15             0.0   61402440.0   31566480.0          0.0          0.0   \n",
       "16             0.0          0.0   14702160.0          0.0          0.0   \n",
       "17             0.0   68138400.0          0.0          0.0          0.0   \n",
       "18             0.0          0.0          0.0          0.0          0.0   \n",
       "19             0.0    4241600.0    8472200.0          0.0          0.0   \n",
       "20             0.0   13516800.0    8910000.0          0.0          0.0   \n",
       "21             0.0          0.0   14031600.0          0.0          0.0   \n",
       "22             0.0          0.0    5728800.0          0.0          0.0   \n",
       "\n",
       "Month        March          May      October    September  \n",
       "0      261485400.0          0.0          0.0          0.0  \n",
       "1      250607064.0          0.0          0.0          0.0  \n",
       "2              0.0   13320000.0   34133832.0  114376176.0  \n",
       "3              0.0          0.0   13598508.0   13274268.0  \n",
       "4              0.0  216516600.0  338088240.0  290282760.0  \n",
       "5              0.0          0.0   14558760.0   27159480.0  \n",
       "6              0.0          0.0    5069370.0   12227760.0  \n",
       "7              0.0    9597060.0          0.0          0.0  \n",
       "8              0.0   29856780.0   10722600.0   11055600.0  \n",
       "9              0.0          0.0     732600.0          0.0  \n",
       "10             0.0          0.0          0.0          0.0  \n",
       "11             0.0          0.0          0.0          0.0  \n",
       "12             0.0          0.0   71507976.0   77858952.0  \n",
       "13     281344800.0          0.0          0.0          0.0  \n",
       "14      15622176.0          0.0          0.0          0.0  \n",
       "15      73890642.0          0.0          0.0          0.0  \n",
       "16             0.0          0.0          0.0          0.0  \n",
       "17      89798040.0          0.0          0.0          0.0  \n",
       "18      21493956.0          0.0          0.0          0.0  \n",
       "19             0.0          0.0          0.0          0.0  \n",
       "20       5324000.0          0.0          0.0          0.0  \n",
       "21             0.0          0.0          0.0          0.0  \n",
       "22             0.0          0.0          0.0          0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nubi[data_nubi['Year']==2022].groupby(['Month','Store'])[['Total Net']].sum().reset_index().pivot(columns='Month',index='Store')['Total Net'].reset_index().fillna(0)#.drop('Month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99486796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fadbb60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7cfadc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b48f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdf52d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\3123295807.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_all = data_all.append(data_nubi, ignore_index = True, sort = False)\n"
     ]
    }
   ],
   "source": [
    "## ini run\n",
    "data_all['Store'] = data_all['Store'].astype(str).str.replace('JD Indonesia - Nutrimart', 'JD Indonesia', regex = False)\n",
    "\n",
    "data_all = data_all[data_all['Store'].isin(['JD Indonesia', 'Lazada', 'Bukalapak', 'Blibli', 'Tokopedia',\n",
    "       'Shopee', 'Elevenia', 'Nutrimart', 'Order Online','Aladin Mall','TikTok'])]\n",
    "data_all = data_all.append(data_nubi, ignore_index = True, sort = False)\n",
    "\n",
    "indeks = data_all[data_all['Store'].isin(['JD Indonesia', 'Lazada', 'Bukalapak', 'Blibli', 'Tokopedia',\n",
    "       'Shopee', 'Elevenia','Aladin Mall','TikTok'])].index.to_list()\n",
    "data_all['Store Type'][indeks] = 'Marketplace'\n",
    "\n",
    "indeks = data_all[data_all['Store'].isin(['Nutrimart', 'Order Online'])].index.to_list()\n",
    "data_all['Store Type'][indeks] = 'Organic'\n",
    "\n",
    "indeks = data_all[data_all['Order #'].astype(str).str.contains('Nubi')].index.to_list()\n",
    "data_all['Store Type'][indeks] = 'Retail Online'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc59244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32aede7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f0ea88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a78cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0c4cb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ini run juga\n",
    "indeks = data_all[data_all['Product Name'] == 'L-Men Bar Crunchy Chocolate (12sch)'].index.to_list()\n",
    "data_all['Real Nama Produk'][indeks] = 'L-Men Bar Crunchy Chocolate 12sch'\n",
    "data_all['Parent Item'][indeks] = 'L-Men Bar Crunchy Chocolate (12 Sch)'\n",
    "data_all['Brand'][indeks] = 'L-Men'\n",
    "data_all['Sub Brand'][indeks] = 'L-MEN POWDER'\n",
    "data_all['Real SKU'][indeks] = '2306592173'\n",
    "data_all['Parent SKU'][indeks] = '2306592173'\n",
    "\n",
    "indeks = data_all[data_all['Product Name'] == 'Heavenly Blush Yogurt Drink To Go Peach (1 pc)'].index.to_list()\n",
    "data_all['Brand'][indeks] = 'Heavenly Blush'\n",
    "\n",
    "indeks = data_all[data_all['Brand'] == 'HB'].index.to_list()\n",
    "data_all['Brand'][indeks] = 'Heavenly Blush'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ede988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef74778b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8424f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a11368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "845e62d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ini run juga\n",
    "data_all['Region Group'] = np.nan\n",
    "\n",
    "index = data_all[data_all['Region'].isin(['Dki Jakarta', 'Banten'])].index.to_list()\n",
    "data_all['Region Group'][index] = 'Jabodetabek'\n",
    "\n",
    "list_city = ['Kota Bekasi', 'Kabupaten Bekasi', 'Kab. Bekasi', 'Kota Bogor', 'Kabupaten Bogor', 'Kab. Bogor', 'Kota Depok', 'Kota Tangerang',\n",
    "             'Kota Tangerang Selatan','Kabupaten Tangerang', 'Kab. Tangerang']\n",
    "\n",
    "index = data_all[data_all['City'].isin(list_city)].index.to_list()\n",
    "data_all['Region Group'][index] = 'Jabodetabek'\n",
    "\n",
    "data_all['Region Group'] = data_all['Region Group'].fillna(data_all['Region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5ff862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d575a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec01c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffe7ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14515e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac710772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75742a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9ac869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d732101a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export Master Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SKU_final = SKU_final.append(no_pair, ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter Status\n",
      "Prepare E-mailing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:903: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  yesterday_sales = all_single[all_single['Store']=='Order Online'][all_single['True datetime'] >= yesterday][all_single[all_single['True datetime'] >= yesterday]['True datetime']<today]\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:916: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mtd_sales = all_single[all_single['Store']=='Order Online'][all_single['True datetime'] >= mtd_date][all_single[all_single['True datetime'] >= mtd_date]['True datetime']<today]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Date 2022-08-01 00:00:00\n",
      "Last Date 2022-09-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:945: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  temp_sales = all_single[all_single['Store']=='Order Online'][all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Date 2022-09-01 00:00:00\n",
      "Last Date 2022-10-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:945: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  temp_sales = all_single[all_single['Store']=='Order Online'][all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Date 2022-10-01 00:00:00\n",
      "Last Date 2022-11-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:945: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  temp_sales = all_single[all_single['Store']=='Order Online'][all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:972: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  table_ecom = table_ecom.append(table_ecom.sum(numeric_only=True), ignore_index=True)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:996: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  yesterday_sales = all_single[all_single['Store']!='Order Online'][all_single['True datetime'] >= yesterday][all_single[all_single['True datetime'] >= yesterday]['True datetime']<today]\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1009: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mtd_sales = all_single[all_single['Store']!='Order Online'][all_single['True datetime'] >= mtd_date][all_single[all_single['True datetime'] >= mtd_date]['True datetime']<today]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Date 2022-08-01 00:00:00\n",
      "Last Date 2022-09-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1038: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  temp_sales = all_single[all_single['Store']!='Order Online'][all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Date 2022-09-01 00:00:00\n",
      "Last Date 2022-10-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1038: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  temp_sales = all_single[all_single['Store']!='Order Online'][all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Date 2022-10-01 00:00:00\n",
      "Last Date 2022-11-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1038: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  temp_sales = all_single[all_single['Store']!='Order Online'][all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1065: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  table_ecom = table_ecom.append(table_ecom.sum(numeric_only=True), ignore_index=True)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1078: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  table_ecom=table_ecom1.append(table_ecom2,ignore_index=True,sort=False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1079: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  table_ecom=table_ecom.append(table_ecom.sum(numeric_only=True), ignore_index=True)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1126: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tblall=tblall.append(total_row,ignore_index=True)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1155: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tblreg=tblreg.append(pd.DataFrame({'Real Region': [\"Retail Online\"], 'Yesterday Sales': [0]}))\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1172: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tblreg3=tblreg3.append(tblregshopee)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1188: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  res=res.append(tblreg[tblreg[\"Region\"]!='Retail Online']).append(sub_total_row,ignore_index=True).append(tblreg[tblreg[\"Region\"]=='Retail Online'])\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1188: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  res=res.append(tblreg[tblreg[\"Region\"]!='Retail Online']).append(sub_total_row,ignore_index=True).append(tblreg[tblreg[\"Region\"]=='Retail Online'])\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1188: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  res=res.append(tblreg[tblreg[\"Region\"]!='Retail Online']).append(sub_total_row,ignore_index=True).append(tblreg[tblreg[\"Region\"]=='Retail Online'])\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1190: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  res=res.append(total_row,ignore_index=True)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1227: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  table_brand_hilo = table_brand_hilo.append(table_brand_hilo.sum(numeric_only=True), ignore_index=True)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1233: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  table_brand_ns = table_brand_ns.append(table_brand_ns.sum(numeric_only=True), ignore_index=True)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1239: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  table_brand_lmen = table_brand_lmen.append(table_brand_lmen.sum(numeric_only=True), ignore_index=True)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1245: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  table_brand_ts = table_brand_ts.append(table_brand_ts.sum(numeric_only=True), ignore_index=True)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1266: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  table_brand = table_brand_hilo.append(pd.Series(), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1266: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  table_brand = table_brand_hilo.append(pd.Series(), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1267: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  table_brand = table_brand.append(table_brand_lmen, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1268: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  table_brand = table_brand.append(pd.Series(), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1268: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  table_brand = table_brand.append(pd.Series(), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1269: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  table_brand = table_brand.append(table_brand_ns, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1270: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  table_brand = table_brand.append(pd.Series(), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1270: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  table_brand = table_brand.append(pd.Series(), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1271: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  table_brand = table_brand.append(table_brand_ts, ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1379: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_table_launch = new_table_launch.append(table_launch[table_launch['Brand'] == i], ignore_index = True, sort = False).append(pd.Series(), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1379: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_table_launch = new_table_launch.append(table_launch[table_launch['Brand'] == i], ignore_index = True, sort = False).append(pd.Series(), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1379: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_table_launch = new_table_launch.append(table_launch[table_launch['Brand'] == i], ignore_index = True, sort = False).append(pd.Series(), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1379: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_table_launch = new_table_launch.append(table_launch[table_launch['Brand'] == i], ignore_index = True, sort = False).append(pd.Series(), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1379: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_table_launch = new_table_launch.append(table_launch[table_launch['Brand'] == i], ignore_index = True, sort = False).append(pd.Series(), ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1379: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_table_launch = new_table_launch.append(table_launch[table_launch['Brand'] == i], ignore_index = True, sort = False).append(pd.Series(), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1379: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_table_launch = new_table_launch.append(table_launch[table_launch['Brand'] == i], ignore_index = True, sort = False).append(pd.Series(), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1379: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_table_launch = new_table_launch.append(table_launch[table_launch['Brand'] == i], ignore_index = True, sort = False).append(pd.Series(), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1379: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_table_launch = new_table_launch.append(table_launch[table_launch['Brand'] == i], ignore_index = True, sort = False).append(pd.Series(), ignore_index = True, sort = False)\n",
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_6556\\1178754581.py:1381: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_table_launch = new_table_launch.append(table_launch[table_launch['Brand'] == i], ignore_index = True, sort = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Data Finish\n",
      "Clean Data Non Nubi Finish\n",
      "Export Data 2020 Finish\n",
      "Prepare Emailing\n",
      "Email Sent\n"
     ]
    }
   ],
   "source": [
    "print(\"Export Master Data\")\n",
    "\n",
    "data_all['PL Before PPN'] = data_all['Price List NFI']/1.1\n",
    "data_all.loc[data_all['True datetime']>='2022-04-01','PL Before PPN']= data_all['Price List NFI']/1.11\n",
    "data_all['Total Net Before PPN'] = data_all['PL Before PPN'] * data_all['Qty. Invoiced']\n",
    "\n",
    "index = data_all[\n",
    "    (pd.to_datetime(data_all['True datetime']) > '2020-09-11') &\n",
    "    (data_all['Real SKU'].astype(str) == '1101909453') \n",
    "].index.to_list()\n",
    "\n",
    "data_all['Real SKU'][index] = '1101909331'\n",
    "\n",
    "index = data_all[\n",
    "    (pd.to_datetime(data_all['True datetime']) > '2020-09-11') &\n",
    "    (data_all['Real SKU'].astype(str) == '1101569453') \n",
    "].index.to_list()\n",
    "\n",
    "data_all['Real SKU'][index] = '1101569326'\n",
    "\n",
    "index = data_all[\n",
    "    (pd.to_datetime(data_all['True datetime']) > '2020-09-11') &\n",
    "    (data_all['Real SKU'].astype(str) == '1101907453') \n",
    "].index.to_list()\n",
    "\n",
    "data_all['Real SKU'][index] = '1101907331'\n",
    "\n",
    "index = data_all[data_all['Real SKU'] == '(B) 2101656'].index.to_list()\n",
    "data_all['Real SKU'][index] = '(B)2101656'\n",
    "\n",
    "index = data_all[data_all['Real SKU'] == '(B)1101989453'].index.to_list()\n",
    "data_all['Brand'][index] = 'Bonus Produk'\n",
    "\n",
    "data_all.loc[data_all['SKU'].isin(['(U)2104115163', '(U)2101809250', '(U)2309005305',\n",
    "                                   '(U)2101845443',\"(U)2101947250\", '(B)71210295',\n",
    "                                   '(B)2106323165']),'Brand']='Bonus Produk'\n",
    "# data_all.loc[data_all['SKU']==\"2152051\",'SKU']='2152051110'\n",
    "# data_all.loc[data_all['SKU']==\"2152051\",'Real SKU']='2152051110'\n",
    "\n",
    "\n",
    "if 'Order Online' not in data_now:\n",
    "    data_now = data_now + ' With Order Online'\n",
    "SKU = pd.read_excel(r'SKU_File/data_SKU.xlsx')\n",
    "SKU_baru = pd.read_excel(r\"SKU_File/Subbrand Baru.xlsx\")\n",
    "\n",
    "SKU_final = SKU.copy()\n",
    "SKU_baru['Item Group Code'] = SKU_baru['Item Group Code'].astype(str).str.replace('.0','', regex = False)\n",
    "SKU_final['SKU Clean'] = SKU_final['SKU'].astype(str).str.replace('(S)', '', regex = False).str.replace('(R)', '', regex = False).str.replace('(B)', '', regex = False).str.replace('(50%)', '', regex = False).str.replace('(E)', '', regex = False)\n",
    "SKU_final = SKU_final.merge(SKU_baru.drop_duplicates('Item Group Code'), how = 'left', left_on = 'SKU Clean', right_on = 'Item Group Code')\n",
    "\n",
    "no_pair = SKU[SKU['SKU'].astype(str).isin(SKU_final[SKU_final['Category Baru'].isnull()]['SKU'].astype(str))]\n",
    "SKU_final = SKU_final[~SKU_final['SKU'].astype(str).isin(no_pair['SKU'].astype(str))]\n",
    "\n",
    "no_pair['SKU Clean'] = no_pair['SKU'].astype(str).str.replace('(S)', '', regex = False).str.replace('(R)', '', regex = False).str.replace('(B)', '', regex = False).str.replace('(50%)', '', regex = False).str.replace('(E)', '', regex = False).str.replace('E', '', regex = False)\n",
    "SKU_baru['Item Group Code'] = SKU_baru['Product Code'].astype(str).str.replace('.0','', regex = False)\n",
    "\n",
    "index = no_pair[no_pair['SKU'].astype(str) == '1101984451'].index[0]\n",
    "no_pair['SKU Clean'][index] = '1101984453'\n",
    "\n",
    "index = no_pair[no_pair['SKU'].astype(str) == '2104393210'].index[0]\n",
    "no_pair['SKU Clean'][index] = '2104392210'\n",
    "\n",
    "no_pair = no_pair.merge(SKU_baru.drop_duplicates('Product Code'), how = 'left', left_on = 'SKU Clean', right_on = 'Product Code')\n",
    "\n",
    "SKU_final = SKU_final.append(no_pair, ignore_index = True, sort = False)\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101569360'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'NS MODERN'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS JERUK PERAS REF 12DX500G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)1101569360'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'NS MODERN'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS JERUK PERAS REF 12DX500G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101686036'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = \"W'DANK LKLT KOPI KAWISTA PLS 12RX10SX15G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin([\"(E)2104407\",'2104407'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS EXTRA VIRGIN OLIVE OIL 12BTLX500ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2305551106'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM CHOCO LATTE 6DX6SX33.5G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2305551106'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM CHOCO LATTE 6DX6SX33.5G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(B)2305551106'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM CHOCO LATTE 6DX6SX33.5G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2304034180'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN GM MANGGA 6DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(R)1101588453', '1101588453', '(B)(R)1101588453', '1101588016'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS MILKY ORANGE PLS 4PX40SX11G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(R)1101588453'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS MILKY ORANGE PLS 4PX40SX11G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101452195'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ACTIVE CHOCOLATE 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101500195'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO GOLD PLAIN 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101524180'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO GOLD BISCUIT CEREAL 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101453195'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL CHOCOLATE 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101651195'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN CHOCOLATE 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2102546125'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SWT JAHE 24Dx50SX2.5G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(B)2102546125'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SWT JAHE 24Dx50SX2.5G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2102546125'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SWT JAHE 24Dx50SX2.5G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2304034180'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN GM MANGGA 6DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(R)1101989453', '1101989453', '(B)(R)1101989453'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS ES CINCAU PLS 4PX40SX13G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(R)1101954453', '1101954453', '(B)(R)1101954453'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS SEMANGKA PLS 4PX40SX13G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(R)1101927453', '1101927453', '(B)(R)1101927453','(E)1101927453'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS NANAS PLS 4PX40SX13G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101538453'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS ANGGUR HIJAU PLS 4PX40SX11G '\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104170104'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS WHITE COFFEE 12DX4SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101656318', '(B)1101656318', '(B)(R)1101656318','(E)1101656318'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI BERONDONG PLS 12RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(R)1101930453', '(B)(R)1101930453', '1101930453',\"(E)1101930453\"])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS COCOPANDAN PLS 4PX40SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['71210158', '(J)71110121'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET NUTRISARI 25 RASA'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(J)71110126'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET NUTRISARI 25 RASA FRESHSTART'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1102574110'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS MIX PAKET BALI 12Dx10S'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['71210165'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET KEHANGATAN WDANK'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104170164'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS WHITE COFFEE 12DX4SX20G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2309005300', '2309005305','(E)2309005300'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PROTEIN CRUNCH BBQ BEEF 20BX20G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['(E)1101688317','1101688317'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS W’DANK EMPON-EMPON PLS 12Rx10Sx12G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2306551173'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN BAR CRUNCHY CHOCOLATE 6SBX12SX22G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2306551173'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN BAR CRUNCHY CHOCOLATE 6SBX12SX22G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101813443'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ES TELER PLS 8RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101813443'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ES TELER PLS 8RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101813036'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ES TELER FC 36PX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101864443'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ES PISANG IJO PLS 8RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101845360'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ES KETAN HITAM REF 12BAGX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101845443'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ES KETAN HITAM PLS 8RX10SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101845443'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ES KETAN HITAM PLS 8RX10SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '71210166'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET LOKALATE UNTUK SOBATKU'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2304008180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN GAINMASS TARO 6DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2305551161'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM CHOCO LATTE 6DX6SX38.5G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2305507288',\"(E)2305507288\"])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM KACANG HIJAU 6KLRX800G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '71210163'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET HAMPERS IMLEK NUTRISARI'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104508105'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS KOREAN GARLIC BUTTER COOKIES 12DX5SX20G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104148164'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS MINT COCOA 12DX4SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104214210'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SAMBAL TERASI 24BTLX200G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2104214210'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SAMBAL TERASI 24BTLX200G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104115163'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS AVOCADO COFFEE 12DX4SX20G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101609180','(E)2101609180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN TARO 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101445144','(E)2101445144'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ACTIVE KETAN HITAM 12DX175G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101485195'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ACTIVE VANILLA 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2102526125'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SWT LEMONGRASS PANDAN 24DX50SX2G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104394210'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SAUS TIRAM 24BTLX200ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2305545288',\"(E)2305545288\"])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM KETAN HITAM 6KLRX800G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2106023014', '(B)2106023014',\"(E)2106023014\"])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SHIRATAKI NOODLES 40PX71G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2T03201001'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS BUMBU KALDU AYAM JAMUR 24PX100G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2106323165'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS BUMBU SAUS TELUR ASIN 24Dx3Sx22G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110113'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET HILO'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET TAKJIL HILO DESSERT'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110110'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET TS'\n",
    "SKU_final['Unnamed: 3'][index] = 'HAMPER IDUL FITRI TS'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110129'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET TS'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET TS BEAT HYPERTENSION 2022'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110114'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET RAMADHAN NUTRISARI 2021'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101413144'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ACTIVE ES TELER 12DX175G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101413144'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ACTIVE ES TELER 12DX175G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110111'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET KEHANGATAN WDANK - RAMADHAN EDITION'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110115'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET TS'\n",
    "SKU_final['Unnamed: 3'][index] = 'GETPLUS HAMPERS IDUL FITRI TS'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2102584125'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SWT ROSE VANILLA 24DX50SX2G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101642180'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN POPCORN CARAMEL 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101642180'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN POPCORN CARAMEL 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101543453'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS APEL JERUK PLS 4PX40SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(B) 2101656'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO RTD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN RTD COFFEE TIRAMISU 24PX200ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101816250'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO RTD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO RTD VANILA COOKIES 24PX200ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2106386249'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS BIRU'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS RTD OAT DRINK VANILLICIOUS 24PX190ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2105028180'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS BIRU'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS LOW FAT MILK KOREAN STRAWBERRY 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104241210'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS MAYONNAISE ROASTED SESAME 24BTLX200G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2104241210'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS MAYONNAISE ROASTED SESAME 24BTLX200G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101996453',\"(E)1101996453\"])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS ES RUJAK JERUK BALI PLS 4PX40SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2300542155'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN DAILY POPCORN CARAMEL 12DX250G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1102110453'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS NUTRI C1000 JERUK PLS 4PX40SX6G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110117'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'NUTRILOGI SERI MBA NANA SI PENUH PESONA'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110116'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'NUTRILOGI SERI MAS KAKA YANG BANYAK AKAL'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110119'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'NUTRILOGI SERI JEJE SI JELI'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1102560453'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'NUTRISARI 4 RASA SUMMER PACKAGE 40 SACHET'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1102561453'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'NUTRISARI 4 RASA LOCAL PACKAGE 40 SACHET'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2104543105'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS KOREAN GOGUMA COOKIES 12DX5SX20G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101651155'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN CHOCOLATE 12DX250G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110118'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET NUTRISARI'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET ORANGE ADVENTURE'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101578180'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO GOLD SWEET POTATO 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101551195'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO GOLD CHOCOLATE 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101700166'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO PLATINUM ORIGINAL 12DX12SX30G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101710110'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO JOINT PLUS 12DX10SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101710110'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO JOINT PLUS 12DX10SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101693318'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI TAPE KETAN PLS 12RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)1101693318'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI TAPE KETAN PLS 12RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101694318'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI ANDALIMAN PLS 12RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101653318'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS W'DANK SARABBA EXTRA PLS 12RX10SX15G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101618318'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS W'DANK MADU TEMULAWAK PLS 12RX10SX11G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110120'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET WDANK'\n",
    "SKU_final['Unnamed: 3'][index] = 'PAKET LOKALATE #RASALOKAL'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101444180'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL STRAW CHEESECAKE 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101486195'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL VANILLA 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101487148', '(B)2101487148','(E)2101487148'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO ALMOND MILK COCONUT 12DX200G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101469180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO MULTIGRAIN ORIGINAL 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101683180', '(B)2101683180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN STRAW MILKSHAKE 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2304097159'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLANTPROTEIN OGURA 6Dx216G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2106395308','(E)2106395308'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SHIRATAKI RICE RASA NASI UDUK 24PX72G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1102070350'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS MODERN'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS TEA LYCHEE TEA REF 12BAGX500G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101505453'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS JERUK NIPIS JAHE PLS 4PX40SX11G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101595453'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS ES KUWUD NIPIS PLS 4PX40SX11G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1101591453'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS GULA ASEM PLS 4PX40SX11G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2104589105','(B)2104589105'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = \"TS COOKIES KLEPON 12DX5SX20G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2304515112'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = \"L-MEN LOSE WEIGHT AVOCADO COFFEE 6DX12SX25G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2LD0905181'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = \"L-MEN GAINMASS KLEPON LATTE 6DX500G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101453607'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = \"HILO SCHOOL CHOCOLATE 12DX250G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101459180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = \"HILO SCHOOL BUBBLE GUM 12DX500G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101478180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO ACTIVE'\n",
    "SKU_final['Unnamed: 3'][index] = \"HILO ACTIVE CARAMEL LATTE 12DX500G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(J)71110124'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'PAKET TS'\n",
    "SKU_final['Unnamed: 3'][index] = 'PARSEL NATAL TAHUN BARU'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101479180'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL COTTON CANDY 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2HF1403250'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO RTD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL RTD COTTON CANDY 24TPKX200ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101692318'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI PISANG BAKAR EPE PLS 12RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101656360'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI BERONDONG 12BAGX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101685360'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI ALPUKAT 12BAGX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)1101686036'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = \"W'DANK LKLT KOPI KAWISTA PLS 12RX10SX15G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101888360'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO KLEPON LATTE REF 12BAGX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101847360'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO THAI TEA REF 12BAGX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2101819360'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TARO LATTE REF 12BAGX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101481118'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL CHOCOLATE CANDY 12SBX20SX8G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2106317152'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS INSTANT CAKE MIX BROWNIES 12Dx230G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2305559288'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM BUBBLE GUM 6KLRX800G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2305584288'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN PLATINUM VANILLA CARAMEL 6KLRX800G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2304576112'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN LW MANGO STICKY RICE 6DX12SX25G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2105055180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS BIRU'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS LOW FAT MILK MACCHIATO COFFEE 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2101618180'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN BISCUIT CARAMEL 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2154084141'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'DIABETAMIL'\n",
    "SKU_final['Unnamed: 3'][index] = 'DIABETAMIL MILK VANILLA 12Dx150G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['2104119110'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SOY LATTE 12Dx10Sx15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2T01812126'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SWT GULA AREN 24DX50SX2G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str).isin(['1102611360'])].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS MODERN'\n",
    "SKU_final['Unnamed: 3'][index] = \"NS TEA LEMON TEA REF 12BAGX500G\"\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2HH1407250'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO RTD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO DRINK RTD CHOC AVOCADO 24TPKX200ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)1101694318'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI ANDALIMAN PLS 12RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101888360'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO KLEPON LATTE REF 12BAGX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2102526125'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SWT LEMONGRASS PANDAN 24DX50SX2G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)1101543453'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'NS TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'NS APEL JERUK PLS 4PX40SX14G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101500195'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO GOLD PLAIN 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101444180'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL STRAW CHEESECAKE 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2104394210'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS MERAH'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS SAUS TIRAM 24BTLX200ML'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101651195'].index[0]\n",
    "SKU_final['Category Baru'][index] = 'HILO TEEN'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO TEEN CHOCOLATE 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)1101694108'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI ANDALIMAN 12DX8SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '2HF0111003'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HI LO SCHOOL STRAWBERRY PLS 12RX10SX27G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '1101686318'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI KAWISTA PLS 12RX10SX15G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101453195'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO SCHOOL'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO SCHOOL CHOCOLATE 6DX1000G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2300542155'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'L-MEN POWDER'\n",
    "SKU_final['Unnamed: 3'][index] = 'L-MEN DAILY POPCORN CARAMEL 12DX250G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2101578180'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'HILO GOLD'\n",
    "SKU_final['Unnamed: 3'][index] = 'HILO GOLD SWEET POTATO 12DX500G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)2104508105'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'TS KUNING OTHERS'\n",
    "SKU_final['Unnamed: 3'][index] = 'TS KOREAN GARLIC BUTTER COOKIES 12DX5SX20G'\n",
    "\n",
    "index = SKU_final[SKU_final['SKU'].astype(str) == '(E)1101656108'].index.to_list()\n",
    "SKU_final['Category Baru'][index] = 'WDANK TRADITIONAL'\n",
    "SKU_final['Unnamed: 3'][index] = 'LOKALATE KOPI BERONDONG 12Dx8Sx15G'\n",
    "\n",
    "SKU = SKU.merge(SKU_final[['SKU', 'Category Baru', 'Unnamed: 3']].drop_duplicates('SKU'), how = 'left', on = 'SKU')\n",
    "SKU = SKU.rename(columns = {'Unnamed: 3' : 'Exported Parent Item'})\n",
    "\n",
    "index = data_all[data_all['Real SKU'] == '2101492P24'].index.to_list()\n",
    "data_all['Brand'][index] = 'Bundle'\n",
    "index = data_all[data_all['SKU'].isin(['71210111', '71210112'])].index.to_list()\n",
    "data_all['Brand'][index] = 'Bundle'\n",
    "index = data_all[data_all['Real SKU'] == '2306592173'].index.to_list()\n",
    "data_all['Brand'][index] = 'L-Men'\n",
    "indeks = data_all[data_all['Brand'] == 'TS'][data_all[data_all['Brand'] == 'TS']['Real SKU'].astype(str) == '2101453180'].index.to_list()\n",
    "data_all['Real SKU'][indeks] = data_all['SKU'][indeks]\n",
    "data_all['Parent Item'][indeks] = 'Tropicana Slim Milk Low Fat Vanilla 500gr'\n",
    "index = data_all[data_all['Brand'] == \"WDANK\"].index.to_list()\n",
    "data_all['Brand'][index] = 'NS'\n",
    "index = data_all[data_all['Brand'] == \"W'dank\"].index.to_list()\n",
    "data_all['Brand'][index] = 'NS'\n",
    "\n",
    "data_all['Real SKU'] = data_all['Real SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "# # # data_all = data_all.drop(['Category Baru', 'Exported Parent Item'], axis = 1)\n",
    "# # data_all.rename(columns = {'SKU_x' : 'SKU'}, inplace = True)\n",
    "\n",
    "no_name = data_all[data_all['Exported Parent Item'].isnull()]\n",
    "no_name = no_name.merge(SKU[['SKU', 'Category Baru', 'Exported Parent Item']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(no_name.index)\n",
    "\n",
    "data_all['Category Baru'][no_name.index] = no_name['Category Baru_y']\n",
    "data_all['Exported Parent Item'][no_name.index] = no_name['Exported Parent Item_y']\n",
    "\n",
    "data_SKU = SKU.copy()\n",
    "data_SKU['Category Baru'] = data_SKU['Category Baru'].fillna(data_SKU['Sub Brand'])\n",
    "data_SKU['Category Baru'] = data_SKU['Category Baru'].fillna(data_SKU['Brand'])\n",
    "data_SKU['Sub Brand'] = data_SKU['Category Baru']\n",
    "data_all['Sub Brand'] = data_all['Category Baru']\n",
    "# data_all = data_all.drop('SKU_y', axis = 1)\n",
    "# data_all.rename(columns = {'SKU_x' : 'SKU'}, inplace = True)\n",
    "\n",
    "index = data_all[data_all['Real SKU'].astype(str) == '2102000155'].index.to_list()\n",
    "data_all['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "\n",
    "index = data_all[data_all['Real SKU'].astype(str) == '2153000314'].index.to_list()\n",
    "data_all['Category Baru'][index] = 'TS KUNING - SWT POWDER'\n",
    "\n",
    "index = data_all[data_all['Real SKU'].astype(str) == '2304097159'].index.to_list()\n",
    "data_all['Category Baru'][index] = 'L-MEN POWDER'\n",
    "data_all['Sub Brand'][index] = 'L-MEN POWDER'\n",
    "\n",
    "index = data_all[data_all['Real SKU'].astype(str) == '2101651155'].index.to_list()\n",
    "data_all['Category Baru'][index] = 'HILO TEEN'\n",
    "data_all['Exported Parent Item'][index] = 'HILO TEEN CHOCOLATE 12DX250G'\n",
    "\n",
    "\n",
    "# # data_SKU['List Brand'] = np.nan\n",
    "# # for i in range(len(data_SKU)):\n",
    "# #     list_brand = []\n",
    "# #     if data_SKU['Brand'][i] == 'Bundle':\n",
    "# #         col_SKU = [x for x in data_SKU.columns if 'SKU Produk' in x]\n",
    "# #         for j in col_SKU:\n",
    "# #             if str(data_SKU[j][i]) != 'nan' and str(data_SKU[j][i]) != '0':\n",
    "# #                 if len(data_SKU[data_SKU['SKU'].astype(str) == str(data_SKU[j][i]).replace('(S)', '').replace('.0', '')]['Brand']) != 0:\n",
    "# #                     subbrand = data_SKU[data_SKU['SKU'].astype(str) == str(data_SKU[j][i]).replace('(S)', '').replace('.0', '')]['Sub Brand'].values[0]\n",
    "# #                     brand = data_SKU[data_SKU['SKU'].astype(str) == str(data_SKU[j][i]).replace('(S)', '').replace('.0', '')]['Brand'].values[0]\n",
    "# #                     if brand == 'Gimmick' : \n",
    "# #                         if str(data_SKU['Nama Produk'][i]).lower() != 'nan' :\n",
    "# #                             if 'voucher' in data_SKU['Nama Produk'][i].lower() or 'saldo' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                 brand = 'Voucher'\n",
    "# #                             elif 'pouch' in data_SKU['Nama Produk'][i].lower() or 'bag ' in data_SKU['Nama Produk'][i].lower() or 'tas ' in data_SKU['Nama Produk'][i].lower() or 'totebag' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                 brand = 'Bag'\n",
    "# #                             elif 'bottle' in data_SKU['Nama Produk'][i].lower() or 'gelas ' in data_SKU['Nama Produk'][i].lower() or 'shaker' in data_SKU['Nama Produk'][i].lower() or 'tumblr' in data_SKU['Nama Produk'][i].lower() or 'tumbler' in data_SKU['Nama Produk'][i].lower() or 'botol' in data_SKU['Nama Produk'][i].lower() or 'thumbler' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                 brand = 'Tumblr'\n",
    "# #                             elif 'lunch' in data_SKU['Nama Produk'][i].lower() or 'tupper' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                 brand = 'Lunch Box'\n",
    "# #                             elif 'emoney' in data_SKU['Nama Produk'][i].lower() or 'e-money' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                 brand = 'E-Money'\n",
    "# #                             elif 'magnet' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                 brand = 'Magnet'\n",
    "# #                             elif 'masker' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                 brand = 'Masker'\n",
    "# #                             elif 'spatula' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                 brand = 'Spatula'\n",
    "# #                             elif 'nivea' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                 brand = 'Nivea'\n",
    "# #                             elif 'card ' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                 brand = 'Card'\n",
    "# #                             elif 'mug' in data_SKU['Nama Produk'][i].lower():\n",
    "# #                                 brand = 'Mug'\n",
    "# #                             list_brand.append(brand)\n",
    "# #                             data_SKU['Sub Brand'][i] = brand\n",
    "# #                     else :\n",
    "# #                         list_brand.append(subbrand)\n",
    "# #     list_brand.sort()\n",
    "# #     data_SKU['List Brand'][i] = list_brand\n",
    "\n",
    "# # for i in range(len(data_SKU)):\n",
    "# #     if data_SKU['Brand'][i] == 'Bundle':\n",
    "# #         list_brand = list(dict.fromkeys(data_SKU['List Brand'][i]))\n",
    "# # #         sum_brand = sum([1 for x in list_brand if x in ['NS', 'TS', 'HiLo', 'L-Men', \"W'dank\"]])\n",
    "# # #         if sum_brand == 1:\n",
    "# #         list_brand = ' + '.join(list_brand)\n",
    "# # #         else :\n",
    "# # #             not_brand = [x for x in list_brand if x not in ['NS', 'TS', 'HiLo', 'L-Men', \"W'dank\"]]\n",
    "# # #             if len(not_brand) == 0:\n",
    "# # #                 list_brand = 'Cross Brand'\n",
    "# # #             else :\n",
    "# # #                 list_brand = 'Cross Brand + ' + ' + '.join(not_brand)\n",
    "# #         data_SKU['Sub Brand'][i] = list_brand\n",
    "\n",
    "\n",
    "temp = data_all.copy()\n",
    "no_name['Real SKU'] = no_name['Real SKU'].astype(str).str.replace('(S)','',regex = False).str.replace('.0','',regex = False)\n",
    "data_SKU['SKU'] = data_SKU['SKU'].astype(str).str.replace('(S)','',regex = False).str.replace('.0','',regex = False)\n",
    "data_all['Sub Brand'][no_name.index] = no_name.merge(data_SKU[['SKU', 'Sub Brand']].drop_duplicates('SKU'), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(no_name.index)['Sub Brand_y']\n",
    "\n",
    "print('Filter Status')\n",
    "index = data_all[data_all['Customer Name'] == 'Shopee Brand Portal'].index.to_list()\n",
    "data_all['Order Status'][index] = 'Delivered'\n",
    "\n",
    "data_success =data_all[data_all['Order Status'].isin([\n",
    "        '\"Delivered\"', '\"Ready to Ship\"', '\"Open\"', '\"Printed\"',\n",
    "       '\"Shipped\"', '\"Delivered, Shipped\"', '\"Shipped, Ready to Ship\"',\n",
    "       '\"Shipped, Delivered\"', '\"Ready to Ship, Delivered\"',\n",
    "       '\"Ready to Ship, Shipped\"', '\"Delivered, Ready to Ship\"',\n",
    "       '\"Delivered, Open\"', '\"Open, Delivered\"', 'Delivered',\n",
    "       '\"Ready to Ship, Open\"', '\"Shipped, Open\"','complete', 'payment_confirmed',\n",
    "       'completed_to_wms', 'processing', \n",
    "       'ready_to_ship', \n",
    "       '\"Open, Ready to Ship\"', '\"Open, Shipped, Ready to Ship\"',\n",
    "       'Sudah Settlement', '\"Delivered, Shipped, Ready to Ship\"',\n",
    "       '\"Ready to Ship, Shipped, Delivered\"',\n",
    "       '\"Ready to Ship, Delivered, Shipped\"', '\"Open, Shipped\"',\n",
    "       '\"Printed, Open\"', '\"Shipped, Printed\"', '\"Delivered, Printed\"',\n",
    "       '\"Open, Printed\"', '\"Printed, Shipped\"', '\"Printed, Delivered\"',\n",
    "       '\"Open, Delivered, Printed\"', '\"Open, Shipped, Printed\"',\n",
    "       '\"Shipped, Open, Printed\"', '\"Ready to Ship, Printed\"',\n",
    "       '\"Printed, Delivered, Open\"', '\"Delivered, Printed, Shipped\"',\n",
    "       '\"Printed, Shipped, Open\"', '\"Delivered, Shipped, Open\"',\n",
    "       '\"Shipped, Open, Ready to Ship\"',\n",
    "       '\"Delivered, Open, Ready to Ship\"', \n",
    "       '\"Ready to Ship, Open, Shipped\"', \n",
    "       'Sudah Isi Pickup Time', '\"Shipped, Ready to Ship, Open\"',\n",
    "       '\"Payout\"',  '\"Printed, Ready to Ship\"',\n",
    "       'Ready to Ship', 'Open',\n",
    "       'Shipped', 'Delivered, Shipped', \n",
    "       'Delivered, Open', 'Printed', 'cod_sent',\n",
    "       'entri_verified', 'incoming', 'completed', 'Open, Ready to Ship',\n",
    "       'Open, Shipped', 'Ready to Ship, Shipped', 'completed_with_awb','Packed','Shipped','Delivered','Ready to Ship','Completed'\n",
    "    ])]\n",
    "\n",
    "# print(data_success[(data_success['Store']=='Order Online')&(data_success['Year']==2022)]['Date'].unique())\n",
    "all_single = data_success[data_success['Brand'].isin(['NS', 'TS', 'L-Men', 'HiLo'])]\n",
    "all_single = all_single[all_single['Exported Parent Item'] != \"W'DANK LKLT KOPI DURIAN PLS 12RX10SX15G\"]\n",
    "#all_single = all_single[all_single['Store'].isin(['JD Indonesia', 'Lazada', 'Bukalapak', 'Blibli', 'Tokopedia',\n",
    "#                                                  'Shopee', 'Nutrimart', 'Elevenia', 'Order Online',\n",
    "#                                                  'CARI SAYUR',  'EMOS', 'INOVASI DIGITAL NIAGA - KALIDERES, PT',\n",
    "#                                                  'RITEL BERSAMA NASIONAL; PT', 'SAYUR BOX', 'TANIHUB','INOVASI DIGITAL NIAGA - SURABAYA, PT',\n",
    "#                                                  'INDOPASIFIK TEKNOLOGI MED INDONESIA, PT','ASTRO TECHNOLOGIES - TANGERANG, PT', 'Aladin Mall','KREASI TANI LAKSMI - SURABAYA, PT', 'TikTok',\n",
    "#                                                  'CIBINONG CENTER INDUSTRIAL ESTATE , PT','KREASI NOSTRA MANDIRI - BOGOR, PT','KREASI NOSTRA MANDIRI - SURABAYA, PT','ECOM RETAIL - ASTRO',\n",
    "#                                                  'ECOM RETAIL - BAYI NINJA JAKARTA','ECOM RETAIL - BAYI NINJA SURABAYA', 'ECOM RETAIL - EMOS',\n",
    "#                                                  'ECOM RETAIL - LIFEPACK','ECOM RETAIL - SAYUR BOX JAKARTA',\n",
    "#                                                  'ECOM RETAIL - SAYUR BOX SURABAYA', 'ECOM RETAIL - TANIHUB',\n",
    "#                                                  'ECOM RETAIL - INDOPASIFIK FARMA MEDIKA INDONESIA',\n",
    "#                                                  'ECOM RETAIL - SWIFT LOGISTICS SOLUTIONS','ECOM RETAIL - SWIFT BEKASI','ECOM RETAIL - SWIFT JKT UTARA'])]\n",
    "\n",
    "all_single = all_single[all_single['Store']!='MITRA TOKOPEDIA']\n",
    "indeks = all_single[all_single['Store'].isin(['CARI SAYUR',  'EMOS', 'INOVASI DIGITAL NIAGA - KALIDERES, PT',\n",
    "                                              'RITEL BERSAMA NASIONAL; PT', 'SAYUR BOX', 'TANIHUB'])].index.to_list()\n",
    "all_single['Exported Parent Item'][indeks] = all_single['Product Name'][indeks]\n",
    "\n",
    "indeks = all_single[(all_single['Store'].isin(['CARI SAYUR',  'EMOS', 'INOVASI DIGITAL NIAGA - KALIDERES, PT',\n",
    "       'RITEL BERSAMA NASIONAL; PT', 'SAYUR BOX', 'TANIHUB']))&\n",
    "                   (all_single['Sub Brand'].isnull())].index.to_list()\n",
    "all_single['Sub Brand'][indeks] = all_single['Category'][indeks]\n",
    "\n",
    "all_single['Total Net'] = all_single['Total Net'].astype(float).astype('int64')\n",
    "\n",
    "bundle_name = data_all[data_all['Real SKU'] == 'PN50N86N87N89G162']['Product Name'].unique()\n",
    "bundle_name = list(bundle_name) + ['NutriSari Orange Adventure (5 x 10 Sch)','NutriSari Bundle - Orange Adventure']\n",
    "indeks = all_single[all_single['Bundle Name'].astype(str).isin(bundle_name)].index.to_list()\n",
    "all_single['Brand'][indeks] = 'NS'\n",
    "all_single['Sub Brand'][indeks] = 'PAKET NUTRISARI'\n",
    "all_single['Exported Parent Item'][indeks] = 'PAKET ORANGE ADVENTURE'\n",
    "\n",
    "all_single['Exported Parent Item'] = all_single['Exported Parent Item'].astype(str).str.replace('TS SHIRATAKI NOODLES 40Px71G', 'TS SHIRATAKI NOODLES 40PX71G')\n",
    "all_single['Exported Parent Item'] = all_single['Exported Parent Item'].astype(str).str.replace('TS KOREAN GARLIC BUTTERCOOKIES12DX5SX20G', 'TS KOREAN GARLIC BUTTER COOKIES 12DX5SX20G')\n",
    "all_single['Exported Parent Item'] = all_single['Exported Parent Item'].astype(str).str.replace('TS WHITE COFFEE 12DX4SX20G', 'TS WHITE COFFEE 12DX4SX15G')\n",
    "all_single['Exported Parent Item'] = all_single['Exported Parent Item'].astype(str).str.replace('TS AVOCADO COFFEE 12DX4SX20G', 'TS AVOCADO COFFEE 12DX4SX14G')\n",
    "\n",
    "all_single.loc[all_single['Real SKU'] == '2152051','Exported Parent Item']='TS DM COOKIES CHOCO 12DX10SX20G'#[['Year','Month','Brand','Store','Sub Brand','Real SKU','Real Nama Produk','Bundle Name']]#.drop_duplicates()\n",
    "all_single.loc[all_single['Real SKU'] == '2152051','Sub Brand']='TS KUNING OTHERS'\n",
    "all_single=all_single[all_single['Real SKU']!=\"(U)1102101155\"]\n",
    "all_single=all_single[all_single['Real SKU']!=\"(U)2307061250\"]\n",
    "all_single.loc[all_single['Order #']=='1000103864','Region Group']='Kab. Bogor'\n",
    "\n",
    "zipnotmapped=all_single[(all_single['Region Group'].isnull())&(all_single['Store Type']=='Marketplace')&(all_single['Year']==2022)&(all_single['Zip Code'].notnull())]['Zip Code'].unique()#.to_excel('Gk ke mapping.xlsx',index=False)\n",
    "for i in zipnotmapped:\n",
    "    regionvalue=all_single[(all_single['Zip Code']==i)&(all_single['Region Group'].notnull())]['Region Group'].unique()[0]\n",
    "    all_single.loc[(all_single['Region Group'].isnull())&(all_single['Region Group'].isnull())&(all_single['Store Type']=='Marketplace')&(all_single['Year']==2022),'Region Group']=regionvalue\n",
    "\n",
    "\n",
    "indeks = all_single[all_single['Exported Parent Item'].isnull()].index.to_list()\n",
    "indeks = indeks + all_single[all_single['Exported Parent Item'] == 'nan'].index.to_list()\n",
    "\n",
    "if len(indeks) == 0:\n",
    "    print(\"Prepare E-mailing\")\n",
    "    \n",
    "    ########################################################\n",
    "    \n",
    "    table_brand = all_single[all_single['Store']=='Order Online'][['Brand','Sub Brand']].drop_duplicates().reset_index(drop = True)\n",
    "    all_single['True datetime'] = pd.to_datetime(all_single['True datetime'])\n",
    "    from datetime import datetime, timedelta\n",
    "    today = datetime.today()\n",
    "    yesterday = datetime.today() - timedelta(days=1)\n",
    "    today = pd.to_datetime(today.strftime('%Y-%m-%d'))\n",
    "    yesterday = pd.to_datetime(yesterday.strftime('%Y-%m-%d'))\n",
    "    yesterday_sales = all_single[all_single['Store']=='Order Online'][all_single['True datetime'] >= yesterday][all_single[all_single['True datetime'] >= yesterday]['True datetime']<today]\n",
    "    yesterday_sales = yesterday_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "    yesterday_sales['Total Net'] = yesterday_sales['Total Net']/1.1\n",
    "    yesterday_sales = yesterday_sales.rename(columns = {'Total Net' : 'Yesterday Sales'})\n",
    "    table_brand = table_brand.merge(yesterday_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "    if int(today.strftime('%d')) > 1 :\n",
    "        mtd_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)\n",
    "        mtd_date = pd.to_datetime(mtd_date.strftime('%Y-%m-%d'))\n",
    "    else :\n",
    "        mtd_date = datetime.today()-timedelta(days=int(yesterday.strftime('%d')))\n",
    "        mtd_date = pd.to_datetime(mtd_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "    mtd_sales = all_single[all_single['Store']=='Order Online'][all_single['True datetime'] >= mtd_date][all_single[all_single['True datetime'] >= mtd_date]['True datetime']<today]\n",
    "    mtd_sales = mtd_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "    mtd_sales['Total Net'] = mtd_sales['Total Net']/1.1\n",
    "    mtd_sales = mtd_sales.rename(columns = {'Total Net' : 'Local Sales'})\n",
    "    table_brand = table_brand.merge(mtd_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "    from calendar import monthrange\n",
    "\n",
    "\n",
    "    if int(today.strftime('%d')) > 1 :\n",
    "        table_brand['Average This Month'] = table_brand['Local Sales']/(int(today.strftime('%d'))-1)\n",
    "        number_of_days = monthrange(today.year, today.month)[1]\n",
    "    else :\n",
    "        table_brand['Average This Month'] = table_brand['Local Sales']/(int(yesterday.strftime('%d')))\n",
    "        number_of_days = monthrange(yesterday.year, yesterday.month)[1]\n",
    "\n",
    "    table_brand['Projected'] = table_brand['Average This Month'] * number_of_days\n",
    "\n",
    "    from dateutil import rrule\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "\n",
    "    start_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)-relativedelta(months=3)\n",
    "    start_date = pd.to_datetime(start_date.strftime('%Y-%m-%d'))\n",
    "    end_date = datetime.today()-timedelta(days=int(today.strftime('%d')))\n",
    "    for dt in rrule.rrule(rrule.MONTHLY, dtstart=start_date, until=end_date):\n",
    "        first_date = pd.to_datetime(dt)\n",
    "        print(\"First Date \" + str(first_date))\n",
    "        last_date = first_date + relativedelta(months=1)\n",
    "        print(\"Last Date \" + str(last_date))\n",
    "        temp_sales = all_single[all_single['Store']=='Order Online'][all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n",
    "        temp_sales = temp_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "        temp_sales['Total Net'] = temp_sales['Total Net']/1.1\n",
    "        colname = str(first_date.month_name()) + ' ' + str(first_date.year)\n",
    "        temp_sales = temp_sales.rename(columns = {'Total Net' : colname})\n",
    "        table_brand = table_brand.merge(temp_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "    cols = list(table_brand)\n",
    "    cols[len(cols)-1], cols[len(cols)-3] = cols[len(cols)-3], cols[len(cols)-1]\n",
    "    table_brand = table_brand.loc[:,cols]\n",
    "    table_brand = table_brand.reset_index(drop = True)\n",
    "    table_brand = table_brand.drop('Average This Month', axis = 1)\n",
    "\n",
    "    def highlight_max(x):\n",
    "        return ['font-weight: bold' if v == x.loc[x.index.max()] else ''\n",
    "                    for v in x]\n",
    "\n",
    "    #     table_brand = table_brand[table_brand['Local Sales'].notnull()]\n",
    "    table_brand['Yesterday Sales'] = table_brand['Yesterday Sales'].fillna(0).astype('int64')\n",
    "    table_brand['Local Sales'] = table_brand['Local Sales'].fillna(0).astype('int64')\n",
    "    table_brand = table_brand.sort_values(['Brand','Local Sales'], ascending = [True, False])\n",
    "\n",
    "    table_ecom = table_brand.copy()\n",
    "\n",
    "    for i in table_ecom.columns[2:]:\n",
    "        table_ecom[i] = table_ecom[i].fillna(0).astype('int64')\n",
    "\n",
    "    table_ecom = table_ecom.append(table_ecom.sum(numeric_only=True), ignore_index=True)\n",
    "    # for i in table_ecom.columns[2:]:\n",
    "    #     table_ecom[i] = table_ecom[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "    #     table_ecom[i][table_ecom.index.max()] = \"<b> {} </b>\".format(table_ecom[i][table_ecom.index.max()])\n",
    "\n",
    "    table_ecom = table_ecom.drop('Brand', axis = 1)\n",
    "    table_ecom['Sub Brand'][table_ecom.index.max()] = '<b>Total E-Commerce (NHD) Sales<b>'\n",
    "    table_ecom = table_ecom.rename(columns = {'Sub Brand' : ''})\n",
    "\n",
    "    table_ecom2 = table_ecom.iloc[[-1]].reset_index(drop = True)\n",
    "\n",
    "    ###############################################################\n",
    "\n",
    "    table_brand = all_single[all_single['Store']!='Order Online'][['Brand','Sub Brand']].drop_duplicates().reset_index(drop = True)\n",
    "    all_single['True datetime'] = pd.to_datetime(all_single['True datetime'])\n",
    "\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    today = datetime.today()\n",
    "    yesterday = datetime.today() - timedelta(days=1)\n",
    "\n",
    "    today = pd.to_datetime(today.strftime('%Y-%m-%d'))\n",
    "    yesterday = pd.to_datetime(yesterday.strftime('%Y-%m-%d'))\n",
    "\n",
    "    yesterday_sales = all_single[all_single['Store']!='Order Online'][all_single['True datetime'] >= yesterday][all_single[all_single['True datetime'] >= yesterday]['True datetime']<today]\n",
    "    yesterday_sales = yesterday_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "    yesterday_sales['Total Net'] = yesterday_sales['Total Net']/1.1\n",
    "    yesterday_sales = yesterday_sales.rename(columns = {'Total Net' : 'Yesterday Sales'})\n",
    "    table_brand = table_brand.merge(yesterday_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "    if int(today.strftime('%d')) > 1 :\n",
    "        mtd_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)\n",
    "        mtd_date = pd.to_datetime(mtd_date.strftime('%Y-%m-%d'))\n",
    "    else :\n",
    "        mtd_date = datetime.today()-timedelta(days=int(yesterday.strftime('%d')))\n",
    "        mtd_date = pd.to_datetime(mtd_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "    mtd_sales = all_single[all_single['Store']!='Order Online'][all_single['True datetime'] >= mtd_date][all_single[all_single['True datetime'] >= mtd_date]['True datetime']<today]\n",
    "    mtd_sales = mtd_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "    mtd_sales['Total Net'] = mtd_sales['Total Net']/1.1\n",
    "    mtd_sales = mtd_sales.rename(columns = {'Total Net' : 'Local Sales'})\n",
    "    table_brand = table_brand.merge(mtd_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "    from calendar import monthrange\n",
    "\n",
    "\n",
    "    if int(today.strftime('%d')) > 1 :\n",
    "        table_brand['Average This Month'] = table_brand['Local Sales']/(int(today.strftime('%d'))-1)\n",
    "        number_of_days = monthrange(today.year, today.month)[1]\n",
    "    else :\n",
    "        table_brand['Average This Month'] = table_brand['Local Sales']/(int(yesterday.strftime('%d')))\n",
    "        number_of_days = monthrange(yesterday.year, yesterday.month)[1]\n",
    "\n",
    "    table_brand['Projected'] = table_brand['Average This Month'] * number_of_days\n",
    "\n",
    "    from dateutil import rrule\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "\n",
    "    start_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)-relativedelta(months=3)\n",
    "    start_date = pd.to_datetime(start_date.strftime('%Y-%m-%d'))\n",
    "    end_date = datetime.today()-timedelta(days=int(today.strftime('%d')))\n",
    "    for dt in rrule.rrule(rrule.MONTHLY, dtstart=start_date, until=end_date):\n",
    "        first_date = pd.to_datetime(dt)\n",
    "        print(\"First Date \" + str(first_date))\n",
    "        last_date = first_date + relativedelta(months=1)\n",
    "        print(\"Last Date \" + str(last_date))\n",
    "        temp_sales = all_single[all_single['Store']!='Order Online'][all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n",
    "        temp_sales = temp_sales.groupby(['Brand', 'Sub Brand'])['Total Net'].sum().reset_index()\n",
    "        temp_sales['Total Net'] = temp_sales['Total Net']/1.1\n",
    "        colname = str(first_date.month_name()) + ' ' + str(first_date.year)\n",
    "        temp_sales = temp_sales.rename(columns = {'Total Net' : colname})\n",
    "        table_brand = table_brand.merge(temp_sales, how = 'left', on = ['Brand', 'Sub Brand'])\n",
    "\n",
    "    cols = list(table_brand)\n",
    "    cols[len(cols)-1], cols[len(cols)-3] = cols[len(cols)-3], cols[len(cols)-1]\n",
    "    table_brand = table_brand.loc[:,cols]\n",
    "    table_brand = table_brand.reset_index(drop = True)\n",
    "    table_brand = table_brand.drop('Average This Month', axis = 1)\n",
    "\n",
    "    def highlight_max(x):\n",
    "        return ['font-weight: bold' if v == x.loc[x.index.max()] else ''\n",
    "                    for v in x]\n",
    "\n",
    "    #     table_brand = table_brand[table_brand['Local Sales'].notnull()]\n",
    "    table_brand['Yesterday Sales'] = table_brand['Yesterday Sales'].fillna(0).astype('int64')\n",
    "    table_brand['Local Sales'] = table_brand['Local Sales'].fillna(0).astype('int64')\n",
    "    table_brand = table_brand.sort_values(['Brand','Local Sales'], ascending = [True, False])\n",
    "\n",
    "    table_ecom = table_brand.copy()\n",
    "\n",
    "    for i in table_ecom.columns[2:]:\n",
    "        table_ecom[i] = table_ecom[i].fillna(0).astype('int64')\n",
    "\n",
    "    table_ecom = table_ecom.append(table_ecom.sum(numeric_only=True), ignore_index=True)\n",
    "    # for i in table_ecom.columns[2:]:\n",
    "    #     table_ecom[i] = table_ecom[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "    #     table_ecom[i][table_ecom.index.max()] = \"<b> {} </b>\".format(table_ecom[i][table_ecom.index.max()])\n",
    "\n",
    "    table_ecom = table_ecom.drop('Brand', axis = 1)\n",
    "    table_ecom['Sub Brand'][table_ecom.index.max()] = '<b>Total E-Commerce (Non NHD) Sales</b>'\n",
    "    table_ecom = table_ecom.rename(columns = {'Sub Brand' : ''})\n",
    "\n",
    "    table_ecom1 = table_ecom.iloc[[-1]].reset_index(drop = True)\n",
    "    # table_ecom=table_ecom1.append(table_ecom2,ignore_index=True,sort=False)\n",
    "    # table_ecom=table_ecom.append(table_ecom.sum(numeric_only=True), ignore_index=True,sort=False)\n",
    "\n",
    "    table_ecom=table_ecom1.append(table_ecom2,ignore_index=True,sort=False)\n",
    "    table_ecom=table_ecom.append(table_ecom.sum(numeric_only=True), ignore_index=True)\n",
    "    table_ecom.loc[(table_ecom[\"\"].isnull()),\"\"]='<b>Total E-Commerce Sales</b>'\n",
    "    table_ecom\n",
    "\n",
    "    for i in table_ecom.columns[1:]:\n",
    "        table_ecom[i] = table_ecom[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        table_ecom[i][table_ecom.index.max()] = \"<b> {} </b>\".format(table_ecom[i][table_ecom.index.max()])\n",
    "\n",
    "    ###############################################################\n",
    "    from datetime import date\n",
    "    sales_total=all_single.groupby(['Year','Month','True datetime','Store'],dropna=False)[['Total Net']].sum().reset_index()\n",
    "    sales_total.loc[sales_total['Store']=='Order Online','Store Group']='<b>Total Ecommerce (NHD) Sales</b>'\n",
    "    sales_total.loc[sales_total['Store']!='Order Online','Store Group']='<b>Total Ecommerce (Non NHD) Sales</b>'\n",
    "\n",
    "    sales_total['Total Net Before PPN']=sales_total['Total Net']/1.1\n",
    "    sales_total.loc[sales_total['True datetime']>='2022-04-01','Total Net Before PPN']=sales_total['Total Net']/1.11\n",
    "\n",
    "    sales_total['Date']=pd.to_datetime(sales_total['True datetime']).dt.date\n",
    "\n",
    "    col1=sales_total[(sales_total['Date']>=(date.today()-timedelta(1)))&\n",
    "                        (sales_total['Date']<(date.today()))].groupby(['Store Group'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':'Yesterday Sales'}))\n",
    "\n",
    "    if '<b>Total Ecommerce (NHD) Sales</b>' not in col1['Store Group'].unique():\n",
    "        col1=col1.append(pd.DataFrame({'Store Group': [\"<b>Total Ecommerce (NHD) Sales</b>\"], 'Yesterday Sales': [0]}))\n",
    "\n",
    "    col2=sales_total[(sales_total['Year']==(datetime.now()-timedelta(1)).year)&\n",
    "                         (sales_total['Month']==(datetime.now()-timedelta(1)).strftime(\"%B\"))&\n",
    "                         (sales_total['Date']<(date.today()))].groupby(['Store Group'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':'Local Sales'}))\n",
    "    lastmonth1=(date.today().replace(day=1)-timedelta(1))#.strftime(\"%B\")\n",
    "    lastmonth2=(lastmonth1.replace(day=1)-timedelta(1))#.strftime(\"%B\")\n",
    "    lastmonth3=(lastmonth2.replace(day=1)-timedelta(1))\n",
    "    col3=col2.copy()\n",
    "    maxday=monthrange((datetime.now()-timedelta(1)).year, (datetime.now()-timedelta(1)).month)[1]\n",
    "    col3['Projected']=col3['Local Sales']*maxday/((datetime.now()-timedelta(1)).day)\n",
    "\n",
    "    col4=sales_total[(sales_total['Year']==lastmonth1.year)&\n",
    "                 (sales_total['Month']==lastmonth1.strftime(\"%B\"))].groupby(['Store Group'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':f'{lastmonth1.strftime(\"%B\")} {lastmonth1.year}'}))\n",
    "    col5=sales_total[(sales_total['Year']==lastmonth2.year)&\n",
    "                 (sales_total['Month']==lastmonth2.strftime(\"%B\"))].groupby(['Store Group'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':f'{lastmonth2.strftime(\"%B\")} {lastmonth2.year}'}))\n",
    "    col6=sales_total[(sales_total['Year']==lastmonth3.year)&\n",
    "                 (sales_total['Month']==lastmonth3.strftime(\"%B\"))].groupby(['Store Group'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':f'{lastmonth3.strftime(\"%B\")} {lastmonth3.year}'}))\n",
    "    tblall=col1.merge(col2,how='left').merge(col3,how='left').merge(col4,how='left').merge(col5,how='left').merge(col6,how='left')\n",
    "    tblall=tblall.fillna(int(0))\n",
    "    tblall=tblall.sort_values('Store Group',ascending=False).reset_index(drop=True)\n",
    "\n",
    "    total_row=tblall.sum(numeric_only=True)\n",
    "\n",
    "    tblall=tblall.append(total_row,ignore_index=True)\n",
    "    tblall.loc[tblall['Store Group'].isnull(),'Store Group']='<b>Total Ecommerce Sales</b>'\n",
    "    tblall.rename(columns={'Store Group':\"\"})\n",
    "    for i in tblall.columns[1:]:\n",
    "        tblall[i] = tblall[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        tblall[i][tblall.index.max()] = \"<b> {} </b>\".format(tblall[i][tblall.index.max()])\n",
    "\n",
    "    # tblall   \n",
    "    \n",
    "    \n",
    "    ###############################################################\n",
    "    sales_region=all_single.groupby(['Year','Month','True datetime','Region Group'],dropna=False)[['Total Net']].sum().reset_index()\n",
    "    mappingarea=pd.read_excel(\"data_supp\\Database Area untuk Report.xlsx\")\n",
    "    mappingarea=mappingarea.rename(columns=({'Region':'Real Region',\"City\":'Region Group'}))\n",
    "    sales_region=sales_region.merge(mappingarea,how='left')\n",
    "    sales_region.loc[sales_region['Region Group'].isnull(),'Real Region']='Retail Online'\n",
    "    \n",
    "    \n",
    "    sales_region['Total Net Before PPN']=sales_region['Total Net']/1.1\n",
    "    sales_region.loc[sales_region['True datetime']>='2022-04-01','Total Net Before PPN']=sales_region['Total Net']/1.11\n",
    "    sales_region['Date']=pd.to_datetime(sales_region['True datetime']).dt.date\n",
    "\n",
    "    tblreg=sales_region[(sales_region['Date']>=(date.today()-timedelta(1)))&\n",
    "                        (sales_region['Date']<(date.today()))].groupby(['Real Region'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':'Yesterday Sales'}))\n",
    "    no_ytd_sales=mappingarea[~mappingarea['Real Region'].isin(tblreg['Real Region'].unique())]['Real Region'].unique()\n",
    "    for i in no_ytd_sales:\n",
    "        tblreg=tblreg.append(pd.DataFrame({'Real Region': [f\"{i}\"], 'Yesterday Sales': [0]}))\n",
    "        tblreg=tblreg.sort_values('Real Region')    \n",
    "    if 'Retail Online' not in tblreg['Real Region'].unique():\n",
    "        tblreg=tblreg.append(pd.DataFrame({'Real Region': [\"Retail Online\"], 'Yesterday Sales': [0]}))\n",
    "\n",
    "    tblreg2=sales_region[(sales_region['Year']==(datetime.now()-timedelta(1)).year)&\n",
    "                         (sales_region['Month']==(datetime.now()-timedelta(1)).strftime(\"%B\"))&\n",
    "                         (sales_region['Date']<(date.today()))].groupby(['Real Region'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':'Local Sales'}))\n",
    "    lastmonth1=(date.today().replace(day=1)-timedelta(1))#.strftime(\"%B\")\n",
    "    lastmonth2=(lastmonth1.replace(day=1)-timedelta(1))#.strftime(\"%B\")\n",
    "    lastmonth3=(lastmonth2.replace(day=1)-timedelta(1))\n",
    "    tblreg3=tblreg2.copy()\n",
    "    maxday=monthrange((datetime.now()-timedelta(1)).year, (datetime.now()-timedelta(1)).month)[1]\n",
    "    tblreg3['Projected']=tblreg3['Local Sales']*maxday/((datetime.now()-timedelta(1)).day)\n",
    "\n",
    "    tblregshopee=tblreg3[tblreg3[\"Real Region\"]=='Retail Online']\n",
    "    tblreg3=tblreg3[tblreg3[\"Real Region\"]!='Retail Online']#.copy()\n",
    "\n",
    "    totprj=tblreg3[tblreg3[\"Real Region\"]!='Retail Online']['Projected'].sum()\n",
    "    tblreg3['Projected %']=tblreg3['Projected']/totprj\n",
    "    tblreg3=tblreg3.append(tblregshopee)\n",
    "\n",
    "    tblreg3=tblreg3[['Real Region','Projected','Projected %']]\n",
    "    tblreg4=sales_region[(sales_region['Year']==lastmonth1.year)&\n",
    "                 (sales_region['Month']==lastmonth1.strftime(\"%B\"))].groupby(['Real Region'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':f'{lastmonth1.strftime(\"%B\")} {lastmonth1.year}'}))\n",
    "    tblreg5=sales_region[(sales_region['Year']==lastmonth2.year)&\n",
    "                 (sales_region['Month']==lastmonth2.strftime(\"%B\"))].groupby(['Real Region'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':f'{lastmonth2.strftime(\"%B\")} {lastmonth2.year}'}))\n",
    "    tblreg6=sales_region[(sales_region['Year']==lastmonth3.year)&\n",
    "                 (sales_region['Month']==lastmonth3.strftime(\"%B\"))].groupby(['Real Region'])[['Total Net Before PPN']].sum().reset_index().rename(columns=({'Total Net Before PPN':f'{lastmonth3.strftime(\"%B\")} {lastmonth3.year}'}))\n",
    "    tblreg=tblreg.merge(tblreg2,how='left').merge(tblreg3,how='left').merge(tblreg4,how='left').merge(tblreg5,how='left').merge(tblreg6,how='left')\n",
    "    tblreg=tblreg.rename(columns={'Real Region':'Region'})\n",
    "\n",
    "    total_row=tblreg.sum(numeric_only=True)\n",
    "    sub_total_row=tblreg[tblreg[\"Region\"]!='Retail Online'].sum(numeric_only=True)\n",
    "    # tblreg.loc[(tblreg[\"Region\"].isnull()),\"Region\"]='<b>Total Sales</b>'\n",
    "    res=pd.DataFrame()\n",
    "    res=res.append(tblreg[tblreg[\"Region\"]!='Retail Online']).append(sub_total_row,ignore_index=True).append(tblreg[tblreg[\"Region\"]=='Retail Online'])\n",
    "    res.loc[res[\"Region\"].isnull(),'Region']='<b>Sub Total Sales</b>'\n",
    "    res=res.append(total_row,ignore_index=True)\n",
    "    res.loc[res[\"Region\"].isnull(),'Region']='<b>Total Sales</b>'\n",
    "\n",
    "    res.loc[(res['Region']=='Retail Online')&\n",
    "               (res['Local Sales'].isnull()),'Local Sales']=0\n",
    "    res.loc[(res['Region']=='Retail Online')&\n",
    "               (res['Projected'].isnull()),'Projected']=0\n",
    "\n",
    "    tblreg=res.copy()\n",
    "    tblreg=tblreg.fillna(0)\n",
    "    for i in tblreg.columns[1:4]:\n",
    "        tblreg[i] = tblreg[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        tblreg[i][tblreg.index.max()] = \"<b> {} </b>\".format(tblreg[i][tblreg.index.max()])\n",
    "\n",
    "    for i in tblreg.columns[4:5]:\n",
    "        tblreg[i] = tblreg[i].apply(lambda x: \"{:.2f} %\".format(x*100))#.str.replace(',','.', regex = False)\n",
    "        tblreg[i][tblreg.index.max()] = \"<b> {} </b>\".format(tblreg[i][tblreg.index.max()])\n",
    "\n",
    "\n",
    "    for i in tblreg.columns[5:]:\n",
    "        tblreg[i] = tblreg[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        tblreg[i][tblreg.index.max()] = \"<b> {} </b>\".format(tblreg[i][tblreg.index.max()])\n",
    "\n",
    "    for i in tblreg.columns[1:]:\n",
    "        tblreg[i][tblreg.index.max()-2] = \"<b> {} </b>\".format(tblreg[i][tblreg.index.max()-2])\n",
    "\n",
    "    tblreg.loc[(tblreg[\"Projected %\"]==\"nan %\"),\"Projected %\"]=''\n",
    "\n",
    "\n",
    "    tblreg\n",
    "\n",
    "    ###################################################################################\n",
    "\n",
    "    for i in table_brand.columns[2:]:\n",
    "        table_brand[i] = table_brand[i].fillna(0).astype('int64')\n",
    "\n",
    "    table_brand_hilo = table_brand[table_brand['Brand'] == 'HiLo'].reset_index(drop = True)\n",
    "    table_brand_hilo = table_brand_hilo.append(table_brand_hilo.sum(numeric_only=True), ignore_index=True)\n",
    "    table_brand_hilo['Sub Brand'][table_brand_hilo.index.max()] = '<b>TOTAL<b>'\n",
    "    table_brand_hilo['Brand'][table_brand_hilo.index.max()] = ''\n",
    "\n",
    "\n",
    "    table_brand_ns= table_brand[table_brand['Brand'] == 'NS'].reset_index(drop = True)\n",
    "    table_brand_ns = table_brand_ns.append(table_brand_ns.sum(numeric_only=True), ignore_index=True)\n",
    "    table_brand_ns['Sub Brand'][table_brand_ns.index.max()] = '<b>TOTAL<b>'\n",
    "    table_brand_ns['Brand'][table_brand_ns.index.max()] = ''\n",
    "\n",
    "\n",
    "    table_brand_lmen = table_brand[table_brand['Brand'] == 'L-Men'].reset_index(drop = True)\n",
    "    table_brand_lmen = table_brand_lmen.append(table_brand_lmen.sum(numeric_only=True), ignore_index=True)\n",
    "    table_brand_lmen['Sub Brand'][table_brand_lmen.index.max()] = '<b>TOTAL<b>'\n",
    "    table_brand_lmen['Brand'][table_brand_lmen.index.max()] = ''\n",
    "\n",
    "\n",
    "    table_brand_ts = table_brand[table_brand['Brand'] == 'TS'].reset_index(drop = True)\n",
    "    table_brand_ts = table_brand_ts.append(table_brand_ts.sum(numeric_only=True), ignore_index=True)\n",
    "    table_brand_ts['Sub Brand'][table_brand_ts.index.max()] = '<b>TOTAL<b>'\n",
    "    table_brand_ts['Brand'][table_brand_ts.index.max()] = ''\n",
    "\n",
    "\n",
    "    for i in table_brand_hilo.columns[2:]:\n",
    "        table_brand_hilo[i] = table_brand_hilo[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        table_brand_hilo[i][table_brand_hilo.index.max()] = \"<b> {} </b>\".format(table_brand_hilo[i][table_brand_hilo.index.max()])\n",
    "\n",
    "    for i in table_brand_lmen.columns[2:]:\n",
    "        table_brand_lmen[i] = table_brand_lmen[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        table_brand_lmen[i][table_brand_lmen.index.max()] = \"<b> {} </b>\".format(table_brand_lmen[i][table_brand_lmen.index.max()])\n",
    "\n",
    "    for i in table_brand_ns.columns[2:]:\n",
    "        table_brand_ns[i] = table_brand_ns[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        table_brand_ns[i][table_brand_ns.index.max()] = \"<b> {} </b>\".format(table_brand_ns[i][table_brand_ns.index.max()])\n",
    "\n",
    "    for i in table_brand_ts.columns[2:]:\n",
    "        table_brand_ts[i] = table_brand_ts[i].apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "        table_brand_ts[i][table_brand_ts.index.max()] = \"<b> {} </b>\".format(table_brand_ts[i][table_brand_ts.index.max()])\n",
    "\n",
    "    table_brand = table_brand_hilo.append(pd.Series(), ignore_index = True, sort = False)\n",
    "    table_brand = table_brand.append(table_brand_lmen, ignore_index = True, sort = False)\n",
    "    table_brand = table_brand.append(pd.Series(), ignore_index = True, sort = False)\n",
    "    table_brand = table_brand.append(table_brand_ns, ignore_index = True, sort = False)\n",
    "    table_brand = table_brand.append(pd.Series(), ignore_index = True, sort = False)\n",
    "    table_brand = table_brand.append(table_brand_ts, ignore_index = True, sort = False)\n",
    "    for i in table_brand.columns:\n",
    "        table_brand[i] = table_brand[i].fillna('')\n",
    "\n",
    "    table_brand = table_brand[(table_brand == 'Rp 0').sum(1) < 5]\n",
    "    table_brand = table_brand.reset_index(drop = True)\n",
    "\n",
    "    # table_brand_hilo.style.apply(highlight_max)\n",
    "    # table_brand_ns.style.apply(highlight_max)\n",
    "    # table_brand_lmen.style.apply(highlight_max)\n",
    "    # table_brand_ts.style.apply(highlight_max)\n",
    "\n",
    "    table_item = all_single[['Brand', 'Sub Brand', 'Exported Parent Item']].drop_duplicates().reset_index(drop = True)\n",
    "    all_single['True datetime'] = pd.to_datetime(all_single['True datetime'])\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    today = datetime.today()\n",
    "    yesterday = datetime.today() - timedelta(days=1)\n",
    "\n",
    "    today = pd.to_datetime(today.strftime('%Y-%m-%d'))\n",
    "    yesterday = pd.to_datetime(yesterday.strftime('%Y-%m-%d'))\n",
    "\n",
    "    yesterday_sales = all_single[all_single['True datetime'] >= yesterday][all_single[all_single['True datetime'] >= yesterday]['True datetime']<today]\n",
    "    yesterday_sales = yesterday_sales.groupby(['Brand', 'Sub Brand', 'Exported Parent Item'])['Total Net'].sum().reset_index()\n",
    "    yesterday_sales['Total Net'] = yesterday_sales['Total Net']/1.1\n",
    "    yesterday_sales = yesterday_sales.rename(columns = {'Total Net' : 'Yesterday Sales'})\n",
    "    table_item = table_item.merge(yesterday_sales, how = 'left', on = ['Brand', 'Sub Brand', 'Exported Parent Item'])\n",
    "\n",
    "    if int(today.strftime('%d')) > 1 :\n",
    "        mtd_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)\n",
    "        mtd_date = pd.to_datetime(mtd_date.strftime('%Y-%m-%d'))\n",
    "    else :\n",
    "        mtd_date = datetime.today()-timedelta(days=int(yesterday.strftime('%d')))\n",
    "        mtd_date = pd.to_datetime(mtd_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "    mtd_sales = all_single[all_single['True datetime'] >= mtd_date][all_single[all_single['True datetime'] >= mtd_date]['True datetime']<today]\n",
    "    mtd_sales = mtd_sales.groupby(['Brand', 'Sub Brand', 'Exported Parent Item'])['Total Net'].sum().reset_index()\n",
    "    mtd_sales['Total Net'] = mtd_sales['Total Net']/1.1\n",
    "    mtd_sales = mtd_sales.rename(columns = {'Total Net' : 'Local Sales'})\n",
    "    table_item = table_item.merge(mtd_sales, how = 'left', on = ['Brand', 'Sub Brand', 'Exported Parent Item'])\n",
    "\n",
    "    if int(today.strftime('%d')) > 1 :\n",
    "        table_item['Average This Month'] = table_item['Local Sales']/(int(today.strftime('%d'))-1)\n",
    "        number_of_days = monthrange(today.year, today.month)[1]\n",
    "    else :\n",
    "        table_item['Average This Month'] = table_item['Local Sales']/(int(yesterday.strftime('%d')))\n",
    "        number_of_days = monthrange(yesterday.year, yesterday.month)[1]\n",
    "\n",
    "    table_item['Projected'] = table_item['Average This Month'] * number_of_days\n",
    "\n",
    "    from dateutil import rrule\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "\n",
    "    start_date = datetime.today()-timedelta(days=int(today.strftime('%d'))-1)-relativedelta(months=3)\n",
    "    start_date = pd.to_datetime(start_date.strftime('%Y-%m-%d'))\n",
    "    end_date = datetime.today()-timedelta(days=int(today.strftime('%d')))\n",
    "    for dt in rrule.rrule(rrule.MONTHLY, dtstart=start_date, until=end_date):\n",
    "        first_date = pd.to_datetime(dt)\n",
    "        last_date = first_date + relativedelta(months=1)\n",
    "        temp_sales = all_single[all_single['True datetime'] >= first_date][all_single[all_single['True datetime'] >= first_date]['True datetime']<last_date]\n",
    "        temp_sales = temp_sales.groupby(['Brand', 'Sub Brand', 'Exported Parent Item'])['Total Net'].sum().reset_index()\n",
    "        temp_sales['Total Net'] = temp_sales['Total Net']/1.11\n",
    "        colname = str(first_date.month_name()) + ' ' + str(first_date.year)\n",
    "        temp_sales = temp_sales.rename(columns = {'Total Net' : colname})\n",
    "        table_item = table_item.merge(temp_sales, how = 'left', on = ['Brand', 'Sub Brand', 'Exported Parent Item'])\n",
    "\n",
    "    cols = list(table_item)\n",
    "    cols[len(cols)-1], cols[len(cols)-3] = cols[len(cols)-3], cols[len(cols)-1]\n",
    "    table_item = table_item.loc[:,cols]\n",
    "\n",
    "    #     table_item = table_item[table_item['Local Sales'].notnull()]\n",
    "    table_item['Yesterday Sales'] = pd.to_numeric(table_item['Yesterday Sales'], errors = 'coerce').fillna(0).astype('int64')\n",
    "    table_item['Local Sales'] = pd.to_numeric(table_item['Local Sales'], errors = 'coerce').fillna(0).astype('int64')\n",
    "    table_item = table_item.sort_values(['Brand','Local Sales'], ascending = [True, False])\n",
    "\n",
    "    for i in table_item.columns[3:]:\n",
    "        table_item[i] = table_item[i].fillna(0).apply(lambda x: \"Rp {:,}\".format(int(x))).str.replace(',','.', regex = False)\n",
    "\n",
    "    table_item = table_item[(table_item == 'Rp 0').sum(1) < 5]\n",
    "    table_item = table_item.reset_index(drop = True)\n",
    "    table_item = table_item.drop('Average This Month', axis = 1)\n",
    "\n",
    "    all_single = all_single.sort_values('True datetime')\n",
    "\n",
    "    first_product = all_single.groupby('Exported Parent Item')['True datetime'].first().reset_index()\n",
    "\n",
    "    product_launch = first_product[first_product['True datetime'] > pd.to_datetime(datetime.today() - relativedelta(months=3))]['Exported Parent Item'].unique()\n",
    "    non_launch =  [\"PARSEL NATAL TAHUN BARU\",'HAMPER IDUL FITRI TS', 'GETPLUS HAMPERS IDUL FITRI TS', 'PAKET TAKJIL HILO DESSERT',\n",
    "                   'HILO CHOCOLATE PLS 15RX10SX14G', 'HILO TEEN TARO 12DX500G', 'TS SAMBAL TERASI 24BTLX200G',\n",
    "                   'TS AVOCADO COFFEE 12DX4SX20G', 'L-MEN PLATINUM KETAN HITAM 6KLRX800G', 'HILO AVOCADO CHOCOLATE PLS 15RX10SX14G', 'TS SHIRATAKI NOODLES 40PX71G',\n",
    "                   'TS KOREAN GARLIC BUTTERCOOKIES12DX5SX20G','TS AVOCADO COFFEE 12DX4SX14G', 'TS SWT CLASSIC 24DX100G', 'HILO WHITE CHOCOLATE PLS 15RX10SX14G', \n",
    "                   'HILO CHOCO HAZELNUT PLS 15RX10SX14G', 'NS ANGGUR PLS 4PX40SX11G',\"NS JERUK MANADO PLS 4PX40SX11G\",\n",
    "                   \"NS TEA LYCHEE TEA REF 12BAGX500G\",\"NUTRISARI 4 RASA SUMMER PACKAGE 40 SACHET\",\"NUTRISARI 4 RASA LOCAL PACKAGE 40 SACHET\",\n",
    "                   'PAKET NUTRISARI 25 RASA FRESHSTART','PAKET TS BEAT HYPERTENSION 2022','HILO SCHOOL CHOCOLATE CANDY 12SBX20SX8G','HILO ES TELER FC 36PX10SX15G','NS BLEWAH FC 72PX10SX11G','NS JERUK MAROKO 72PX10SX14G']\n",
    "    product_launch = [x for x in product_launch if x not in non_launch]\n",
    "\n",
    "    table_launch = table_item[table_item['Exported Parent Item'].isin(product_launch)]\n",
    "    table_item = table_item[~table_item['Exported Parent Item'].isin(product_launch)]\n",
    "\n",
    "    table_hilo = table_item[table_item['Brand'] == 'HiLo'].reset_index(drop = True)\n",
    "    table_ns= table_item[table_item['Brand'] == 'NS'].reset_index(drop = True)\n",
    "    table_ns = table_ns[table_ns['Exported Parent Item'] != \"W'DANK LKLT KOPI DURIAN PLS 12RX10SX15G\"]\n",
    "    table_lmen = table_item[table_item['Brand'] == 'L-Men'].reset_index(drop = True)\n",
    "    table_ts = table_item[table_item['Brand'] == 'TS'].reset_index(drop = True)\n",
    "\n",
    "    new_table_launch = pd.DataFrame()\n",
    "    for i in table_launch['Brand'].unique():\n",
    "        if i != table_launch['Brand'].unique()[-1]:\n",
    "            new_table_launch = new_table_launch.append(table_launch[table_launch['Brand'] == i], ignore_index = True, sort = False).append(pd.Series(), ignore_index = True, sort = False)\n",
    "        else :\n",
    "            new_table_launch = new_table_launch.append(table_launch[table_launch['Brand'] == i], ignore_index = True, sort = False)\n",
    "\n",
    "    for i in new_table_launch.columns:\n",
    "        new_table_launch[i] = new_table_launch[i].fillna('')\n",
    "\n",
    "    index = data_all[data_all['Sub Brand'] == 'WDANK TRADITIONAL'][data_all[data_all['Sub Brand'] == 'WDANK TRADITIONAL']['Bundle Flag'].isnull()].index.to_list()\n",
    "    data_all['Brand'][index] = 'WDANK'\n",
    "\n",
    "    # data_all['PL Before PPN'] = data_all['Price List NFI']/1.11\n",
    "    \n",
    "    ### komen 11 Juli 2022 taro atas\n",
    "    # data_all['PL Before PPN'] = data_all['Price List NFI']/1.1\n",
    "    # data_all.loc[data_all['True datetime']>='2022-04-01','PL Before PPN']= data_all['Price List NFI']/1.11\n",
    "    # data_all['Total Net Before PPN'] = data_all['PL Before PPN'] * data_all['Qty. Invoiced']\n",
    "    ### komen 11 Juli 2022 \n",
    "\n",
    "    # data_all.to_csv(r'Clean Data/data_all_' + data_now + '.csv', sep = ';', index = False)\n",
    "    print(\"Clean Data Finish\")\n",
    "    #     data_all[data_all['Store Type'] != 'Retail Online'].to_csv(r'Clean Data/Non Nubi/data_all_non_nubi' + data_now + '.csv', sep = ';', index = False)\n",
    "    print(\"Clean Data Non Nubi Finish\")\n",
    "\n",
    "\n",
    "    # data_all[data_all['Year'] == 2021][['Order #','Order Status','Date', 'Month','Year',\n",
    "    #          'Hour',\n",
    "    #          'Channel', 'Store','Store Type',\n",
    "    #          'SKU',\n",
    "    #          'Brand',\n",
    "    #          'Product Name',\n",
    "    #          'Bundle Name',\n",
    "    #          'Price List NFI',\n",
    "    #          'Qty. Invoiced',\n",
    "    #          'Total Net',\n",
    "    #          'Sub Brand',\n",
    "    #          'Real SKU',\n",
    "    #          'Real Nama Produk',\n",
    "    #          'Parent Item',\n",
    "    #          'Parent SKU',\n",
    "    #          'Bundle Flag',\n",
    "    #          'Customer Email',\n",
    "    #          'Customer Name',\n",
    "    #          'Customer Group',\n",
    "    #          'Phone',\n",
    "    #          'Country',\n",
    "    #          'Region',\n",
    "    #          'City',\n",
    "    #          'Kecamatan',\n",
    "    #          'Kelurahan',\n",
    "    #          'Address',\n",
    "    #          'Zip Code','Shipping Courier',\n",
    "    #          'Total',\n",
    "    #          'Coupon Code','Subtotal',\n",
    "    #          'Discounts','Cart Name Rule','Voucher Amount','Warehouse Name',\n",
    "    #          'Regular Price',\n",
    "    #          'Selling Price','Shipping',\n",
    "    #          'Actual Shipping',\n",
    "    #          'Seller Discount','True datetime',\n",
    "    #          'Promo',\n",
    "    #          'Discount MC',\n",
    "    #          'Harga Cost',\n",
    "    #          'Total Harga Cost','nominal',\n",
    "    #          'btlcost',\n",
    "    #          'gs',\n",
    "    #          'commfee',\n",
    "    #          'fullfee','Shipping Province',\n",
    "    #          'Shipping City',\n",
    "    #          'Shipping Address1',\n",
    "    #          'Shipping Phone', 'PL Before PPN', 'Total Net Before PPN']].to_csv(r'Export Data/data_all_2021_' + data_now + '.csv', sep = ';', index = False)\n",
    "    print(\"Export Data 2020 Finish\")\n",
    "\n",
    "\n",
    "    print(\"Prepare Emailing\")\n",
    "    ### sad sdh gk bisa via gmail ####\n",
    "#     s = smtplib.SMTP('smtp.gmail.com', 587) \n",
    "\n",
    "#     # start TLS for security \n",
    "#     s.starttls() \n",
    "\n",
    "#     # Authentication \n",
    "#     s.login(\"automationnfi@gmail.com\", \"nutrifood24\") \n",
    "\n",
    "#     me = \"automationnfi@gmail.com\"\n",
    "#     to = \"andra.miftah@nutrifood.co.id\"\n",
    "\n",
    "#     html = '''\n",
    "#     <html>\n",
    "#     <head>\n",
    "#     <style>\n",
    "\n",
    "#         h2 {\n",
    "#             text-align: center;\n",
    "#             font-family: Helvetica, Arial, sans-serif;\n",
    "#         }\n",
    "#         table { \n",
    "#             margin-left: auto;\n",
    "#             margin-right: auto;\n",
    "#         }\n",
    "#         table, th, td {\n",
    "#             border: 1px solid black;\n",
    "#             border-collapse: collapse;\n",
    "#         }\n",
    "#         th, td {\n",
    "#             padding: 5px;\n",
    "#             text-align: center;\n",
    "#             font-family: Helvetica, Arial, sans-serif;\n",
    "#             font-size: 90%;\n",
    "#         }\n",
    "#         table tbody tr:hover {\n",
    "#             background-color: #dddddd;\n",
    "#         }\n",
    "#         .wide {\n",
    "#             width: 90%; \n",
    "#         }\n",
    "\n",
    "#     </style>\n",
    "#     </head>\n",
    "#     <body>\n",
    "#         '''\n",
    "#     html = html + \"\"\"\n",
    "#         <p> Dear all, </p>\n",
    "#         <p> Berikut data penjualan E-Com (Before PPN) tanggal <b> {tanggal} </b> dengan rincian channel sebagai berikut : </p>\n",
    "#         <p> Channel Marketplace : Blibli, Bukalapak, Elevenia, Lazada, Nutrimart, Order Online, Shopee, Tokopedia, Aladin Mall, TikTok </p>\n",
    "#         <p> Channel Retail : Cari Sayur, Emos, Farmaku, Inovasi Digital Niaga, Ritel Bersama Nasional, Sayurbox, Tanihub  </p>\n",
    "#     \"\"\".format(tanggal = str(datetime.today().date().strftime('%B %d, %Y')))\n",
    "\n",
    "#     html = html + tblall.to_html(classes='wide', escape=False).replace('&lt;b&gt;', '<b>').replace('&lt;/b&gt;', '</b>')\n",
    "    \n",
    "#     html = html + \"\"\"\n",
    "#         <p> Dan berikut data penjualan E-Com (After PPN) per Area :</p>\n",
    "#         \"\"\"\n",
    "\n",
    "#     html = html + tblreg.to_html(classes='wide', escape=False)\n",
    "\n",
    "#     html = html + \"\"\"\n",
    "#         <p> Dan Berikut data penjualan E-Com (After PPN) tanggal <b> {tanggal} </b> per Brand :</p>\n",
    "#     \"\"\".format(tanggal = str(datetime.today().date().strftime('%B %d, %Y'))) \n",
    "\n",
    "#     html = html + table_brand.to_html(classes='wide', escape=False).replace('&lt;b&gt;', '<b>').replace('&lt;/b&gt;', '</b>')\n",
    "\n",
    "#     html = html + \"\"\"\n",
    "#         <p> Dan berikut data penjualan E-Com (After PPN) per Item :</p>\n",
    "#         <p> Item Launching : </p>\"\"\"\n",
    "\n",
    "#     html = html + new_table_launch.to_html(classes='wide', escape=False)\n",
    "\n",
    "#     html = html + \"<p> HiLo : </p>\"    \n",
    "\n",
    "#     html = html + table_hilo.to_html(classes='wide', escape=False)\n",
    "\n",
    "#     html = html + \"<p> L-Men : </p>\"    \n",
    "\n",
    "#     html = html + table_lmen.to_html(classes='wide', escape=False)\n",
    "\n",
    "#     html = html + \"<p> NutriSari : </p>\"    \n",
    "\n",
    "#     html = html + table_ns.to_html(classes='wide', escape=False)\n",
    "\n",
    "#     html = html + \"<p> Tropicana Slim : </p>\"    \n",
    "\n",
    "#     html = html + table_ts.to_html(classes='wide', escape=False)\n",
    "\n",
    "\n",
    "\n",
    "#     html = html + \"\"\"\n",
    "#         <p></p>\n",
    "#         <p> Best regards, </p>\n",
    "#         <p> Andra Miftah Ar Rahman </p>\n",
    "#         <p> E-Commerce Executive </p>\n",
    "#     <body>\n",
    "#     </html>\n",
    "#     \"\"\"\n",
    "\n",
    "#     # text = text.format(tanggal = str(datetime.today().date()), table_brand = table_brand.to_html(), table_hilo = table_hilo.to_html(), table_ns = table_ns.to_html(), table_lmen = table_lmen.to_html(), table_ts = table_ts.to_html())\n",
    "\n",
    "#     msg = MIMEMultipart(\"alternative\", None, [MIMEText(html, 'html')])\n",
    "#     msg['Subject'] = \"Testing Report Ecom \" + str(datetime.today().date().strftime('%B %d, %Y'))\n",
    "\n",
    "#     # part1 = MIMEText(text)\n",
    "#     # msg.attach(part1)\n",
    "\n",
    "#     # sending the mail \n",
    "#     s.sendmail(\"automationnfi@gmail.com\", ['timotius.giovandi@nutrifood.co.id'], msg.as_string()) \n",
    "# # ,\"andra.miftah@nutrifood.co.id\"\n",
    "#     # terminating the session\n",
    "#     s.quit()\n",
    "    import win32com.client\n",
    "    o = win32com.client.Dispatch(\"Outlook.Application\")\n",
    "    for oacc in o.Session.Accounts:\n",
    "        if oacc.SmtpAddress == \"customer@nutrifood.co.id\":\n",
    "            oacctouse = oacc\n",
    "            break\n",
    "    Msg = o.CreateItem(0)\n",
    "    if oacctouse:\n",
    "        Msg._oleobj_.Invoke(*(64209, 0, 8, 0, oacctouse))  # Msg.SendUsingAccount = oacctouseif to:\n",
    "\n",
    "        to = ['steven.nathanael@nutrifood.co.id']\n",
    "\n",
    "        list_to = ';'.join(to)\n",
    "\n",
    "        Msg.To = list_to\n",
    "        Msg.Subject = \"Report E-commerce \" + \\\n",
    "        str(datetime.today().date().strftime('%B %d, %Y'))\n",
    "\n",
    "\n",
    "    html = '''\n",
    "    <html>\n",
    "    <head>\n",
    "    <style>\n",
    "\n",
    "        h2 {\n",
    "            text-align: center;\n",
    "            font-family: Helvetica, Arial, sans-serif;\n",
    "        }\n",
    "        table { \n",
    "            margin-left: auto;\n",
    "            margin-right: auto;\n",
    "        }\n",
    "        table, th, td {\n",
    "            border: 1px solid black;\n",
    "            border-collapse: collapse;\n",
    "        }\n",
    "        th, td {\n",
    "            padding: 5px;\n",
    "            text-align: center;\n",
    "            font-family: Helvetica, Arial, sans-serif;\n",
    "            font-size: 90%;\n",
    "        }\n",
    "        table tbody tr:hover {\n",
    "            background-color: #dddddd;\n",
    "        }\n",
    "        .wide {\n",
    "            width: 90%; \n",
    "        }\n",
    "        p\n",
    "\n",
    "    </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        '''\n",
    "    html = html + \"\"\"\n",
    "        <p> Dear all,</p>\n",
    "        <p> Berikut data penjualan E-Com <b> (Before PPN) tanggal {tanggal} </b> dengan rincian channel sebagai berikut : </p>\n",
    "        <p> Channel Marketplace : Blibli, Bukalapak, Elevenia, JD Indonesia, Lazada, Nutrimart, Order Online, Shopee, Tokopedia, Aladin Mall, TikTok </p>\n",
    "        <p> Channel Retail : Cari Sayur, Emos, Farmaku, Inovasi Digital Niaga, Ritel Bersama Nasional, Sayurbox, Tanihub, Astro, Lifepack, Toko Now   </p>\n",
    "        <p> Notes: Mohon maaf ada keterlambatan data untuk retail online </p>\n",
    "\n",
    "    \"\"\".format(tanggal = str(datetime.today().date().strftime('%B %d, %Y')))\n",
    "\n",
    "    html = html + tblall.to_html(classes='wide', escape=False).replace('&lt;b&gt;', '<b>').replace('&lt;/b&gt;', '</b>')\n",
    "\n",
    "    html = html + \"\"\"\n",
    "        <p> Dan berikut data penjualan E-Com (Before PPN) per Area :</p>\n",
    "        \"\"\"\n",
    "\n",
    "    html = html + tblreg.to_html(classes='wide', escape=False)\n",
    "\n",
    "    html = html + \"\"\"\n",
    "        <p> Dan Berikut data penjualan E-Com <b> (Before PPN) tanggal {tanggal} </b> per Brand :</p>\n",
    "    \"\"\".format(tanggal = str(datetime.today().date().strftime('%B %d, %Y'))) \n",
    "\n",
    "\n",
    "    html = html + table_brand.to_html(classes='wide', escape=False).replace('&lt;b&gt;', '<b>').replace('&lt;/b&gt;', '</b>')\n",
    "\n",
    "\n",
    "\n",
    "    html = html + \"\"\"\n",
    "        <p> Dan berikut data penjualan E-Com (Before PPN) per Item :</p>\n",
    "        <p> Item Launching : </p>\"\"\"\n",
    "\n",
    "    html = html + new_table_launch.to_html(classes='wide', escape=False)\n",
    "\n",
    "    html = html + \"<p> HiLo : </p>\"    \n",
    "\n",
    "    html = html + table_hilo.to_html(classes='wide', escape=False)\n",
    "\n",
    "    html = html + \"<p> L-Men : </p>\"    \n",
    "\n",
    "    html = html + table_lmen.to_html(classes='wide', escape=False)\n",
    "\n",
    "    html = html + \"<p> NutriSari : </p>\"    \n",
    "\n",
    "    html = html + table_ns.to_html(classes='wide', escape=False)\n",
    "\n",
    "    html = html + \"<p> Tropicana Slim : </p>\"    \n",
    "\n",
    "    html = html + table_ts.to_html(classes='wide', escape=False)\n",
    "\n",
    "    html = html + \"\"\"\n",
    "        <p></p>\n",
    "        <p> Best regards, </p>\n",
    "        <p> E-Commerce Nutrifood </p>\n",
    "    <body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    Msg.HTMLBody = html\n",
    "    Msg.Send()\n",
    "    print('Email Sent')\n",
    "else :\n",
    "    print('Missing Parent Item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "752fe9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04fb1b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 1), dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ini cek kalau pembagian region sama total (tbl 1 & 2 Beda) update di file area utk report\n",
    "sales_region[(sales_region['Region Group'].notnull())&(~sales_region['Region Group'].isin(mappingarea['Region Group'].unique()))][['Region Group']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ac15cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real SKU</th>\n",
       "      <th>Real Nama Produk</th>\n",
       "      <th>Category Baru</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Real SKU, Real Nama Produk, Category Baru]\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if error missing parent item\n",
    "# listing di kode atas, exported parent item liat tatanama akun admin login user&pass: nutrifood\n",
    "all_single[all_single['Exported Parent Item'] == 'nan'][['Real SKU','Real Nama Produk','Category Baru']].drop_duplicates()#.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8482cee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Order #', 'Sales Order ID', 'AWB', 'Paid Date', 'Order Status',\n",
       "       'Order date', 'Week', 'Date', 'Month', 'Quarter',\n",
       "       ...\n",
       "       'Fee Amount', 'Invoice Amount', 'Payment Received ID',\n",
       "       'Payment Received Ref. number', 'Category Baru', 'Exported Parent Item',\n",
       "       'Unnamed: 0', 'Price List NFI_x', 'Customer Type', 'Real Region'],\n",
       "      dtype='object', length=197)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_single.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fc2fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ea7655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f012d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5ace5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eaae8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b97a7bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### run 12\n",
    "### take out item yang gk masuk email automation\n",
    "buang = ['PAKET HILO']\n",
    "table_brand = table_brand[~table_brand['Sub Brand'].isin(buang)]\n",
    "table_hilo = table_hilo[~table_hilo['Sub Brand'].isin(buang)]\n",
    "table_hilo\n",
    "\n",
    "buang = ['PAKET TS']\n",
    "table_brand = table_brand[~table_brand['Sub Brand'].isin(buang)]\n",
    "table_ts = table_ts[~table_ts['Sub Brand'].isin(buang)]\n",
    "# table_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a16f6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833cd208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a122e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad8b507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed544a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### run 13\n",
    "### send email automation final ke user\n",
    "\n",
    "import win32com.client\n",
    "\n",
    "o = win32com.client.Dispatch(\"Outlook.Application\")\n",
    "for oacc in o.Session.Accounts:\n",
    "    if oacc.SmtpAddress == \"customer@nutrifood.co.id\":\n",
    "        oacctouse = oacc\n",
    "        break\n",
    "\n",
    "Msg = o.CreateItem(0)\n",
    "if oacctouse:\n",
    "    Msg._oleobj_.Invoke(*(64209, 0, 8, 0, oacctouse))  # Msg.SendUsingAccount = oacctouseif to:\n",
    "    \n",
    "    to=[\"mardi@nutrifood.co.id\", \"Elvina@nutrifood.co.id\", \"susana@nutrifood.co.id\",\n",
    "        \"ignasius.dwi@nutrifood.co.id\", \"may@nutrifood.co.id\", \"Meirza@nutrifood.co.id\", \"christian.jesaya@nutrifood.co.id\",\n",
    "        \"didit@nutrifood.co.id\", \"noviana@nutrifood.co.id\",\"reynald.tjandra@nutrifood.co.id\", \"elvira@nutrifood.co.id\",\n",
    "        \"manthovani.annice@nutrifood.co.id\",\"geny.pitaloka@nutrifood.co.id\", \"joshua.suhendro@nutrifood.co.id\",\"stephanie.wonoadi@nutrifood.co.id\",\n",
    "        \"lisa.arianti@nutrifood.co.id\",'charissa.lungkat@nutrifood.co.id','rosariani@nutrifood.co.id',\"zakaria@nutrifood.co.id\",\"geovano.satria@nutrifood.co.id\",\"agus_s@nutrifood.co.id\",\"romi.anggara@nutrifood.co.id\",\n",
    "        \"edward@nutrifood.co.id\", \"elisa.putri@nutrifood.co.id\",\"teddy.andreas@nutrifood.co.id\", \"muroby.rocky@nutrifood.co.id\",\n",
    "        \"evelyn@nutrifood.co.id\",\"sheila.odilia@nutrifood.co.id\",\"timotius.giovandi@nutrifood.co.id\",\n",
    "        'ronaldo.yolanda@nutrifood.co.id','bagus.sindhu@nutrifood.co.id',\"sony.hartono@nutrifood.co.id\",'christovertand.wim@nutrifood.co.id',\n",
    "        'steven.nathanael@nutrifood.co.id']\n",
    "    # to = ['timotius.giovandi@nutrifood.co.id']\n",
    "\n",
    "    list_to = ';'.join(to)\n",
    "\n",
    "    Msg.To = list_to\n",
    "    Msg.Subject = \"Report E-commerce \" + \\\n",
    "    str(datetime.today().date().strftime('%B %d, %Y'))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "html = '''\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "\n",
    "    h2 {\n",
    "        text-align: center;\n",
    "        font-family: Helvetica, Arial, sans-serif;\n",
    "    }\n",
    "    table { \n",
    "        margin-left: auto;\n",
    "        margin-right: auto;\n",
    "    }\n",
    "    table, th, td {\n",
    "        border: 1px solid black;\n",
    "        border-collapse: collapse;\n",
    "    }\n",
    "    th, td {\n",
    "        padding: 5px;\n",
    "        text-align: center;\n",
    "        font-family: Helvetica, Arial, sans-serif;\n",
    "        font-size: 90%;\n",
    "    }\n",
    "    table tbody tr:hover {\n",
    "        background-color: #dddddd;\n",
    "    }\n",
    "    .wide {\n",
    "        width: 90%; \n",
    "    }\n",
    "    p\n",
    "\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "    '''\n",
    "html = html + \"\"\"\n",
    "    <p> Dear all,</p>\n",
    "    <p> Berikut data penjualan E-Com <b> (Before PPN) tanggal {tanggal} </b> dengan rincian channel sebagai berikut : </p>\n",
    "    <p> Channel Marketplace : Blibli, Bukalapak, JD Indonesia, Lazada, Nutrimart, Order Online, Shopee, Tokopedia, Aladin Mall, TikTok </p>\n",
    "    <p> Channel Retail : Cari Sayur, Emos, Farmaku, Inovasi Digital Niaga, Ritel Bersama Nasional, Sayurbox, Tanihub, Astro, Lifepack, Toko Now  </p>\n",
    "\"\"\".format(tanggal = str(datetime.today().date().strftime('%B %d, %Y')))\n",
    "\n",
    "html = html + tblall.to_html(classes='wide', escape=False).replace('&lt;b&gt;', '<b>').replace('&lt;/b&gt;', '</b>')\n",
    "\n",
    "html = html + \"\"\"\n",
    "    <p> Dan berikut data penjualan E-Com (Before PPN) per Area :</p>\n",
    "    \"\"\"\n",
    "\n",
    "html = html + tblreg.to_html(classes='wide', escape=False)\n",
    "\n",
    "html = html + \"\"\"\n",
    "    <p> Dan Berikut data penjualan E-Com <b> (Before PPN) tanggal {tanggal} </b> per Brand :</p>\n",
    "\"\"\".format(tanggal = str(datetime.today().date().strftime('%B %d, %Y'))) \n",
    "\n",
    "\n",
    "html = html + table_brand.to_html(classes='wide', escape=False).replace('&lt;b&gt;', '<b>').replace('&lt;/b&gt;', '</b>')\n",
    "\n",
    "\n",
    "\n",
    "html = html + \"\"\"\n",
    "    <p> Dan berikut data penjualan E-Com (Before PPN) per Item :</p>\n",
    "    <p> Item Launching : </p>\"\"\"\n",
    "\n",
    "html = html + new_table_launch.to_html(classes='wide', escape=False)\n",
    "\n",
    "html = html + \"<p> HiLo : </p>\"    \n",
    "\n",
    "html = html + table_hilo.to_html(classes='wide', escape=False)\n",
    "\n",
    "html = html + \"<p> L-Men : </p>\"    \n",
    "\n",
    "html = html + table_lmen.to_html(classes='wide', escape=False)\n",
    "\n",
    "html = html + \"<p> NutriSari : </p>\"    \n",
    "\n",
    "html = html + table_ns.to_html(classes='wide', escape=False)\n",
    "\n",
    "html = html + \"<p> Tropicana Slim : </p>\"    \n",
    "\n",
    "html = html + table_ts.to_html(classes='wide', escape=False)\n",
    "\n",
    "html = html + \"\"\"\n",
    "    <p></p>\n",
    "    <p> Best regards, </p>\n",
    "    <p> E-Commerce Nutrifood </p>\n",
    "<body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "Msg.HTMLBody = html\n",
    "Msg.Send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324514f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc53e928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a2975f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4a214e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0653d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "### run 14\n",
    "### export masterdata\n",
    "\n",
    "data_all.to_csv(r'D:\\Masterdata\\Clean Data\\data_all_' + data_now + '.csv', sep = ';', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9964b88f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e22f1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2899a604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a0ea376",
   "metadata": {},
   "source": [
    "Export Lite Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01d452d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BARA\n",
      "Jabodetabek\n",
      "Jawa Barat\n",
      "Jawa Tengah\n",
      "Jawa Timur\n",
      "Kalimantan\n",
      "PUMA\n",
      "Sulawesi\n",
      "Sumatera 1\n",
      "Sumatera 2\n"
     ]
    }
   ],
   "source": [
    "mappingarea=pd.read_excel(\"data_supp\\Database Area untuk Report.xlsx\")\n",
    "mappingarea=mappingarea.rename(columns=({'Region':'Real Region',\"City\":'Region Group'}))\n",
    "# temp=data_all.merge(mappingarea,how='left')\n",
    "# temp.loc[temp['Region Group'].isnull(),'Real Region']='Retail Online'\n",
    "for i in mappingarea['Real Region'].unique():\n",
    "    print(i)\n",
    "    reg=mappingarea[mappingarea['Real Region']==i]['Region Group'].unique()\n",
    "    data_all.loc[data_all['Region Group'].isin(reg),'Real Region']=i\n",
    "data_all.loc[data_all['Region Group'].isnull(),'Real Region']='Retail Online'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a41230ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "osf=pd.read_excel(r\"data_supp\\order filter.xlsx\")\n",
    "data_all[(data_all['Year'].isin([2021,2022]))&\n",
    "         (data_all['Order Status'].isin(osf['order filter'].unique()))].groupby(['Year','Month','Store Type','Store','Channel','Real Region','Warehouse Name','Order Status','Region Group','Coupon Code','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name'],dropna=False).agg({'Order #':'nunique','Phone':'nunique','Qty. Invoiced':'sum','Total Net Before PPN':'sum'}).reset_index().to_excel(f'masterdata_{date.today()}_lite.xlsx',index=False)\n",
    "# data_all.groupby(['Year','Month','Date','Store Type','Store','Channel','Order Status'])[['Order #']].nunique().reset_index().to_excel(f'Cek order gerak {date.today()}.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc8d6f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "osf=pd.read_excel(r\"data_supp\\order filter.xlsx\")\n",
    "data_all[(data_all['Year'].isin([2022]))&\n",
    "         (data_all['Order Status'].isin(osf['order filter'].unique()))].groupby(['Year','Month','Date','Store Type','Store','Channel','Warehouse Name','Order Status','Region Group','Coupon Code','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name'],dropna=False).agg({'Order #':'nunique','Phone':'nunique','Qty. Invoiced':'sum','Total Net Before PPN':'sum'}).reset_index().to_excel(f'D:\\Masterdata\\Masterdata Lite\\masterdata_{date.today()}_lite new.xlsx',index=False)\n",
    "# data_all.groupby(['Year','Month','Date','Store Type','Store','Channel','Order Status'])[['Order #']].nunique().reset_index().to_excel(f'Cek order gerak {date.today()}.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e9d4098",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This sheet is too large! Your sheet size is: 1050572, 26 Max sheet size is: 1048576, 16384",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdata_all\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata_all\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrue datetime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2022-04-01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOrder #\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOrder Status\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMonth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWeek\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStore Type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mChannel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBrand\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReal SKU\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReal Nama Produk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBundle Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQty. Invoiced\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTotal Net Before PPN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTotal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCoupon Code\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCustomer Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCustomer Email\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPhone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAddress\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWarehouse Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRegion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRegion Group\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReal Region\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMasterdata Lite Order \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoday\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2345\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes, storage_options)\u001b[0m\n\u001b[0;32m   2332\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2334\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2335\u001b[0m     df,\n\u001b[0;32m   2336\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2343\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2344\u001b[0m )\n\u001b[1;32m-> 2345\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2347\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\excel.py:877\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[0;32m    875\u001b[0m num_rows, num_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_rows \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_rows \u001b[38;5;129;01mor\u001b[39;00m num_cols \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_cols:\n\u001b[1;32m--> 877\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    878\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis sheet is too large! Your sheet size is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_rows\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax sheet size is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_rows\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    880\u001b[0m     )\n\u001b[0;32m    882\u001b[0m formatted_cells \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_formatted_cells()\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(writer, ExcelWriter):\n",
      "\u001b[1;31mValueError\u001b[0m: This sheet is too large! Your sheet size is: 1050572, 26 Max sheet size is: 1048576, 16384"
     ]
    }
   ],
   "source": [
    "data_all[data_all['True datetime']>'2022-04-01'][['Order #','Order Status','Year','Month','Week','Date','Store Type','Store',\n",
    "                                                  'Channel','Brand','Real SKU','Real Nama Produk','Bundle Name','Qty. Invoiced',\n",
    "                                                  'Total Net Before PPN','Total','Coupon Code','Customer Name','Customer Email',\n",
    "                                                  'Phone','Address','Warehouse Name','City','Region','Region Group','Real Region']].to_excel(f'Masterdata Lite Order {date.today()}.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bc94e314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tinggal append export\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steven.nathanael\\AppData\\Local\\Temp\\ipykernel_9700\\2005371542.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  resa.append(resb).to_excel(f'masterdata_{date.today()}_custlite v2.xlsx',index=False)\n"
     ]
    }
   ],
   "source": [
    "resb=data_all[(data_all['Year'].isin([2021,2022]))&(data_all['Order Status'].isin(osf['order filter'].unique()))].groupby(['Year','Month','Date','Store Type','Store','Channel','Coupon Code','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name'],dropna=False).agg({'Order #':'nunique','Phone':'nunique','Qty. Invoiced':'sum','Total Net Before PPN':'sum'}).reset_index()\n",
    "resb=resb[resb['Store Type']!='Organic']#['Store'].unique()\n",
    "resa=data_all[(data_all['Year'].isin([2022,2021]))&(data_all['Order Status'].isin(osf['order filter'].unique()))&\n",
    "                           (data_all['Store Type']=='Organic')][['Order #','Year','Month','Date','Store Type','Store','Channel','Coupon Code','Brand','Sub Brand','Real SKU','Real Nama Produk','Bundle Name','Qty. Invoiced','Total','Total Net','Total Net Before PPN','Customer Name','Customer Email','Phone','Payment Channel','City','Region','Real Region']]\n",
    "print('tinggal append export')\n",
    "resa.append(resb).to_excel(f'D:\\Masterdata\\Masterdata Lite\\masterdata_{date.today()}_custlite v2.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c54ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8913e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e390ec81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
